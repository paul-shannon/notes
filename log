options(error=recover)  # debugging aid

--- kickoff the mongo daemon:
test: mongo
mongod --dbpath /Users/pshannon/mongo/data/db &


--- kickoff mysql: sudo /usr/local/mysql/support-files/mysql.server start
test:
ps aux | grep -i mysql

#--- assignGeneIDs
source("~/github/projects/utils/geneIdMapping/symToGeneID.R"); test_assignGeneIDs()
source("~/s/data/public/human/symToGeneID.R"); test_assignGeneIDs()
assignGeneIDs(geneSymbols)
returns a list of 3 lists: "mapped"    "failures"  "multiples"
mapped:   a list of all the input geneSymbols, with either geneID, NA, or multiple geneIDs
failures: that

  devel: svn co https://hedgehog.fhcrc.org/bioconductor/trunk/madman/Rpacks/<pkgname>
release: svn co https://hedgehog.fhcrc.org/bioconductor/branches/RELEASE_3_5/madman/Rpacks/<pkgname>


onco:
svn co https://hedgehog.fhcrc.org/hb/devel/hbolouri/dataPackages
svn co https://hedgehog.fhcrc.org/hb/devel/hbolouri/oncoDev14/Oncoscape/inst/scripts/eric


macbook/modem/49th avenue internet connection info: ~/s/notes/internetConfigScreenshot.png
~/s/notes/medicalBills/records:  keep track of bills here
~/s/notes/studies/forest/hemlock: the hemlock/annosus story
~/s/data/fosp/forest/archive.html  links to the peninsula maps
load ('~/s/data/public/mouse/symbolsToGeneIDs.RData', envir=.GlobalEnv)
load ('~/s/data/public/human/symbolsToGeneIDs.RData', envir=.GlobalEnv)
source('~/s/data/public/human/names.R')
http://db.systemsbiology.net:8080/cytoscape/gaggle/test/cy2rpc/     /net/dblocal/tomcat/webapps/cytoscape/gaggle/test/cy2rpc

http://r.research.att.com/#nightly
sudo /usr/sbin/pkgutil --forget org.r-project.R.Leopard.fw.pkg

rcytoscape web site:
emacs -nw /net/dblocal/tomcat/webapps/cytoscape/RCytoscape -f shell
tail -1000 /var/log/httpd/rcytoscape/access_log; tail -f /var/log/httpd/rcytoscape/access_log
http://db.systemsbiology.net:8080/cytoscape/RCytoscape
http://rcytoscape.systemsbiology.net/
cd /net/dblocal/tomcat/webapps/cytoscape/RCytoscape
tail -f /var/log/httpd/rcytoscape/access_log

;; works well on laptop
(set-default-font "-adobe-courier-medium-r-normal--13-*")
(set-default-font "-adobe-courier-medium-r-normal--14-*")
(set-default-font "-adobe-courier-medium-r-normal--15-*")

;; works well on apple 23 inch monitor
(set-default-font "-adobe-courier-medium-r-normal--14-*")
;;(set-default-font "-adobe-courier-medium-r-normal--15-*")


;; works very well on dell 30 screen: no boldness
(set-default-font "-adobe-courier-medium-r-normal--14-*")
(set-default-font "-adobe-courier-medium-r-normal--15-*")
(set-default-font "-adobe-courier-medium-r-normal--13-*")
;; works very well on thunderbolt screen
(set-default-font "-adobe-courier-medium-r-normal--15-*")
(set-default-font "-adobe-courier-medium-r-normal--16-*")
(set-default-font "-adobe-courier-medium-r-normal--17-*")
;; works well on thunderbolt screen
(set-default-font "-adobe-courier-medium-r-normal--18-*")

;; works well on thunderbolt screen
(set-default-font "-adobe-courier-bold-r-normal--10-*")
;; works well on thunderbolt screen
(set-default-font "-adobe-courier-bold-r-normal--19-*")

;; works well on thunderbolt screen
(set-default-font "-adobe-courier-bold-r-normal--20-*")


*------------------------------------------------------------------------------------------------100
;; eval last sexp: ^x^e
(set-background-color "wheat")
(set-background-color "lemonChiffon3")
(set-background-color "#D1D1C2")
(set-background-color "#F1E1C2")

# easy auto assignment of tolower gene symbol variable names:
#tmp <- mget(keys(org.Hs.eg.db), org.Hs.egSYMBOL)
tmp <- mget(geneIDs.of.interest, org.Hs.egSYMBOL)
eval(parse(text=sprintf("%s <- '%s'", tolower(as.character(tmp)), names(tmp))))

symbol <- function(geneIDs) as.character(mget(as.character(geneIDs), org.Hs.egSYMBOL, ifnotfound=NA))

bed format: chrom, start, end, name, score, strand

* -top-
*-----------------------------------------------------------------------------------------------------------------------
*-----------------------------------------------------------------------------------------------------------------------
*-----------------------------------------------------------------------------------------------------------------------
* having started an R/rpy2 enabled jupyter notebook server: now, rpy2 tips (10 oct 2017)

  https://pandas.pydata.org/pandas-docs/stable/r_interface.html

  # cell 0
  import pandas as pd
  from rpy2.robjects import r
  from rpy2.robjects import pandas2ri
  pandas2ri.activate()
  type(r['iris'])      
     #  -> either pandas.core.frame.DataFrame or rpy2.robjects.vectors.DataFrame depending upon
     # pandas2ri.activate() having been called


*-----------------------------------------------------------------------------------------------------------------------
* rpy2 on docker (10 cot 2017)

  --- advice from website
  a jupyter notebook (on port 8888):   docker run --rm -p 8888:8888     rpy2/jupyter
  an ipython console:                  docker run -it --rm -p 8888:8888 rpy2/jupyter ipython

  --- on riptide, macos
   docker pull rpy2/rpy2     #  Status: Downloaded newer image for rpy2/rpy2:latest
   docker pull rpy2/jupyter

   docker images
      REPOSITORY                    TAG                 IMAGE ID            CREATED             SIZE
      rpy2/jupyter                  latest              70a1c2f3745e        40 hours ago        1.56GB
      rpy2/rpy2                     latest              2640bc9a72e9        44 hours ago        1.39GB
      jupyterlabdocker_jupyterlab   latest              47ad43cd27ee        3 weeks ago         894MB
      hello-world                   latest              05a3bd381fc2        4 weeks ago         1.84kB
      rpy2/rpy2                     <none>              dd0a2957fbd9        4 weeks ago         1.38GB

   docker run -it --rm -p 8888:8888 rpy2/jupyter ipython
      -i: interactive
      -t: allocates a pseuod tty
    --rm: Automatically remove the container when it exits
      -p: 8888:8888




*-----------------------------------------------------------------------------------------------------------------------
* rpy2 on whovian (10 oct 2017)

  see below: "* matt mccoy installs rpy2 on whovian for me to use with notebooks"  (25 sep 2017, i think)

  jupyter --version # 4.2.1
  jupyter notebook --version  # 5.1.0

  whovian, cd ~/github/notebooks/rpy2-examples
  jupyter notebook --port=10002 --NotebookApp.token=


*-----------------------------------------------------------------------------------------------------------------------
* evaluating snps in footprints in the scz tsnare1 gwas loci (7 oct 2017)

----- assessing  1) rs10100321
TSNARE1 rs10100321, tfs.wt,     11 in model:  0
TSNARE1 rs10100321, tfs.mut,    37 in model:  2
TSNARE1 rs10100321, tfs.lost,    0 in model:  0
TSNARE1 rs10100321, tfs.gained, 26 in model:  2
   tf 34 gained: BHLHE22
   tf  7 gained: ID3
----- assessing  2) rs12234969
TSNARE1 rs12234969, tfs.wt,     52 in model:  2
TSNARE1 rs12234969, tfs.mut,    53 in model:  2
TSNARE1 rs12234969, tfs.lost,    1 in model:  0
TSNARE1 rs12234969, tfs.gained,  2 in model:  0
----- assessing  3) rs12676511
TSNARE1 rs12676511, tfs.wt,      7 in model:  0
TSNARE1 rs12676511, tfs.mut,     6 in model:  0
TSNARE1 rs12676511, tfs.lost,    1 in model:  0
TSNARE1 rs12676511, tfs.gained,  0 in model:  0
----- assessing  4) rs13438979
TSNARE1 rs13438979, tfs.wt,      4 in model:  1
TSNARE1 rs13438979, tfs.mut,     0 in model:  0
TSNARE1 rs13438979, tfs.lost,    4 in model:  1
TSNARE1 rs13438979, tfs.gained,  0 in model:  0
   tf 20 lost: NFIX
----- assessing  5) rs4284148
TSNARE1 rs4284148, tfs.wt,      4 in model:  0
TSNARE1 rs4284148, tfs.mut,     3 in model:  0
TSNARE1 rs4284148, tfs.lost,    1 in model:  0
TSNARE1 rs4284148, tfs.gained,  0 in model:  0
----- assessing  6) rs4976977
TSNARE1 rs4976977, tfs.wt,     13 in model:  1
TSNARE1 rs4976977, tfs.mut,    37 in model:  2
TSNARE1 rs4976977, tfs.lost,    5 in model:  0
TSNARE1 rs4976977, tfs.gained, 29 in model:  1
   tf 34 gained: BHLHE22
----- assessing  7) rs4976982
TSNARE1 rs4976982, tfs.wt,     36 in model:  2
TSNARE1 rs4976982, tfs.mut,     3 in model:  0
TSNARE1 rs4976982, tfs.lost,   34 in model:  2
TSNARE1 rs4976982, tfs.gained,  1 in model:  0
   tf 17 lost: TCFL5
   tf 13 lost: EPAS1
----- assessing  8) rs59554395
TSNARE1 rs59554395, tfs.wt,      0 in model:  0
TSNARE1 rs59554395, tfs.mut,    53 in model:  0
TSNARE1 rs59554395, tfs.lost,    0 in model:  0
TSNARE1 rs59554395, tfs.gained, 53 in model:  0
----- assessing  9) rs7465677
TSNARE1 rs7465677, tfs.wt,      1 in model:  0
TSNARE1 rs7465677, tfs.mut,    22 in model:  2
TSNARE1 rs7465677, tfs.lost,    0 in model:  0
TSNARE1 rs7465677, tfs.gained, 21 in model:  2
   tf 17 gained: TCFL5
   tf 13 gained: EPAS1
----- assessing 10) rs7822538
TSNARE1 rs7822538, tfs.wt,     28 in model:  2
TSNARE1 rs7822538, tfs.mut,    57 in model:  3
TSNARE1 rs7822538, tfs.lost,    5 in model:  1
TSNARE1 rs7822538, tfs.gained, 34 in model:  2
   tf 32 lost: ATF3
   tf 17 gained: TCFL5
   tf 13 gained: EPAS1
----- assessing 11) rs8180914
TSNARE1 rs8180914, tfs.wt,     50 in model:  1
TSNARE1 rs8180914, tfs.mut,    50 in model:  1
TSNARE1 rs8180914, tfs.lost,    0 in model:  0
TSNARE1 rs8180914, tfs.gained,  0 in model:  0

tfs gained at 85%, collected: ATF3 (#34 in m2), TCFL5, EPAS1 (#23 in m1), BHLHE22, BHLHE22, ID3 (#46 in m1)
tfs lost at 85%,   collected: TCFL5  EPAS1, NFIX (rank 11 in geneModel.2, mtx.cer)

   save(tbl.geneModel.1.tfc, tbl.geneModel.2.tfc, tbl.geneModel.3.tfc,
        tbl.geneModel.1.mdb, tbl.geneModel.2.mdb, tbl.geneModel.3.mdb,
        file="geneModels.6.3matrices.mdb.tfc.lookup.RData")

[1] rank of ATF3
[1] table 2: 30
[1] rank of TCFL5
[1] rank of EPAS1
[1] table 1: 19
[1] rank of BHLHE22
[1] rank of ID3
[1] table 1: 44
[1] rank of NFIX
[1] table 2: 11
[1] table 5: 3

  -- looking at NFIX, rs4976977
    head(tbl.geneModel.2.mdb)
      gene   beta.lasso pearson.coeff  rf.score  beta.ridge spearman.coeff concordance   pcaMax binding.sites
   1  HEY1 -0.125185660    -0.3516960 12.027139 -0.05295559     -0.3306789   0.5998627 2.149381           162
   2   SP2  0.054781252     0.3407061  3.566340  0.03350704      0.3063749   0.4958117 1.265255          4433
   3  NFIX  0.037892404     0.3237507  2.956642  0.02871457      0.3154248   0.4736702 1.175988           202
   4 MEF2A  0.016101218     0.3179430  2.481262  0.04151545      0.2837201   0.4493849 1.172892            36
   5 CENPB  0.000000000     0.2692497  4.647041  0.02803634      0.2588462   0.4623728 1.151129             7
   6  PBX1  0.003959147     0.2688789  2.918706  0.04347878      0.2192414   0.4451965 1.090274            51

   as.data.frame(snpsById(SNPlocs.Hsapiens.dbSNP150.GRCh38, "rs4976977"))
      seqnames       pos strand RefSNP_id alleles_as_ambig
             8 142232793      * rs4976977                W   (A -> T)

     tbl.rs4976977 <- assessSnp(trena, pfms, "rs4976977", 7, 85)
      as.data.frame(t(tbl.rs4976977[grep("NFIX", tbl.rs4976977$motifName),]))
                                                                    3                                            61
     motifName                      Hsapiens-jaspar2016-NFIX-MA0671.1             Hsapiens-jaspar2016-NFIX-MA0671.1
     status                                                        wt                                           mut
     assessed                                                 in.both                                       in.both
     motifRelativeScore                                     0.9675002                                     0.8618954
     delta                                                          0                                             0
     signature          Hsapiens-jaspar2016-NFIX-MA0671.1;142232792;- Hsapiens-jaspar2016-NFIX-MA0671.1;142232792;-
     chrom                                                       chr8                                          chr8
     motifStart                                             142232792                                     142232792
     motifEnd                                               142232800                                     142232800
     strand                                                         -                                             -
     match                                                  GTTGGCAGA                                     GATGGCAGA
     variant                                                rs4976977                                     rs4976977




   assessSnp(trena, pfms, "rs4976977", 10, 85)
    3       Hsapiens-jaspar2016-NFIX-MA0671.1;142232792;-  chr8  142232792 142232800      -     GTTGGCAGA rs4976977
    61      Hsapiens-jaspar2016-NFIX-MA0671.1;142232792;-  chr8  142232792 142232800      -     GATGGCAGA rs4976977


*-----------------------------------------------------------------------------------------------------------------------
* rosmap (and other)  brain expression data (8 oct 2017)

  --- rosmap
  ~/s/work/priceLab/cory/module-109/rosmap_rnaseq_fpkm_geneSymbols_24593x638.RData
    mtx <- asinh(mtx)
    mtx.var <- apply(mtx, 1, var)
    deleters <- which(mtx.var < 0.01)
    if(length(deleters) > 0)   # 15838 x 638
       mtx <- mtx[-deleters,]
   dim(mtx);      # [1] 15538   638
   fivenum(mtx)   # [1]  0.000000  1.370301  2.659855  3.662176 13.081307
   mtx.rosmap.normalized <- mtx
   save(mtx.rosmap.normalized, file="~/s/work/priceLab/cory/brainExpressionData/mtx.rosmap.normalized.RData")
   print(load("~/s/work/priceLab/cory/brainExpressionData/mtx.rosmap.normalized.RData"))

*-----------------------------------------------------------------------------------------------------------------------
* assess all snps in the scz tsnare1 loci (mon 9 oct)

  cd ~/github/trenaSCZ
  run assessSnp(trena, jaspar.pfms, "rs4976977", 10, 90) with just jaspar human pfms, see if any tfs are
    lost or gained by 20%, against either cory's +/-5kb wg model, or my

    save(tbl.geneModel.2, file="tbl.geneModel.cer.RData")
    save(tbl.geneModel, file="tbl.geneModel.tcx.RData")
    tbl.geneModel$gene

 [1] "DNMT3A"  "TEAD3"   "NFKB2"   "ATF4"    "NCOR2"   "DDIT3"   "CEBPG"   "STAT3"   "TP53"
[10] "HES5"    "NFATC2"  "BCL6"    "MZF1"    "SP4"     "MTA2"    "GLIS3"   "ETV6"    "KLF2"
[19] "EPAS1"   "SNAPC4"  "TCF7"    "RCOR2"   "MSX1"    "REST"    "HIF1A"   "NFE2L2"  "TFE3"
[28] "HES7"    "PRRX1"   "SMARCC2" "YAP1"    "BPTF"    "STAT5A"  "MAFK"    "ZNF410"  "RELA"
[37] "ZNF263"  "CDC5L"   "TFAP2E"  "XBP1"    "ELK3"    "TGIF1"   "GLIS2"   "CEBPD"   "TEAD1"
[46] "SP100"   "RFX4"    "SP1"     "ID3"     "IRF9"    "EGR4"    "ATF5"    "GTF2I"

 tbl.geneModel.2$gene
 [1] "HEY1"     "DMAP1"    "ZNF384"   "CENPB"    "SMARCA4"  "SP2"      "MEF2A"    "NFIX"
 [9] "ZFHX2"    "DNMT3B"   "TEAD3"    "ATF4"     "TP53"     "ETV6"     "CEBPB"    "ZBTB12"
[17] "SMARCAL1" "POU6F2"   "BPTF"     "DDIT3"    "NFKB2"    "SOX18"    "DLX1"     "SIX4"
[25] "HYKK"     "GLIS3"    "NFIB"     "ARID5B"   "CEBPG"    "NCOA1"    "ATF3"     "MAFF"
[33] "LHX5"     "ESRRA"    "PRRX1"    "MAFG"     "SNAI2"    "NR3C1"    "STAT3"    "BACH1"
[41] "SOX1"     "ARNTL"    "TFE3"     "JDP2"     "RELA"     "NFE2L3"   "PAX2"     "ELK4"
[49] "NFE2L2"   "EBF3"     "KLF6"     "SOX17"
>
   nothing here
> assessSnp(trena, pfms, "rs4976977", 10, 90)
                               motifName status assessed motifRelativeScore       delta                                         signature chrom motifStart  motifEnd strand      match   variant
5      Mmusculus-jaspar2016-Myb-MA0100.2     wt  wt.only          0.9361425  0.11835089     Mmusculus-jaspar2016-Myb-MA0100.2;142232787;-  chr8  142232787 142232796      - AGACAGTTGG rs4976977
4      Mmusculus-jaspar2016-Myb-MA0100.1     wt  wt.only          0.9873817  0.14511041     Mmusculus-jaspar2016-Myb-MA0100.1;142232788;+  chr8  142232788 142232795      +   GACAGTTG rs4976977
7     Mmusculus-jaspar2016-Hic1-MA0739.1     wt  wt.only          0.9049373  0.07378138    Mmusculus-jaspar2016-Hic1-MA0739.1;142232791;-  chr8  142232791 142232799      -  AGTTGGCAG rs4976977
31   Mmusculus-jaspar2016-Gata1-MA0035.1    mut mut.only          0.9907407 -0.22685185   Mmusculus-jaspar2016-Gata1-MA0035.1;142232791;+  chr8  142232791 142232796      +     AGATGG rs4976977
51 Mmusculus-jaspar2016-Bhlha15-MA0607.1    mut mut.only          0.9116160 -0.11789451 Mmusculus-jaspar2016-Bhlha15-MA0607.1;142232789;-  chr8  142232789 142232796      -   ACAGATGG rs4976977
41   Mmusculus-jaspar2016-Atoh1-MA0461.1    mut  in.both          1.0000000  0.00000000   Mmusculus-jaspar2016-Atoh1-MA0461.1;142232790;+  chr8  142232790 142232797      +   CAGATGGC rs4976977
6    Mmusculus-jaspar2016-Atoh1-MA0461.1     wt  in.both          0.9209577  0.00000000   Mmusculus-jaspar2016-Atoh1-MA0461.1;142232790;+  chr8  142232790 142232797      +   CAGTTGGC rs4976977
21      Hsapiens-jaspar2016-YY1-MA0095.1    mut mut.only          1.0000000 -0.20731707      Hsapiens-jaspar2016-YY1-MA0095.1;142232792;-  chr8  142232792 142232797      -     GATGGC rs4976977
3      Hsapiens-jaspar2016-NFIX-MA0671.1     wt  wt.only          0.9675002  0.10560476     Hsapiens-jaspar2016-NFIX-MA0671.1;142232792;-  chr8  142232792 142232800      -  GTTGGCAGA rs4976977
1      Hsapiens-jaspar2016-NFIC-MA0161.1     wt  wt.only          1.0000000  0.12680150     Hsapiens-jaspar2016-NFIC-MA0161.1;142232793;+  chr8  142232793 142232798      +     TTGGCA rs4976977
2      Hsapiens-jaspar2016-NFIA-MA0670.1     wt  wt.only          0.9551917  0.13673896     Hsapiens-jaspar2016-NFIA-MA0670.1;142232791;-  chr8  142232791 142232800      - AGTTGGCAGA rs4976977
11    Hsapiens-jaspar2016-GATA2-MA0036.1    mut mut.only          0.9234694 -0.26530612    Hsapiens-jaspar2016-GATA2-MA0036.1;142232791;+  chr8  142232791 142232795      +      AGATG rs4976977


*-----------------------------------------------------------------------------------------------------------------------
* create a dnsnp hg38 build 150 track for igv.js? (5 oct 2017)

   6 years ago, mentioned on biostars:
      http://hgdownload.cse.ucsc.edu/goldenPath/hg19/database/snp132.txt.gz

   biocGet("SNPlocs.Hsapiens.dbSNP150.GRCh38")

*-----------------------------------------------------------------------------------------------------------------------
* scz demo: find a broken gene model in proximal promoter from the 108 scz-associated genetic loci (5 oct 2017)

   cd ~/github/trenaSCZ

   word doc with 108 loci as an embedded table.  select.  Table->Convert->Table to Text, copy and paste into emacs

   https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4112379/bin/NIHMS59304-supplement-Supplementary_Information.docx

   ~/github/trenaSCZ/docs/biologicalInsightsFrom108schizophreniaAssociatedGeneticLoci.pdf

     Independently associated SNPs do not translate to well-bounded
     chromosomal regions. Nevertheless, it is useful to define
     physical boundaries for the SNP associations to identify
     candidate risk genes. We defined an associated locus as the
     physical region containing all SNPs correlated at r2 > 0.6 with
     each of the 128 index SNPs. Associated loci within 250 kb of each
     other were merged. This resulted in 108 physically distinct
     associated loci, 83 of which have not been previously implicated
     in schizophrenia and therefore harbour potential novel biological
     insights into disease aetiology (Supplementary Table 3; regional
     plots in Supplementary Figure 1). The significant regions include
     all but 5 loci previously reported as genome-wide significant in
     large samples (Supplementary Table 3).

     For each of the schizophrenia associated loci, we identified a
     credible causal set of SNPs (for definition see Supplementary
     text). 36 In only 10 instances (Supplementary Table 4) was the
     association signal credibly attributable to a known nonsynonymous
     exonic polymorphism. The apparently limited role of protein
     coding variants is consistent both with exome sequencing findings
     33 and with the hypothesis that most associated variants detected
     by GWAS exert their effects through altering gene expression
     rather than protein structure37,38 and with the observation that
     schizophrenia risk loci are enriched for expression quantitative
     trait loci (eQTL).39

     To try to identify eQTLs that could explain associations with
     schizophrenia, we merged the credible causal set of SNPs defined
     above with eQTLs from a meta-analysis of human brain cortex eQTL
     studies (N=550) and an eQTL study of peripheral venous blood
     (N=3754)40 (Supplementary Text). Multiple schizophrenia loci
     contained at least one eQTL for a gene within 1 Mb of the locus
     (Supplementary Table 4). However, in only 12 instances was the
     eQTL plausibly causal (two in brain, and nine in peripheral
     blood, one in both). This low proportion suggests that if most
     risk variants are regulatory, available eQTL catalogs do not yet
     provide power, cellular specificity, or developmental diversity
     to provide clear mechanistic hypotheses for follow-up
     experiments.

id <- "rs12676511"
id <- "rs4976977"
id <- "rs4976982"
id <- "rs7465677"
id <- "rs7822538"
id <- "rs12234969"


---- TFClass:
"PPARG" "MYB" "REST" "ATF1" "CREBL2" "CREBZF" "CREB3" "CREB3L1"
 "CREB3L2" "CREB3L3" "CREB3L4" "CREM" "ATF3" "JDP2" "FOSB" "TBX21"
 "TBR1" "EOMES"

---- MotifDb
 "PPARG" "Crem"  "Atf1"  "Atf3"  "TBX21" "EOMES" "Myb"   "brk"   "REST"

    --- credible snps, imputed along with the standout snp
id <- "rs12676511"
loc <- subset(tmp.bed, rsid==id)$start # [1] 142232025
subset(tbls.fp[["postgres://whovian/brain_wellington_20"]], motifStart <= loc & motifEnd >= loc)
   chrom motifStart  motifEnd motifName strand    score length distance.from.tss                                    id
8   chr8  142232005 142232025  MA0528.1      +  9.36735     21           -122826 TSNARE1.fp.downstream.122826.MA0528.1
16  chr8  142232019 142232028  MA0606.1      - 13.09680     10           -122812 TSNARE1.fp.downstream.122812.MA0606.1
17  chr8  142232021 142232027  MA0152.1      - 12.20220      7           -122810 TSNARE1.fp.downstream.122810.MA0152.1
18  chr8  142232021 142232035  MA0517.1      -  9.31818     15           -122810 TSNARE1.fp.downstream.122810.MA0517.1


id <- "rs4976977"
loc <- subset(tmp.bed, rsid==id)$start # 142232793
subset(tbls.fp[["postgres://whovian/brain_hint_16"]], motifStart <= loc & motifEnd >= loc)
subset(tbls.fp[["postgres://whovian/brain_hint_20"]], motifStart <= loc & motifEnd >= loc)
subset(tbls.fp[["postgres://whovian/brain_wellington_16"]], motifStart <= loc & motifEnd >= loc)
subset(tbls.fp[["postgres://whovian/brain_wellington_20"]], motifStart <= loc & motifEnd >= loc)
# all agree:
# chr8  142232787 142232796  MA0100.2      - 14.0492     10           -122044 TSNARE1.fp.downstream.122044.MA0100.2

id <- "rs4976982"
loc <- subset(tmp.bed, rsid==id)$start  # 142235164
subset(tbls.fp[["postgres://whovian/brain_hint_16"]], motifStart <= loc & motifEnd >= loc)
subset(tbls.fp[["postgres://whovian/brain_hint_20"]], motifStart <= loc & motifEnd >= loc)
subset(tbls.fp[["postgres://whovian/brain_wellington_16"]], motifStart <= loc & motifEnd >= loc)
subset(tbls.fp[["postgres://whovian/brain_wellington_20"]], motifStart <= loc & motifEnd >= loc)
# all 4 sources agree:
# chr8  142235154 142235174  MA0138.2      - 9.57143     21           -119677 TSNARE1.fp.downstream.119677.MA0138.2

id <- "rs7465677"
loc <- subset(tmp.bed, rsid==id)$start  # 142239356
subset(tbls.fp[["postgres://whovian/brain_hint_16"]], motifStart <= loc & motifEnd >= loc)
# chrom motifStart  motifEnd motifName strand   score length distance.from.tss                                    id
#  chr8  142239352 142239361  MA0690.1      + 10.8727     10           -115479 TSNARE1.fp.downstream.115479.MA0690.1
#  chr8  142239352 142239364  MA0800.1      + 10.9756     13           -115479 TSNARE1.fp.downstream.115479.MA0800.1
subset(tbls.fp[["postgres://whovian/brain_hint_20"]], motifStart <= loc & motifEnd >= loc)
subset(tbls.fp[["postgres://whovian/brain_wellington_16"]], motifStart <= loc & motifEnd >= loc)
subset(tbls.fp[["postgres://whovian/brain_wellington_20"]], motifStart <= loc & motifEnd >= loc)

id <- "rs7822538"
loc <- subset(tmp.bed, rsid==id)$start  # 142241748
subset(tbls.fp[["postgres://whovian/brain_hint_16"]], motifStart <= loc & motifEnd >= loc)
#  chrom motifStart  motifEnd motifName strand   score length distance.from.tss                                    id
#   chr8  142241740 142241749  MA0609.1      - 12.7705     10           -113091 TSNARE1.fp.downstream.113091.MA0609.1
#   chr8  142241741 142241748  MA0604.1      - 13.0492      8           -113090 TSNARE1.fp.downstream.113090.MA0604.1
#   chr8  142241742 142241749  MA0605.1      - 11.9180      8           -113089 TSNARE1.fp.downstream.113089.MA0605.1

subset(tbls.fp[["postgres://whovian/brain_hint_20"]], motifStart <= loc & motifEnd >= loc)
subset(tbls.fp[["postgres://whovian/brain_wellington_16"]], motifStart <= loc & motifEnd >= loc)
subset(tbls.fp[["postgres://whovian/brain_wellington_20"]], motifStart <= loc & motifEnd >= loc)


id <- "rs12234969"
loc <- subset(tmp.bed, rsid==id)$start  # 142245289
subset(tbls.fp[["postgres://whovian/brain_hint_16"]], motifStart <= loc & motifEnd >= loc)
subset(tbls.fp[["postgres://whovian/brain_hint_20"]], motifStart <= loc & motifEnd >= loc)
subset(tbls.fp[["postgres://whovian/brain_wellington_16"]], motifStart <= loc & motifEnd >= loc)
subset(tbls.fp[["postgres://whovian/brain_wellington_20"]], motifStart <= loc & motifEnd >= loc)
# all 4 agree:
# chrom motifStart  motifEnd motifName strand   score length distance.from.tss                                    id
#  chr8  142245279 142245291  MA0105.4      + 1.16327     13           -109552 TSNARE1.fp.downstream.109552.MA0105.4
#  chr8  142245289 142245308  MA0066.1      - 8.57778     20           -109542 TSNARE1.fp.downstream.109542.MA0066.1


# collected:
# fp.snp.motifs <- c("MA0066.1", "MA0609.1", "MA0604.1", "MA0605.1", "MA0690.1", "MA0800.1", "MA0100.2", "MA0138.2")

# motifToGene(MotifDb, fp.snp.motifs, source="TFclass")
#      motif geneSymbol pubmedID  source
# 1  MA0066.1      PPARG 23180794 TFClass
# 2  MA0100.2        MYB 23180794 TFClass
# 3  MA0138.2       REST 23180794 TFClass
# 4  MA0604.1       ATF1 23180794 TFClass
# 5  MA0604.1     CREBL2 23180794 TFClass
# 6  MA0604.1     CREBZF 23180794 TFClass
# 7  MA0604.1      CREB3 23180794 TFClass
# 8  MA0604.1    CREB3L1 23180794 TFClass
# 9  MA0604.1    CREB3L2 23180794 TFClass
# 10 MA0604.1    CREB3L3 23180794 TFClass
# 11 MA0604.1    CREB3L4 23180794 TFClass
# 12 MA0604.1       CREM 23180794 TFClass
# 13 MA0605.1       ATF3 23180794 TFClass
# 14 MA0605.1       JDP2 23180794 TFClass
# 15 MA0605.1       FOSB 23180794 TFClass
# 16 MA0609.1       CREM 23180794 TFClass
# 17 MA0609.1     CREBL2 23180794 TFClass
# 18 MA0609.1     CREBZF 23180794 TFClass
# 19 MA0609.1      CREB3 23180794 TFClass
# 20 MA0609.1    CREB3L1 23180794 TFClass
# 21 MA0609.1    CREB3L2 23180794 TFClass
# 22 MA0609.1    CREB3L3 23180794 TFClass
# 23 MA0609.1    CREB3L4 23180794 TFClass
# 24 MA0609.1       ATF1 23180794 TFClass
# 25 MA0690.1      TBX21 23180794 TFClass
# 26 MA0690.1       TBR1 23180794 TFClass
# 27 MA0800.1      EOMES 23180794 TFClass

# from MotifDb motif/tf mapping
# tf.map.motifDB <- lapply(fp.snp.motifs, function(motif) unique(mcols(query(MotifDb, motif))$geneSymbol))
# names(tf.map.motifDB) <- fp.snp.motifs
# tf.map.motifDB
# MA0066.1  [1] "PPARG"
# MA0609.1  [1] "Crem"
# MA0604.1  [1] "Atf1"
# MA0605.1  [1] "Atf3"
# MA0690.1  [1] "TBX21"
# MA0800.1  [1] "EOMES"
# MA0100.2  [1] "Myb" "brk"
# MA0138.2  [1] "REST"





*-----------------------------------------------------------------------------------------------------------------------
* git, bioc, motifdb (4 oct 2017)

  cd ~/github/MotifDb
   git remote -v
    origin	https://github.com/PriceLab/MotifDb.git (fetch)
    origin	https://github.com/PriceLab/MotifDb.git (push)

  git remote add upstream git@git.bioconductor.org:packages/MotifDb.git

  git remote -v
    origin	https://github.com/PriceLab/MotifDb.git (fetch)
    origin	https://github.com/PriceLab/MotifDb.git (push)
    upstream	git@git.bioconductor.org:packages/MotifDb.git (fetch)
    upstream	git@git.bioconductor.org:packages/MotifDb.git (push)


git status
Unmerged paths:
  (use "git add <file>..." to mark resolution [after, I assume, manual editing]
                        or: git checkout HEAD <each of these files in turn,
			    which means: treat my local version as the true one)

	both added:      NAMESPACE
	both added:      R/MotifList-class.R
	both added:      R/zzz.R
	both added:      inst/unitTests/test_MotifDb.R
	both added:      man/query.Rd

git checkout HEAD man/query.Rd
git add .
git commit -m "merged"
git push origin master
git push upstream master


*-----------------------------------------------------------------------------------------------------------------------
* astrakan cafe: https://www.youtube.com/watch?v=HWWi4fFPTl8
*-----------------------------------------------------------------------------------------------------------------------
* biomaRt tss tips (29 sep 2017)

  --- for mouse
   mm10 <- useMart(biomart="ensembl", dataset="mmusculus_gene_ensembl")
   getBM(attributes=c("chromosome_name", "transcription_start_site", "mgi_symbol", "strand"), filters="mgi_symbol", value="Tcf7", mart=mm10)
       chromosome_name transcription_start_site mgi_symbol strand
                    11                 52282571       Tcf7     -1
                    11                 52283014       Tcf7     -1
   goi <- c("Bcl6", "Tcf7", "Pdcd1", "Prdm1", "Brat1")

   ---- is tss corrected for strand?
   getBM(attributes=c("chromosome_name", "transcription_start_site", "mgi_symbol", "strand"), filters="mgi_symbol", value="Bcl6", mart=mm10)
      chromosome_name transcription_start_site mgi_symbol strand
                   16                 23988852       Bcl6     -1
                   16                 23972380       Bcl6     -1
   use this in igv:  chr16:23988852-23972380
   mgi says: Chr16:23965052-23988852


*-----------------------------------------------------------------------------------------------------------------------
* hamid's larget model: create the code he will use (29 sep 2017)

   cd ~/github/TcellExhaustion/
   source("explore.R")
   tbl.net <- readHamidsTCellNetwork()
   length(unique(c(tbl.net$Source, tbl.net$Target))) #  119

   hamid says:  My favorite genes are Bcl6, Tcf7, Pdcd1, and Prdm1

*-----------------------------------------------------------------------------------------------------------------------
* hamid's larger model (29 sep 2017)  [from emails (27 sep 2017)]

   cd ~/github/TcellExhaustion/
   My favorite genes are BCL6, TCF7, PDCD1, and PRDM1 :)


   --- I proposed:

    1) take all the TFs in your model (do I have the latest version?)

    2) report scores and locations of all associated motifs, of those TFs,
       in the promoters of all genes in the model.  Include possibilities of
       self-regulation.  (Promoter +/- 5kb?  Bigger?  From which TSS?)
       Each putative regulation will motif match, binding site count, and expression
       modeling scores.

    3) Look for new TFs not yet in your model, predicted by trena to be
       possible regulators

   --- hamid replies

    Yes, that's pretty much what _I_ hope to do. If it makes things
    easier, you don't need to run the analysis for all the 113 genes
    in the network. I am happy to do that if you show me how.

    -- I need to make the search fairly stringent, so maybe limit the
       genomic regions to be searched to just 2Kbp upstream and 200bp
       downstream of each TSS.

   Likewise, to be conservtive, I'd use only the motifs in MotifDB (or
   even just JASPAR + Jolma2013) and set the PWM match threshold to
   90% or higher.

   Here is the simplistic way I was thinking of doing it:

     1) Run Trena on all 113 genes in my network, save the results as a table.

     2) I can then post-process the results to subset just the TFs in
     my 113 gene network, filter by various scoring/matching criteria,
     ask whether hits for my TFs are enriched compared to other TFs,
     look at co-occurrence patterns, etc.

  -- I _imagine_ this means is to be able to run Trena in a "headless"
     mode (no HTML output), then after selecting hits of interest, to
     visualize just those ones post-hoc.

  --- to which I said:

    I will write a function parameterized by

      target gene
      expression matrix
      upstream
      downstream
      pfms
      motif match threshold




*-----------------------------------------------------------------------------------------------------------------------
* chrome bug with version 61.0.3163.100   net::ERR_CACHE_OPERATION_NOT_SUPPORTED  (28 sep 2017)

   VM37:1 GET https://s3.amazonaws.com/igv.broadinstitute.org/data/hg19/encode/wgEncodeBroadHistoneGm12878H3k4me3StdSig.bigWig
   net::ERR_CACHE_OPERATION_NOT_SUPPORTED

  --- i think i noticed automatic update to Version 61.0.3163.100 (Official Build) (64-bit) yesterday

   got older version here:
     https://www.slimjet.com/chrome/google-chrome-old-version.php
     first trying 59.0.3071.86 from (12 jun 2017)


   defaults read com.google.Keystone.Agent checkInterval    # 180000 (or some similar number)
   defaults write com.google.Keystone.Agent checkInterval 0
   defaults read com.google.Keystone.Agent checkInterval    # 0

*-----------------------------------------------------------------------------------------------------------------------
* footprint databases on bdds, whovian, khaleesi

   database.host <- "whovian.systemsbiology.net"
   db <- dbConnect(PostgreSQL(), user="trena", password="trena", host=database.host)
   dbGetQuery(db, "select datname from pg_database")

   dbListTables(db)
   dbDisconnect(db)

   database.host <- "bddsrds.globusgenomics.org"
   db <- dbConnect(PostgreSQL(), user="trena", password="trena", host=database.host)
   dbGetQuery(db, "select datname from pg_database")

   dbListTables(db)
   dbDisconnect(db)

*-----------------------------------------------------------------------------------------------------------------------
* trenaViz tips

  --- add tracks

   starts <- 26860646 + round(runif(segments,3,300))
   ends   <- starts + round(runif(segments,3,8))
   tbl.bed <- data.frame(chr=rep("18", segments),
                         start=starts,
                         end=ends,
                         name=LETTERS[1:segments],
                         score=runif(segments, -1, 1),
                         stringsAsFactors=FALSE)

   addBedTrackFromDataFrame(tv, "tbl.bed", tbl.bed, displayMode="EXPANDED", color="darkRed")
   showGenomicRegion(tv, sprintf("chr18:%d-%d", min(tbl.bed$start) - 10, max(tbl.bed$end) + 10))

   tbl.bedGraph <- tbl.bed[, c(1,2,3,5,4)]
   addBedGraphTrackFromDataFrame(tv, "tbl.bedGraph", tbl.bedGraph, color="darkGreen",
                                 minValue=min(tbl.bedGraph$score), maxValue=max(tbl.bedGraph$score),
                                 displayMode="EXPANDED")

   checkEquals(sort(getTrackNames(tv)), c("Gencode v24",  "tbl.bed", "tbl.bedGraph"))
   Sys.sleep(3)
   removeTracksByName(tv, c("tbl.bed", "tbl.bedGraph"))


*-----------------------------------------------------------------------------------------------------------------------
* seth ament's schizophrenia trenaViz demo (2 oct 2017): do snps align to genome?

  cd ~/github/trenaSCZ/gwas/
  gwas biggest hit: rs4702  chr15:90883330
     GCCAGCCCGGCTGGTTTTGTAAGAT[A/G]CTGGGTTGGTGCACAGTGATTTTTT
   blat: GCCAGCCCGGCTGGTTTTGTAAGATACTGGGTTGGTGCACAGTGATTTTTT
     98.1%    15   +   90,883,305  90883355     51

  in early intron: rs17514846
  dbsnp says: https://www.ncbi.nlm.nih.gov/projects/SNP/snp_ref.cgi?rs=17514846
   chr15:90873320
   GCGCCTGA[A/C/G]GCCTGCTTTCTT

*-----------------------------------------------------------------------------------------------------------------------
* seth ament's schizophrenia trenaViz demo (28 sep 2017)

   genes of interest (email 20 sep 2017): FURIN, TSNARE1, CNTN4, CLCN3, SNAP91, SOX2, FOXG1, and SREBF1
  following manhattan plot in seth's email (26 sep 2017):
  cd ~/github/trenaSCZ/gwas/
  go.R subsets the big "ckqny.scz2snpres" file, 9.4M rows into just a region around FURBIN, with ~1800 snps
  key change from original approach, inspired by that manhattan plot: includes all pval <= 0.5
     eventually producing scores:
      fivenum(tbl.snps$score)  [1]  0.3011169  0.4590452  0.7221617  1.2014184 11.6386500

  read these in to ~/github/trenaSCZ/explore.R

*-----------------------------------------------------------------------------------------------------------------------
* seth ament's schizophrenia trenaViz demo (25 sep 2017)

   --- from email (20 sep 2017)

   The best SCZ RNA-seq dataset is on Synapse. The individual-level
   data are controlled access, but the differential expression results
   are public and available here:
   https://www.synapse.org/#!Synapse:syn5607603 I think that's the
   main thing we want to display, anyway.

   I don't yet have the ATAC-seq data from these samples. It was
   generated trough PsychENCODE, and I'm still applying for the
   data. In the meantime, a closely related dataset is here:
   https://www.ncbi.nlm.nih.gov/geo/query/acc.cgi?acc=GSE83345

   A handful of genes of interest in this dataset are FURIN, TSNARE1,
   CNTN4, CLCN3, SNAP91, SOX2, FOXG1, and SREBF1.

   The SCZ GWAS are available here:
   https://www.med.unc.edu/pgc/results-and-downloads


   --- bigWig files
     https://software.broadinstitute.org/software/igv/bigwig

        The bigWig format is for display of dense, continuous data
        that will be displayed as a graph. BigWig files are created
        initially from WIG type files, using the UCSC program
        wigToBigWig. Alternatively, bigWig files can be created from
        bedGraph files, using the UCSC program bedGraphToBigWig. In
        either case, the resulting bigWig files are in an indexed
        binary format. The main advantage of the bigWig files is that
        only the portions of the files needed to display a particular
        region are transferred, so for large data sets bigWig is
        considerably faster than regular WIG files.

*-----------------------------------------------------------------------------------------------------------------------
* gwas track, seth's scz (26 sep 2017)

                 {name: "igap gwas scores",
                  type: "wig",
                  format: "bedgraph",
                  min: 0,
                  max: 20,
                  url: 'http://pshannon.systemsbiology.net/hg38/variants/igap.bedgraph',
                  indexed: false,
                  //visibilityWindow: 1000000,
                  color: "#4400AA"
                  },

*-----------------------------------------------------------------------------------------------------------------------
* bigwig files, igv.js, tiny test (26 sep 2017)

   /Library/Frameworks/R.framework/Versions/3.4/Resources/library/rtracklayer/tests/test.bw
   scp /Library/Frameworks/R.framework/Versions/3.4/Resources/library/rtracklayer/tests/test.bw pshannon@whovian:/local/httpd/vhosts/pshannon/experiments/

           # 9 regions on chr2 and chr19:
    system.file(package="rtracklayer", "tests", "test.bw")

    import(system.file(package="rtracklayer", "tests", "test.bw"))
    GRanges object with 9 ranges and 1 metadata column:
          seqnames       ranges strand |     score
             <Rle>    <IRanges>  <Rle> | <numeric>
      [1]     chr2 [   1,  300]      * |        -1
      [2]     chr2 [ 301,  600]      * |     -0.75
      [3]     chr2 [ 601,  900]      * |      -0.5
      [4]     chr2 [ 901, 1200]      * |     -0.25
      [5]     chr2 [1201, 1500]      * |         0
      [6]    chr19 [1501, 1800]      * |      0.25
      [7]    chr19 [1801, 2100]      * |       0.5
      [8]    chr19 [2101, 2400]      * |      0.75
      [9]    chr19 [2401, 2700]      * |         1
      -------
      seqinfo: 2 sequences from an unspecified genome


*-----------------------------------------------------------------------------------------------------------------------
* bigwig files, import, rtracklayer (26 sep 2017)

   https://support.bioconductor.org/p/58156/
   library(rtracklayer)
   bw.file <- system.file("tests", "test.bw", package="rtracklayer")
   xx = import(test_bw, which=seqinfo(BigWigFile(test_bw))["chr19"])
   length(xx)   # [1] 1653959


   cd ~/github/trenaSCZ/geo/
   bw.file <- "GSM2199917_S2_Neuronal_Nuclei.bw"
   xx <- import(bw.file, which=seqinfo(BigWigFile(bw.file))["chr19"])
     GRanges object with 4 ranges and 1 metadata column:
           seqnames       ranges strand |     score
              <Rle>    <IRanges>  <Rle> | <numeric>
       [1]    chr19 [1501, 1800]      * |      0.25
       [2]    chr19 [1801, 2100]      * |       0.5
       [3]    chr19 [2101, 2400]      * |      0.75
       [4]    chr19 [2401, 2700]      * |         1
       -------
       seqinfo: 2 sequences from an unspecified genome
   length(xx) # 4

   bw.file <- "GSM2199917_S2_Neuronal_Nuclei.bw"
   xx <- import(bw.file, which=seqinfo(BigWigFile(bw.file))["chr13"])
   bw.file <- "GSM2199917_S2_Neuronal_Nuclei.bw"
   xx <- import(bw.file, which=seqinfo(BigWigFile(bw.file))["chr13"])
   length(xx) # [1] 7352354



*-----------------------------------------------------------------------------------------------------------------------
* matt mccoy installs rpy2 on whovian for me to use with notebooks

   It looks like you needed to install the readline-dev headers. And
   when I say you, I mean me since that is something you root powers
   to do. So I installed that dev headers:

    [root@whovian mmccoy]# yum install readline-devel
       And then installed the rpy2 plugin as you:
    [root@whovian mmccoy]# su pshannon
    whovian.mmccoy> cd
    whovian.~> pwd   # /users/pshannon
    whovian.~> pip install rpy2
       Collecting rpy2
       Using cached rpy2-2.9.0.tar.gz
       Requirement already satisfied: six in /local/pshannon/anaconda3/lib/python3.5/site-packages (from rpy2)
       Building wheels for collected packages: rpy2
       Running setup.py bdist_wheel for rpy2 ... done
       Stored in directory: /users/pshannon/.cache/pip/wheels/6a/9d/7c/81f13b770d01fe5c33ea466e1febfae0cefaa576d39a90b4d0
       Successfully built rpy2
       Installing collected packages: rpy2
       Successfully installed rpy2-2.9.0
    Seems to be installed just fine now:
    whovian.~> pip show rpy2
      Name: rpy2
      Version: 2.9.0
      Summary: Python interface to the R language (embedded R)
      Home-page: http://rpy2.bitbucket.io
      Author: Laurent Gautier
      Author-email: lgautier@gmail.com
      License: GPLv2+
      Location: /local/pshannon/anaconda3/lib/python3.5/site-packages
      Requires: six

*-----------------------------------------------------------------------------------------------------------------------
* aqp4 trenaViz demo for matt, "eat our own dogfood" (25 sep 2017)

  new private github repo:

    cd  ~/github/aquaporin4
    explore.R

  --- previous work, for 6/25 price lab meeting
    cd ~/github/trenaHelpers/inst/demos/aqp4/labMeeting-22jun2017
    library(gplots)
    mtx.rosmap.aqp4 <- mtx[c("AQP4", strongGeneModels[["rosmap"]]$tf),]
    save(mtx.rosmap.aqp4, file="mtx.rosmap.aqp4.RData")
    heatmap.2(mtx.rosmap.aqp4, trace='none')



*-----------------------------------------------------------------------------------------------------------------------
* inslee's environmental staff, approach re sword ferns (25 sep 2017)

Natural Resources / Environment
Robert Duff
Senior Policy Advisor, Environment
(360) 902-0532
robert.duff@gov.wa.gov
*-----------------------------------------------------------------------------------------------------------------------
* github bioconductor motifdb maintainer push priviletes (25 sep 2017)

  The new maintainer will need to make their ssh public key available;
  do this by filling in the form at
  https://goo.gl/forms/eg36vcBkIUjfZfLe2 and indicating, in the email,
  the svn or github id associated with your public key(s).

  --- do i already have a ssh key for github?   3 possiblilites.  used the first
      dir ~/.ssh/id_rsa*
        -rw-------  1 paul  staff  891 Feb  1  2016 /Users/paul/.ssh/id_rsa
        -rw-------  1 paul  staff  245 Feb  1  2016 /Users/paul/.ssh/id_rsa.pub

    dir ~/.ssh/id_dsa*
        -rw-------  1 paul  staff  668 Feb  1  2016 id_dsa
        -rw-r--r--  1 paul  staff  621 Feb  1  2016 id_dsa.pub
       but also have
    dir ~/.ssh/github_rsa*
        -rw-------  1 paul  staff  1766 Jan 20  2016 /Users/paul/.ssh/github_rsa
        -rw-r--r--  1 paul  staff   404 Jan 20  2016 /Users/paul/.ssh/github_rsa.pub

   --- add id_rsa.pub to github


   https://www.bioconductor.org/developers/how-to/git/sync-existing-repositories/

    I submitted my keys by giving my Github ID via the form Martin linked:

      https://goo.gl/forms/eg36vcBkIUjfZfLe2



*-----------------------------------------------------------------------------------------------------------------------
* try nglview in notebook, for daylight an dhodh (23 sep 2017)

  cd ~/github/nglview
  git pull origin
  python setup.py install

*-----------------------------------------------------------------------------------------------------------------------
* install rpy2 for jupyter (lab) on whovian (23 sep 2017)

  [status: asked it for help]

   jupyter --version; jupyter notebook --version; jupyter lab --version
      4.2.1
      4.3.1
      jupyter: 'lab' is not a Jupyter command

   conda update -c conda-forge jupyter
   conda install -c conda-forge jupyterlab
   conda upgrade -c conda-forge notebook
   jupyter --version; jupyter notebook --version; jupyter lab --version
     4.2.1
     5.1.0
     0.27.0

   conda upgrade -c conda-forge notebook

   --- latest python?
    conda search python  # lots of results, but 3.6.2 listed
    conda --version      # conda 4.3.23
    conda update -c conda-forge conda
    conda --version

   --- latest R?
      R --version  # 3.3.2
      conda update r-essentials
      R --version  # 3.4.1

   --- rpy2

     pip install rpy2
       ./rpy/rinterface/_rinterface.c:80:31: fatal error: readline/readline.h: No such file or directory
     #include <readline/readline.h>
                                   ^
    compilation terminated.
    error: command 'gcc' failed with exit status 1

   --- one failed suggestion from stack overflow
       conda remove --force readline
       pip install readline
       pip install rpy2

   --- try ldd (present, in R)
    ldd /local/pshannon/anaconda3/lib/R/lib/libR.so | grep readline
	libreadline.so.6 => /local/pshannon/anaconda3/lib/R/lib/../../libreadline.so.6 (0x00007f393a426000)

   ---- pip install rpy2   # problem solved by jusa adding an include directory?
      Compilation parameters for rpy2's C components:
          include_dirs    = ['/local/pshannon/anaconda3/lib/R/include']
          library_dirs    = ['/local/pshannon/anaconda3/lib', '/local/pshannon/anaconda3/lib/R/lib']
          libraries       = ['gfortran', 'R', 'pcre', 'lzma', 'bz2', 'z', 'rt', 'dl', 'm', 'iconv', 'icuuc', 'icui18n']
          extra_link_args = ['-Wl,--export-dynamic', '-fopenmp']

      find /local/pshannon -name "readline.h"
        /local/pshannon/gemini/anaconda/pkgs/readline-6.2-2/include/readline/readline.h
        /local/pshannon/gemini/anaconda/include/readline/readline.h
        /local/pshannon/anaconda3/pkgs/readline-6.2-2/include/readline/readline.h
        /local/pshannon/anaconda3/envs/py27/include/readline/readline.h
        /local/pshannon/anaconda3/include/readline/readline.h

    --- another possibility:  build R from source,
     When compiling R from source, do not forget to specify –enable-R-shlib at the ./configure step.
     cd ~/src
     curl -O https://cran.r-project.org/src/base/R-3/R-3.4.1.tar.gz
     tar zxf R-3.4.1.tar.gz
     ./configure --enable-R-shlib
       configure: error: --with-readline=yes (default) and headers/libs are not available

*-----------------------------------------------------------------------------------------------------------------------
* R tips matrix tips: preserve data.frame or matrix

    x[1, 1:3, drop=FALSE]

*-----------------------------------------------------------------------------------------------------------------------
* pdb tips: the 6 record types

   https://www.cgl.ucsf.edu/chimera/docs/UsersGuide/tutorials/pdbintro.html

   Record Type	Data Provided by Record

   ATOM    atomic coordinate record containing the X,Y,Z orthogonal Å
           coordinates for atoms in standard residues (amino acids and nucleic
           acids).

   HETATM:  atomic coordinate record containing the X,Y,Z orthogonal Å
            coordinates for atoms in nonstandard residues. Nonstandard
            residues include inhibitors, cofactors, ions, and solvent. The
            only functional difference from ATOM records is that HETATM
            residues are by default not connected to other residues. Note that
            water residues should be in HETATM records.

   TER indicates the end of a chain of residues. For example, a
       hemoglobin molecule consists of four subunit chains that are
       not connected. TER indicates the end of a chain and prevents
       the display of a connection to the next chain.

   HELIX:  indicates the location and type (right-handed alpha, etc.) of helices. One record per helix.

   SHEET: indicates the location, sense (anti-parallel, etc.) and registration with respect to the previous strand in the sheet (if any) of each strand in the model. One record per strand.

   SSBOND: defines disulfide bond linkages between cysteine residues.

*-----------------------------------------------------------------------------------------------------------------------
* pdb tips: the HELIX record

HELIX	1-5	“HELIX”		character
8-10	Helix serial number	right	integer
12-14	Helix identifier	right	character
16-18§	Initial residue name	right	character
20	Chain identifier		character
22-25	Residue sequence number	right	integer
26	Code for insertions of residues		character
28-30§	Terminal residue name	right	character
32	Chain identifier		character
34-37	Residue sequence number	right	integer
38	Code for insertions of residues		character
39-40	Type of helix†	right	integer
41-70	Comment	left	character
72-76	Length of helix	right	integer

123456789.123456789.123456789.123456789.123456789.123456789.123456789.123456789.
HELIX    1   1 ASP A   34  HIS A   41  1                                   8
HELIX    2   2 HIS A   41  LEU A   50  1                                  10
HELIX    3   3 ASP A   51  LEU A   65  1                                  15

  --- ngl select 1st helix, residues 34-41
  x = stage.getComponentsByName('3kvk').list[0]
  x.removeAllRepresentations()
  x.addRepresentation("cartoon", {sele: "34-41"})





*-----------------------------------------------------------------------------------------------------------------------
* pdb tips: the ATOM record

  from 3kvk
  a single chain of 2788 atoms

123456789.123456789.123456789.123456789.123456789.123456789.123456789.123456789.
ATOM      1  N   GLY A  33     -10.201  20.698  -2.001  1.00 63.90           N

 7-11: atom serial number                         1
13-16: atom name                                  N
   17: alternate location indicator
18-20: residue name                             GLY
   22: chain identifier                           A
23-26: residue sequence number                   33
   27: code for insertions of residuces
31-38: X                                    -10.201
39-46: Y                                     20.698
47-54: Z                                     -2.001
55-60: occupancy                              1.00
61-66: termperature factor                   63.90
73-76: segment identifier
77-78: element symbol                            N
79-80: charge
*-----------------------------------------------------------------------------------------------------------------------
* ngl & dhodh (19 sep 2017)

  --- from the two miller syndrome papers: two mutations in dhodh, chr16
        mutation      exon      amino acid change   location
         c.56G>A	2	p.G19E	             chr16:70603484
    	c.454G>A	4	p.G152R	             chr16:70608443

       70,608,443        70,612,611
     CAC GGG CTT  ... CTG GGC CCC
         AGG              GCC
        (mom)            (dad)


codon   amino acid
 GGG   Glycine
 AGG   Arginine

 GGC   Glycine
 GCC   Alanine

  cd ~/github/projects/examples/ngl/dhodh
  index.html

  ---  with referencesw to the 20 helices in 3kvk.pdb, here displaying the first two

  HELIX    1   1 ASP A   34  HIS A   41  1                                   8
  HELIX    2   2 HIS A   41  LEU A   50  1                                  10

  123456789.123456789.123456789.123456789.123456789.123456789.123456789.
  SHEET    1   A 2 VAL A  81  VAL A  83  0
  SHEET    2   A 2 HIS A  86  PHE A  88 -1  O  PHE A  88   N  VAL A  81
  SHEET    1   B 9 VAL A  92  ILE A  94  0
  SHEET    2   B 9 PHE A 115  VAL A 121  1  O  PHE A 115   N  ILE A  94
  SHEET    3   B 9 LEU A 178  LEU A 182  1  O  GLY A 179   N  VAL A 116


  SHEET    2   A 2 HIS A  86  PHE A  88 -1  O  PHE A  88   N  VAL A  81


   var x = stage.getComponentsByName('3kvk').list[0]

   x.removeAllRepresentations()

   x.addRepresentation('cartoon', {sele: "34-41", color: "blue"})
   x.addRepresentation('cartoon', {sele: "41-51", color: "grey"})
   x.addRepresentation('cartoon', {sele: "51-65", color: "yellow"})
   x.addRepresentation('cartoon', {sele: "76-80", color: "green"})

   x.addRepresentation('cartoon', {sele: "81-88", color: "orange"})

   --- next up:
     continue with piecewise construction and display of dhodh
     identify the two miller syndrome snps

*-----------------------------------------------------------------------------------------------------------------------
* jocelyn trenaViz demo, two HD genes (18 sep 2017)

   cd ~/github/projects/priceLab/jocelyn/trenaVizDemo-HD

   --- email thread (6 sep and following)

     Could we please look at two genes related to Huntington's disease:

     HTT - the gene for which a CAG expansion in the first exon causes
     Huntington's disease.  I am interested in which TF motifs and
     footprints are within a +/- 10 kb region upstream and downstream.
     The gene track itself is 13 kb I believe, so perhaps we should
     extend this out 10 kb past the last exon.

     MLH1 - a DNA repair enzyme implicated as a genetic modifier of HD
     in patients and in mouse models of the disease.

     Footprint predictions from brain samples will be particularly
     interesting, but a general map across tissues will also be of
     use.

   --- our footprints are human, so jocelyn suggests this expression data:

    Human Allen Brain Atlas data located here:

        /proj/price1/sament/human_aba/HO351

       77309399 Dec 24  2015 H0351.1009/gene_based_expression.RData
      114036716 Dec 24  2015 H0351.1012/gene_based_expression.RData
      101668506 Dec 24  2015 H0351.1015/gene_based_expression.RData
      108160857 Dec 24  2015 H0351.1016/gene_based_expression.RData
      201613948 Dec 24  2015 H0351.2001/gene_based_expression.RData
      190818982 Dec 24  2015 H0351.2002/gene_based_expression.RData

    see: http://human.brain-map.org/mri_viewers/data

   scp pshannon@whovian:/proj/price1/sament/human_aba/H0351.1009/gene_based_expression.RData H0351.1009.RData
   scp pshannon@whovian:/proj/price1/sament/human_aba/H0351.1012/gene_based_expression.RData H0351.1012.RData
   scp pshannon@whovian:/proj/price1/sament/human_aba/H0351.1015/gene_based_expression.RData H0351.1015.RData
   scp pshannon@whovian:/proj/price1/sament/human_aba/H0351.1016/gene_based_expression.RData H0351.1016.RData
   scp pshannon@whovian:/proj/price1/sament/human_aba/H0351.2001/gene_based_expression.RData H0351.2001.RData
   scp pshannon@whovian:/proj/price1/sament/human_aba/H0351.2002/gene_based_expression.RData H0351.2002.RData

   scp pshannon@whovian:/proj/price1/sament/human_aba/H0351.1009/SampleAnnot.csv H0351.1009.metadata.csv
   scp pshannon@whovian:/proj/price1/sament/human_aba/H0351.1012/SampleAnnot.csv H0351.1012.metadata.csv
   scp pshannon@whovian:/proj/price1/sament/human_aba/H0351.1015/SampleAnnot.csv H0351.1015.metadata.csv
   scp pshannon@whovian:/proj/price1/sament/human_aba/H0351.1016/SampleAnnot.csv H0351.1016.metadata.csv
   scp pshannon@whovian:/proj/price1/sament/human_aba/H0351.2001/SampleAnnot.csv H0351.2001.metadata.csv
   scp pshannon@whovian:/proj/price1/sament/human_aba/H0351.2002/SampleAnnot.csv H0351.2002.metadata.csv

*-----------------------------------------------------------------------------------------------------------------------
* tr tips

  --- solve this problem: tr: Illegal byte sequence

  export LC_ALL=C; cat TableofDNAsehypersensitivitydataforpaul.txt | tr '\r' '\n'  > dhsSources.tsv

*-----------------------------------------------------------------------------------------------------------------------
* pdb tips

   In the PDB data file format for macromolecular models, each atom is
   designated either ATOM or HETATM (which stands for hetero
   atom). ATOM is reserved for atoms in standard residues of protein,
   DNA or RNA. HETATM is applied to non-standard residues of protein,
   DNA or RNA, as well as atoms in other kinds of groups, such as
   carbohydrates, substrates, ligands, solvent, and metal ions.


*------------------------------------------------------------------------------------------------------------------------
* ngl tips: operations on crambin (1 oct 2017)

  file:///Users/paul/github/projects/examples/ngl/crambin/crambin.html
  c = stage.getComponentsByName("1crn").list[0]
  c.removeAllRepresentations();
  c.addRepresentation('cartoon');
  c.removeAllRepresentations();
  defaultStructureRepresentation(c)

  c.addRepresentation("spacefill", {sele: "10", scale:2})

*------------------------------------------------------------------------------------------------------------------------
* ngl tips: how to do visually distinct selections (17 sep 2017)

   see https://github.com/arose/ngl/issues/161

*------------------------------------------------------------------------------------------------------------------------
* ngl tips: tube rendering

   https://codepen.io/arose/pen/dzLbaK?editors=0010

  stage.loadFile("data://1u19.pdb").then(function (o) {
  o.addRepresentation("tube", {
    sele: ":A",
    radius: "bfactor",
    scale: 0.010,
    color: "bfactor",
    colorScale: "RdYlBu"
  })

  o.addRepresentation("ball+stick", {
    sele: ":A and sidechainAttached",
    aspectRatio: 1.5,
    color: "bfactor",
    colorScale: "RdYlBu"
  })

  o.autoView(":A")
})

*------------------------------------------------------------------------------------------------------------------------
* ngl tips: defaultStructureRepresentation

    // apparently defined and standard for ngl

  function defaultStructureRepresentation( component ){
     if( component.type !== "structure" ) return;


*------------------------------------------------------------------------------------------------------------------------
* ngl tips: control rendering from javascript console

   cd ~/github/ngl/
   open examples/webapp.html
   File -> PDB -> 1crn
   stage.getComponentsByName('1crn').addRepresentation('ball+stick', { sele: '1' })

   --- the protein 1crn

    Crambin is a small seed storage protein from the Abyssinian
    cabbage. It belongs to thionins. It has 46 residues (amino
    acids). It has been extensively studied by X-ray crystallography
    since its crystals are unique and diffract to a resolution of 0.48
    . Neutron scattering measurements are available also at a
    resolution of 1.1 ,[2] PDB ID 3U7T.

   --- some commands: these "addRepresentation" command are cumulative, with cartoon the default, these further two added.
    var stage = new NGL.Stage( "viewport" );
    stage.loadFile( "rcsb://1crn", {defaultRepresentation: false});
    stage.getComponentsByName('1crn').addRepresentation('ball+stick', {sele: "*"})
    stage.getComponentsByName('1crn').addRepresentation('ribbon', {sele: "*"})
    stage.getComponentsByName('1crn').autoView()
    stage.getComponentsByName('1crn').addRepresentation('ball+stick', {sele: '1-10'})


    x = stage.getComponentsByName('1crn')
    y = x.list[0]
    Object.keys(y)
    "name"
    "uuid"
    "visible"
    "signals"
    "stage"
    "viewer"
    "reprList"
    "annotationList"
    "matrix"
    "position"
    "quaternion"
    "scale"
    "transform"
    "controls"
    "structure"
    "trajList"
    "selection"
    "structureView"
    "defaultAssembly"


   --- reprList keeps all of the representations thus far added:
     stage.getComponentsByName('1crn').list[0].reprList
   (5) [RepresentationComponent, RepresentationComponent, RepresentationComponent, RepresentationComponent, RepresentationComponent]
        0: RepresentationComponent {name: "cartoon", uuid: "DD40FD5D-39BB-4FC7-8066-267BCD23915A", visible: true, signals: {…}, stage: Stage, …}
	1: RepresentationComponent {name: "base", uuid: "DBB8F817-466A-4439-897A-0C17B2ED866D", visible: true, signals: {…}, stage: Stage, …}
	2: RepresentationComponent {name: "ball+stick", uuid: "5B5A7CDA-F00B-4BF8-A2B7-80D6D2BBB739", visible: true, signals: {…}, stage: Stage, …}
	3: RepresentationComponent {name: "ball+stick", uuid: "D084EB6B-253E-4B59-AFC0-11CF2B239C18", visible: true, signals: {…}, stage: Stage, …}
	4: RepresentationComponent {name: "ball+stick", uuid: "1CC57707-1BFE-45CF-886B-F216BCF901F8", visible: true, signals: {…}, stage: Stage, …}length: 5__proto__: Array(0)

     # remove them all?
   stage.getComponentsByName("1crn").list[0].removeAllRepresentations()   # model no longer displayed

     # now re-render:
  stage.getComponentsByName('1crn').addRepresentation('cartoon', {sele: "*", colorScale: "Set1", colorScheme: "residueindex"})

   ---- detailed control of rendering
    var stage = new NGL.Stage( "viewport" );
    stage.loadFile( "rcsb://1crn", {defaultRepresentation: true});
    stage.getComponentsByName("1crn").list[0].removeAllRepresentations()
    stage.getComponentsByName('1crn').addRepresentation('cartoon', {sele: "* and not 15", colorScale: "Set1", colorScheme: "residueindex"})
    stage.getComponentsByName('1crn').addRepresentation("spacefill", {sele: "15", scale: "2"})

  ---- view each chain of 1IZL, Crystal Structure of Photosystem II

    var stage = new NGL.Stage( "viewport" );
    stage.loadFile( "rcsb://1IZL" ).then(function(comp){
       comp.addRepresentation('ball+stick', { sele: 'PHO and :A' })
       comp.autoView('PHO and :A')
       });

    var pdbID = "1IZL"
    stage.getComponentsByName(pdbID).list[0].removeAllRepresentations()
    stage.getComponentsByName(pdbID).addRepresentation('cartoon', {sele: ":A", colorScale: "Set1", colorScheme: "residueindex"}).autoView();

    stage.getComponentsByName(pdbID).list[0].removeAllRepresentations()
    stage.getComponentsByName(pdbID).addRepresentation('cartoon', {sele: ":A OR :B", colorScale: "Set1", colorScheme: "residueindex"}).autoView();







   --- more complex selection

     // select C-alpha atoms of residue 10 with insertion code A
     // from chain F in model 0 at alternate location C

        10^A:F.CA%C/0

    which is the same as

       10 and ^A and :F and .CA and %C and /0

    Single expressions may be left out as long as the order (see above) is kept, for example:

       :A/0 # select chain A from model 0


   --- the reprList after default load of 1crn:
   stage.getComponentsByName('1crn').list[0].reprList
  p(3) [RepresentationComponent, RepresentationComponent, RepresentationComponent]
    0: RepresentationComponent {name: "cartoon", uuid: 1:"F555FEFF-5550-48A2-ACB9-E6FE73E0643B", visible: true, signals: {…}, stage: Stage, …}
    1: RepresentationComponent {name: "base", uuid: "1D5F845F-9E55-41DA-B9B7-0291128912CF", visible: true, signals: {…}, stage: Stage, …}
    2: RepresentationComponent {name: "ball+stick", uuid: "F586B4FF-F07A-4D61-90DC-395BFE74DA12", visible: true, signals: {…}, stage: Stage, …}length: 3__proto__: Array(0)

   stage.getComponentsByName("1crn").list[0].removeAllRepresentations()   # model is gone
     // then representations can be added
    stage.getComponentsByName('1crn').addRepresentation('ribbon', {sele: "*"})  // style color all blue, sub-optimal

*------------------------------------------------------------------------------------------------------------------------
* ngl tips, build ngl demo webapp

   cd ~/github/ngl/
   npm install
   npm run-script build
   open examples/webapp.html

   --- look for code to change visibility dynamically, as occurs in the webapp gui

*------------------------------------------------------------------------------------------------------------------------
* ngl tips selection language (17 sep 2017)

   https://github.com/arose/ngl/blob/master/doc/usage/selection-language.md
   ligand  -> (( not polymer or hetero ) and not ( water or ion ))

   Select the side-chain and C-alpha atoms plus the backbone nitrogen in case of proline:

      not backbone or .CA or (PRO and .N)

   This selection is useful to display the sidechains together with a backbone trace.
   Hence there is also the keyword sidechainAttached for it.


*------------------------------------------------------------------------------------------------------------------------
* ngl tips

  1CRN:  WATER STRUCTURE OF A HYDROPHOBIC PROTEIN AT ATOMIC RESOLUTION. PENTAGON RINGS OF WATER MOLECULES IN CRYSTALS OF CRAMBIN
         very small

   --- minimal js
     var stage = new NGL.Stage( "viewport" );
     stage.loadFile( "rcsb://1mbo", {defaultRepresentation: true});
        // or:
     stage.loadFile( "rcsb://1F45" ).then(function(component){
       var representations = ["ball+stick", "cartoon", "spacefill", "surface",
                              "ribbon", "tube", "rope", "rocket", "hyperball"];
       component.addRepresentation(representations[1]);
       component.autoView();
       });


   --- specify multiple representations
     function defaultStructureRepresentation( component ){
        // bail out if the component does not contain a structure
       if( component.type !== "structure" ) return;
       // add three representations
       component.addRepresentation( "cartoon", {
         aspectRatio: 3.0,
         scale: 1.5
         });
       component.addRepresentation( "licorice", {
         sele: "hetero and not ( water or ion )",
         multipleBond: true
         });
       component.addRepresentation( "spacefill", {
         sele: "water or ion",
         scale: 0.5
        });
      }

   // Pass that function as a callback whenever you load a structure file via {@link Stage#loadFile}.

   stage.loadFile( "rcsb://1crn" ).then( defaultStructureRepresentation );
   stage.loadFile( "rcsb://4hhb" ).then( defaultStructureRepresentation );


   --- to learn some good representation color parameters, see  http://nglviewer.org/ngl/
     eg, popup the cartoon parameters
        colorScale: Spectral
	colorScheme: resname, atomindex, chainindex

*-----------------------------------------------------------------------------------------------------------------------
* ngl select pheophytin from crystal structure of photosystem 2 1IZL (15 sep 2017)

   I created an issue https://github.com/arose/ngl/issues/383#issuecomment-329830822

     when viewing 1IZL, Crystal Structure of Photosystem II, I'd like to zoom in on, and see the
     unaccompanied structure, of (for example) pheophytin, or the oxygen-evolving complex.

   -- arose quickly replied
      https://codepen.io/arose/pen/XebPwK

    var stage = new NGL.Stage( "viewport" );
    window.addEventListener( "resize", function( event ){
       stage.handleResize();
       }, false );

    stage.loadFile( "rcsb://1IZL" ).then(function(comp){
       comp.addRepresentation('ball+stick', { sele: 'PHO and :A' })
       comp.autoView('PHO and :A')
       });

   --- api
      http://nglviewer.org/ngl/api/class/src/component/component.js~Component.html


*-----------------------------------------------------------------------------------------------------------------------
* alison's trena project: the placental clock (15 sep 2017)


  cd  ~/github/projects/priceLab/alison/placentalClock/

 --- email (later on 5 sep 2017): a trn for just one gene, CRH

    Known as the “placental clock”, corticotropin hormone (CRH) is produced by the placenta in
    massive amounts thereby influencing the in utero environment.

    Using 200 placenta microarray samples, build a model of CRH expression using placental-specific
    footprints from +/-5kb from the TSS.

    The placental footprints of interest are a subset of larger tissue grouping from ENCODE,
    specifically samples ENCSR000EOR, ENCSR575VMI and ENCSR499IFY from the tissue extraembryonic
    structure.


  --- email (5 sep 2017)  asking for a full placental trn

   In response to Pauls request for more problems, I am attaching my research strategy and specific
   aims page for this grant. As you can see, I have a specific research question which I need TRENA
   to help answer, which is drafted up in my preliminary data section.  We need to build a placenta
   specific draft TRN to answer these questions.  I am attaching another copy of the transcriptomics
   data (from 200 samples).  DNAse hypersensitivity data is available from 9 samples
   (https://www.encodeproject.org/search/?type=Experiment&replicates.library.biosample.donor.organism.scientific_name=Homo+sapiens&organ_slims=placenta&assay_slims=DNA+accessibility). I
   am not sure what else you need, but from my understanding as a test case biologist, this seems to
   be what I understand trena would expect.  Id also appreciate any general feedback or comments you
   have on my application if anything pops out.  Thanks! I hope this helps and let me know if you
   need anything else and how we can work together on this.



*-----------------------------------------------------------------------------------------------------------------------
* docker & jlab jupyterlab (14 sep 2017)

  from:

    https://github.com/mikebirdgeneau/jupyterlab-docker
    http://mikebirdgeneau.com/blog/python-docker/

*-----------------------------------------------------------------------------------------------------------------------
* rpy2 install as docker image (14 sep 2017)

  [macos native install failed -- see below -- so not trying docker]
  cd ~/tmp
  docker pull rpy2/rpy2   #   Status: Downloaded newer image for rpy2/rpy2:latest
  docker images | grep rpy2

    REPOSITORY                TAG                 IMAGE ID            CREATED             SIZE
    rpy2/rpy2                 latest              dd0a2957fbd9        3 days ago          1.38GB

*-----------------------------------------------------------------------------------------------------------------------
* rpy2 install (13 sep 2017)

  failed to build/install:  https://bitbucket.org/rpy2/rpy2/issues/403/cannot-pip-install-rpy2-with-latest-r-340
*-----------------------------------------------------------------------------------------------------------------------
* jlab, jupyterlab, jupyterlab (13 sep 2017)

  jupyter --version; jupyter notebook --version; jupyter lab --version # 4.2.1  5.0.0  0.27.0
    conda update -c conda-forge jupyter
    conda update -c conda-forge jupyterlab

  track progress here: https://github.com/jupyterlab/jupyterlab/milestones
*-----------------------------------------------------------------------------------------------------------------------
>    model.alldna$model
   gene  beta.lasso lasso.p.value pearson.coeff     rf.score  beta.ridge spearman.coeff concordance   pcaMax binding.sites
4 FOXP1  0.92848103  2.821271e-08     0.9006827 2.265511e+01  0.08199787      0.8921107   0.5115060 2.101184           124
7  PBX3  0.00000000  1.000000e+00    -0.7072301 2.262076e+01 -0.01917186     -0.8726338   0.5475756 1.626534            15
5  HHEX  0.00000000  1.959919e-03    -0.8206347 1.865959e+01 -0.03173266     -0.8866397   0.4868999 1.467359             3
8  TLX2  0.00000000  1.000000e+00    -0.2968107 9.922508e-04 -0.28060570     -0.2773501   0.4816145 1.404318             3
2 FOXN3 -0.40812313  1.350927e-06    -0.7317324 8.510167e+00 -0.14663851     -0.6809279   0.4887895 1.396618           124
1 BACH2  0.19832372  4.923623e-07     0.8396795 6.836456e+00  0.06597966      0.8098260   0.4636323 1.275841             2
3 FOXO1  0.10422311  8.090102e-06     0.8493228 6.677053e+00  0.07371543      0.9415691   0.4526230 1.190437           124
6   HLX -0.09892207  4.694723e-07    -0.8535354 4.174713e+00 -0.02787638     -0.8395886   0.4731160 1.178247             3
> model.atac$model
   gene  beta.lasso lasso.p.value pearson.coeff     rf.score  beta.ridge spearman.coeff concordance   pcaMax binding.sites
3 FOXP1  1.07986141  2.821271e-08     0.9006827 23.432249755  0.09327269      0.8921107   0.5189486 2.201991            85
6  PBX3  0.00000000  1.000000e+00    -0.7072301 24.334705345 -0.02080122     -0.8726338   0.5394414 1.688766            11
7  TLX2  0.00000000  1.000000e+00    -0.2968107  0.001677437 -0.31799458     -0.2773501   0.5490774 1.492967             3
1 FOXN3 -0.48520965  1.434750e-06    -0.7317324  6.937462895 -0.16104474     -0.6809279   0.4368318 1.439597            85
5   HLX -0.13484042  4.694723e-07    -0.8535354  7.374724828 -0.03219004     -0.8395886   0.4761267 1.357985             3
2 FOXO1  0.08439158  2.222069e-05     0.8493228  7.567489071  0.08232786      0.9415691   0.3921644 1.252042            85
4  HHEX  0.00000000  1.000000e+00    -0.8206347 14.803327449 -0.03513143     -0.8866397   0.4151086 1.178915             3

> model.bigAtac$model
   gene beta.lasso lasso.p.value pearson.coeff     rf.score  beta.ridge spearman.coeff concordance   pcaMax binding.sites
4 FOXP1  0.9284633  2.821271e-08     0.9006827 19.173642775  0.08222329      0.8921107   0.5402178 1.960882           312
7  PBX3  0.0000000  1.000000e+00    -0.7072301 24.815464211 -0.01915537     -0.8726338   0.5245669 1.811345            32
8  TLX2  0.0000000  1.000000e+00    -0.2968107  0.002208447 -0.27979217     -0.2773501   0.4871155 1.399496             3
2 FOXN3 -0.4331421  1.350927e-06    -0.7317324  7.974748016 -0.14606188     -0.6809279   0.4799099 1.387913           312
3 FOXO1  0.1139337  8.090102e-06     0.8493228  9.985391465  0.07352379      0.9415691   0.4660341 1.299375           312
5  HHEX  0.0000000  1.959919e-03    -0.8206347 14.606146484 -0.03162607     -0.8866397   0.4156989 1.270284             3
1 BACH2  0.2035208  4.923623e-07     0.8396795  6.276275082  0.06547852      0.8098260   0.4677285 1.266304             4
6   HLX -0.1005293  4.694723e-07    -0.8535354  5.809852152 -0.02780077     -0.8395886   0.4333838 1.212393             3
>
*-----------------------------------------------------------------------------------------------------------------------
* MotifMatcher bug (10 sep 2017)

  library(trena)
  library(MotifDb)
  pfms.human <- as.list(query(query(MotifDb, "jaspar2016"), "hsap"))
  tbl.regions.1 <- data.frame(chrom="chr5", start=134115543, end=134115576, stringsAsFactors=FALSE)
  tbl.regions.2 <- data.frame(chrom="chr5", start=134115543, end=134115596, stringsAsFactors=FALSE)

  mm <- MotifMatcher("hg38", pfms.human)
    # we expect everything in 1 to also be in 2
  tbl.motifs.1 <- findMatchesByChromosomalRegion(mm, tbl.regions.1, pwmMatchMinimumAsPercentage=92)
  tbl.motifs.2 <- findMatchesByChromosomalRegion(mm, tbl.regions.2, pwmMatchMinimumAsPercentage=92)

*-----------------------------------------------------------------------------------------------------------------------
* igap, gwas, utility of footprints, enrichment (5 sep 2017)

   cd ~/github/projects/priceLab/gwasADfootprintEnrichment/

   ---- enrichment.R
library(RPostgreSQL)
library(trena)
print(load("tbl.gwas.level_1.RData"))
tbl.gwas <- subset(tbl.gwas, P < 10e-8)
table(tbl.gwas$CHR)
#  chr1 chr11 chr14 chr18 chr19  chr2  chr5  chr6  chr7  chr8
#    23   240     1     1   559    54     2   271    34    19
tbl.gwas19 <- subset(tbl.gwas, CHR=="chr19")
dim(tbl.gwas19)

database.host <- "bddsrds.globusgenomics.org"
dbName <- "brain_hint"
db.fp <- dbConnect(PostgreSQL(), user= "trena", password="trena", dbname=dbName, host=database.host)
dbGetQuery(db.fp, "select * from hits limit 3")


genome.db.uri    <- "postgres://bddsrds.globusgenomics.org/hg38"                  # has gtf and motifsgenes tables
footprint.db.uri <- "postgres://bddsrds.globusgenomics.org/brain_hint"            # has hits and regions tables
fpf <- FootprintFinder(genome.db.uri, footprint.db.uri, quiet=FALSE)
chrom <- "chr19"
start <- 1
end   <- 58617616
#end   <- 617616
tbl.fp <- getFootprintsInRegion(fpf, chrom, start, end)l
save(tbl.fp, file="chr19.hint.footprints.RData")
gr.fp <-  with(tbl.fp,   GRanges(seqnames=chrom, IRanges(start=start, end=endpos)))
gr.snp <- with(subset(tbl.gwas, CHR=="chr19"), GRanges(seqnames=CHR, IRanges(start=oldPos, end=oldPos)))
tbl.ov <- as.data.frame(findOverlaps(gr.snp, gr.fp, type='any'))
length(unique(tbl.ov$queryHits))  # [1] 46
length(gr.snp)
printf("percentage of snps in chr19 footprints: %4.2f%%", 100 * length(unique(tbl.ov$queryHits))/ length(gr.snp))  # 8.23%

fp.widths <- 1 + tbl.fp$endpos - tbl.fp$start
mean(fp.widths)   # 11.96
sd(fp.widths)     #  2.90
nrow(tbl.fp)      # 1,183,971

# generate integer lengths which match
#set.seed(37)
rnorm2 <- function(n,mean,sd) { mean+sd*scale(rnorm(n)) }
widths <- rnorm2(n=nrow(tbl.fp), mean=mean(fp.widths), sd=sd(fp.widths))
widths <- as.integer(round(widths))
widths <- abs(widths)   # 12 are < 0
starts <- sort(sample(seq_len(58617616), size=nrow(tbl.fp)))

gr.simfp <- GRanges(seqnames="chr19", IRanges(start=starts, end=starts+widths))
tbl.ovsim <- as.data.frame(findOverlaps(gr.snp, gr.simfp, type='any'))
length(unique(tbl.ovsim$queryHits))  # [1] 46
length(gr.snp)
printf("percentage of snps in chr19 footprints: %4.2f%%", 100 * length(unique(tbl.ovsim$queryHits))/ length(gr.snp))  # 21.65%

library(trenaViz)
tv <- trenaViz(10000:100010)
setGenome(tv, "hg38")
addBedTrackFromDataFrame(tv, "gwas", tbl.gwas19[, c(1, 3, 3)], color="red")
showGenomicRegion(tv, "chr19")
showGenomicRegion(tv, "chr19:44,374,461-45,372,413")

tbl.fpsim <- as.data.frame(gr.simfp)
tbl.fpsim.focused <- subset(tbl.fpsim, start > 44374450 & end < 45372420)[, c(1,2,3)]
addBedTrackFromDataFrame(tv, "fp.sim", tbl.fpsim.focused, color="blue")
tbl.gwas19[, c(1, 3, 3)], color="red")

tbl.fp.focused <- subset(tbl.fp, start > 44374450 & endpos < 45372420) [, c(2,3,4)]
addBedTrackFromDataFrame(tv, "fp", tbl.fp.focused, color="darkgreen")



*-----------------------------------------------------------------------------------------------------------------------
* running chia.systemsbiology.net (5 sep 2017)

  --- on eager
    ssh pshannon@eager.systemsbiology.net   doug fir, version 3
    cd ~/github/clevelandHighSchool
    git pull    # get latest version of index.common
    cd webapps/current

   --- find old process, kill it, start new
    ps x | grep run
    8824 ?        S      1:53 /usr/lib64/R/bin/exec/R -f runCleveland.R

   nohup R -f runCleveland.R


*-----------------------------------------------------------------------------------------------------------------------
* trena/trenaViz demo for hmaid (4 sep 2017)

  possibly interesting results?

  --- hamid says

    I can confirm that TCF7 expression is known to be high in naive
    cells ("N" samples) and then go down sharply over time. It is
    thought that EZH2 and the Polycombe Repressor complex are involved
    in that repression. We can use this info to select the most
    plausible candidate co-regulators.

    Additionally, we can prioritize candidate regulators by selecting
    those already in my network (or directly interacting with them, if
    necessary).

    BTW, TCF7 and another gene - BCL6 - are in a positive feedback
    (mutually activating) loop, and BCL6 is also high in naive cells
    and then declines over time. So it would be interesting to see if
    any candidate regulators co-regulate both genes.

    One complicating issue is that both BCL6 and TCF7 are themselves
    repressors when acting alone. They become activators through the
    action of co-factors that bind _them_ (not necessarily
    DNA-binding). For TCF7, the activating co-factor is beta-catenin,
    which is activated by WNT signaling. BCL6 tends to act by
    out-competing other DNA-binding TFs.

    ----

   NATURE IMMUNOLOGY | ARTICLE (June 2015)

    LEF-1 and TCF-1 (aka LEF1 & TCF7) orchestrate TFH differentiation by regulating
    differentiation circuits upstream of the transcriptional repressor Bcl6

   head(tbl.geneModel)
        gene   beta.lasso lasso.p.value pearson.coeff     rf.score  beta.ridge spearman.coeff concordance    pcaMax
        LEF1  0.336696639  1.093581e-08     0.9271825 24.474555836  0.02876639     0.87504103   0.4616362 2.5637600
       FOXP1  0.530204004  5.420291e-08     0.9006827 13.383763620  0.09014859     0.89211073   0.5800644 2.2109767
       ARNT2 -0.008488160  9.658097e-05    -0.8637621 22.036353175 -0.02249347    -0.80056802   0.6257747 1.9598855
        TLX2  0.000000000  1.000000e+00    -0.2968107  0.011702321 -0.32006168    -0.27735010   0.5506956 1.8411414
         HLX -0.063131220  7.760001e-07    -0.8535354  3.914422177 -0.03149307    -0.83958858   0.5509229 1.3229453
        KLF2  0.000000000  1.566211e-04     0.8682252 10.728938451  0.04250484     0.82405077   0.4700648 1.3055301
       FOXN3  0.000000000  2.308095e-04    -0.7317324  3.790987550 -0.13857376    -0.68092789   0.4066082 1.2055869
       FOXO1  0.000000000  2.356756e-04     0.8493228  5.402958188  0.07836379     0.94156910   0.4831901 1.1707793
        HHEX  0.000000000  1.000000e+00    -0.8206347 11.392134236 -0.03501994    -0.88663968   0.5114109 1.1554832
        PAX9 -0.002826544  5.888288e-06    -0.7868435  2.197140009 -0.03479626    -0.75686853   0.4943390 1.1396958

*-----------------------------------------------------------------------------------------------------------------------
* trena/trenaViz demo for hamid (3 sep 2017)

   cd ~/github/projects/external/hamid/TcellDevelopment/

   ---
   --- already have ataq-seq, now need rna-seq
   overall project here: https://www.ncbi.nlm.nih.gov/geo/query/acc.cgi?acc=GSE89309

   --- one file, and its annotation

     Public on May 17, 2017
     Title	Transcriptome analysis of tumor-specific CD8 T cells in murine solid tumors
     Organism	Mus musculus
     Experiment type	Expression profiling by high throughput sequencing
     Summary	RNAseq analysis of CD8 T cells becoming dysfunctional in progressing tumors.
                The overall goal of this study was to elucidate the molecular program that
		mediates functional unresponsiveness in tumor-specific CD8 T cells. In comparison,
		we also investigated CD8 T cells differentiating to functional effector and memory
		T cells during an acute listeria infection.


   https://www.ncbi.nlm.nih.gov/geo/download/?acc=GSM2365761&format=file&file=GSM2365761%5FRNA%5FN1%5FnormalizedCounts%2Etxt%2Egz
   https://www.ncbi.nlm.nih.gov/geo/download/?acc=GSM2365762&format=file&file=GSM2365762%5FRNA%5FN2%5FnormalizedCounts%2Etxt%2Egz
   https://www.ncbi.nlm.nih.gov/geo/download/?acc=GSM2365763&format=file&file=GSM2365763%5FRNA%5FN3%5FnormalizedCounts%2Etxt%2Egz


   see ~/github/projects/external/hamid/TcellDevelopment/explore.R
   uses first 6 samples (3 naive, 3 L5) crudely mapping mouse to human genes (to pick up motifs) by
   uppercase transformation only.   most were lost when using inparanoid mapping through protein ids.

   dim(mtx.rna)#  [1] 20148     6



*-----------------------------------------------------------------------------------------------------------------------
* abstract for children's talk (1 sep 2017)

Tools for Navigating a Data Lake

Biologists and clinicians, having deep knowledge of the domains in which
they practice, stand to benefit from easy access to many kinds of molecular
data and algorithms.  To become relevant, however, these must be selectively
extracted, judiciously combined, and then presented so that the
researcher can ask the often highly specific questions which arise in
each research project.

The software and data science skills required to do this are hard to
come by.  One solution is to employ a bioinformatician or
computational biologist per project or research group.  A practicing
biologist may invest the time to acquire the necessary programming
skills.  Most common, perhaps, is the ad hoc use of spreadsheets and
public web sites, with consequent problems of reproducibility and
depth of analysis.

I will present a middle path, using "notebooks", an approach which has
become very popular in many scientific communities.  Juypter and
RStudio both support high-level documents -- notebooks with code,
data, documentation and interactive graphics.  Installation and execution of
the code, and access to data becomes easy for the biologist.  Research
reproducibility and easier collaboration often result.  Notebooks also
offer a safe environment in which a motivated biologist can learn
computational skills as time and interest permit.

I will demonstrate this approach using a "trena" notebook from our
work at the ISB, along with "trenaViz".  These two R packages,
accompanied by project-specific notebooks, help to identify
transcriptional regulatory networks, by combining DNAse I footprints,
ATAQ-seq, motifs describing TF binding, and microarray or RNA-seq
expression data, along with a wide assortment of feature selection
algorithms (including random forest and a variety of LASSO variants).

If time permits, I will also show new work for exploring the impact of
DNA coding variants upon 3D protein structure.


*-----------------------------------------------------------------------------------------------------------------------
* webpack tips, learning, tutorial (30 aug 2017)

   https://www.ag-grid.com/ag-grid-understanding-webpack/
   cd ~/github/projects/examples/webpack/simpleMath/

   dist/bundle.js
   index.html
   src/index.js, multiply.js, sum.js
   webpack.config.js:
      var path = require('path');
      module.exports = {
         entry: './src/index.js',
         output: {
            path: path.resolve(__dirname, './dist/'),
            filename: 'bundle.js'
            }
        }

   ---- bundle.js
     (function(modules) {   // an anonymous function, executed on a list of modules (3 in this example)
         var installedModules = {};
         function __webpack_require__(moduleId){
            ...
	    }
	 return __webpack_requore__(0);
        })
     ([(function(module, exports){  // module 0
          var sum = function (a, b) {return a + b;};
          module.exports = sum;
          }),
       (function(module, exports, __webpack_require__) { // module 1
          var sum = __webpack_require__(0);
          var multiply = function (a, b) {
          var total = 0;
          for (var i = 0; i < b; i++) {
             total = sum(a, total);
             }
          return total;
          };
          module.exports = multiply;
          }),
       (function(module, exports, __webpack_require__) { // module 2
          var multiply = __webpack_require__(1);
          var sum = __webpack_require__(0);
          var totalMultiply = multiply(5, 3);
          var totalSum = sum(5, 3);
          console.log('Product of 5 and 3 = ' + totalMultiply);
          console.log('Sum of 5 and 3 = ' + totalSum);
          })
        ]);


*-----------------------------------------------------------------------------------------------------------------------
* trenaViz windows tips (29 aug 2017)

  --- on porch, the pricelab windows 7 laptop
    R is installed here:
        "C:/Program Files/R/R-3.5.1/bin/R.exe"
    start interactive shell (in git bash shell):
        "C:/Program Files/R/R-3.5.1/bin/R.exe" --no-save

  start up git bash shell
  start up RStudio
  source("paul/test_tv.R")
  runTests()

  --- test_tv.R
    library(trenaViz)
    source(system.file(package="trenaViz", "unitTests", "test_trenaViz.R"))

*-----------------------------------------------------------------------------------------------------------------------
* GO filter example, get all genes mapped to a term AND its subterms (29 aug 2017)

    library(org.Hs.eg.db)

      #  GO:0010467                        gene expression
      #  GO:0097659   nucleic acid-templated transcription
      #  GO:0001172           transcription, RNA-templated
      #  GO:0006351           transcription, DNA-templated

    term0 <- "GO:0010467"
    term1 <- "GO:0097659"
    term2 <- "GO:0001172"
    term3 <- "GO:0006351"



    length(unique(unlist(mget(term0, env = org.Hs.egGO2ALLEGS), use.names=FALSE)))   # 5247
    length(unique(unlist(mget(term1, env = org.Hs.egGO2ALLEGS), use.names=FALSE)))   # 3775
    length(unique(unlist(mget(term2, env = org.Hs.egGO2ALLEGS), use.names=FALSE)))   # 2
    length(unique(unlist(mget(term3, env = org.Hs.egGO2ALLEGS), use.names=FALSE)))   # 3756


*-----------------------------------------------------------------------------------------------------------------------
* m4 tips, backticks

   --- backticks: a quick hack
   some print statements, in i.e. javascript, use backticks so that appear in the printed form
   cd  ~/s/examples/m4/backticks/
   cat file-with-backticks.txt
      util.error('Can not create element with invalid string ID `' + data.id + '`');
   sed s/\`//g file-with-backticks.txt
      util.error('Can not create element with invalid string ID ' + data.id + '');

*-----------------------------------------------------------------------------------------------------------------------
* webpack font-awesome (27 aug 2017)

   ~/github/trenaViz/inst/browserCode/src/css/font-awesome.min.css

   can be included via
      import css from './css/trenaviz.css';
   but that css file tries to load font files from default location http://localhost:8000/...
   a special webpack font loader might be needed
   maybe clustergrammer webpack.config.js has the answer?

*-----------------------------------------------------------------------------------------------------------------------
* html tips: scrolling

  ~/github/projects/examples/html/scrollingDiv/scrollingDiv.html

#outerDiv{
   margin: 100px;
   border-style: solid;
   border-width: 5px;
   border-color: lightblue;
   border-radius: 10px;
   overflow-x: scroll;
   overflow-y: scroll;
   height:400px;
   }

 <div id="outerDiv">
   <img src="clustergrammer.png" height="600"></img>
 </div>

   see also, using igv.js:
     ~/github/projects/examples/js/igvBareBones/hg38-scrolling.html

*-----------------------------------------------------------------------------------------------------------------------
* igv.js reference tracks (27 aug 2017)

  --- jim's suggestion for explicit creation of hg38 reference
   fasta
     https://s3.amazonaws.com/igv.broadinstitute.org/genomes/seq/hg38/hg38.fa
     https://s3.amazonaws.com/igv.broadinstitute.org/genomes/seq/hg38/hg38.fa.fai

    cytoband
      https://s3.amazonaws.com/igv.broadinstitute.org/annotations/hg38/cytoBandIdeo.txt

    for an annotation track you can use
      https://s3.amazonaws.com/igv.broadinstitute.org/annotations/hg38/genes/gencode.v24.annotation.sorted.gtf.gz
      https://s3.amazonaws.com/igv.broadinstitute.org/annotations/hg38/genes/gencode.v24.annotation.sorted.gtf.gz.tbi


  --- claimed support actually not yet offered
   jim claims that fasta and cytoband tracks automatically provided by from s3 for mm9/10, hg19/38
   but in fact
              reference: {id: "mm10"},

   https://s3.amazonaws.com/igv.broadinstitute.org/annotations/hg38/hg38_annotations.xml

   --- jim robinson https://github.com/igvteam/igv.js/issues/363

     There is not a list per se, but its easily discoverable. First step is the "data server registry" file for the
     genome, a flat list of xml files. For genomes of interest

       http://data.broadinstitute.org/igvdata/hg18_dataServerRegistry.txt
       http://data.broadinstitute.org/igvdata/hg19_dataServerRegistry.txt
       http://data.broadinstitute.org/igvdata/hg38_dataServerRegistry.txt

    Then look through the XMLs listed. For your purposes the "annotation" xml is probably the most interesting, for example

      http://www.broadinstitute.org/igvdata/annotations/hg18/hg18_annotations.xml

    Its might also be helpful to run IGV desktop, select a genome, then select "File > Load from server" to see what is there.
    hg38 leads to this: http://www.gencodegenes.org/releases/27.html











*-----------------------------------------------------------------------------------------------------------------------
* jupytercon jupyterhub-tutorial (23 aug 2017)


   conda install -c conda-forge jupyterhub
   conda install notebook

  jupyterhub -h
  confirurable-http-proxy -h

  conda-forge: communidty managed conda packages

  pip install dockerspawner
  docker pull jupyterhub/singleuser:0.7
  /Applications/Docker.app/Contents/MacOS/Docker pull jupyterhub/singleuser:0.7

 use ssl: wget https://dl.eff.org/crebot-auto: free ssl for any domain



*-----------------------------------------------------------------------------------------------------------------------
* jupytercon prep (21 aug 2017)

  --- before any updates
    jupyter --version      # 4.2.1
    jupyter lab --version  # 0.25.1

   --- do update
    conda update -c conda-forge jupyter
    jupyter --version      # 4.2.1
    conda update -c conda-forge jupyterlab
    jupyter lab --version  # 0.26.5

*-----------------------------------------------------------------------------------------------------------------------
* jquery-ui and webpack (18 aug 2017)

   https://github.com/jzaefferer/webpack-jquery-ui
   also see extensive notes below

*-----------------------------------------------------------------------------------------------------------------------
* html tips   emacs html mode

  balance tabs, in html mode:  sit on the opening tag, then ^c ^f
*-----------------------------------------------------------------------------------------------------------------------
* isb hr howtos (17 aug 2017)

PTO REQUESTS and PAY STUBS in Paychex Flex
Go to https://www.paychexflex.com and log in.

HOW TO VIEW YOUR PAID TIME OFF BALANCES
•	From your dashboard, Select Time Off, View Details
HOW TO REQUEST PTO
•	Click on Human Resources from the menu
•	Under My Info, click on Compensation
•	Select Attendance/Time Off
•	Click the “Add” button to enter a PTO request
HOW TO VIEW YOUR PTO REQUESTS
•	Click on Human Resources from the menu
•	Under My Info, click on Compensation
•	Select Attendance/Time Off: See current PTO balances and submitted requests (you can sort them)
•	Select Options, Display Requests: See pending requests and PTO history (approved/declined/ cancelled requests)
HOW TO VIEW YOUR PAYSTUBS
•	Click on the Dashboard.  Your most recent 3 checkstubs will be displayed (pdfs)
•	To see earlier paystubs, select View All. These go back to 10/30/2015.
•	To view older paystubs (10/15/15 and earlier), go to Human Resources, then select the Compensation Menu and select Check History.
SUPERVISORS: HOW TO VIEW AND APPROVE PTO REQUESTS
•	Click on Human Resources from the menu
•	Click the More option in the menu and select HR Admin.
•	Click Notifications, then Time Off Requests.


*-----------------------------------------------------------------------------------------------------------------------
* pairserver, pshannon.net

    ssh paulshannnon@paulshannnon.pairserver.com; date
    cd ~/github/howDaylightWasStolen-harryMoses/current/harryMoses/howDaylightWasStolen/
    scp daylight-short.html paulshannnon@pshannon.net:tmp/

   date; ssh paulshannnon@paulshannnon.pairserver.com; date
*-----------------------------------------------------------------------------------------------------------------------
* mark from bdds chicago adds wellington_20 to the publicly facing footprint database (15 aug 2017)

 PGPASSWORD=trena psql bone_element_wellington_20 --host=bddsrds.globusgenomics.org --port=5432 --username=trena
library(RPostgreSQL)
database.host <- "bddsrds.globusgenomics.org"
# dbName <- "brain_hint"
dbName <- "bone_element_wellington_20"
db.fp <- dbConnect(PostgreSQL(), user= "trena", password="trena", dbname=dbName, host=database.host)
dbGetQuery(db.fp, "select * from hits limit 3")
t(dbGetQuery(db.fp, "select * from hits limit 3"))
           1                                    2                                    3
loc        "chr9:385991-386001"                 "chr9:735380-735390"                 "chr9:2469858-2469868"
fp_start   " 385971"                            " 735376"                            "2469838"
fp_end     " 385996"                            " 735401"                            "2469861"
type       "motif.in.footprint"                 "motif.in.footprint"                 "motif.in.footprint"
name       "Hsapiens-jaspar2016-RUNX1-MA0002.1" "Hsapiens-jaspar2016-RUNX1-MA0002.1" "Hsapiens-jaspar2016-RUNX1-MA0002.1"
length     "11"                                 "11"                                 "11"
strand     "-"                                  "+"                                  "-"
sample_id  "ENCSR000EMH"                        "ENCSR000EMH"                        "ENCSR000EMH"
method     "WELLINGTON"                         "WELLINGTON"                         "WELLINGTON"
provenance "bone_element_wellington_20.minid"   "bone_element_wellington_20.minid"   "bone_element_wellington_20.minid"
score1     "-13.02510"                          "-41.33410"                          " -4.54585"
score2     "11.4157"                            "12.1910"                            "12.1236"
score3     "6.92e-05"                           "4.08e-05"                           "4.27e-05"
score4     NA                                   NA                                   NA
score5     NA                                   NA                                   NA
score6     NA                                   NA                                   NA
>



*-----------------------------------------------------------------------------------------------------------------------
* cory's rstudio notebook, snps for lizBlue (3 aug 2017)

   ~/github/coryCodeGrabBag/lizBlue/familyAD/exploreSnps.Rmd

*-----------------------------------------------------------------------------------------------------------------------
* pair networks, pshannon.net (15 aug 2017)

   pshannon.net has successfully been added to your pair Networks Web hosting account.
   Your domain's IP address is: 216.146.223.24
   Your name servers are:
     ns0.ns0.com	(IP Address: 209.197.64.1)
     dns2.pair.com	(IP Address: 216.146.195.24)
     The domain is mapped to /usr/home/paulshannnon/public_html/pshannon.net/

*-----------------------------------------------------------------------------------------------------------------------
* bdds deliverables

  publicly-facing databases: hint, wellington, 16/24 * how many tissues
     brain, hint, lymphoblast
     piq: segun working on this, may not be delivered
  paper submitted: oct 1
  rory's notebooks
  matt working on figures for paper
  MotifDb: gene<->motif mapping
           motif similarity sparse matrix

*-----------------------------------------------------------------------------------------------------------------------
* httpuv, startDaemonizedServer, close port, kill port connection (14 aug 2017)

   Error in startServer(host, port, app) : Failed to create server

   --- rather than netstat, use lsof
      brew install lsof  -> /usr/local/bin/lsof



    lsof -i -n -P | grep TCP


*-----------------------------------------------------------------------------------------------------------------------
* RClustergrammer, better control of tree for the 11-step navigator (14 aug 2017)

  https://stackoverflow.com/questions/7404035/how-to-plot-dendrograms-with-large-datasets

  hc <- hclust(dist(USArrests)); hcd <- as.dendrogram(hc)
  str(hcd)


*-----------------------------------------------------------------------------------------------------------------------
* martin shelton's neuronal single cell data (13 aug 2017) as an RStudio notebook

  cd ~/github/projects/external/martinShelton/neuronSingleCell

*-----------------------------------------------------------------------------------------------------------------------
* martin shelton's neuronal single cell data (10 aug 2017)

  cd ~/s/work/priceLab/martinShelton/singleCellNeuronData/
  tbl <- read.table("~/s/work/priceLab/martinShelton/singleCellNeuronData/neuron.dg2.all.txt", sep="\t", as.is=TRUE, nrow=-1, header=TRUE)
  mtx <- as.matrix(tbl[, 2:ncol(tbl)])
  rownames(mtx) <- sub("qpcr-", "", tbl[,1])
  dim(mtx)
*-----------------------------------------------------------------------------------------------------------------------
* refactored BrowserVizDemo now working, using npm for all javascript, webpack to assemble (9 aug 2017)

  cd ~/github/BrowserVizDemoApp/

  --- depends upon ~/github/BrowserVizJS, a node package, package.json and browserviz.js:

      var BrowserViz = {
          onDocumentReadyFunctions:  [],
          name: "node BrowserViz",
          ...
	  }
      module.exports = BrowserViz;

    # used in ~/github/BrowserVizDemoApp/inst/browserCode/src/browservizdemo.js:
      var hub = require("browservizjs")


  --- to run
   cd ~/github/BrowserVizDemoApp/inst/browserCode
   make
      npm update
      webpack
      (cd ./dist; m4 -P browservizdemo.html-template > browservizdemo.html)
      ls -l ./dist/browservizdemo.html
      (cd ../../..; R CMD build --no-build-vignettes BrowserVizDemoApp)
      (cd ../../..; R CMD INSTALL `ls -at BrowserVizDemo_* | head -1`)

   cd ~/github/BrowserVizDemoApp/inst/unitTests
     in tsh-bvNode
     source("test_BrowserVizDemo.R");
     app <- BrowserVizDemo(PORT.RANGE)
     checkTrue(ready(app))
     checkEquals(ping(app), "pong")
     title <- "simple xy plot test";
     setBrowserWindowTitle(app, title)
     checkEquals(getBrowserWindowTitle(app), title)
     plot(app, 1:10, (1:10)^2)
       # no selection yet


*-----------------------------------------------------------------------------------------------------------------------
* chrome tips: autopen javascript console

   /Applications/Google\ Chrome.app/Contents/MacOS/Google\ Chrome --auto-open-devtools-for-tabs

*-----------------------------------------------------------------------------------------------------------------------
*-----------------------------------------------------------------------------------------------------------------------
* bug.  todo.  close all postgres database connections in trena (4 aug 2017)

      db.connections <- dbListConnections(RPostgreSQL::PostgreSQL())
      lapply(db.connections, dbDisconnect)


*-----------------------------------------------------------------------------------------------------------------------
* do footprints truly help with unexplanined intergenic snps? (4 aug 2017) for cory's paper

  cd ~/github/projects/priceLab/gwasADfootprintEnrichment/
   table(tbl.gwas$CHR)

    chr1 chr10 chr11 chr12 chr13 chr14 chr15 chr16 chr17 chr18 chr19  chr2 chr20 chr21 chr22  chr3  chr4  chr5  chr6  chr7  chr8  chr9
   33885 19550 21696 20646 13870 14325 14564 15641 16122 10084 11624 35350  9607  5179  5971 27104 30036 27264 36177 27105 24237 18572



*-----------------------------------------------------------------------------------------------------------------------
* categorize microglial genes for omar's clustergrammer demo (3 aug 2017)

  cd ~/github/projects/priceLab/cory/microglialGeneCategorization/
  print(load("mtx.microglial.RData")) # "mtx.microglial"
  dim(mtx.microglial) # [1] 302 264
  goi <- rownames(mtx.microglial)


print(load("mtx.microglial.RData")) # "mtx.microglial"
dim(mtx.microglial) # [1] 302 264
source("~/s/data/public/human/symToGeneID.R"); test_assignGeneIDs()
genes <- rownames(mtx.microglial)
symbol.entrez.map <- assignGeneIDs(genes)$mapped
tbl.go <- select(org.Hs.eg.db, keys=genes, keytype="SYMBOL", columns=c("SYMBOL", "GO"))
tbl.go.bp <- subset(tbl.go, ONTOLOGY=="BP")   # 3636 rows
tbl.go.bp.tasFirst <- tbl.go.bp[order(tbl.go.bp$EVIDENCE, decreasing=TRUE),]
tbl.x <- tbl.go.bp.tasFirst[match(genes, tbl.go.bp.tasFirst$SYMBOL),]
go.params <- new("GOHyperGParams", geneIds=unique(geneIDs),
                 universeGeneIds = gene.universe, annotation = "org.Hs.eg.db",
                 ontology = 'BP', pvalueCutoff = 0.05, conditional = FALSE,
                 testDirection = "over")
go.bp.hgr <- hyperGTest(go.params)
tbl.goBP <- summary(go.bp.hgr)

go.cats <- list()
unassigned.genes <- genes

for(i in 1:nrow(tbl.goBP)){
   goid <- tbl.goBP$GOBPID[i]
   goTerm <- tbl.goBP$Term[i]
   bp.geneIDs <- unique(unlist(mget(goid, env = org.Hs.egGO2ALLEGS), use.names=FALSE))
   bp.symbols <- unlist(mget(bp.geneIDs, env=org.Hs.egSYMBOL), use.names=FALSE)
   genes.this.term <- intersect(unassigned.genes, bp.symbols)
   if(length(genes.this.term) > 0){
      go.cats[[goTerm]] <- genes.this.term
      unassigned.genes <- setdiff(unassigned.genes, genes.this.term)
      }
   } # for i


processes.expanded <- unlist(lapply(names(go.cats), function(name) rep(name, length(go.cats[[name]]))))
genes.assigned <- unlist(go.cats, use.names=FALSE)
genes.unassigned <- setdiff(genes, genes.assigned)
processes.expanded <- c(processes.expanded, rep("unassigned", length(genes.unassigned)))
genes.assigned <- c(genes.assigned, genes.unassigned)
length(genes.assigned); length( processes.expanded)

tbl.GO <- data.frame(process=processes.expanded, stringsAsFactors=FALSE)
rownames(tbl.GO) <- genes.assigned


*-----------------------------------------------------------------------------------------------------------------------
* isb expense reimbursement form (31 jul 2017)

  https://intranet.systemsbiology.net/Plone/administration/finance/finance-accounts-payable/
   choose from left menut: "Expense Reimbursement Formt" an xlsx spreadsheet

*-----------------------------------------------------------------------------------------------------------------------
* create tomtom MotifDb pfm similarity sparse matrix matt's tomtom.txt (18 sep 2017)

  cd ~/github/projects/motifDb/tomtom
  scp pshannon@khaleesi:/ssd/mrichard/data/TOMTOM/all_MotifDb_results/tomtom.txt .
  tbl <- read.table("tomtom.txt", sep="\t", nrow=-1, as.is=TRUE)   # [1] 3963410      10
  save(tbl, file="tbl.RData")
     -rw-r--r--  1 paul  staff   81213283 Sep 18 14:51 tbl.RData
     -rw-r--r--  1 paul  staff  535197180 Sep 18 14:44 tomtom.txt

  tbl <- read.table("tomtom.txt", sep="\t", nrow=-1, as.is=TRUE)
  dim(tbl) # [1] 3963410      10
  colnames(tbl)[1:4] <- c("a", "b", "xx", "pval")
  fivenum(tbl$pval)   # [1] 0.00000000 0.00031219 0.00380397 0.01659200 0.14829900

    # more plausible are 4 and 6
   fivenum(tbl$V4) # [1] 0.00000000 0.00031219 0.00380397 0.01659200 0.14829900
   fivenum(tbl$V5) # [1]    0.00000    2.61272   31.83540  138.85800 1241.11000
   fivenum(tbl$V6) # [1]  0.0000000  0.0173034  0.1467830  0.3290130 0.4999990

   ---- try putting this into a sparse matrix
     library(Matrix)
     packageVersion("Matrix") # [1] ‘1.2.11’

   ---- quick test of usage, resulting size (1.5% of regular matrix
    smtx <- rsparsematrix(1000, 1000, density=0.01)
    object.size(smtx)                         #   125424 bytes
     mtx <- matrix(0, nrow=1000, ncol=1000)
    object.size(mtx)                           # 8000200 bytes

   --- test of expected full size: can it fit within a bioc package?
      length(unique(c(tbl$a, tbl$b))) # [1] 8369
      matrix.names <- sort(unique(c(tbl$a, tbl$b)))
      smtx <- rsparsematrix(nrow=8369, ncol=8369, nnz=3963410)
       mtx[tbl$a, tbl$b] <- tbl$pval

   --- learn something of tomtom
     library(MotifDb)
     mdb.jaspar2016.human <- query(query(MotifDb, "hsapiens"), "jaspar2016")

     http://meme-suite.org/tools/tomtom
     query(query(MotifDb, "hsapiens"), "MA0511.1")[[2]]

0.09322034 0.1553672 0.14218456 0.1139360 0.1167608 0.07062147 0.008474576 0.0000000000 0.014124294  0 0.000000000 0.00000000 0.03954802 0.242937853 0.1186441
0.12523540 0.1120527 0.07438795 0.1619586 0.1459510 0.36911488 0.003766478 0.0009416196 0.002824859  0 0.000000000 0.12429379 0.17890772 0.007532957 0.1186441
0.41713748 0.4180791 0.40112994 0.4491525 0.2306968 0.12523540 0.010357815 0.9698681733 0.000000000  1 0.998116761 0.08474576 0.14877589 0.134651601 0.4350282
0.36440678 0.3145009 0.38229755 0.2749529 0.5065913 0.43502825 0.977401130 0.0291902072 0.983050847  0 0.001883239 0.79096045 0.63276836 0.614877589 0.3276836

    paste the above 4 lines into the tomtom webform:  http://meme-suite.org/tools/tomtom
    select target motifs: JASPAR CORE and UniPROBE Mouse

   --- matches
      MA0511.1: 2.36e-28
      MA0002.2: 8.84e-10
      MA0073.1: 3.12e-06
     UP00025_2: 3.87e-05
      MA242.1:  1.42e-04

   --- suggesting our sparse matrix could have the following number of significant values

     nrow(subset(tbl, pval < 10e-4))    1355004
     nrow(subset(tbl, pval < 10e-10))     54188
     nrow(subset(tbl, pval < 10e-8))     118607
     nrow(subset(tbl, pval < 10e-7))     204080
     nrow(subset(tbl, pval <= 10e-5))    731413
     nrow(subset(tbl, pval <= 10e-1))   3963410

   object.size(rsparsematrix(nrow=8369, ncol=8369, nnz=54188))   685152 bytes
   object.size(rsparsematrix(nrow=8369, ncol=8369, nnz=118607)) 1458184 bytes
   object.size(rsparsematrix(nrow=8369, ncol=8369, nnz=204080)) 2483856
   object.size(rsparsematrix(nrow=8369, ncol=8369, nnz=731413)) 8811856 bytes

    MotifDb already very close to bioc pkg max of 4MB: 3,987,611 Sep 18 16:15 MotifDb_1.19.7.tar.gz
    so adding a similarity matrix of .6MB or more may not be possible.


*-----------------------------------------------------------------------------------------------------------------------
* create tomtom upperdiagonal matrix from matt's tomtom.txt (31 jul 2017)

   read.table("tomtom.txt", sep="\t", nrow=3, as.is=TRUE)
                                     V1                                                V2 V3          V4          V5          V6 V7       V8       V9 V10
    1 Scerevisiae-cispb_1.02-M0001_1.02                 Scerevisiae-cispb_1.02-M0001_1.02  0 3.40815e-19 2.85228e-15 5.70138e-15  8 TTATCACT TTATCACT   +
    2 Scerevisiae-cispb_1.02-M0001_1.02                 Scerevisiae-ScerTF-DAL80-harbison  0 2.10796e-06 1.76415e-02 1.76316e-02  5 TTATCACT    TTATC   -
    3 Scerevisiae-cispb_1.02-M0001_1.02 Dmelanogaster-FlyFactorSurvey-So_Cell_FBgn0003460 -1 1.45161e-04 1.21485e+00 4.00760e-01  7 TTATCACT  TATCATT   -

  tbl <- read.table("tomtom.txt", sep="\t", nrow=-1, as.is=TRUE)
  dim(tbl) # [1] 3963410      10
  colnames(tbl)[1:4] <- c("a", "b", "xx", "pval")
  fivenum(tbl$pval)   # [1] 0.00000000 0.00031219 0.00380397 0.01659200 0.14829900

    # more plausible are 4 and 6
   fivenum(tbl$V4) # [1] 0.00000000 0.00031219 0.00380397 0.01659200 0.14829900
   fivenum(tbl$V5) # [1]    0.00000    2.61272   31.83540  138.85800 1241.11000
   fivenum(tbl$V6) # [1]  0.0000000  0.0173034  0.1467830  0.3290130 0.4999990

  length(unique(c(tbl$a, tbl$b))) # [1] 8369
  matrix.names <- sort(unique(c(tbl$a, tbl$b)))
  mtx <- matrix(1.0, nrow=8369, ncol=8369, dimnames=list(matrix.names, matrix.names))
  mtx[tbl$a, tbl$b] <- tbl$pval



*-----------------------------------------------------------------------------------------------------------------------
* RCyjs history

  devel branch:  version 1.9.4  (31 jul 2017): staticViewTemplate buttons now work.  uses latest cy.js 3.1.4

*-----------------------------------------------------------------------------------------------------------------------
* clustergrammer: add column and row groups to the display (27 jul 2017)

  cd ~/github/heatmap/clustergrammer/matrixToClusteredJSON/
  result: file:///Users/paul/github/heatmap/clustergrammer/matrixToClusteredJSON/index.html

  filename = "tiny2.tsv"
  from clustergrammer import Network
  net = Network()
  net.load_file(filename)

  net.add_cats('row',
      [{'title':'ODD',
        'cats':{'true':['R1','R3']}},
       {'title':'BIG',
        'cats':{'true':['R3']}}
      ])

  net.add_cats('col',
      [{'title':'ODD',
        'cats':{'true':['C1','C3']}},
       {'title':'BIG',
        'cats':{'true':['C3']}}
      ])

  net.cluster()
  net.export_net_json()


*-----------------------------------------------------------------------------------------------------------------------
* first clustergrammer gene expression matrix for omar, from cory (26 jul 2017)

  cd ~/s/work/priceLab/cory/AD-clusters-from-sage

  /local/Cory/Alzheimers/synapse.windsorized/mayo.tcx.RData
  /local/Cory/trn/genome-scale-trn/new.sage/*.csv

  For the gene lists, just read them into R and pull out the column named "external_gene_name"

     958 astro_consensusdarkolivegreenTCX.csv
     722 cer_downinad_consensuspurpleCBE.csv
     234 cer_upinad_consensuslightcyanDLPFC.csv
     448 endo_consensusblackCBE.csv
     316 microg_consensussalmonIFG.csv
     354 myelin_consensustanCBE.csv
     804 neuron_consensusroyalblueSTG.csv


*-----------------------------------------------------------------------------------------------------------------------

* todo (24 jul 2017)

  deposit fosp check
  auto deposit for bob and tony
  matrices for rich
  model notation for max
  reimbursement for jupytercon delta flight
  single snp for liz blue
  guitar repair insurance

*-----------------------------------------------------------------------------------------------------------------------
*-----------------------------------------------------------------------------------------------------------------------
*-----------------------------------------------------------------------------------------------------------------------
*-----------------------------------------------------------------------------------------------------------------------
* leo's champlin guitar repair (25 jul 2017)

  sent photos of crack and invoice today to Traci.Hernandez@thehartford.com
  Shannon P - Claim CP17469414 [CONFIDENTIAL]

*-----------------------------------------------------------------------------------------------------------------------
* minerva trem2 snp (24 jul 2017)

   chr6:41182853 A>C

   Yes, it would be great if you could evaluate how this regulatory
   SNP alters TF binding based on TReNA. The SNP is rs9357347, located
   within a DNase hypersensitive site, and it is predicted to alter
   both SP1 and PPAR binding. It is located within sequence reported
   to be subject to enhancer-associated histone marks in the
   hippocampus.

   I'm copying Nilufer to keep her in the loop.

   Thank you! Minerva

   --- first developed minerva.R:

    cd ~/s/work/priceLab/cory/minerva-trem2-2017july


   --- moved to github
*-----------------------------------------------------------------------------------------------------------------------

* statistical formula notation in R (24 jul 2017)

   http://faculty.chicagobooth.edu/richard.hahn/teaching/formulanotation.pdf

*-----------------------------------------------------------------------------------------------------------------------
* restart dora after whovian reboot (24 jul 2017)

   --- microservices
     cd  ~/github/dora/microservices/skin-PnG
     nohup R -f trenaSkinServer.R &

   --- notebook server
     jupyter notebook --port=10001  --NotebookApp.token=
*-----------------------------------------------------------------------------------------------------------------------
* add two new expression matrices to dora-skin for rich (24 jul 2017)

   The two new matrices for Rich are on whovian:  /local/Cory/Alzheimers/synapse.windsorized
   They are the two RData files in that subdirectory.

   whovian, cd ~/github/dora/datasets/skin

*-----------------------------------------------------------------------------------------------------------------------
* Liz blue, trem2, trenaViz, enhancers (21 jul 2017)

  cd ~/s/work/priceLab/cory/lizBlue-trem2-2017jul

*-----------------------------------------------------------------------------------------------------------------------
* index and public-facing webserver on whovian (aka trena|pshannnon.systemsbiology.net) (26 sep 2017)

   /local/httpd/vhosts/pshannon/

*-----------------------------------------------------------------------------------------------------------------------
* track types in igv.js  (19 jul 2017)

   --- variable height regions

               {name: "igap gwas scores",
                  type: "wig",
                  format: "bedgraph",
                  min: 0,
                  max: 20,
                  url: 'http://pshannon.systemsbiology.net/hg38/variants/igap.bedgraph',
                  indexed: false,
                  //visibilityWindow: 1000000,
                  color: "#4400AA"
                  },

     chr1 1042813 1042813 1.46699097750451
     chr1 1063015 1063015 1.59465363982429
     chr1 1064776 1064776 1.77288491741087
     chr1 1065797 1065797 1.74184180665921


   --- bigWig (works with 1.0.9, 26 sep 2017)

    simple and general javascript solution: loadTrack seems to adapt to file type, maybe by file extension
    igv.browser.loadTrack(
      {url: 'https://s3.amazonaws.com/igv.broadinstitute.org/data/hg19/encode/wgEncodeBroadHistoneGm12878H3k4me3StdSig.bigWig',
       name: 'H3k4me3'
      })

    ~/github/projects/examples/js/igvBareBones/bigWig.html

 $(document).ready(function () {
    var igvDiv, options;
    igvDiv = $("#igvDiv")[0];
    options = {locus: "chr2:1-2000",
               minimumBases: 5,
               showRuler: true,
               reference: {id: "hg38"},
               tracks: [
                 {name: 'Gencode v24',
                       url: "https://s3.amazonaws.com/igv.broadinstitute.org/annotations/hg38/genes/gencode.v24.annotation.sorted.gtf.gz",
                  indexURL: "https://s3.amazonaws.com/igv.broadinstitute.org/annotations/hg38/genes/gencode.v24.annotation.sorted.gtf.gz.tbi",
                  format: 'gtf',
                  visibilityWindow: 2000000,
                  displayMode: 'EXPANDED'
                  },
                 {name: 'test.bw',
                  url: "http://pshannon.systemsbiology.net/experiments/test.bw",
		  color: "darkGeen"
		  },
                  {name: "Gm12878H3k4me3",
                   url: "https://s3.amazonaws.com/igv.broadinstitute.org/data/hg19/encode/wgEncodeBroadHistoneGm12878H3k4me3StdSig.bigWig",
		   color: "blue"
                  }

                 ]
              }; // options
        browser = igv.createBrowser(igvDiv, options);
    });




*-----------------------------------------------------------------------------------------------------------------------
* bio paragraph

I spent my twenties as a carpenter, eventually returning to college to
prepare for a second career as a scientific programmer, subsequently
working in a variety of disciplines: atmospheric chemistry,
psychoacoustics, mechanical engineering, radio astronomy, then
realized his long-held aspiration to work in biology and medicine by
joining the Insititute for Systems Biology in 2001.

For many years I have wandered in, and done some volunteer work in the
Magnificent Forest at Seward Park - a beautiful 120 acre old-growth
forest, a lucky remnant of the million acres of doug fir/cedar/hemlock
forests that once covered the Puget lowland.  A few years ago
a few of us noticed, started tracking and trying to figure out
a worrisome sword fern die-off, and account of which is available
here:  http://sewardparkswordferndieoff.blogspot.com/




*-----------------------------------------------------------------------------------------------------------------------
* samtools tips: subset a bam file (18 jul 2017)

   samtools view -b -h ENCSR000ENF.bam chr1 > out_chr1.bam
   samtools index out_chr1.bam
   samtools idxstats out_chr1.bam

*-----------------------------------------------------------------------------------------------------------------------
* piq & RSofia for cory (17 jul 2017)

  ----- RSofia first
     cd ~/s
     curl -O https://cran.r-project.org/src/contrib/Archive/RSofia/RSofia_1.1.tar.gz
     tar xvf RSofia_1.1.tar
     cd RSofia/
     R CMD install .
     version 1.1, 2011-09-06
     cd ~/s/RSofia/inst/unitTests/
     R -f runTests.R
        RUNIT TEST PROTOCOL -- Mon Jul 17 16:01:17 2017
        ***********************************************
        Number of test functions: 258
        Number of errors: 0
        Number of failures: 0

  --- now piq
     cd ~/github/piq-single
     # git clone https://bitbucket.org/thashim/piq-single.git
     git pull origin

     cd ~/github/piq-single/testers
     bash tester.sh


*-----------------------------------------------------------------------------------------------------------------------
* trena dhs regions from encode:  also retrieve data when ucsc has not provided database (17 jul 2017)

   --- see below "* aml trena demo for hamid (29 jun 2017)"
     I wonder why you didn't find the CD34 DNASE1 HS track. The file:
        wgEncodeUwDnaseCd34mobilizedPkRep1.narrowPeak.gz   (1.9M file)
     is available here: http://hgdownload.soe.ucsc.edu/goldenPath/hg19/encodeDCC/wgEncodeUwDnase/

   http://hgdownload.soe.ucsc.edu/goldenPath/hg19/encodeDCC/wgEncodeUwDnase/wgEncodeUwDnaseCd34mobilizedPkRep1.narrowPeak.gz
   did liftover



*-----------------------------------------------------------------------------------------------------------------------
* add other genomes to trenaViz igv (13 jul 2017)  mm10

   cd ~/github/projects/examples/js/igvBareBones/

   --- gencode: high quality reference gene annotation for human and mouse genomes
      https://www.gencodegenes.org/
      url: "http://pshannon.systemsbiology.net/mm10/gencode.vM14.basic.annotation.sorted.gtf.gz",
      indexURL: "http://pshannon.systemsbiology.net/mm10/gencode.vM14.basic.annotation.sorted.gtf.gz.tbi",

   ---- mouse: get genemodels and full genomic sequence
     reference data for igv:

        gunzipped GRCm38.primary_assembly.genome.fa.gz # need bgzip compression for
        R> bgzip("GRCm38.primary_assembly.genome.fa", "GRCm38.primary_assembly.genome.fa.gz")
        bash> samtools faidx GRCm38.primary_assembly.genome.fa   # index the ascii file.

     gencode:
       whovian, cd /local/httpd/vhosts/pshannon/mm10/
       bedtools sort -i gencode.vM14.basic.annotation.gtf > gencode.vM14.basic.annotation.sorted.gtf
       library(Rsamtools)
       bgzip("gencode.vM14.basic.annotation.sorted.gtf", "gencode.vM14.basic.annotation.sorted.gtf.gz")
       print(indexTabix("gencode.vM14.basic.annotation.sorted.gtf.gz", format="gtf"))
       print(indexTabix("gencode.vM14.basic.annotation.sorted.gtf.gz", format="gff"))
        [1] "gencode.vM14.basic.annotation.sorted.gtf.gz.tbi"


   --- igv options
          # note: no need to specify the indexURL which accompanies fastURL
       options = {locus: "5:88,621,548-88,999,827", //"22:40,000,000-40,200,000",
               minimumBases: 5,
               showRuler: true,
               reference: {id: "mm10",
                     fastaURL: "http://pshannon.systemsbiology.net/mm10/GRCm38.primary_assembly.genome.fa.gz",
                  cytobandURL: "http://pshannon.systemsbiology.net/mm10/cytoBand.txt"
                  },
               tracks: [
                 {name: 'Gencode vM14',
                   url: "http://pshannon.systemsbiology.net/mm10/gencode.vM14.basic.annotation.sorted.gtf.gz",
                  indexURL: "http://pshannon.systemsbiology.net/mm10/gencode.vM14.basic.annotation.sorted.gtf.gz.tbi",
                  format: 'gtf',
                  visibilityWindow: 2000000,
                  displayMode: 'EXPANDED'
                  },
                 ]
              }; // options



*-----------------------------------------------------------------------------------------------------------------------
* quick look at regulatory regions for alison (13 jul 2017)

   cd ~/github/projects/external/alison/

   gene of interest: CRH: https://www.ncbi.nlm.nih.gov/gene/1392
   This gene is produced in both the hypothalamus and placenta, but I believe operates under different
   levels of transcriptional regulation.

      10271992 Jul 12 16:26 GSM2400374_ENCFF326MMH_peaks_hg19.bed
          4798 Jul 12 16:23 GSM2400374_ENCLB356SYJ_README.txt

    --- from the README
       file name: ENCFF326MMH_peaks_hg19.bed.gz
       file encode accession: ENCFF326MMH
       status: released
       file format: bed
       file type: bed narrowPeak
       file size: 2232047
       md5sum: 3cc380cefa4be3328fbfec1061d6e264
       content md5sum: 2a9f16e3e382d143d516331f008e85aa
       output category: annotation
       output type: peaks
       assembly: hg19
       derived from: ENCFF894CSA.bam; ENCFF163ZHO

    --- the bed file
     bed format: chrom, start, end, name, score, strand
      1) chrom - Name of the chromosome (or contig, scaffold, etc.).
      2) chromStart - The starting position of the feature in the chromosome or scaffold. The first base in a chromosome is numbered 0.
      3) chromEnd - The ending position of the feature in the chromosome or scaffold. The chromEnd base is not included in the display of the feature. For example, the first 100 bases of a chromosome are defined aschromStart=0, chromEnd=100, and span the bases numbered 0-99.
      4) name - Name given to a region (preferably unique). Use '.' if no name is assigned.
      5) score - Indicates how dark the peak will be displayed in the browser (0-1000). If all scores were '0' when the data were submitted to the DCC, the DCC assigned scores 1-1000 based on signal value. Ideally the average signalValue per base spread is between 100-1000.
      6) strand - +/- to denote strand or orientation (whenever applicable). Use '.' if no orientation is assigned.
      7) signalValue - Measurement of overall (usually, average) enrichment for the region.
      8) pValue - Measurement of statistical significance (-log10). Use -1 if no pValue is assigned.
      9) qValue - Measurement of statistical significance using false discovery rate (-log10). Use -1 if no qValue is assigned.
     10) peak - Point-source called for this peak; 0-based offset from chromStart. Use -1 if no point-source called.

    read.table("GSM2400374_ENCFF326MMH_peaks_hg19.bed", sep="\t", nrow=3, as.is=TRUE)
         V1    V2    V3 V4 V5 V6 V7 V8 V9 V10
     1 chr1 10155 10305  .  0  . 32 -1 -1  75
     2 chr1 10175 10325  .  0  . 31 -1 -1  75
     3 chr1 10435 10585  .  0  . 84 -1 -1  75



*-----------------------------------------------------------------------------------------------------------------------
* hamid's T cell atac-seq multi-stage regulatory models: do atac regions vary across samples? (12 jul 2017)

  cd ~/github/projects/external/hamid/TcellDevelopment/

   head -2  *_1_*
   ==> GSM2365810_ATAC_L5_1_normalizedCounts.txt <==
   chr	start	end	symbol	refseqID	peak_annotation	L5_1
   chr1	9772732	9773228	1700034P13Rik	NR_040462	intergenic	113.379454745262

   ==> GSM2365814_ATAC_L7_1_normalizedCounts.txt <==
   chr	start	end	symbol	refseqID	peak_annotation	L7_1
   chr1	9772732	9773228	1700034P13Rik	NR_040462	intergenic	113.541653297377

   ==> GSM2365817_ATAC_L14_1_normalizedCounts.txt <==
   chr	start	end	symbol	refseqID	peak_annotation	L14_1
   chr1	9772732	9773228	1700034P13Rik	NR_040462	intergenic	125.268306286882

   ==> GSM2365820_ATAC_L21_1_normalizedCounts.txt <==
   chr	start	end	symbol	refseqID	peak_annotation	L21_2
   chr1	9772732	9773228	1700034P13Rik	NR_040462	intergenic	205.531637833183

    wc -l *_1_*
   75690 GSM2365810_ATAC_L5_1_normalizedCounts.txt
   75690 GSM2365814_ATAC_L7_1_normalizedCounts.txt
   75690 GSM2365817_ATAC_L14_1_normalizedCounts.txt
   75690 GSM2365820_ATAC_L21_1_normalizedCounts.txt

   --- email from hamid

    If this invariance also happens around genes such as IFNG, BCL6,
    TCF7, PRDM1, and PDCD1, then there's something wrong. If it's just
    DNMT3A, it's a discovery :)

   --- get regions in and around IFNG
     Chr10:118441047-118445892 bp, + strand





*-----------------------------------------------------------------------------------------------------------------------
* hamid's T cell atac-seq multi-stage regulatory models (12 jul 2017)

  cd ~/github/projects/external/hamid/TcellDevelopment/

  --- email from hamid (12 jul 2017)

    Sounds great. There is a great dataset here:
      https://www.ncbi.nlm.nih.gov/geo/query/acc.cgi?acc=GSE89309
   which has both RNA-seq and ATAC-seq for T cells as they differentiate over time.
   The way I have been exploring this data, and would recommend to you is this:

    The are 3 replicates for each of expression and ATAC-seq peaks for 'naive' T cells:

     GSM2365761 	RNA_N1
     GSM2365762 	RNA_N2
     GSM2365763 	RNA_N3

     GSM2365799 	ATAC_N1
     GSM2365800 	ATAC_N2
     GSM2365801 	ATAC_N3

   These define the starting state of the T cells (point of
   reference). At this point the cells are mature but "inexperienced".

   Then there are expression and peak data sets with identifier like
   RNA_L5_1, etc. The L stands for Liver tumor and the number after
   the L is how many days after the naive cells (starting state) were
   stimulated with antigen. What I am doing is building a gene
   regulatory network of interactions that start in state naive and go
   through states L5, L7, ... till L28. The data includes later days
   (35 and 60), in these late stages a second differentiation process
   starts (memory cell formation) and for now we can skip that stage.

   So you have 4 developmental stages (L5, 7, 14, 21) with RNA and
   ATAC-seq. The genes that I think are the most likely players are
   listed in the attached Cytoscape annot file.


   --- try to streamline curl of all L5,7,14,21 atac-seq files

  ftp://ftp.ncbi.nlm.nih.gov/geo/samples/GSM2365nnn/GSM2365810/suppl/GSM2365810_ATAC_L5_1_normalizedCounts.txt.gz
  ftp://ftp.ncbi.nlm.nih.gov/geo/samples/GSM2365nnn/GSM2365811/suppl/GSM2365811_ATAC_L5_2_normalizedCounts.txt.gz

*-----------------------------------------------------------------------------------------------------------------------
* clustergrammer/R/heatmap, heatmap.2, hclust (14 jul 2017), for omar

   cd ~/github/heatmap/R-demo/
   library(gplots)
   cluster.info <- heatmap.2(as.matrix(USArrests), trace="none", col=rev(heat.colors(10)), margins=c(10,8))
   print(names(cluster.info))

*-----------------------------------------------------------------------------------------------------------------------
* clustergrammer, minimal demo for omar (12 jul 2017)

   cd ~/github/heatmap/clustergrammer/requirejs/

          app.js                index.html      lib             tiny.json       tinyData.js

          ./lib:        css/   fonts/   js/
          ./lib/css:    bootstrap.css      custom.css              custom_scrolling.css    font-awesome.min.css
          ./lib/fonts:  FontAwesome.otf                        fontawesome-webfont.svg         fontawesome-webfont.woff
                        fontawesome-webfont.eot                fontawesome-webfont.ttf         fontawesome-webfont.woff2
          ./lib/js:     bootstrap.min.js d3.js                 jquery-1.11.2.min.js
                        clustergrammer.js                      graph-scroll.js         underscore-min.js

*-----------------------------------------------------------------------------------------------------------------------
* macos @ + acl extended attributes (9 jul 2017)

   ls -le  shows the acl and extended attributes
   sudo xattr -c *
   chmod -N *


*-----------------------------------------------------------------------------------------------------------------------
* first hack at phosphorjs >= 1.0 (9 jul 2017)

  cd ~/github/phosphor/examples/try0
  npm install     # fetches libary specified in package.json
  npm run build   # runs webpack

  open index.html

  experimented with ~/github/phosphor/examples/try0/src/index.ts, class ContentWidget extends Widget
  hoped to find a way to add immediate html, then remote html.  failed for now...

*-----------------------------------------------------------------------------------------------------------------------
* first look at phosphorjs >= 1.0 (8 jul 2017)

  cd ~/github/phosphor/examples/example-dockpanel
  npm run build
  webpack
  open index.html

*-----------------------------------------------------------------------------------------------------------------------
* how daylight was captured, lab (8 jul 2017)

    conda update anaconda
    conda update -c conda-forge jupyterlab
    jupyter --version      # 4.3.0
    jupyter lab --version  # 0.25.1

    conda install nglview -c bioconda
      # installs ipywidgets-5.2

*-----------------------------------------------------------------------------------------------------------------------
* add neuron module model to the structure viz project (6 jul 2017)

  cd ~/github/projects/priceLab/cory/trnStructure/firstLook
  scp pshannon@whovian:/local/Cory/trn/genome-scale-trn/sage.modules/mod22IFG .

*-----------------------------------------------------------------------------------------------------------------------
* direct javascript manipulation of cyjs style (6 jul 2017)

   cy.style().selector("node").css({"background-color": "purple"})
   cy.style().selector("#LAIR1").css({"background-color": "purple"})
   cy.style().selector("node:selected").css({"background-color": "purple"});

   cy.style().update()


*-----------------------------------------------------------------------------------------------------------------------
* local indian tales

  coll thrush in native seattle tells story of a doctor john who lived in or near salmon bay,
  after the smallpox, and his failure to cure anyone in his community, and other sorts of
  marginalization, hung himself.

  lynda mapes (2 jul 2017) seattle times piece, "life before the locks" meantion:

    snoqualmie tribla elder and traditional chief andy de los angeles notes the loss of
    of the homestead of his ancstor, jim zackuse, near the north shore of lake union.
    "gone from those waters is the portal to the underworld; gone from that place is the
     spirit power that Zackuse, a poweful indian doctor, accessed to heal the people"


*-----------------------------------------------------------------------------------------------------------------------
* jquery DataTable tips:  in right panel, cyjs in left (4 jul 2017)

   ~/github/projects/examples/cyjsWithDataTable/cyjsDT.html

*-----------------------------------------------------------------------------------------------------------------------
* clustergrammer grok json format (3 jul 2017)

  cd ~/github/heatmap/clustergrammer/
      requirejs/
      matrixToClusteredJSON

  pip install --upgrade clustergrammer

      Col-A   Col-B   Col-C
Row-A 0.0     -0.1    1.0
Row-B 3.0     0.0     8.0
Row-C 0.2     0.1     2.5


from clustergrammer import Network
net = Network()
net.load_file("tiny.tsv")
net.cluster()
net.write_json_to_file('viz', 'tiny.json')

   --- error in clustered group click (need new version of d3?)
     clustergrammer.js:3831 Uncaught TypeError: $(...).modal is not a function
       at SVGPathElement.<anonymous> (clustergrammer.js:3831)
       at SVGPathElement.__onclick (d3.min.js:1)

*-----------------------------------------------------------------------------------------------------------------------
* clustergrammer requirejs demo (3 jul 2017)

  cd ~/github/projects/examples/clustergrammer/requirejsDemo-new/

   cp -prv ~/github/clustergrammer/lib/* .
   cp -prv ~/github/clustergrammer/clustergrammer.js libs/js
   cp -prv ~/github/clustergrammer/css/custom.js libs/css/

   index.html: 28 lines
   app.js:     73 lines


   ---- the crucial parts,  index.html:

       <script data-main="app" src="http://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.2/require.min.js"></script>
       <body>
        <div id="cgDiv">
           <h1 class='wait_message'>Please wait ...</h1>
        </div>
      </body>


   --- the crucial parts,   app.js
      require.config({
          paths: {
              'underscore'    :  'https://cdnjs.cloudflare.com/ajax/libs/underscore.js/1.8.3/underscore-min',
              'jquery'        :  'http://code.jquery.com/jquery-1.12.4.min',
              'clustergrammer':  'lib/js/clustergrammer'
              },
          shim: {underscore: {
                   exports: '_'
                   }}
          });
     require(['underscore', 'jquery', 'clustergrammer'], function (_, $, clustergrammer) {
     window.cwg = clustergrammer;


    --- heatmap data docs
       http://clustergrammer.readthedocs.io/clustergrammer_js.html#visualization-json

    network_data =
        {"views":
         [{"N_row_sum": "all", "dist": "cos", "nodes":
           {"col_nodes": [{"ini": 3, "rank": 2, "name": "s01_120405", "clust": 1,
                           "group": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0], "rankvar": 2},
                          {"ini": 2, "rank": 1, "name": "s02_120405", "clust": 0,
                           "group": [3.0, 3.0, 2.0, 2.0, 2.0, 2.0, 2.0, 1.0, 1.0, 1.0, 1.0], "rankvar": 0},
                          {"ini": 1, "rank": 0, "name": "s03_120405", "clust": 2,
                           "group": [2.0, 2.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0], "rankvar": 1}],
            "row_nodes": [{"ini": 2, "rank": 0, "name": "HLTF", "clust": 0,
                           "group": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0], "rankvar": 0},
                          {"ini": 1, "rank": 1, "name": "POU2F1", "clust": 1,
                           "group": [2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 1.0], "rankvar": 1}]}},
          {"dist": "cos", "N_row_var": "all", "nodes":
           {"col_nodes": [{"ini": 3, "rank": 2, "name": "s01_120405", "clust": 1,
                           "group": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0], "rankvar": 2},
                          {"ini": 2, "rank": 1, "name": "s02_120405", "clust": 0,
                           "group": [3.0, 3.0, 2.0, 2.0, 2.0, 2.0, 2.0, 1.0, 1.0, 1.0, 1.0], "rankvar": 0},
                          {"ini": 1, "rank": 0, "name": "s03_120405", "clust": 2,
                           "group": [2.0, 2.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0], "rankvar": 1}],
            "row_nodes": [{"ini": 2, "rank": 0, "name": "HLTF", "clust": 0,
                           "group": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0], "rankvar": 0},
                          {"ini": 1, "rank": 1, "name": "POU2F1", "clust": 1,
                           "group": [2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 1.0], "rankvar": 1}]}}],
         "col_nodes": [{"ini": 3, "rank": 2, "name": "s01_120405", "clust": 1,
                        "group": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0], "rankvar": 2},
                       {"ini": 2, "rank": 1, "name": "s02_120405", "clust": 0,
                        "group": [3.0, 3.0, 2.0, 2.0, 2.0, 2.0, 2.0, 1.0, 1.0, 1.0, 1.0], "rankvar": 0},
                       {"ini": 1, "rank": 0, "name": "s03_120405", "clust": 2,
                        "group": [2.0, 2.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0], "rankvar": 1}],
         "links": [{"target": 0, "value": 5.591991, "source": 0},
                   {"target": 1, "value": 11.939007, "source": 0},
                   {"target": 2, "value": 7.738552, "source": 0},
                   {"target": 0, "value": 31.060965999999997, "source": 1},
                   {"target": 1, "value": 18.00348, "source": 1},
                   {"target": 2, "value": 21.577569, "source": 1}],
         "row_nodes": [{"ini": 2, "rank": 0, "name": "HLTF", "clust": 0,
                        "group": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0], "rankvar": 0},
                       {"ini": 1, "rank": 1, "name": "POU2F1", "clust": 1,
                        "group": [2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 1.0], "rankvar": 1}]};




     make_clust(network_data);




*-----------------------------------------------------------------------------------------------------------------------
* umass soil sampling (30 jun 2017)

  413-545-2311
  use y1 code: just the nutrients, no suggestions are made to remedy deficits towards a specific crop.


*-----------------------------------------------------------------------------------------------------------------------
* aml trena demo for hamid (29 jun 2017)

   ~/github/projects/external/hamid/aml-trena/


   --- what dhs table to use?

     Will the attached MAF file of the var coords work for you?
     I wonder why you didn't find the CD34 DNASE1 HS track. The file:
         wgEncodeUwDnaseCd34mobilizedPkRep1.narrowPeak.gz
     is available here:
         http://hgdownload.soe.ucsc.edu/goldenPath/hg19/encodeDCC/wgEncodeUwDnase/



   --- full list of variants and indels
    https://www.dropbox.com/s/5piv50xibtxj5q1/allSomaticFilteredWGS.indels.txt?dl=0
    https://www.dropbox.com/s/8l3380aftq7jhk7/allSomaticFilteredWGS.SNVs.txt?dl=0

   98693 allSomaticFilteredWGS.SNVs.txt
   39687 allSomaticFilteredWGS.indels.txt



*-----------------------------------------------------------------------------------------------------------------------
* internet of species pilot project proposal, allen frontiers group (29 jun 2017)

  https://www.alleninstitute.org/what-we-do/frontiers-group/about/directors-blog/posts/fifth-revolution

https://www.alleninstitute.org/what-we-do/frontiers-group/about/directors-blog/posts/fifth-revolution

From the end of Tom Skalak’s blog post:


Important attributes of living systems such as adaptation during life, evolution across generations, human health and disease, social dynamics, and inter-species interactions (including human-induced changes to the environment and climate) all depend on biological information flows. Bio-geoengineering, which may now be critical to save the planet from global warming, depends on biological information flows.

The Fifth Revolution is upon us, and there will be room for individual creatives, institutions, businesses, and governments to navigate among the trillions of possibilities and realize audacious dreams.

-- Tom Skalak, Ph.D., Executive Director, The Paul G. Allen Frontiers Group

Subject: an ISB software engineer proposes an internet of species pilot project

We propose an “Internet of Species” pilot project, right here in Seattle, addressing a “canary in the coal mine” in-progress species loss in Seward Park’s 100 acre old-growth forest.  This rare remnant forest, with five hundred year old trees, bald eagles and owls, is a vital recreational resource to ethnically and economically diverse south Seattle.  The sword fern die-off, in progress since 2013, is globally unprecedented, unexplained (despite meticulous field and lab work) doubling in extent each year, and now recorded from a few sites elsewhere in the Puget Sound.   Seward Park’s Magnificent Forest is the ideal observation and experimental site for what looms as a possible regional species loss, and the consequent degradation of our forested lands.  Contributing factors are thought to be environmental stress (temperature, extreme swings in precipitation, urban pollution) the introduction of one or more novel pathogens.

In the pilot project, we would identify the causes of the die-off (using the latest metagenomic sequencing techniques) and then establish internet of species monitoring via unobtrusive networked sensors, environmental and biologic, to track and improve the health of the Magnificent Forest, the jewel of Seattle’s park system.


Show 2011/2017 before-and-after photos

*-----------------------------------------------------------------------------------------------------------------------
* structure exploration for cory's 7/10 talk (28 jun 2017)

  cd ~/github/projects/priceLab/cory/trnStructure/firstLook/

  --- data
    rnaseq expresion matrix: mtx.cer from mayo: 15160   263
    whole genome trn:   trn.mayoTcx <- readRDS("mayo.tcx.rds")  #  501037     11
    co-expression matrix from sage: tbl.mod60 <- read.table("mod60CEB", stringsAsFactors=FALSE, sep=",", header=TRUE)
       265 x 9 (265 genes)

  --- possibiity 1
     represent each of the co-expressed (mod60) genes as a linear model of its transcription factors
     choosing only those tfs which meet a high threshold
     get superset of tfs
     create model for each target gene in the co-expressed set
     use mds to place these models in 3 space
     portray in 3js
*-----------------------------------------------------------------------------------------------------------------------
* hierarchical clustering for omar, on rosmap aqp4 model (27 jun 2017)

  cd ~/github/trenaHelpers/inst/demos/aqp4/labMeeting-22jun2017
  library(gplots)
  mtx.rosmap.aqp4 <- mtx[c("AQP4", strongGeneModels[["rosmap"]]$tf),]
  save(mtx.rosmap.aqp4, file="mtx.rosmap.aqp4.RData")
  heatmap.2(mtx.rosmap.aqp4, trace='none')

*------------------------------------------------------------------------------------------------------------------------
* bdds postgres footprint hint usage in 4 lines
library(RPostgreSQL)
database.host <- "bddsrds.globusgenomics.org"
db.hint <- dbConnect(PostgreSQL(), user= "trena", password="trena", dbname="brain_hint", host=database.host)
dbGetQuery(db.hint, "select * from hits limit 3")
                 loc               type     name length strand        sample_id method         provenance score1  score2   score3 score4 score5 score6
1 chr1:187058-187068 motif.in.footprint MA0002.2     11      - ENCSR000EIJ_hint   HINT brain.filler.minid     15 12.7759 2.03e-05     NA     NA     NA
2 chr1:817425-817435 motif.in.footprint MA0002.2     11      + ENCSR000EIJ_hint   HINT brain.filler.minid     79 13.0345 1.59e-05     NA     NA     NA
3 chr1:943841-943851 motif.in.footprint MA0002.2     11      - ENCSR000EIJ_hint   HINT brain.filler.minid     13 12.2931 3.18e-05     NA     NA     NA

*------------------------------------------------------------------------------------------------------------------------
* gtf tips: get basic info on hg38 gene (26 jun 2017)

   library(RPostgreSQL)
   database.host <- "bddsrds.globusgenomics.org"
   db.hg38 <- dbConnect(PostgreSQL(), user= "trena", password="trena", dbname="hg38", host=database.host)
   query <- "select * from gtf where moleculetype='gene' and gene_biotype='protein_coding' and gene_name='THAP11' limit 5"
   dbGetQuery(db.hg38, query)[, c(1:3,5,10)]
         chr    start   endpos strand gene_name
     1 chr16 67842082 67844195      +    THAP11


*-----------------------------------------------------------------------------------------------------------------------
* qiang, laustend and xiaowei's gbm genes (26 jun 2017)

  --- prior work (15 may 2017)
    given exonic snps, found nothing of interest (just "minor possibly interesting regulatory relations"
    suggested that non-exonic snps migbt be revealing

  --- xiaowei sent two large files

   cd ~/github/trenaHelpers/inst/demos/qiang
     18170182 Jun 26 10:29 SN243_Somatic.tsv
     21349475 Jun 26 10:30 SN291_Somatic.tsv

   four genes suggested in may:
      thap11, pten aimp2 tp53

  --- thap11


*-----------------------------------------------------------------------------------------------------------------------
* gene annotation, kegg & go hyperGTest enrichment (26 jun 2017)  for cory

  cd ~/github/projects/priceLab/cory/mef2c-targets-geneAnnotation/
print(load("mef2c.tcx.RData"))
tbl <- temp
genes <- tbl$target.gene # 263
#--- assignGeneIDs
source("~/s/data/public/human/symToGeneID.R"); test_assignGeneIDs()


library(GSEABase)
library(GOstats)
library(GO.db)
library(Category)
library(org.Hs.eg.db)
library(KEGG.db)

symbol.entrez.map <- assignGeneIDs(genes)$mapped

gene.universe = character(0)
geneIDs <- unlist(symbol.entrez.map, use.names=FALSE)

go.params <- new("GOHyperGParams", geneIds=unique(geneIDs),
                 universeGeneIds = gene.universe, annotation = "org.Hs.eg.db",
                 ontology = 'BP', pvalueCutoff = 0.05, conditional = FALSE,
                 testDirection = "over")

kegg.params <- new("KEGGHyperGParams", geneIds = unique(geneIDs),
                   universeGeneIds = character(0), annotation = "org.Hs.eg.db",
                   pvalueCutoff = 0.1, testDirection = "over")

go.bp.hgr <- hyperGTest(go.params)
kegg.hgr  <- hyperGTest(kegg.params)


   --- map GO term to all of its geneIDs
      library(org.Hs.eg.db)
      unique(unlist(mget("GO:0009060", env = org.Hs.egGO2ALLEGS), use.names=FALSE))



*-----------------------------------------------------------------------------------------------------------------------
* update TrenaViz addHttpGraph

   fetch("http://localhost:11004?g.json").then(function(responseObj) {return responseObj.json();}).then(function(j){xx = j});


*-----------------------------------------------------------------------------------------------------------------------
* standard regulatoryRegions format for trenaViz (20 jun 2017)

   --- FootprintFilter
     library(TReNA)
     genome.db.uri <- "postgres://bddsrds.globusgenomics.org/hg38"   # has gtf and motifsgenes tables
     footprint.db.uri <- sprintf("postgres://whovian/%s", "brain_hint_20")
     chromLoc <- list(chrom="chr18", start=26864201, end=26864369)
     fpFilter <- FootprintFilter(genome.db.uri, footprint.db.uri, list(), with(chromLoc, sprintf("%s:%d-%d", chrom, start, end)))
     x.fp <- getCandidates(fpFilter)

    --- HumanDHSFilter
     dhsFilter <- HumanDHSFilter(genome="hg38",
                                 encodeTableName="wgEncodeRegDnaseClustered",
                                 pwmMatchPercentageThreshold=85L,
                                 geneInfoDatabase.uri="postgres://whovian/gtf",
                                 geneCenteredSpec=list(),
                                 regionsSpec=with(chromLoc, sprintf("%s:%d-%d", chrom, start-100, end+100)))
     x.dhs <- getCandidates(dhsFilter)
     intersect(x.dhs$tbl$motifName, x.fp$tbl$motifName) # [1] "MA0107.1" "MA0670.1" "MA0101.1" "MA0671.1"

     x.dhs$tbl$length <- nchar(x.dhs$tbl$match)
     tbl.dhs.demo <- subset(x.dhs$tbl, motifName=="MA0107.1")

     colnames(tbl.dhs.demo)[grep("motifRelativeScore", colnames(tbl.dhs.demo))] <- "score"
        motifName chrom motifStart motifEnd strand motifScore motifRelativeScore      match regulatoryRegionStart regualtoryRegionEnd regulatorySequence variant  tfs
     11  MA0107.1 chr18   26864287 26864296      +   8.500000          1.0000000 GGGAATTTCC              26864220            26864370                  1      47 RELA
     12  MA0107.1 chr18   26864293 26864302      -   7.277778          0.8562092 GGAATTTCCA              26864220            26864370                  1      47 RELA

      tbl.fp.demo <- subset(x.fp$tbl, motifName=="MA0107.1")
      colnames(x.fp$tbl) <- c("chrom", "motifStart", "motifEnd", "motifName", "length", "strand", "score1", "score", "score3")
        chrom    start      end motifName length strand score1  score2   score3   tf
     77 chr18 26864287 26864296  MA0107.1     10      +    156 17.3265 9.09e-07 RELA
     85 chr18 26864288 26864297  MA0107.1     10      -    156 12.1939 3.24e-05 RELA

     coi <- c("chrom", "motifStart", "motifEnd", "motifName", "strand", "score", "length", "label")
     tbl.dhs.demo[, coi]
        chrom motifStart motifEnd motifName strand     score length
     11 chr18   26864287 26864296  MA0107.1      + 1.0000000     10
     12 chr18   26864293 26864302  MA0107.1      - 0.8562092     10
     tbl.fp.demo <- subset(x.fp$tbl, motifName=="MA0107.1")
     tbl.fp.demo[, coi]
        chrom motifStart motifEnd motifName strand   score length
     77 chr18   26864287 26864296  MA0107.1      + 17.3265     10
     85 chr18   26864288 26864297  MA0107.1      - 12.1939     10





*-----------------------------------------------------------------------------------------------------------------------
* new sword fern die-off spots

   --- rochester wa, independence road (18 jun 2017) (about 10 miles ssw of olympia)
     We own 15 acres of forest land in Rochester just off of Independence Road and began to notice a similar die-off last summer.
     https://www.reddit.com/r/SeattleWA/comments/6hx7xz/massive_mystery_fern_dieoff_at_seattle_park/

   --- lake forest park, lynda goodrich (17 jun 2017), email to tim
      potebgoodrichl@comcast.net

      Sorry, this is my third attempt to add my location to the sword
      ferns die-off.  I have lived in Lake Forest Park for 40 years &
      this year all my sword ferns are dying.  (These ferns are
      underneath a 150 yr old silver maple.).

   --- indianola, from dan hinkley, neighbor of heidi danilchuck

      The Indianola Church Camp in Indianola, directly across the road
      from our house at 10345 NE Shore Drive, has a perimeter trail
      that we walk our dogs on. Our dog sitter took them for a walk
      yesterday and happened to wonder aloud upon her return what was
      happening to the sword ferns on the trail After we filled her in
      on the situation, she returned to take pictures this morning.
      In full disclosure, I have not yet seen the patches myself.

      We would have to fill the manager of the Church Camp in ono the
      situation before you could get permission to take a look at the
      patch, if after seeing the photos you deem necessary to do, and
      to take samples.  They should not have a problem with it and I
      will introduce you when you are ready.


   --- weona park, west side of lake sammamish (10 jul 2017)
     al smith reported 30 newly dead ferns in february, no additional spread on a recent visit

   --- red town trailhead, cougar mountain (10 jul 2017)
     a few ferns in february 2017, now 30, near trail head

   --- baring, highway 2 on the way to stevens pass
     reported stpring


*-----------------------------------------------------------------------------------------------------------------------
* javascript this
*-----------------------------------------------------------------------------------------------------------------------
* ma0152.1  human/mouse/rat motif, length7, good candidate for injecting snps into TReNA footprintfinder (19 jun 2017)

    loc        chr5:88894577-88894583
    chrom                        chr5
    start                    88894577
    endpos                   88894583
    type           motif.in.footprint
    name                     MA0152.1
    length                          7
    strand                          +
    sample_id  ENCSR318PRQ_wellington
    method                 WELLINGTON
    provenance     brain.filler.minid
    score1                   -14.5905
    score2                    12.2022
    score3                   7.93e-05
    score4                       <NA>
    score5                       <NA>
    score6                       <NA>


*-----------------------------------------------------------------------------------------------------------------------
* new brain hint|wellington|16seed|20seed footprint databses created by matt on whovian (19 jun 2017)


*-----------------------------------------------------------------------------------------------------------------------
* trenaViz multi-model network display: figure out javascript cyjs swithcing functions

  --- set randomForest=0 on all TF nodes:
    cy.nodes().filter(function(node){return node.data("type") == "TF"}).map(function(node){node.data({"randomForest": 0})})
    cy.nodes().filter(function(node){return node.data("type") == "TF"}).map(function(node){node.data({"pearson": 0})})

  --- copy wt model randomForest and pearson data to be current values
    cy.nodes().show()
    cy.nodes().filter(function(node){return node.data("type") == "TF"}).map(function(node){node.data({"randomForest": 0})})
    cy.nodes().filter(function(node){return node.data("type") == "TF"}).map(function(node){node.data({"pearson": 0})})
    cy.nodes("[type='TF']").map(function(node){node.data({"randomForest":  node.data("wt.randomForest")})})
    cy.nodes("[type='TF']").map(function(node){node.data({"pearson":       node.data("wt.pearson")})})
    cy.nodes().filter(function(node){return(node.data("randomForest") == 0 && node.data("type") == "TF")}).hide()

    cy.nodes().show()
    cy.nodes().filter(function(node){return node.data("type") == "TF"}).map(function(node){node.data({"randomForest": 0})})
    cy.nodes().filter(function(node){return node.data("type") == "TF"}).map(function(node){node.data({"pearson": 0})})
    cy.nodes("[type='TF']").map(function(node){node.data({"randomForest":  node.data("rs3875089.randomForest")})})
    cy.nodes("[type='TF']").map(function(node){node.data({"pearson":       node.data("rs3875089.pearson")})})
    cy.nodes().filter(function(node){return(node.data("randomForest") == 0 && node.data("type") == "TF")}).hide()




  --- hide all TFs with 0 randomForest
    cy.nodes().filter(function(node){return(node.data("randomForest") == 0 && node.data("type") == "TF")}).hide()

*-----------------------------------------------------------------------------------------------------------------------
* trenaViz node attribute puzzle (18 jun 2017)

   --- tiny example

      g2 <- graphNEL(nodes=c("a", "b"), edgemode="undirected")
      nodeDataDefaults(g2, attr="age") <- 24
      nodeData(g2)
        $a
        $a$age
        [1] 24
        $b
        $b$age
        [1] 24

      nodeData(g2, attr="age")
        $a
        [1] 24
        $b
       [1] 24


*-----------------------------------------------------------------------------------------------------------------------
* create multimodel trenaViz using rs3875089 (17 jun 2017)

  cd ~/github/TReNA/inst/misc/multiModels
  source("aqp4-multi.R");

  pad<-8
  i<-2
  x.wt <- buildModelForRegion("chr18", tbl.snp$loc[i] - pad, tbl.snp$loc[i] + pad)
  x.mut <- buildModelForRegion("chr18", tbl.snp$loc[i] - pad, tbl.snp$loc[i] + pad, tbl.snp$snp[2])

  save(x.wt, x.mut, file="../../extdata/twoAQP4modelsForTesting.RData")


    setdiff(subset(x.mut$tbl.model, randomForest>5)$tf, subset(x.wt$tbl.model, randomForest >5)$tf)
         "SOHLH1" "NCOA2"  "NPAS1"  "NPAS3"  "EPAS1"
    setdiff(subset(x.wt$tbl.model, randomForest>5)$tf, subset(x.mut$tbl.model, randomForest >5)$tf)
         "TEAD1" "PRRX1" "OTX1"  "SOX4"

*-----------------------------------------------------------------------------------------------------------------------
* one MA0090.2-disrupting snps from ohsu, trenaViz (16 jun 2017)

   cd ~/github/TReNA/inst/misc/multiModels
   source("aqp4-multi.R")
   identifyPerturbedMotifs()
   tbl.snp
     target.gene chromosome      loc       snp genome
            AQP4      chr18 26864410 rs3763040   hg38
            AQP4      chr18 26865469 rs3875089   hg38   # this disrupts TEAD1 binding
            AQP4      chr18 26855623  rs335929   hg38
            AQP4      chr18 26855854 rs3763043   hg38
            AQP4      chr18 26850565 rs9951307   hg38

   ---  rs3875089: chr18 26865469

         pad<-8; i<-2; as.data.frame(t(subset(x.wt$tbl, motifStart > tbl.snp$loc[i]-pad  & motifEnd < tbl.snp$loc[i]+pad & motifRelativeScore > 0.70 & grepl("TEAD", tf))[, -11]))
                                              22626                  141744                  142220
         motifName                         MA0090.2                MA0808.1                MA0809.1
         chrom                                chr18                   chr18                   chr18
         motifStart                        26865465                26865466                26865465
         motifEnd                          26865474                26865473                26865474
         strand                                   +                       +                       +
         motifScore                        5.653203                5.564402                5.470297
         motifRelativeScore               0.8174939               0.8368466               0.8060669
         match                           AGCATCCCTT                GCATCCCT              AGCATCCCTT
         chromStart                        26850465                26850465                26850465
         chromEnd                          26870469                26870469                26870469
         status                                  wt                      wt                      wt
         tf                 TEAD1;TEAD2;TEAD3;TEAD4 TEAD3;TEAD1;TEAD2;TEAD4 TEAD4;TEAD1;TEAD2;TEAD3

      pad<-8; i<-2; nrow(subset(x.mut$tbl, motifStart > tbl.snp$loc[i]-pad  & motifEnd < tbl.snp$loc[i]+pad & motifRelativeScore > 0.70 & grepl("TEAD", tf)))  # [1] 0




      subset(x.wt$tbl, motifStart >= 26865465 & motifEnd <= 26865474)
             motifName chrom motifStart motifEnd strand motifScore motifRelativeScore      match chromStart chromEnd                                      seq status                                                                                                                                                                                                                                        tf
      22626   MA0090.2 chr18   26865465 26865474      +   5.653203          0.8174939 AGCATCCCTT   26850465 26870469      wt                                                                                                                                                                                                                   TEAD1;TEAD2;TEAD3;TEAD4
      141744  MA0808.1 chr18   26865466 26865473      +   5.564402          0.8368466   GCATCCCT   26850465 26870469      wt                                                                                                                                                                                                                   TEAD3;TEAD1;TEAD2;TEAD4
      142220  MA0809.1 chr18   26865465 26865474      +   5.470297          0.8060669 AGCATCCCTT   26850465 26870469      wt                                                                                                                                                                                                                   TEAD4;TEAD1;TEAD2;TEAD3
      97668   MA0676.1 chr18   26865465 26865473      -   5.236973          0.7024059  TTGCCTCTG   26850465 26870469      wt                                           NR2E1;NR2C1;NR2C2;NANOG;NOTO;VENTX;BSX;HHEX;HLX;EN1;EN2;EMX1;EMX2;DLX1;DLX2;DLX3;DLX4;DLX5;DLX6;DBX1;DBX2;VAX1;VAX2;TLX1;TLX2;TLX3;BARX1;BARX2;HMX1;HMX2;HMX3;MSX1;MSX2;LBX1;LBX2;BARHL1;BARHL2
      93311   MA0671.1 chr18   26865466 26865474      -   4.617483          0.7892166  TTTGCCTCT   26850465 26870469      wt                                                                                                                                                                                                                       NFIX;NFIA;NFIB;NFIC
      19699   MA0081.1 chr18   26865466 26865472      -   4.591837          0.8241758    TGCCTCT   26850465 26870469      wt                                                                                                                     SPIB;SPDEF;ETV6;ETV7;SPIC;EHF;ELF3;ELF5;ELF1;ELF2;ELF4;ELK1;ELK3;ELK4;ETV1;ETV4;ETV5;ERF;ETV2;FLI1;ERG;FEV;ETV3;ETV3L
      120690  MA0719.1 chr18   26865465 26865472      +   4.148499          0.7778568   AGCATCCC   26850465 26870469      wt RHOXF1;HOPX;ISX;LEUTX;NOBOX;OTP;ARGFX;RAX;SEBOX;SHOX;UNCX;ARX;DPRX;DRGX;GSC;GSC2;ESX1;DUXA;DUX4;VSX1;VSX2;TPRX1;SHOX2;RHOXF2;RHOXF2B;RAX2;PRRX1;PRRX2;PROP1;PITX1;PITX2;PITX3;PHOX2A;PHOX2B;OTX1;OTX2;CRX;MIXL1;HESX1;ALX1;ALX3;ALX4;ELF3

      subset(x.mut$tbl, motifStart >= 26865465 & motifEnd <= 26865474)
            motifName chrom motifStart motifEnd strand motifScore motifRelativeScore      match chromStart chromEnd  status                                                                                                                                                                                              tf
      60163  MA0595.1 chr18   26865465 26865474      +   5.982759          0.7478448 AGCACCCCTT   26850465 26870469 C   mut                                                                                                                                                                                          SREBF1
      97645  MA0676.1 chr18   26865465 26865473      -   5.236973          0.7024059  TTGCCTCTG   26850465 26870469 C   mut NR2E1;NR2C1;NR2C2;NANOG;NOTO;VENTX;BSX;HHEX;HLX;EN1;EN2;EMX1;EMX2;DLX1;DLX2;DLX3;DLX4;DLX5;DLX6;DBX1;DBX2;VAX1;VAX2;TLX1;TLX2;TLX3;BARX1;BARX2;HMX1;HMX2;HMX3;MSX1;MSX2;LBX1;LBX2;BARHL1;BARHL2
      58147  MA0522.2 chr18   26865465 26865474      +   5.122349          0.7083695 AGCACCCCTT   26850465 26870469 C   mut                                                                                                                                                                                 TCF3;TCF4;TCF12
      93286  MA0671.1 chr18   26865466 26865474      -   4.617483          0.7892166  TTTGCCTCT   26850465 26870469 C   mut                                                                                                                                                                             NFIX;NFIA;NFIB;NFIC
      19690  MA0081.1 chr18   26865466 26865472      -   4.591837          0.8241758    TGCCTCT   26850465 26870469 C   mut                                                                           SPIB;SPDEF;ETV6;ETV7;SPIC;EHF;ELF3;ELF5;ELF1;ELF2;ELF4;ELK1;ELK3;ELK4;ETV1;ETV4;ETV5;ERF;ETV2;FLI1;ERG;FEV;ETV3;ETV3L

      pad<-6; i<-2; subset(x.wt$tbl, motifStart > tbl.snp$loc[i]-pad  & motifEnd < tbl.snp$loc[i]+pad & motifRelativeScore > 0.8)
              motifName chrom motifStart motifEnd strand motifScore motifRelativeScore      match chromStart chromEnd                                      seq status                                                                                                                    tf
               MA0090.2 chr18   26865465 26865474      +   5.653203          0.8174939 AGCATCCCTT   26850465 26870469 CCCATATATATGCTCACAATTGATAATTATTCTAATG...     wt                                                                                               TEAD1;TEAD2;TEAD3;TEAD4
               MA0808.1 chr18   26865466 26865473      +   5.564402          0.8368466   GCATCCCT   26850465 26870469 CCCATATATATGCTCACAATTGATAATTATTCTAATG...     wt                                                                                               TEAD3;TEAD1;TEAD2;TEAD4
               MA0809.1 chr18   26865465 26865474      +   5.470297          0.8060669 AGCATCCCTT   26850465 26870469 CCCATATATATGCTCACAATTGATAATTATTCTAATG...     wt                                                                                               TEAD4;TEAD1;TEAD2;TEAD3
               MA0081.1 chr18   26865466 26865472      -   4.591837          0.8241758    TGCCTCT   26850465 26870469 CCCATATATATGCTCACAATTGATAATTATTCTAATG...     wt SPIB;SPDEF;ETV6;ETV7;SPIC;EHF;ELF3;ELF5;ELF1;ELF2;ELF4;ELK1;ELK3;ELK4;ETV1;ETV4;ETV5;ERF;ETV2;FLI1;ERG;FEV;ETV3;ETV3L
      pad<-6; i<-2; subset(x.mut$tbl, motifStart > tbl.snp$loc[i]-pad  & motifEnd < tbl.snp$loc[i]+pad & motifRelativeScore > 0.8)
              motifName chrom motifStart motifEnd strand motifScore motifRelativeScore   match chromStart chromEnd                                      seq status                                                                                                                    tf
               MA0081.1 chr18   26865466 26865472      -   4.591837          0.8241758 TGCCTCT   26850465 26870469 CCCATATATATGCTCACAATTGATAATTATTCTAATG...    mut SPIB;SPDEF;ETV6;ETV7;SPIC;EHF;ELF3;ELF5;ELF1;ELF2;ELF4;ELK1;ELK3;ELK4;ETV1;ETV4;ETV5;ERF;ETV2;FLI1;ERG;FEV;ETV3;ETV3L


      pad<-6; i<-2; subset(x.wt$tbl, motifStart > tbl.snp$loc[i]-pad  & motifEnd < tbl.snp$loc[i]+pad & motifRelativeScore > 0.7)
      pad<-6; i<-2; subset(x.mut$tbl, motifStart > tbl.snp$loc[i]-pad  & motifEnd < tbl.snp$loc[i]+pad & motifRelativeScore > 0.7)


*-----------------------------------------------------------------------------------------------------------------------
* cory's instructions for aws ssh, access to latest brain footprints 4 jun 2017)


   Ok, I've generated an ssh private key for you (attached), aka pem
   file. I suggest you delete this email once we're done. Save the
   file in a directory from which you ssh (or if you have a prefered
   way, do what you know). Do the following chmod command on the pem
   file:

        chmod 400 pshannon.pem

   then do the following command:

        ssh-keygen -y

   book..aws> ssh-keygen -y
   Enter file in which the key is (/Users/paul/.ssh/id_rsa):

     ssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAAAgQG7iSP065CPzS2mQOCuPH4EU2WHlQD5tjULGhiDnWTYLBKROC+JO7kyZOE71nma4TPvBwyn9ftchsPc1L7G3pY6ga2hwzxdJbanDeAHbR5lJB3kOoBr3vkUGZ1f/BaxsStd0w4hJ7RWhqALtWQQO1WDd/QayLIFmN295TH4ipIp0w==



   This will generate another long string. Send me that string. I will
   then place that in the AWS EC2 instance. You will then ssh into the
   instance as follows:

     ssh -i <pshannon.pem> ubuntu@ec2-52-42-53-213.us-west-2.compute.amazonaws.com

  The ec2 address will change every time we spin up a new instance, but how you point to the pem file will always be the same.

*-----------------------------------------------------------------------------------------------------------------------
* next up, aqp4 (13 jun 2017)

  cd ~/github/TReNA/inst/misc/multiModels/

  aqp4.R, runWithAugmentedFootprints()
  coryFP not in a database, so may wish to intersect footprints and motifs, overlap="any", then build a model.

*-----------------------------------------------------------------------------------------------------------------------
* R tips, replicate data.frame rows, strsplit tfs: speed it up

  cd ~/s/examples/R/replicateDataFrameRows

     library(splitstackshape)
     library(RUnit)

     print(load("tbl.toRep.RData"))
     dim(tbl.toRep) # [1] 37504    13
     tbl.toRep <- subset(tbl.toRep, nchar(tf)!=0)
     dim(tbl.toRep)
     tfs.split <- strsplit(tbl.toRep$tf, ";")
     length(tfs.split) # [1] 36929
     counts <- unlist(lapply(tfs.split, length))
     tfs.split.vec <- unlist(tfs.split)
     tbl2 <- expandRows(tbl.toRep, counts, count.is.col=FALSE, drop=FALSE)
     checkEquals(length(tfs.split.vec), nrow(tbl2))
     tbl2$tf <- tfs.split.vec
     dim(tbl2) # [1] 969392     13

*-----------------------------------------------------------------------------------------------------------------------
* R tips, replicate data.frame rows, strsplit tfs

   [this is very slow on a 37k line data.frame.  see above]
   cd ~/github/TReNA/inst/misc/multiModels/

   tbl.motifs <- data.frame()
   for(r in 1:nrow(x.wt$tbl)){
      tfs <- strsplit(x.wt$tbl$tf[r], ";")[[1]]
      tbl.tmp <- as.data.frame(lapply(x.wt$tbl[r,], rep, length(tfs)))
      tbl.tmp$tf <- tfs
      tbl.motifs <- rbind(tbl.motifs, tbl.tmp)
      } # for r

*-----------------------------------------------------------------------------------------------------------------------
* trenaViz: display network aqp4 + 5 snps:

  see below: build no-footprint model encompassing snps + 5kb upstream (10 jun 2017)

   tbl.reg <- x.wt$tbl
   tbl.gm <- subset(model.wt$edges, IncNodePurity > 2)
   save(tbl.reg, tbl.gm, file="~/github/TReNA/inst/extdata/aqp4-model-regRegions.RData")
*-----------------------------------------------------------------------------------------------------------------------
* trenaViz: create cyjs view of randomForest TReNA results (10 jun 2017)

  --- from http://whovian:10001/notebooks/dora-skin.ipynb
      ~/github/dora/notebooks/skin-PnG/dora-skin.ipynb
      ~/github/dora/microservices/trenaCommon/trenaServer.R

  def createGeneModelFromGenomeView(targetGene, expressionMatrixName):
   region = app.getChromLocString()
   msg = json.dumps({"cmd": "createGeneModel", "status": "request", "callback": "",
                     "payload": {"targetGene": targetGene, "matrix": expressionMatrixName, "footprintRegion": region}})
   socket.send_string(msg)
   response = json.loads(socket.recv_string())
   status = response['status']
   print(status)
   payload = response['payload']
   if(status == 'error'):
      print(payload)
   else:
     graphData = json.loads(payload['network'])
     app.deleteGraph()
     app.addGraph(graphData)
     app.loadNetworkStyleFile("js/style-ensemble.js")
     app.fit()
     tbl_model = payload['model']
     app.addGeneModelTable(json.dumps(tbl_model));
     tbl_footprints = payload['footprints']
     app.addFootprintTable(json.dumps(tbl_footprints));
   return(response)
*-----------------------------------------------------------------------------------------------------------------------
* seward park plants

  --- similar ground/stalky plants

    piggyback
    foam flower
    fringecup
    enchanter's nightshade
    baldhip rose: in fact hairy stems
    nootka rose
    cluster rose

   --- shrubs
     high bush cranberry
     mock orange

   --- ferns
     deer fern
     lady fern (has hips)(fronds have no basal stem|stipe)
     bracken fern (like lady? but with a basal stem
     spiny wood fern: triangular fronds, bottomost pinnae are arranged two-opposite-one

*-----------------------------------------------------------------------------------------------------------------------
* aqp4 + 5 snps: build no-footprint model encompassing snps + 5kb upstream (10 jun 2017)

  cd ~/github/TReNA/inst/misc/multiModels/
  source("aqp4.R")
  identifyMotifs()
  dim(subset(tbl.counts[, 1:4], diff !=0))  # [1] 45  4
  subset(tbl.counts[, 1:4], abs(diff) >= 2)
          motif wtCount mutCount diff
    57  MA0090.2      80       78    2
    369 MA0808.1      77       75    2
    370 MA0809.1     107      105    2
  save(tbl.counts, file="aqp4.tbl.counts.5kbUpstream.RData")

  buildModel()
    subset(model.wt$edges, IncNodePurity > 2)
           IncNodePurity   gene.cor
    TEAD1      34.691496  0.7605383
    SOX9       14.990602  0.7402240
    HIF1A      13.463053  0.6949043
    ATF7       12.213881  0.7163899
    RFX4       11.290013  0.7504778
    GLIS3       9.821468  0.6856911
    SMAD9       9.246654  0.6694617
    SP3         6.439329  0.6837160
    GLI2        5.271985  0.5750392
    THAP9       3.676609  0.6453760
    SOX5        3.575288  0.6827886
    ZBTB33      3.369010  0.6415588
    ID4         3.264924  0.6631979
    ZBTB7A      3.092141 -0.5151684
    NFE2L2      2.729482  0.6886920
    NR2E1       2.200849  0.6457334



*-----------------------------------------------------------------------------------------------------------------------
* MotifDb motif -> tf mapping (10 jun 2017)

  use MA0090.2 -> TEAD1 as example
  library(MotifDb)
  unique(mcols(query(mdb, "MA0090\\."))$geneSymbol) # [1] "TEAD1"

*-----------------------------------------------------------------------------------------------------------------------
* whovian psql tips


   --- psql shell
     psql -U trena --host whovian   # prompts for password which is also "trena"
     select datname from pg_database;

   --- from R
     library(RPostgreSQL)
     db <- dbConnect(PostgreSQL(), user= "trena", password="trena", host="whovian")
     tbl <- dbGetQuery(db, "select datname from pg_database")

*-----------------------------------------------------------------------------------------------------------------------
* track down excess of TEAD1 motifs in aqp4 model (6 jun 2017)

  cd ~/github/TReNA/inst/misc/multiModels/
  source("aqp4.R")
  step through code in test.createModel():

    start <- 26860992  #26860742
    end   <- 26870492 # 26882685
    m1 <- createModel("AQP4", "chr18", start, end)
    m1.mut <- createModel("AQP4", "chr18", start, end, variants="rs3875089")


*-----------------------------------------------------------------------------------------------------------------------
* aqp4 multiModels (30 may 2017)   TEADn motif disruption?

  cd ~/github/TReNA/inst/misc/multiModels/
  source("aqp4.R")

  --- currently configured to find regulatory regions, and thus tfs, in
    regionsSpec <- "chr18:26865459-26865479"

    getDHSCandidates(); getFootprintCandidates()
    m <- test.createModel()
    head(m$model.dhs$edges)

  --- next up: i have lost the affect of the snps
    create new bed files for aqp4 region, from dhs database, and the sqlite.

  --- old result to reproduce, email of 11 may 2017, titled "TEAD-off: rs3875089"
  tbl.wt[grep("TEAD", tbl.wt$tfs),]
  motifName chrom motifStart motifEnd strand motifScore motifRelativeScore      match regulatoryRegionStart regualtoryRegionEnd                     tfs
3   MA0090.2 chr18   26865465 26865474      +   5.653203          0.8174939 AGCATCCCTT              26865449            26865489 TEAD1;TEAD2;TEAD3;TEAD4
21  MA0808.1 chr18   26865466 26865473      +   5.564402          0.8368466   GCATCCCT              26865449            26865489 TEAD3;TEAD1;TEAD2;TEAD4
22  MA0809.1 chr18   26865465 26865474      +   5.470297          0.8060669 AGCATCCCTT              26865449            26865489 TEAD4;TEAD1;TEAD2;TEAD3


   --- test.createModel reproduces this and more
     # next up: do with the tbl.snp[2,] variant.   does these tfs.big drop out?


  --- from the aforementioned test.createModel

    # chr18:26,860,742-26,882,685: includes all footprints and dhs clusters
  start <- 26860742
  end   <- 26882685
  m1 <- createModel("AQP4", "chr18", start, end)
  m1.mut <- createModel("AQP4", "chr18", start, end, variants="rs3875089")

    # chr18:26865450-26865480: 30 bases around rs3875089
  start <- 26865450
  end   <- 26865480
  m2 <- createModel("AQP4", "chr18", start, end)
  m2.mut <- createModel("AQP4", "chr18", start, end, variants="rs3875089")

  --- now get the motifs mapped across
   tbl.tead1.motifs <- m1$candidates.dhs$tbl[grep("TEAD1", m1$candidates.dhs$tbl$tfs),][, c("chrom", "motifStart", "motifEnd", "motifName", "motifRelativeScore")]
   tbl.tead1.motifs <- tbl.tead1.motifs[order(tbl.tead1.motifs$motifStart),]
   dim(tbl.tead1.motifs) #  1839    5
   head(tbl.tead1.motifs) #  359 5
            chrom motifStart motifEnd motifName motifRelativeScore
     149194 chr18   26860748 26860757  MA0809.1          0.7755605
     24304  chr18   26860748 26860757  MA0090.2          0.7355868
     148436 chr18   26860785 26860794  MA0809.1          0.7404271
     23678  chr18   26860785 26860794  MA0090.2          0.7206383
     149193 chr18   26860787 26860796  MA0809.1          0.7273741
     24303  chr18   26860787 26860796  MA0090.2          0.7050259
  write.table(subset(tbl.tead1.motifs, motifRelativeScore >= 0.8),
             row.names=FALSE, col.names=FALSE, quote=FALSE, sep="\t", file="tead1-motifs.bed")
  system("scp tead1-motifs.bed pshannon@whovian:/local/httpd/vhosts/pshannon/annotations/")

*-----------------------------------------------------------------------------------------------------------------------
* create aqp4 sqlite footprints database for trenaViz exploration (30 may 2017)

  cd ~/s/work/priceLab/ohsu-aquaporin/
  toMysql.R has these contents:

library(TReNA)
library(RPostgreSQL)
library(RUnit)
library(RSQLite)

print(load("footprintsFromCory/aqp4_fp.RData"))  # fp
names(fp$AQP4)  # [1] "tfs" "tbl" "tfs" "tbl" "tfs" "tbl" "tfs" "tbl"
tbl.snps <- data.frame()
tbl.snps <- rbind(tbl.snps, fp$AQP4[[2]])
tbl.snps <- rbind(tbl.snps, fp$AQP4[[4]])
tbl.snps <- rbind(tbl.snps, fp$AQP4[[6]])
tbl.snps <- rbind(tbl.snps, fp$AQP4[[8]])
dim(tbl.snps) # [1] 240237     20


genome.db.uri    <- "postgres://bddsrds.globusgenomics.org/hg38"                  # has gtf and motifsgenes tables
footprint.db.uri <- "postgres://bddsrds.globusgenomics.org/brain_hint"            # has hits and regions tables
fpf <- FootprintFinder(genome.db.uri, footprint.db.uri, quiet=FALSE)
chrom <- unique(tbl.snps$chrom) # [1] "chr18"
start <- min(tbl.snps$start)    # [1] 26825884
end   <- max(tbl.snps$endpos)   #  [1] 26905808
tbl.fp <- getFootprintsInRegion(fpf, "chr18", start, end)   # dim(1185 17)


db <- dbConnect(PostgreSQL(), user= "trena", password="trena", dbname="brain_hint", host="whovian")
query <- sprintf("select * from regions where chrom='%s' and start>=%d and endpos <= %d", chrom, start, end)
tbl.regions.a <- dbGetQuery(db, query)   # 681 x 4

loc.set <- sprintf("('%s')", paste(tbl.regions.a$loc, collapse="','"))
query.hits <- sprintf("select * from hits where loc in %s", loc.set)
tbl.hits.a <- dbGetQuery(db, query.hits)    # 1185 x 14
tbl.out <- merge(tbl.regions.a, tbl.hits.a, on="loc")


# now make sure we can create new, small tbl.regions and tbl.hits.a by simple column-subsetting
# of tbl.snps

checkTrue(all(colnames(tbl.regions.a) %in% colnames(tbl.snps)))
checkTrue(all(colnames(tbl.hits.a) %in% colnames(tbl.snps)))

tbl.regions <- tbl.snps[, colnames(tbl.regions.a)]
tbl.hits <- tbl.snps[, colnames(tbl.hits.a)]


db.lite <- dbConnect(dbDriver("SQLite"), "aqp4.sqlite")
dbWriteTable(db.lite, "regions", tbl.regions)
dbWriteTable(db.lite, "hits", tbl.hits)
dbDisconnect(db.lite)


*-----------------------------------------------------------------------------------------------------------------------
* clustergrammer, minimal demo (30 may 2017)

  cd ~/github/clustergrammer_requirejs/examples/simpleDemo
  open index.html
  just two genes in 3 conditions

*-----------------------------------------------------------------------------------------------------------------------
* contra non-invasive health monitoring

  http://www.cancer.net/navigating-cancer-care/prevention-and-healthy-living/cancer-screening

*------------------------------------------------------------------------------------------------------------------------
* exploring ermrest from R, in preparation for a new FootprintFinder protocol (27 may 2017)

  cd ~/github/TReNA/inst/misc/ermrestExplorations/
  simple.R

  https://bdds-dev.isrd.isi.edu/ermrest/catalog/7/entity/lymphoblast:regions/loc=chr1%3A817425-817435/HITS:=(loc)=(lymphoblast:hits:loc)/REGION:=left(loc)=(lymphoblast:regions:loc)/$HITS?accept=json

  curl "https://bdds-dev.isrd.isi.edu/ermrest/catalog/7/entity/public:regions/loc=chr1%3A817425-817435?accept=json"
    [{"loc":"chr1:817425-817435","chrom":"chr1","start":817425,"endpos":817435,"id":2}]

  url <- "https://bdds-dev.isrd.isi.edu/ermrest/catalog/7/entity/public:regions/loc=chr1%3A817425-817435?accept=json"
  fromJSON(getURL(url))

library(RCurl)
library(jsonlite)
url <- "https://bdds-dev.isrd.isi.edu/ermrest/catalog/7/entity/public:regions/loc=chr1%3A817425-817435?accept=json"
print(fromJSON(getURL(url)))
                 loc chrom  start endpos id
1 chr1:817425-817435  chr1 817425 817435  2

url2 <- "https://bdds-dev.isrd.isi.edu/ermrest/catalog/7/entity/public:regions/loc=chr1%3A817425-817435/HITS:=(loc)=(public:hits:loc)/REGION:=left(loc)=(public:regions:loc)/$HITS?accept=json"
print(fromJSON(getURL(url2)))

                 loc               type     name length strand        sample_id method         provenance score1  score2   score3 score4 score5 score6       id
1 chr1:817425-817435 motif.in.footprint MA0002.2     11      + ENCSR000EIJ_hint   HINT brain.filler.minid     79 13.0345 1.59e-05     NA     NA     NA 38957240
2 chr1:817425-817435 motif.in.footprint MA0483.1     11      - ENCSR000EIJ_hint   HINT brain.filler.minid     79 12.0517 4.18e-05     NA     NA     NA 39017717
3 chr1:817425-817435 motif.in.footprint MA0002.2     11      + ENCSR000ENE_hint   HINT brain.filler.minid    268 13.0345 1.59e-05     NA     NA     NA 39408967
4 chr1:817425-817435 motif.in.footprint MA0483.1     11      - ENCSR000ENE_hint   HINT brain.filler.minid    268 12.0517 4.18e-05     NA     NA     NA 39474334







*-----------------------------------------------------------------------------------------------------------------------
* hugelkultur blog post

  http://www.greenseattle.org/amending-soil-through-hugelkultur/

*-----------------------------------------------------------------------------------------------------------------------
* sword fern info

  --- june 2011 hatchery trail photos, jordan jackson
    http://metropolitangardens.blogspot.com/2011/11/seward-park.html
    http://3.bp.blogspot.com/-vTGQx6jJB4Y/TooXF2SrtxI/AAAAAAAATrM/wt7FpggKfLY/s640/Fallen+tree+0611.JPG
    http://1.bp.blogspot.com/-CkVIBfzU74I/TooXIpvuJ9I/AAAAAAAATrk/k7q9uqsf3Xo/s1600/Seward+Park+valley+0611.JPG

  --- bill gardner, ParaLogics Water Sciences
    Name: Bill Gardner
    Email: billgardner35@msn.com

     Comment: Has symptoms of a fungal problem. Collect soil samples in a location at the leading edge of the
     encroachment and a sample two feet into the growing area measured from the first sample. Have a lab compare the two
     samples and look for a microbe present in first sample and absent in the second sample. If one is found the
     restoration should be relatively simple. We deal with similar infestations (not in forest settings) routinely at
     ParaLogics Water Sciences.

   --- another healthy fern photo
      http://thomasbancroft.photoshelter.com/image/I00008oMmkkItv8c
        "Sword ferns grow in abundance under the closed canopy of an old growth forest at Seward Park."

*-----------------------------------------------------------------------------------------------------------------------
* toggle hide and show div (18 may 2017)

   ~/s/examples/js/verticalPanel/index.html
*-----------------------------------------------------------------------------------------------------------------------
* cellphoneJS, simulator webapp, add phone tree and help (17 may 2017)



  cd ~/github/cellphoneJS/webpack-version/
  make   # calls webpacks, then open index.html


  --- bootrap sliding pane?
    cd ~/s/examples/js/bootstrapSlider

*-----------------------------------------------------------------------------------------------------------------------
* trenaViz demo, aqp4 and rs3763043: make an sqlite database (30 may 2017)

  [status (30 may 2017): cory provided /local/Cory/for_Paul/aqp4_fp.RData
   cd ~/s/work/priceLab/ohsu-aquaporin
   print(load("footprintsFromCory/aqp4_fp.RData"))  # fp
   names(fp$AQP4)  # [1] "tfs" "tbl" "tfs" "tbl" "tfs" "tbl" "tfs" "tbl"
   tbl.snps <- data.frame()
   tbl.snps <- rbind(tbl.snps, fp$AQP4[[2]])
   tbl.snps <- rbind(tbl.snps, fp$AQP4[[4]])
   tbl.snps <- rbind(tbl.snps, fp$AQP4[[6]])
   tbl.snps <- rbind(tbl.snps, fp$AQP4[[8]])
   dim(tbl.snps) # [1] 240237     20

   --- compare this to hits and regions on a whovian database


*-----------------------------------------------------------------------------------------------------------------------
* trenaViz demo, aqp4 and  rs3763043

  [status (30 may 2017): cory provided /local/Cory/for_Paul/aqp4_fp.RData
   cd ~/s/work/priceLab/ohsu-aquaporin
   print(load("footprintsFromCory/aqp4_fp.RData"))  # fp
   names(fp$AQP4)  # [1] "tfs" "tbl" "tfs" "tbl" "tfs" "tbl" "tfs" "tbl"


[1] --- rs3763043
[1] lostTFs.20: TEAD1,TCF12,NEUROD2,PRRX1,OTX1,ELF1,ELK3,ELF2,NFATC1,ELK4,TEAD3,ELK1,HOPX,SCX,TCF4,NFAT5,NFATC2,TCF3,NFATC4,HESX1,NHLH1,ETV4,TEAD2,FEV,LYL1,ERG,FLI1,MESP2,ARX,NEUROD6,ERF,ALX3,VSX1,RAX2,ETV1,MESP1,ETV5,TEAD4,NEUROD1,ELF4,ETV3,TWIST2,DRGX,ETV7,TWIST1,TAL1,NHLH2,RHOXF1,BHLHE22,SPDEF,ETV6,NFATC3
[1] createdTFs.20: HSF1,HSF4,HSF2
        IncNodePurity     gene.cor
TEAD1     29.90525712  0.760538317
TCF12      1.62745534  0.661929427
NEUROD2    2.20841964 -0.563189422
PRRX1      1.54042301  0.619890322



   --- no regulatory regions in brain_hint of encode dhsclustered for any of the 4 ohsu aqp4 snps.
     got new footprints from cory:
     lapply(c(2,4,6,8), function(i) dim(fp$AQP4[[i]]))
        [1] 86694    20
        [1] 93769    20
        [1] 29662    20
        [1] 30112    20

    tbl.snps <- data.frame()
    tbl.snps <- rbind(tbl.snps, fp$AQP4[[2]])
    tbl.snps <- rbind(tbl.snps, fp$AQP4[[4]])
    tbl.snps <- rbind(tbl.snps, fp$AQP4[[6]])
    tbl.snps <- rbind(tbl.snps, fp$AQP4[[8]])
    dim(tbl.snps) # [1] 240237     20

    table(tbl.snps$provenance)

      brain_hint_16.minid       brain_hint_20.minid brain_wellington_16.minid brain_wellington_20.minid
                    86694                     93769                     29662                     30112

    tbl.bed <- unique(tbl.snps[, c("chrom", "start", "endpos", "name", "score1", "strand")])
    dim(tbl.bed) # [1] 13936     6
    write.table(tbl.bed, row.names=FALSE, col.names=FALSE, quote=FALSE, sep="\t", file="aqp4-fp.bed")


*-----------------------------------------------------------------------------------------------------------------------
* cognitive biology

  bacterial cognition: http://mechanism.ucsd.edu/teaching/f13/cs200/bacterialinformationprocessing.pdf

*-----------------------------------------------------------------------------------------------------------------------
* jquery tab tips:  raise tab, on tab activation

  --- for example:

   <div id="trenaVizDiv">
     <ul>
       <li><a href="#igvDiv">IGV</a></li>
       <li><a href="#cyOuterDiv">Network</a></li>
       <li><a href="#modelDiv">Model</a></li>
     </ul>


     <div id="cyOuterDiv">
        <div id="cyMenubarDiv">
            <button id='cyFitButton' class="cyMenuButton">Fit</button>
            <button id='cyFitSelectedButton'class="cyMenuButton">Fit Selected</button>
            <button id='cySFNButton' class="cyMenuButton">SFN</button>
            <button id='cyHideUnselectedButton' class="cyMenuButton">Hide Unselected</button>
            <button id='cyShowAllButton' class="cyMenuButton">Show All</button>
        </div>
        <div id="cyDiv"></div>
     </div>

     <div id="igvDiv"> </div>
     <div id="modelDiv">
       tabular view coming soon
     </div>
   </div>



  --- one solution
    $('a[href="#igvDiv"]').click();       // raises first tab
    see this in a switch statement:
       ~/github/trenaUtilities/inst/scripts/trenaViz.html, raiseTab(msg)

  --- another
    $("#trenaVizDiv").tabs({active: 2})   // raise 3rd tab


   --- on  tab activation
  trenaVizDiv.tabs({
     activate: function(event, ui){
        if(ui.newPanel.is("#cyOuterDiv")){
          console.log("cy!");
          handleWindowResize();
          cy.resize();
          }
        else if(ui.newPanel.is("#igvDiv")){
          console.log("igv!");
          }
        else if(ui.newPanel.is("#modelDiv")){
          console.log("model!");
          }
        else{
          console.log("unrecognized tab activated");
          }
        }
     });


*-----------------------------------------------------------------------------------------------------------------------
* how to grok dbSNP and SNPlocs.Hsapiens.dbSNP144.GRCh38 (12 may 2017)

snpsById(SNPlocs.Hsapiens.dbSNP144.GRCh38, "rs3763040")
GPos object with 1 position and 2 metadata columns:
      seqnames       pos strand |   RefSNP_id alleles_as_ambig
         <Rle> <integer>  <Rle> | <character>      <character>
  [1]     ch18  26864410      + |   rs3763040                D

                                         |
   chr18:26,864,405-26,864,415 wt:  ACAGGGGGGTG

   IUPAC_CODE_MAP[["D"]]   # [1] "AGT"

                             T/G/A
   ATGCGTGGGATGTGGCTGGCCACCC[A/C/T]CCTGTGGAGCCAGCTCTTCCTTTAT   # reverse strand
   Chromosome: 18:26864410

   Gene:AQP4-AS1 (GeneView) AQP4 (GeneView) Functional Consequence:
   intron variant,upstream variant 2KB Validated: by 1000G,by
   cluster,by frequency,by hapmap HGVS: NC_000018.10:g.26864410G>A,
   NC_000018.10:g.26864410G>T, NC_000018.9:g.24444374G>A,
   NG_029560.1:g.6343C>A, NG_029560.1:g.6343C>T,
   NM_001317384.1:c.32+1248C>A, NM_001317384.1:c.32+1248C>T,
   NM_001317387.1:c.32+1248C>A, NM_001317387.1:c.32+1248C>T,
   NM_001650.5:c.32+1248C>A, NM_001650.5:c.32+1248C>T,
   NM_004028.4:c.-1848C>A, NM_004028.4:c.-1848C>T,
   NR_026908.1:n.-898G>A, NR_026908.1:n.-898G>T,
   XM_005258257.1:c.-31+1248C>T, XM_011525942.2:c.-1438C>A,
   XM_011525942.2:c.-1438C>T, XR_243846.1:n.-181G>A

  --- simpler example?
     as.data.frame(snpsById(SNPlocs.Hsapiens.dbSNP144.GRCh38, "rs3875089"))
       seqnames      pos strand RefSNP_id alleles_as_ambig
     1     ch18 26865469      + rs3875089                Y  (C or T)
     IUPAC_CODE_MAP[["Y"]] #  "CT"
     getSequence(mm, data.frame(chrom="chr18", start=26865469, end=26865469))  # [1] "T"

    but https://www.ncbi.nlm.nih.gov/snp/?term=rs3875089 says:
       GCATAGAGAAGGTAGAAGAAAAGGG[A/G]TGCTTTTTAGCCAAATCCTCCATAT
    blat puts this on the minus strand
    thus [A/G] means +strand wt T, mutant allele C

  --- strategy when supplied with rsid



*-----------------------------------------------------------------------------------------------------------------------
* ohsu aquaporin AQP4 variants (12 may 2017)

  https://www.ncbi.nlm.nih.gov/pubmed/26433375:
     The Potential Roles of Aquaporin 4 in Alzheimer's Disease, 2016

   ~/s/work/priceLab/ohsu-aquaporin/go.R

  rs3763040: 18:26864410 A/C/T
  rs3875089: 18:26865469 A/G
  rs335929:  18:26855623 A/C/G
  rs3763043: 18:26855854 A/G
  rs9951307: 18:26850565 A/G


*-----------------------------------------------------------------------------------------------------------------------
* qiang's gbm variants: do they change TReNA predictions? spreadsheet for  (17 may 2017)

  cd ~/s/work/qiang/gbm/
  go.R

*-----------------------------------------------------------------------------------------------------------------------
* qiang's gbm variants: do they change TReNA predictions? (9 may 2017)


  --- email from xiaowei
  Here are the variants we are curious about their effects in GBM:

     ---   copy number lost (hg19):
        chr1:6,212,000-7,790,000

    --- SNP (hg19):
      chr16: 67876493   THAP11_c.36C>A    thap11 (short gene), see also nutf2 and cenpt, tsnaxip1
      chr7:  6063107    AIMP2_c.748A>G, plus strand   also EIF2AK1 gene, minus strand, and PMS2 on minsu strand
      chr17: 7578509   PTEN_c.803C>G
      chr17: 7578509  TP53_c.421T>C


*-----------------------------------------------------------------------------------------------------------------------
* R regexpr match

s <- "chr5:120-500"
match <- regexpr("(?<chromosome>chr.*):(?<startPos>\\d+)-(?<endPos>\\d+)", "chr5:120-500", perl=TRUE)
if(match == 1){
   info <- attributes(match)
   result <- list()
   for(name in info$capture.names){
      start <- as.integer(info$capture.start[1, name])
      length <- as.integer(info$capture.length[1, name])
      result[[name]] <- substring(s, start, start+length-1)
      if(name %in% c("startPos", "endPos"))
         result[[name]] <- as.numeric(result[[name]])
      } # for name
   } # if match


print(result)



*-----------------------------------------------------------------------------------------------------------------------
* comparing fimo and bioc motif matching with vrk2:  is bioc good enough (5 may 2017)

  cd ~/github/TReNA/inst/unitTests
  test_getCandidates.vrk2.rs13384219.neighborhood()

   candidateFilterSpec <- create.vrk2.rs13384219.neighborhood.candidateFilterSpec()

   hdf <- with(candidateFilterSpec,
               HumanDHSFilter(genomeName,
                              encodeTableName=encodeTableName,
                              fimoDatabase.uri=fimoDB,
                              geneInfoDatabase.uri=geneInfoDB,
                              regionsSpec=regionsSpec,
                              geneCenteredSpec=geneCenteredSpec,
                              quiet=TRUE))
   x <- getCandidates(hdf)
   browser()
   checkEquals(sort(names(x)), c("tbl.bioc", "tbl.fimo", "tfs.bioc", "tfs.fimo"))
   motifs.bioc <- x$tbl.bioc$motifname   # 148
   motifs.fimo <- x$tbl.fimo$motifname   # 13

    motifname chrom    start   endpos strand motifscore     pval         sequence chromStart chromEnd count score                                                                                                           tf
   2   MA0078.1  chr2 57907329 57907337      -  12.303400 2.03e-05        CACATTGTC   57907313 57907333     1    98 SOX17;SOX30;SOX15;SOX7;SOX18;SOX8;SOX9;SOX10;SOX5;SOX6;SOX13;SOX4;SOX11;SOX12;SOX1;SOX2;SOX3;SOX14;SOX21;SRY
   9   MA0646.1  chr2 57907311 57907321      -  12.183700 3.29e-05      CATGCTGGTTC   57907313 57907333     1    98                                                                                                    GCM1;GCM2
   22  MA0834.1  chr2 57907333 57907346      -   6.857140 8.54e-05   CTATGAAGTCACAT   57907313 57907333     1    98                                                   ATF7;ATF2;CREB5;NFE2L1;NFE2L2;NFE2L3;BACH1;BACH2;JUNB;JUND
   3   MA0088.2  chr2 57907311 57907326      +   0.844828 7.81e-05 GAACCAGCATGCAAAT   57907313 57907333     1    98                                                                                                       ZNF143


  ---- why do we miss MA0078.1?
    consensusString(reverseComplement(pfms[["MA0078.1"]]))  # [1] "GACAATG??"
    consensusString(pfms[["MA0078.1"]])                     # [1] "??CATTGTC"
   tbl <- TReNA:::.getScoredMotifs("ACCAGCATGCAAATTAGACAA", 50)[[1]]
   matchPWM(reverseComplement(pfms[["MA0078.1"]]), "TTGTCTAATTTGCATGCTGGT", with.score=TRUE, min.score="50%")
       start end width
           4  12     9 [TCTAATTTG]


  --- tbl.regions
     chrom chromStart chromEnd count score
   9  chr2   57907313 57907333     1    98
   seqs <- "ACCAGCATGCAAATTAGACAA"

   pfms[["MA0078.1"]]
              1         2          3          4          5 6 7          8         9
    A 0.2258065 0.2580645 0.09677419 0.96774194 0.00000000 0 0 0.00000000 0.0000000
    C 0.2903226 0.2580645 0.58064516 0.00000000 0.03225806 0 0 0.00000000 0.5483871
    G 0.1935484 0.1290323 0.03225806 0.00000000 0.00000000 0 1 0.06451613 0.3225806
    T 0.2903226 0.3548387 0.29032258 0.03225806 0.96774194 1 0 0.93548387 0.1290323

   consensusString(pfms[["MA0078.1"]]) # [1] "??CATTGTC"
   segs.rc <- as.character(reverseComplement(DNAString(seqs)))  #  "TTGTCTAATTTGCATGCTGGT"



*-----------------------------------------------------------------------------------------------------------------------
*  bdds fimo db (5 may 2017)

  --- riptide
   /Applications/Postgres.app//Contents/Versions/9.6/bin/psql -U trena --host bddsrds.globusgenomics.org fimo  password also trena

  PGPASSWORD=bdds_postgres_rds_pass*word psql fimo --host=bddsrds.globusgenomics.org --port=5432 --username=galaxy

*-----------------------------------------------------------------------------------------------------------------------
* direct calls to getRegulatoryRegions yields nothing, in context of getCandidates returns > 0 rows (4 may 2017)

  [status: I had the chromosme wrong.  sheesh]

  > source("test_HumanDHSFilter.R"); test_checkAllEncodeTables()
     [1] --- test_checkAllEncodeTables

     [1] "fimo_hg38"
     [1] query: select * from wgEncodeRegDnaseClustered where chrom = 'chr5' and chromStart >= 57907313 and chromEnd <= 57907333
     [1] 0 DHS regions reported in 21 bases, start:end unmodified
     [1] possible that start:end (21) is small relative to DHS regions, extend by 10000
     [1] query with extended region, 17 rows
     [1] tbl.regionsExtended: 17 rows, now have intersection
     [1] GenomicRanges intersections of extended region with original target: 0

  > test_getCandidates.vrk2.rs13384219.neighborhood()
     [1] --- test_getCandidates.vrk2.rs13384219.neighborhood
     [1] "fimo_hg38"
     [1] query: select * from wgEncodeRegDnaseClustered where chrom = 'chr2' and chromStart >= 57907313 and chromEnd <= 57907333
     [1] 0 DHS regions reported in 21 bases, start:end unmodified
     [1] possible that start:end (21) is small relative to DHS regions, extend by 10000
     [1] query with extended region, 20 rows
     [1] tbl.regionsExtended: 20 rows, now have intersection
     [1] GenomicRanges intersections of extended region with original target: 1


  --- comparing the extended region query

   select * from wgEncodeRegDnaseClustered where chrom = 'chr5' and chromStart >= 57897313 and chromEnd   <= 57917333
   select * from wgEncodeRegDnaseClustered where chrom = 'chr2' and chromStart >= 57897313 and chromEnd   <= 57917333


   --- once fixed, the cell type emerges

    I have been using your VRK2 promoter variant to develop and test
    the recipe-driven TReNA I have been working on.

    I found just one sample in wgEncodeRegDnaseClustered, which is
    built from 95 cell types.  So I looked into each contributing
    table to find out which one has the DHS reads:


   wgEncodeRegDnaseUwGm12878Peak

    Described at https://www.genome.gov/26524238/encode-project-common-cell-types/

   GM12878 is a lymphoblastoid cell line produced from the blood of a
   female donor with northern and western European ancestry by EBV
   transformation. It was one of the original HapMap cell lines and
   has been selected by the International HapMap Project for deep
   sequencing using the Solexa/Illumina platform. This cell line has a
   relatively normal karyotype and grows well. Choice of this cell
   line offers potential synergy with the International HapMap Project
   and genetic variation studies. It represents the mesoderm cell
   lineage. Cells will be obtained from the Coriell Institute for
   Medical Research [coriell.org] (Catalog ID GM12878).


*-----------------------------------------------------------------------------------------------------------------------
* todo, wednesday (3 may 2017)

   cd ~/github/TReNA/inst/unitTests
   source("test_HumanDHSFilter.R"); test_getRegulatoryRegions()
    [1] --- test_getRegulatoryRegions
    [1] "fimo_hg38"
    [1] query: select * from wgEncodeRegDnaseClustered where
   Error in .local(conn, statement, ...) (from test_HumanDHSFilter.R#176) :
    could not run statement: You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near '' at line 1

*-----------------------------------------------------------------------------------------------------------------------
* TReNA: some possible sources for regulatory regions

   http://www.genecards.org/Guide/GeneCard (2 may 2017)
      search for "Regulatory Elements for MEF2C Gene" on http://www.genecards.org/cgi-bin/carddisp.pl?gene=MEF2C

*-----------------------------------------------------------------------------------------------------------------------
* fimo whole genome hg38 database on whovian
  library(RPostgreSQL)
  database.host <- "whovian"
  db <- dbConnect(PostgreSQL(), user= "trena", password="trena", dbname="fimo", host=database.host)
  dbListTables(db)  # [1] "fimo_hg38"
  dbGetQuery(db, "select * from fimo_hg38 limit 10")
       motifname chrom start endpos strand motifscore     pval empty    sequence
    1   MA0002.2    10 18991  19001      -    12.4655 2.73e-05       TTCTGTGGTTC
    2   MA0002.2    10 19478  19488      -    13.3448 1.17e-05       TTCTGTGGTTG
    3   MA0002.2    10 20814  20824      -    12.9483 1.69e-05       GGCTGTGGGTT

*-----------------------------------------------------------------------------------------------------------------------
* cyjs cellphone, dijkstra shortest paths on hidden edges


   max says:

     Most functions and algorithms can be called on subgraphs such
     that the function only considers the subgraph (i.e. calling
     collection).

   If you call cy.elements(':visible').dijkstra(), for example, only visible elements will be considered.

*-----------------------------------------------------------------------------------------------------------------------
* cellphone cyjs

  cd ~/github/cellphoneJS/webpack-version

  make clean install run


*-----------------------------------------------------------------------------------------------------------------------
* webpack jquery bootstrap cellphone simulator (24 apr 2017)


  [better info on this: see ~/github/cellphoneJS/webpack-version/package.json]

  cd ~/github/projects/examples/js/webpack/learning-webpack2/moreModularCyjs/

#npm install --save-dev bootstrap
npm install webpack
npm install --save-dev bootstrap@v4.0.0-alpha.4
npm install --save-dev bootstrap-sass
npm install --save-dev extract-text-webpack-plugin
npm install --save-dev node-sass
npm install --save-dev resolve-url-loader@*
npm install --save-dev url-loader@*
npm install --save-dev file-loader@*
npm install --save-dev sass-loader@*
npm install --save-dev bootstrap-loader


*-----------------------------------------------------------------------------------------------------------------------
* upton sinclair

  Sinclair helped found the California chapter of the American Civil
  Liberties Union in the 1920s.

  Sinclair is well-known for his principle: "It is difficult to get a
  man to understand something when his salary depends on his not
  understanding it." This line has been quoted in many political
  books, essays, articles, and other forms of media, including Al
  Gore's 2006 film, An Inconvenient Truth.

*-----------------------------------------------------------------------------------------------------------------------
* barbara mclintock: the genome is a "highly sensitive organ of the cell"
*-----------------------------------------------------------------------------------------------------------------------
* git tips, github tips, unstage (large) file which can't be pushed (23 apr 2017)

  remote: error: File priceLab/AD/IGAP_stage_1.txt.lifted is 383.12 MB; this exceeds GitHub's file size limit of 100.00 MB
  remote: error: File priceLab/AD/gwasFimo/IGAP_stage_1.txt is 320.98 MB; this exceeds GitHub's file size limit of 100.00 MB
  remote: error: File priceLab/AD/snp.zip is 391.85 MB; this exceeds GitHub's file size limit of 100.00 MB


*-----------------------------------------------------------------------------------------------------------------------
* webpack version of cellphoneJS (22 apr 2017)

  cd ~/github/cellphoneJS/webpack-version
  npm install webpack -g

*-----------------------------------------------------------------------------------------------------------------------
* gulp tips

   npm install gulp-cli -g
   npm install gulp -D
   touch gulpfile.js
   gulp --help

*-----------------------------------------------------------------------------------------------------------------------
* node and npm tips

  --- where are -g modules installed?

     /usr/local/bin/gulp -> /usr/local/lib/node_modules/gulp-cli/bin/gulp.js
     dir /usr/local/lib/node_modules/
       408 Apr 23 13:33 gulp-cli/
       850 Feb 21 16:33 npm/
       408 Apr 22 19:40 webpack/



*-----------------------------------------------------------------------------------------------------------------------
* cyjs: build the latest version using gulp (23 apr 2017)

  cd ~/github/cytoscape.js

  git pull origin
  npm install gulp
  npm install

  gulp build
  gulp test
  gulp dist

   dir ~/github/cytoscape.js/dist

     3347362 Apr 23 13:46 cytoscape.js
      288661 Apr 23 13:46 cytoscape.min.js



*-----------------------------------------------------------------------------------------------------------------------
* simple cyjs and webpack version 2 (23 apr 2017)

   cd ~/github/projects/examples/js/webpack/learning-webpack2/simpleCyjs/

   following https://www.npmjs.com/package/cytoscape
   npm install cytoscape --save   # 1 node_modules directory
   npm install webpack


*-----------------------------------------------------------------------------------------------------------------------
* simple jquery and webpack version 2 (23 apr 2017)

   cd ~/github/projects/examples/js/webpack/learning-webpack2/jquery
   make clean install run

   to start, 6 files:
     index.html
     content.js
     entry.js
     style.css
     makefile
     webpack.config.js
        var path = require('path');
        const webpack = require('webpack'); //to access built-in plugins
        module.exports = {
          entry: './entry.js',
          plugins: [
            new webpack.ProvidePlugin({
              $: "jquery",
              jQuery: "jquery"
              })],
          module: {
            rules:[{
               test: /\.css$/,
               use: [ 'style-loader', 'css-loader' ]
               }]},
          output: {
           path: path.resolve(__dirname, 'dist'),
           filename: 'bundle.js'
           },
        };

   ---- install modules
     npm init -y
     npm install jquery --save
     npm install webpack --save
     npm install style-loader css-loader --save-dev
     make
        we see that this line in entry.js executes:   $("#cyDiv").height(300);


*-----------------------------------------------------------------------------------------------------------------------
* learning webpack version 2 (23 apr 2017)

  --- how to load css?
     following https://webpack.js.org/loaders/css-loader/
     import css from './style.css';

  --- install npm-related modules
    npm init -y  # create package.json
       # add description and repository fields
    npm install --save-dev css-loader   # adds 119 modules!
    npm install --save-dev style-loader # adds 1 more

  cd ~/github/projects/examples/js/webpack/learning-webpack2/level0
  make
  uses this webpack.config.js:

      var path = require('path');
      module.exports = {
        entry: './entry.js',
        module: {
          rules:[{
             test: /\.css$/,
             use: [ 'style-loader', 'css-loader' ]
             }]
          },
       output: {
         path: path.resolve(__dirname, 'dist'),
         filename: 'bundle.js'
         },
      };



*-----------------------------------------------------------------------------------------------------------------------
* cellphoneJS simulator (22 apr 2017)

   cd ~/github/cellphoneJS/submenu-simple/


   --- to run
     open index.html


*-----------------------------------------------------------------------------------------------------------------------
* toggle cyjs trena for jocelyn (21 apr 2017)

  expression data: /price1/sament/human_aba
  snps in ~/github/projects/priceLab/joceyln/psychiatricDisease/snps.scz2_108_loci.p1e4.tfbs.trn.cor.eQTL.coreTFs.xlsx

*-----------------------------------------------------------------------------------------------------------------------
* bddsrds.globusgenomics.org    ravi

    ~/github/projects/examples/database/footprints/directAccessToRegionsAndHitsTables.R

   genome.db.uri    <- "postgres://bddsrds.globusgenomics.org/hg38"                  # has gtf and motifsgenes tables
   footprint.db.uri <- "postgres://bddsrds.globusgenomics.org/brain_hint"            # has hits and regions tables
   fpf <- FootprintFinder(genome.db.uri, footprint.db.uri, quiet=FALSE)
   tbl.fp <- getFootprintsInRegion(fpf, "chr5", 88822685, 89011824)

   * direct 2-query extraction of footprints from globusgenomics brain/hint database (21 apr 2017)

   library(RPostgreSQL)
   database.host <- "bddsrds.globusgenomics.org"

   # first, the hg38 gtf table
   db.hg38 <- dbConnect(PostgreSQL(), user= "trena", password="trena", dbname="hg38", host=database.host)
   dbListTables(db.hg38)   # [1] "motifsgenes" "gtf"
   query <- "select * from gtf where moleculetype='gene' and gene_biotype='protein_coding' limit 5"
   dbGetQuery(db.hg38, query)[, c(1:3,5,10)]

   # now, the footprint database, brain, hint as footprint caller, two tables: regions and hits
   # the regions table has every unique chromosome:start-end region in the whole genome in which
   # one or more samples had a footprint called.  there are no duplicates in the regions table
   # the hits table has the actual footprint information, sample ID, score,
   db.fp  <- dbConnect(PostgreSQL(), user= "trena", password="trena", dbname="brain_hint", host=database.host)

   chromosome <- "chr5"
   start <- 88717221
   end   <- 88717502

   query.part.1 <- "select loc, chrom, start, endpos from regions"
   query.part.2 <- sprintf("where chrom='%s' and start >= %d and endpos <= %d", chromosome, start, end)
   query.regions <- paste(query.part.1, query.part.2)

   tbl.regions <- dbGetQuery(db.fp, query.regions)   # just 5 rows


   loc.set <- sprintf("('%s')", paste(tbl.regions$loc, collapse="','"))
   query.hits <- sprintf("select * from hits where loc in %s", loc.set)
   tbl.hits <- dbGetQuery(db.fp, query.hits)
   tbl.out <- merge(tbl.regions, tbl.hits, on="loc")


*-----------------------------------------------------------------------------------------------------------------------
* GO annotation filter for TReNA, 94 GO terms, 2898 genes

   ~/github/projects/GO/go.R

   -- some plausible BP terms:

     # 1 GO:0010467                      gene expression
     # 2 GO:0006351         transcription, DNA-templated
     # 3 GO:0097659 nucleic acid-templated transcription
     # 4 GO:0001172         transcription, RNA-templated
     # 5 GO:0006351         transcription, DNA-templated

   print(load("~/github/TReNA/inst/extdata/human.regulatory.genes.RData"))
    "all.regulatory.genes" "tbl.names"

      sort(sapply(all.regulatory.genes, length), decreasing=TRUE)
       GO:0006351  GO:0045944  GO:0000122  GO:0006366 unannotated  GO:0042795
             1786         947         703         509          72          70
       GO:0006383  GO:0042789  GO:0009303  GO:0006390  GO:0042791  GO:0042796
               32          15          12          10           6           6
       GO:0042797  GO:0006360  GO:0009299  GO:0009301  GO:0001172  GO:0061614
                6           5           5           4           2           2
       GO:0009304  GO:0097659  GO:0001059  GO:0001060  GO:0001121  GO:0009300
                2           1           1           1           1           1
> unlist(lapply(names(head(sort(sapply(all.regulatory.genes, length), decreasing=TRUE), n=12)), function(name) subset(tbl.names, GOID==name)$TERM))
 [1] "transcription, DNA-templated"
 [2] "positive regulation of transcription from RNA polymerase II promoter"
 [3] "negative regulation of transcription from RNA polymerase II promoter"
 [4] "transcription from RNA polymerase II promoter"
 [5] "unannotated"  # from seth's motifsGenes list
 [6] "snRNA transcription from RNA polymerase II promoter"
 [7] "transcription from RNA polymerase III promoter"
 [8] "mRNA transcription from RNA polymerase II promoter"
 [9] "rRNA transcription"
[10] "transcription from mitochondrial promoter"
[11] "5S class rRNA transcription from RNA polymerase III type 1 promoter"
[12] "snRNA transcription from RNA polymerase III promoter"



names(head(sort(sapply(all.regulatory.genes, length), decreasing=TRUE), n=12))
 [1] "GO:0006351"  "GO:0045944"  "GO:0000122"  "GO:0006366"  "unannotated"
 [6] "GO:0042795"  "GO:0006383"  "GO:0042789"  "GO:0009303"  "GO:0006390"
[11] "GO:0042791"  "GO:0042796"
>


      head(tbl.names)
              GOID                                                                 TERM
      1 GO:0097659                                 nucleic acid-templated transcription
      2 GO:0001172                                         transcription, RNA-templated
      3 GO:0006351                                         transcription, DNA-templated
      4 GO:0000122 negative regulation of transcription from RNA polymerase II promoter
      5 GO:0045944 positive regulation of transcription from RNA polymerase II promoter
      6 GO:0001059                        transcription from RNA polymerase IV promoter



   save(all.regulatory.genes, tbl.names, file="human.regulatory.genes.RData")
all.regulatory.genes$unannotated
 [1] "PRRX2"    "TEAD1"    "E2F3"     "HNF4G"    "EMX1"     "CENPB"    "LHX9"     "VENTX"
 [9] "NR3C2"    "ZBED1"    "ZIC4"     "PKNOX2"   "TEAD4"    "RXRG"     "E2F2"     "DLX6"
[17] "EMX2"     "EVX2"     "GSC2"     "ISL2"     "SMARCA5"  "SMARCAD1" "SMARCAL1" "SMARCD1"
[25] "SMARCE1"  "MAZ"      "NKX2-4"   "RFXAP"    "NKX1-1"   "NKX1-2"   "HYKK"     "DBX1"
[33] "DBX2"     "TLX3"     "FOXD4L3"  "GATAD1"   "DNMT3L"   "MTA3"     "TCF23"    "MKX"
[41] "IRX1"     "IRX2"     "IRX4"     "IRX6"     "LEUTX"    "TPRX1"    "RHOXF2"   "RHOXF2B"
[49] "TBPL2"    "HDX"      "RFX7"     "THAP10"   "PRKRIR"   "THAP2"    "THAP3"    "THAP4"
[57] "THAP6"    "THAP8"    "THAP9"    "DMRTA2"   "DEC1"     "ZBED2"    "ZBED4"    "ZBED5"
[65] "DNAJC1"   "CRAMP1"   "HMGXB3"   "TOX4"     "UBTFL1"   "UBTFL6"   "SP140"    "SP140L"
>

   go.R   # very hacky code:


   root.0 <- "GO:0097659" # nucleic acid-templated transcription
   root.1 <- "GO:0001172" # transcription, RNA-templated
   root.2 <- "GO:0006351" # transcription, DNA-templated
   root.3 <- "GO:0000122" # negative regulation of transcription from RNA polymerase II promoter
   root.4 <- "GO:0045944" # positive regulation of transcription from RNA polymerase II promoter

   roots <- c(root.0, root.1, root.2, root.3, root.4)
   root.children <- unique(unlist(lapply(child2, showChildren)))  # 74

   child2 <- unique(unlist(lapply(root.children, showChildren)))  #90
   child3 <- unique(unlist(lapply(child2, showChildren)))  # 74
   child4 <- unique(unlist(lapply(child3, showChildren)))  # 90

   child5 <- unique(unlist(lapply(child4, showChildren)))  # 91
   child6 <- unique(unlist(lapply(child5, showChildren)))  # 91

   all.regulatory.terms <- unique(c(roots, child2, child3, child4, child5, child6))  # 95
   all.regulatory.genes <- lapply(all.regulatory.terms, genesAnnotatedTo)
   names(all.regulatory.genes) <- all.regulatory.terms
   reg.genes <- unique(unlist(all.regulatory.genes, use.names=FALSE))
   tbl.mg <- read.table("~/github/TReNA/inst/extdata/motifGenes.tsv", sep="\t", as.is=TRUE, header=TRUE)
   unannotated.genes <- setdiff(tbl.mg$tf.gene, reg.genes) # [1] 72
   all.regulatory.genes[["unannotated"]] <- unannotated.genes
   reg.genesPP <- unique(unlist(all.regulatory.genes, use.names=FALSE))
   setdiff(tbl.mg$tf.gene, reg.genesPP)
   x <- lapply(names(all.regulatory.genes)[-96], lookupID)  # 96 is "unannotated"
   tbl.names <- do.call("rbind", x)
   save(all.regulatory.genes, tbl.names, file="all.regulatory.genes.RData")

*-----------------------------------------------------------------------------------------------------------------------
* proposed GO annotation filter for TReNA, look at ESR1 and CREB3L1 genes (20 apr 2017)

  ESR1 is a TF, usually a homodimer, active after binding estrogen.  may be annotated as a nuclear hormone receptor
  CREB3L1 is (?) a more conventional TF
  DNMT3A (DNA Methyltransferase 3 Alpha)  not a proper transcription factor, but found in seth's motifsgenes.tsv

     GO:0010468 regulation of gene expression
     GO:0045893 positive regulation of transcription, DNA-templated

     library(org.Hs.eg.db)
     db <- org.Hs.eg.db
     select(db, keys="GO:1903799", keytype="GO", columns=c("SYMBOL", "GO"))
     library(GO.db)
     select(GO.db, keys="GO:1903799", keytype="GOID", columns=c("GOID", "TERM", "ONTOLOGY", "DEFINITION"))
     as.data.frame(t(select(GO.db, keys="GO:1903799", keytype="GOID", columns=c("GOID", "TERM", "ONTOLOGY", "DEFINITION"))))
                                                                                                                                               V1
       GOID  GO:1903799
       TERM  negative regulation of production of miRNAs involved in gene silencing by miRNA
       ONTOLOGY BP
       DEFINITION Any process that stops, prevents or reduces the frequency, rate or extent
                  of production of miRNAs involved in gene silencing by miRNA.

     ---- how many and which genes are annotated to (or below)?
        GO:0010468 regulation of gene expression
        x <- as.list(GOBPCHILDREN)
        x[["GO:0010468"]]
                 is_a         is_a         is_a         is_a         is_a         is_a
         "GO:0002331" "GO:0006355" "GO:0007468" "GO:0010608" "GO:0010628" "GO:0010629"
                 is_a      part_of         is_a         is_a         is_a         is_a
         "GO:0010793" "GO:0023019" "GO:0032922" "GO:0036206" "GO:0039656" "GO:0040029"
                 is_a         is_a         is_a         is_a         is_a         is_a
         "GO:0043484" "GO:0046782" "GO:0050684" "GO:0060968" "GO:1900095" "GO:1902796"
                 is_a         is_a         is_a
         "GO:1903317" "GO:2000232" "GO:2000235"
          parent <- "GO:0010468"
          kids <- as.character(x[[parent]])
          family <- c(parent, kids)
        --- get all genes annotated to goid<- "GO:0010468";
          dim(select(db, keys=goid, keytype="GO", columns=c("SYMBOL", "GO"))) # 90 genes
          dim(select(db, keys=kids, keytype="GO", columns=c("SYMBOL", "GO"))) # 1864

       length(unique(select(db, keys=kids, keytype="GO", columns=c("SYMBOL", "GO")))$SYMBOL)  # [1] 1864

         select(GO.db, keys=kids, keytype="GOID", columns=c("GOID", "TERM", "ONTOLOGY"))
         'select()' returned 1:1 mapping between keys and columns
                  GOID                                                              TERM ONTOLOGY
         1  GO:0002331                                      pre-B cell allelic exclusion       BP
         2  GO:0006355                        regulation of transcription, DNA-templated       BP
         3  GO:0007468                           regulation of rhodopsin gene expression       BP
         4  GO:0010608                 posttranscriptional regulation of gene expression       BP
         5  GO:0010628                            positive regulation of gene expression       BP
         6  GO:0010629                            negative regulation of gene expression       BP
         7  GO:0010793                            regulation of mRNA export from nucleus       BP
         8  GO:0023019     signal transduction involved in regulation of gene expression       BP
         9  GO:0032922                           circadian regulation of gene expression       BP
         10 GO:0036206                             regulation of histone gene expression       BP
         11 GO:0039656                       modulation by virus of host gene expression       BP
         12 GO:0040029                         regulation of gene expression, epigenetic       BP
         13 GO:0043484                                        regulation of RNA splicing       BP
         14 GO:0046782                                 regulation of viral transcription       BP
         15 GO:0050684                                     regulation of mRNA processing       BP
         16 GO:0060968                                      regulation of gene silencing       BP
         17 GO:1900095 regulation of dosage compensation by inactivation of X chromosome       BP
         18 GO:1902796                                   regulation of snoRNA processing       BP
         19 GO:1903317                                  regulation of protein maturation       BP
         20 GO:2000232                                     regulation of rRNA processing       BP
         21 GO:2000235                                     regulation of tRNA processing       BP

         select(GO.db, keys=family, keytype="GOID", columns=c("GOID", "TERM", "ONTOLOGY"))
         'select()' returned 1:1 mapping between keys and columns
                  GOID                                                              TERM ONTOLOGY
         1  GO:0010468                                     regulation of gene expression       BP
         2  GO:0002331                                      pre-B cell allelic exclusion       BP
         3  GO:0006355                        regulation of transcription, DNA-templated       BP
         4  GO:0007468                           regulation of rhodopsin gene expression       BP
         5  GO:0010608                 posttranscriptional regulation of gene expression       BP
         6  GO:0010628                            positive regulation of gene expression       BP
         7  GO:0010629                            negative regulation of gene expression       BP
         8  GO:0010793                            regulation of mRNA export from nucleus       BP
         9  GO:0023019     signal transduction involved in regulation of gene expression       BP
         10 GO:0032922                           circadian regulation of gene expression       BP
         11 GO:0036206                             regulation of histone gene expression       BP
         12 GO:0039656                       modulation by virus of host gene expression       BP
         13 GO:0040029                         regulation of gene expression, epigenetic       BP
         14 GO:0043484                                        regulation of RNA splicing       BP
         15 GO:0046782                                 regulation of viral transcription       BP
         16 GO:0050684                                     regulation of mRNA processing       BP
         17 GO:0060968                                      regulation of gene silencing       BP
         18 GO:1900095 regulation of dosage compensation by inactivation of X chromosome       BP
         19 GO:1902796                                   regulation of snoRNA processing       BP
         20 GO:1903317                                  regulation of protein maturation       BP
         21 GO:2000232                                     regulation of rRNA processing       BP
         22 GO:2000235                                     regulation of tRNA processing       BP

       dim(select(db, keys=family, keytype="GO", columns=c("SYMBOL", "GO"))) #  1954    4


   --- huge mismatch between our tbl.motifsgenes:
     tbl.mg <- read.table("~/github/TReNA/inst/aextdata/motifGenes.tsv", sep="\t", as.is=TRUE, header=TRUE)
     tfs <- unique(tbl.mg$tf.gene) # 845
     tbl.go <- select(db, keys=family, keytype="GO", columns=c("SYMBOL", "GO"))
      dim(tbl.go)  # [1] 1954    4
      setdiff(tfs, tbl.go$SYMBOL)  # > 514

      RUNX1 as sample: annotated to cellular component, core-binding factor complex

select(db, keys="RUNX1", keytype="SYMBOL", columns=c("SYMBOL", "GO"))
'select()' returned 1:many mapping between keys and columns
   SYMBOL         GO EVIDENCE ONTOLOGY
1   RUNX1 GO:0000975      IDA       MF
2   RUNX1 GO:0000977      IDA       MF
3   RUNX1 GO:0000977      IMP       MF
4   RUNX1 GO:0001047      IDA       MF
5   RUNX1 GO:0001228      IDA       MF
6   RUNX1 GO:0001228      IMP       MF
7   RUNX1 GO:0001503      IBA       BP
8   RUNX1 GO:0002062      IBA       BP
9   RUNX1 GO:0005515      IPI       MF
10  RUNX1 GO:0005524      IEA       MF
11  RUNX1 GO:0005634      IDA       CC
12  RUNX1 GO:0005654      IDA       CC
13  RUNX1 GO:0005737      IDA       CC
14  RUNX1 GO:0006366      IEA       BP
15  RUNX1 GO:0030097      IDA       BP
16  RUNX1 GO:0030854      IMP       BP
17  RUNX1 GO:0032743      IMP       BP
18  RUNX1 GO:0043231      IDA       CC
19  RUNX1 GO:0045766      ISS       BP
20  RUNX1 GO:0045893      IDA       BP
21  RUNX1 GO:0045944      IDA       BP
22  RUNX1 GO:0045944      IMP       BP
23  RUNX1 GO:0048935      TAS       BP
24  RUNX1 GO:0071425      TAS       BP
>

*-----------------------------------------------------------------------------------------------------------------------
* Seed limitation and lack of downed wood, not invasive species, threaten conifer regeneration in an urban forest

  open ~/Documents/swordFern-dieOff/Ettingeretal2017UE-Seed-limitation-and-lack-of-downed-wood-not-invasive-species-threaten-conifer-regen.pdf

   Ailene K. Ettinger & Benjamin R. Lee & Sarah Montgomery
   2017

*-----------------------------------------------------------------------------------------------------------------------
* nylgut banjo strings (14 jan 2015, 19 apr 2017)

  Aquila 5B Banjo Strings Set, medium tension, red B
  http://www.amazon.com/Aquila-5B-Banjo-Strings-Set/dp/B005WFSNX4/ref=sr_1_1?s=books&ie=UTF8&qid=1452820761&sr=8-1&keywords=nylgut+banjo+strings

*-----------------------------------------------------------------------------------------------------------------------
* studio 3 signs 117 nw 54th st: no-boot, no boot, don't walk here seward park signs (19 apr 2017)

  (206) 622-8204

   request pricing on 6 foam core, 6x6 no-boot signs
   http://www.dirtcheapsigns.com/Custom-Rider-Pins.php: H-stakes and "rider pins"


*-----------------------------------------------------------------------------------------------------------------------
* ess configuration (18 apr 2017)

  ~/.ess -> /Applications/Emacs2.app/Contents/Resources/site-lisp/ess/ess-custom.el
  made read-write, with distributed version renamed to
     /Applications/Emacs2.app/Contents/Resources/site-lisp/ess/ess-custom.el-orig

   these ~/.emacs custom variables were set by:
      f1-v ess-default-style
      click on you can CUSTOMIZE this variable
      make selection from pull down menu
      click "Apply and Save" button
1
     (custom-set-variables
      ;; custom-set-variables was added by Custom.
      ;; If you edit it by hand, you could mess it up, so be careful.
      ;; Your init file should contain only one such instance.
      ;; If there is more than one, they won't work right.
      '(ess-default-style (quote OWN))
      '(ess-indent-offset 20 t)
      '(ess-indent-with-fancy-comments nil)
      '(ess-own-style-list
        (quote
         ((ess-indent-offset . 3)
          (ess-offset-arguments . open-delim)
          (ess-offset-arguments-newline . prev-call)
          (ess-offset-block . open-delim)
          (ess-offset-continued . straight)
          (ess-align-nested-calls "ifelse")
          (ess-align-arguments-in-calls "function[ 	]*(")
          (ess-align-continuations-in-calls . t)
          (ess-align-blocks control-flow)
          (ess-indent-from-lhs arguments fun-decl-opening)
          (ess-indent-from-chain-start . t)
          (ess-indent-with-fancy-comments))))
      '(inferior-R-program-name "/usr/local/bin/R"))    # which R in ess?


     make OWN the ess-default style

  --- cannot yet make this stick, but this works in an R buffer
     esc-x set-var
       ess-indent-with-fancy-comments  nil
     f1-v: describe variable ess-default-style  'RRR'.

  use gui buffer to change, apply, save: You can customize this variable.

     which add this to the bottom of my ~/.emacs

       (custom-set-variables
         '(ess-default-style (quote BSD)))


  --- try changing the just installed customization file:
     /Applications/Emacs2.app/Contents/Resources/site-lisp/ess/ess-custom.el
     variables:
         ess-default-style    RRR is the default
         ess-indent-with-fancy-comments, value is t, non-nil means distinquish between #,##,###

   changed t to nil

    (defcustom ess-indent-with-fancy-comments nil
      "Non-nil means distiguish between #, ##, and ### for indentation.
       See `ess-style-alist' for for an overview of ESS indentation."
     :type 'boolean
     :group 'ess-edit)


*-----------------------------------------------------------------------------------------------------------------------
* TReNA, comparing biostrings matchPWM with FootprintFinder/brain/hint, with pre-calculated fimo (17 apr 2017)

   ~/github/TReNA/inst/unitTests

   jaspar <- dhsFilter@pfms


    ---- fpf.out$tbl finds 3 motifs in chr2:127107783-127107856

       chrom     start       end motifName length strand score1   score2   score3    tf
        chr2 127107794 127107814  MA0138.2     21      -    105  4.87755 7.39e-05  REST
        chr2 127107797 127107809  ZBTB6.p2     13      +     43  9.28947 6.56e-05 ZBTB6
        chr2 127107812 127107820  GTF2I.p2      9      +     64 13.57320 1.28e-05 GTF2I

    getSequence(dhsFilter, with(fpf.out$tbl, data.frame(chrom=chrom, chromStart=start, chromEnd=end)))
       [1] "TTCGGTCTCCGTGGCCCTAGA" "GGTCTCCGTGGCC"         "AGAGGTAGG"


     maxScore(jaspar[["MA0138.2"]])  1] 16.48217
     hits.fwd <- matchPWM(jaspar[["MA0138.2"]], "TTCGGTCTCCGTGGCCCTAGA", min.score="50%", with.score=TRUE)
     hits.rev <- matchPWM(reverseComplement(jaspar[["MA0138.2"]]), "TTCGGTCTCCGTGGCCCTAGA", min.score="50%", with.score=TRUE)

      mcols(hits)
DataFrame with 1 row and 1 column
      score
  <numeric>
1  10.81034
>


*-----------------------------------------------------------------------------------------------------------------------
* lost lake trail plants (spring 2017)

  Corylus cornuta, beaked hazelnut 40
  Mahonia nervosa, dwarf Oregon grape 60
  Oemleria cerasiformis, indian plum 30
  Pseudotsuga menziesii, Douglas fir 40
  Rubus parviflorus, thimbleberry 40
  Rubus spectabilis, salmonberry 40
  Rubus ursinus, trailing blackberry 50

*-----------------------------------------------------------------------------------------------------------------------
* igap cyjs model toggle todo (17 apr 2017)

  cd ~/github/dora/microservices/trena-igap
    use few inital lines in test_trenaIgapBrainServer.R

  igap snp at ~ chr2:127,108,473 falls in dhs, near brain hint footprints
  see if it creates a novel motif
  if so, create a model with and without that motif
  toggle back and forth

  start jupyter notebook server:
     cd ~/github/dora/notebooks/igap/
     jupyter notebook --port=10002 --NotebookApp.token=

  http://localhost:10002/notebooks/igap.ipynb

*-----------------------------------------------------------------------------------------------------------------------
* some igv.js tracks

  also see:
     file:///Users/paul/github/projects/examples/js/igvBareBones/trackTester.html

           var igvOptionsLocal = {locus: "chr1:167,682,112-167,754,838", // mpzl1 promoter
                                  showRuler: true,
             reference: {id: "geneSymbols_hg38",
                 fastaURL: "http://pshannon.systemsbiology.net/genomes/hg38.fa",
                 cytobandURL: "http://pshannon.systemsbiology.net/genomes/cytoband.hg38.txt",
                 },
                tracks: [
                  {name: 'Gencode v24',
                   url: "http://pshannon.systemsbiology.net/hg38/gencode.v24.annotation.sorted.gtf.gz",
                  indexURL: "http://pshannon.systemsbiology.net/hg38/gencode.v24.annotation.sorted.gtf.gz.tbi",
                  format: 'gtf',
                  visibilityWindow: 2000000,
                  displayMode: 'EXPANDED'
                  },
               {name: "igap gwas scores",
                  type: "wig",
                  format: "bedgraph",
                  min: 0,
                  max: 20,
                  url: 'http://pshannon.systemsbiology.net/hg38/variants/igap.bedgraph',
                  indexed: false,
                  //visibilityWindow: 1000000,
                  color: "#4400AA"
                  },

               {name: "brain hint fp",
                   type: "bed",
                   format: "bed",
                   min: 0,
                   max: 10,
                   color: "#AA0000",
                   indexed: true,
                   url: "http://pshannon.systemsbiology.net/annotations/brain_hint.bed.gz",
                   indexURL: "http://pshannon.systemsbiology.net/annotations/brain_hint.bed.gz.tbi",
                   },


              {name: 'geneSymbols_hg38',
                  url: 'http://pshannon.systemsbiology.net/hg38/geneSymbolSearch.bed',
                  indexed: false,
                  searchable: true,
                  visibilityWindow: 5000000,
                  displayMode: 'COLLAPSED',
                  color: "#448844"
                  },
              {name: "brain hint fp chr1 all",
                 type: "wig",
                 format: "bedgraph",
                 min: 0,
                 max: 10,
                 visibilityWindow: 100000,
                 indexed: true,
                 url: "http://pshannon.systemsbiology.net/annotations/brain_hint_chr1_all.bed.gz",
                 indexURL: "http://pshannon.systemsbiology.net/annotations/brain_hint_chr1_all.bed.gz.tbi",
                 },




*-----------------------------------------------------------------------------------------------------------------------
* .gitignore

.Rhistory
*.RData
.DS_Store

*-----------------------------------------------------------------------------------------------------------------------
* returning to TReNA, HumanDNaseCluterFilter, broadening to try to include all regulatory region tracks (13 apr 2017)

   https://genome.ucsc.edu/ENCODE/downloads.html

*-----------------------------------------------------------------------------------------------------------------------
* inject 59 possibly regualtory snps/motifs/tfs into liz blue's mpzl1 gene model (12 apr 2017)

   cd ~/github/dora/notebooks/AD-family.UM0463F/addSnpEffects/

   --- using prior work
     cp /Users/paul/github/dora/datasets/AD-family.cUM0463F/snps59.hg38.bed .
     cp -p /Users/paul/github/dora/notebooks/AD-trena/explorations/laptm5.R  .

   --- new work: createTable.R


*-----------------------------------------------------------------------------------------------------------------------
* mike iverson, hotel california, clawhammer

 https://www.youtube.com/watch?v=4MtYVyuZVG8

*-----------------------------------------------------------------------------------------------------------------------
* dan banjo


  going up to hamburg
  the girl I left on sandy
  jaybird died of the whooping cough
  bryson higgin's tune
  bull of the woods - james bryan
  farewell trion (also james bryan)
  marion reese's cumberland gap
  clyde davenport's boating up sandy

  sugar babe (not yet learned)
  boatman song
  john brown's march
  all young (modal)

  dark-haired girl, F
  josie-o, F
  baby ben - james byrant
  come on boys lets go to anaky?  http://neighborlymusic.net/m3222l07/wp-content/uploads/2016/05/Come-On-Boys-Lets-Go-To-Anaky.mp3
  roosian rabbit (straight & crooked) - john salyer


   --- rattletap tunes
      the girl I left on sandy
      jaybird died (G)
      bryson higgin's (G)
      farewell trion (C)
      cumberland gap, marion reese, G
      hell up coal holler, F
      henry king's reel
      rocking the weary land (d, starts on A chord)
      walking up georgia row (d)
      charlie barnett lowe's tune (d)

   --- candidates
     elzic's farewell: https://www.youtube.com/watch?v=f1ieaEHk77c   anna & mac, mt.airy
            wilson douglas: https://www.youtube.com/watch?v=fprZ66lKdfA
            rockbridge: https://www.youtube.com/watch?v=sqs8O7pho88
            banjo a la riley bagus: https://www.youtube.com/watch?v=xwUi1all8zs
            fretless: https://www.youtube.com/watch?v=4dnhAEL_alo

*-----------------------------------------------------------------------------------------------------------------------
* banjo cluck: 5 techniques
  https://www.youtube.com/watch?v=RVqWF_FC554
*-----------------------------------------------------------------------------------------------------------------------
* git-lfs on riptide (10 apr 2017)

  /usr/bin/ruby -e "$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/master/install)"
  brew install git-lfs
  dir /usr/local/bin/git-lfs
   lrwxr-xr-x  1 paul  admin  35 Apr 10 12:01 /usr/local/bin/git-lfs -> ../Cellar/git-lfs/2.0.2/bin/git-lfs

*-----------------------------------------------------------------------------------------------------------------------
* add dhs tracks to igv.js in dora (10 apr 2017)

   https://genome.ucsc.edu/ENCODE/downloads.html
   http://hgdownload.soe.ucsc.edu/goldenPath/hg19/encodeDCC/wgEncodeRegDnaseClustered/wgEncodeRegDnaseClustered.bed.gz     9M 2011
   http://hgdownload.soe.ucsc.edu/goldenPath/hg19/encodeDCC/wgEncodeRegDnaseClustered/wgEncodeRegDnaseClusteredV2.bed.gz  12M
   http://hgdownload.soe.ucsc.edu/goldenPath/hg19/encodeDCC/wgEncodeRegDnaseClustered/wgEncodeRegDnaseClusteredV3.bed.gz  70M  2014

    --- better approach?  googling wgEncodeRegDnaseClustered hg38 led to
      http://hgdownload.cse.ucsc.edu/goldenpath/hg38/database/
      and
      http://hgdownload.cse.ucsc.edu/goldenpath/hg38/database/wgEncodeRegDnaseClustered.txt.gz

    --- start with v2 first
     [status: this failed on a seqlevels problem]
     cd  ~/github/dora/datasets/tracks/dhsClustered/
     rsync -a -P rsync://hgdownload.soe.ucsc.edu/goldenPath/hg19/encodeDCC/wgEncodeRegDnaseClustered/wgEncodeRegDnaseClusteredV2.bed.gz ./
     gunzip wgEncodeRegDnaseClusteredV2.bed.gz
        38970545 Jan 16  2013 wgEncodeRegDnaseClusteredV2.bed
     # need PrivateCoryData installed for source("~/github/snpFoot/R/liftoverHg19BedFiles.R"); needs git-lfs (see above)
     source("~/github/snpFoot/R/liftoverHg19BedFiles.R")

     liftoverBedFile.19.38("wgEncodeRegDnaseClusteredV2.bed")
        # first try failed: Error: is(values, "vectorORfactor") is not TRUE

*-----------------------------------------------------------------------------------------------------------------------
* ecological research firms, for possible sword fern die-off work

   confluence environmental company: http://www.confenv.com   left message (7 apr 2017)
   anchor QEA, http://www.anchorqea.com/aqj/, left message (7 apr 2017)
*-----------------------------------------------------------------------------------------------------------------------
* dora skin, createGeneModel -> mergeTFmodelWithRegulatoryRegions (7 apr 2017)

   region <- 'chr17:50,201,552-50,201,727'
   target.gene <- "COL1A1"
   result <- createGeneModel(mtx=mtx.gtexPrimary, target.gene, region)

    ARNT2 maps to MA0632.1, but this is in exactly the same location MA1099.1:
    so ARNT2 loses its footprint/motif, and creates a JSONDecodeError at
       ---> 18      graphData = json.loads(payload['network'])
    as json tries to parse NaN, created from an orphan ARNT2 in addGeneModelLayout


      74 chr17:50201587-50201596 chr17 50201587 50201596 motif.in.footprint MA1099.1     10      - ENCSR000EIT   HINT skin.filler.minid     80 10.30070 4.21e-05     NA     NA     NA
      36 chr17:50201587-50201596 chr17 50201587 50201596 motif.in.footprint MA0632.1     10      + ENCSR000EPP   HINT skin.filler.minid   2237  9.79839 9.97e-05     NA     NA     NA

    confirmed looking at jsapar logos:
       http://jaspar.genereg.net/?ID=MA1099.1&rm=present&collection=CORE
       http://jaspar.genereg.net/?ID=MA0632.1&rm=present&collection=CORE

    -- solution:  do not uniquify on oc alone, but on loc/motif


*-----------------------------------------------------------------------------------------------------------------------
* Refnet run error (5 apr 2017) [actually in PSICQUIC/R/IDMapper-class.R]

   --- RefNet vignette reports
    tbl.9 <- addStandardNames(idMapper, tbl.8)
       Error in getBM(filters = filter, values = uniprots, attributes = columns,  :
        Invalid attribute(s): uniprot_sptrembl
        Please use the function 'listAttributes' to get valid attribute names

    --- recreate in plain R
      library(biomaRt)
      dataset <- "hsapiens_gene_ensembl"
      mart <- useMart(biomart="ENSEMBL_MART_ENSEMBL", dataset=dataset)

*-----------------------------------------------------------------------------------------------------------------------
* dora skin updates for rich (1 apr 2017)

   add two gtex expression datasets.  preserve access to old

   cd ~/github/dora/datasets/skin/
   scp -p pshannon@whovian:/local/Cory/skin/gtex/Rich/* .
     # added these to ~/github/dora/.gitignore
   print(load("gtex.primary.RData")) # [1] "gtex.primary"
   print(load("gtex.fib.RData"))  # 1] "gtex.fib"
   dim(gtex.fib); dim(gtex.primary)
      [1] 18067   284
      [1] 21436   607

*-----------------------------------------------------------------------------------------------------------------------
* cory's reduction of liz's 59 snps (11 apr 2017)

  the 59 fall into two rough groups

   tbl.RUNX1_fp <- getFootprintsInRegion(fpf, "chr1", 167602155, 167602355)   chr1:167602155-167602355
   tbl.RUNX2_fp <- getFootprintsInRegion(fpf, "chr1", 167529948, 167530148)   chr1:167529948-167530148

*-----------------------------------------------------------------------------------------------------------------------
* intersect liz blue's 59 family snps with new dhs clusters, encode, 95 cell types

   --- based upon: "* new notebook for liz blue's family-UM0463, continued (6 mar 2017)"

      cd  ~/github/dora/datasets/AD-family.UM0463F/
      region of interest:   chr1:167,007,138-168,787,658

   --- strategy
     use (abuse) new TReNA HumanDNAseClusterFilter class to get dhs regions
     ~/github/dora/datasets/AD-family.UM0463F/dhsExploration.R


    --- hand-check this claim
                   dhs.region                                          snp
     chr1  167829960 167830230   350          17  chr1 167830170 167830170  rs34423320-C-T
     https://www.ncbi.nlm.nih.gov/projects/SNP/snp_ref.cgi?rs=34423320 confirms:
        hg38: chr1:167830170
        as.character(getSeq(reference.genome, GRanges("chr1", IRanges(167830170, 167830170))))                  "C"
        as.character(getSeq(reference.genome, GRanges("chr1", IRanges(167830169, 167830171))))                 "TCC"
        as.character(getSeq(reference.genome, GRanges("chr1", IRanges(167830164, 167830174))))            "ACTATTCCCCT"
        as.character(getSeq(reference.genome, GRanges("chr1", IRanges(167830154, 167830184))))  "TACATAATTGACTATTCCCCTAGCTGCTCCT"

     ma0478.1
         TGA[c/g]TCA

     1:167829170-167831170

    --- regions 2,5,19 overlap with snp 56:
    x$tbl[c(2,5,19),]
     chrom regionStart regionEnd regionScore sourceCount    motif       match motif.start motif.end motif.width motif.score strand                                                                                      tf
      chr1   167829960 167830230         350          17 MA0478.1 GCATGACTCAG   167830164 167830174          11    7.938699      -                                                                                   FOSL2
      chr1   167829960 167830230         350          17 MA0099.2     TGACTCA   167830167 167830173           7    5.833333      -                                                                                 FOS;JUN
      chr1   167829960 167830230         350          17 MA0089.1      CATGAC   167830165 167830170           6    4.882353      - MAFG;NFE2L1;MAFF;MAFK;MAFA;MAFB;NRL;ATF2;ATF7;CREB5;NFE2L2;NFE2L3;BACH1;BACH2;JUNB;JUND
   tbl.snps[56,]
     chrom     start       end            snp
      chr1 167830170 167830170 rs34423320-C-T

          match  motif.start
              ***.***
           GCATGACTCAG    167830164
              TGACTCA     167830167
            CATGAC        167830165
                 C
                TCC
           ACTATTCCCCT
 TACATAATTGACTATTCCCCTAGCTGCTCCT

     https://www.ncbi.nlm.nih.gov/projects/SNP/snp_ref.cgi?rs=34423320 confirms:
        hg38: chr1:167830170
        as.character(getSeq(reference.genome, GRanges("chr1", IRanges(167830170, 167830170))))                  "C"
        as.character(getSeq(reference.genome, GRanges("chr1", IRanges(167830169, 167830171))))                 "TCC"
        as.character(getSeq(reference.genome, GRanges("chr1", IRanges(167830164, 167830174))))            "ACTATTCCCCT"
        as.character(getSeq(reference.genome, GRanges("chr1", IRanges(167830154, 167830184))))  "TACATAATTGACTATTCCCCTAGCTGCTCCT"



*-----------------------------------------------------------------------------------------------------------------------
* harry moses, how daylight was stolen (5 aug 2017)  how a piece of daylight was broken off?

  hess and hilbert, 106-107:
     dil         tu-[s]-pekwib-i-d-s               ti?e? s-lex-il          gwel tu-saxweb-txw
     anaphoric   past-[abs]-snatch-secondary-tr-3   this abs-light-become  and  past-jump/run-caus
  (the aforementioned)
  secondary: one of a small set of suffixes, expanding the set of transitive endings a given stem allows

  saxweb: LD200, jump, leap, scamper off; run (especially in a short burst of energy as
          opposed to telawil, wich is to run for a sustained period)
  saxweb-tx: transitive, run off with, kidnap; run with it (to run off with someone to a known place, possibly -DM)
        compare liq'w: to kidnap away to an unknown destination LD 200

  beck and hess and lines 76-80, including 77,
     diɬ tuspəkwibids tiʔəʔ sləxil gwəl tusaxwəbtxw
     diɬ  tu=s=pəkwib–bi–d=s         tiʔəʔ sləxil   gwəl tu=saxwəb–txw
     foc past=nm=snatch–map–ics=3po prox  daylight sconj past=jump–ecs

     map: middle applicative
     ics: internal causative
     3po: third person possessive
       =: clitic boundary  (an unstressed word that normally occurs only in combination with another word, for example ῾m in I'm.)

     ‘He snatched the daylight and ran off with it.’

   lushootseed dictionary, p163
     pkw(u) also recorded pqw(u), peqw(u): break off a piece (leaving a larger portion)
     peqwyid: break off a piece so he can have some

*-----------------------------------------------------------------------------------------------------------------------
* harry moses, how daylight was stolen (29 mar 2017)

  on paul.thurmond.shannon@gmail.com, google drive
*-----------------------------------------------------------------------------------------------------------------------
* ensembl regulatory build in biomart (28 mar 2017)

  library(biomaRt)
  listEnsembl()
               biomart               version
  1            ensembl      Ensembl Genes 87
  2 ENSEMBL_MART_MOUSE      Mouse strains 87
  3                snp  Ensembl Variation 87
  4         regulation Ensembl Regulation 87
  5               vega               Vega 67
  listMarts()
                 biomart               version
  1 ENSEMBL_MART_ENSEMBL      Ensembl Genes 87
  2   ENSEMBL_MART_MOUSE      Mouse strains 87
  3     ENSEMBL_MART_SNP  Ensembl Variation 87
  4 ENSEMBL_MART_FUNCGEN Ensembl Regulation 87
  5    ENSEMBL_MART_VEGA               Vega 67

  mart.reg <- useMart("ENSEMBL_MART_FUNCGEN")
  listDatasets(mart.reg)
                            dataset                                description   version
  1         mmusculus_motif_feature           Mouse Binding Motifs (GRCm38.p5) GRCm38.p5
  2      mmusculus_external_feature Mouse Other Regulatory Regions (GRCm38.p5) GRCm38.p5
  3      hsapiens_annotated_feature      Human Regulatory Evidence (GRCh38.p7) GRCh38.p7
  4    mmusculus_regulatory_feature      Mouse Regulatory Features (GRCm38.p5) GRCm38.p5
  5          hsapiens_motif_feature           Human Binding Motifs (GRCh38.p7) GRCh38.p7
  6     hsapiens_regulatory_feature      Human Regulatory Features (GRCh38.p7) GRCh38.p7
  7   hsapiens_mirna_target_feature     Human miRNA Target Regions (GRCh38.p7) GRCh38.p7
  8  dmelanogaster_external_feature  Fruitfly Other Regulatory Regions (BDGP6)     BDGP6
  9     mmusculus_annotated_feature      Mouse Regulatory Evidence (GRCm38.p5) GRCm38.p5
  10 mmusculus_mirna_target_feature     Mouse miRNA Target Regions (GRCm38.p5) GRCm38.p5
  11      hsapiens_external_feature Human Other Regulatory Regions (GRCh38.p7) GRCh38.p7

  mart.reg <- useMart("ENSEMBL_MART_FUNCGEN", dataset="hsapiens_motif_feature")
  mart.reg2 <- useMart("ENSEMBL_MART_FUNCGEN", dataset="hsapiens_regulatory_feature")

  listAttributes (mart.reg)   # show what values can be retrieved
  listFilters (mart.reg)      # show values to search (filter) on

   --- attributes
     listAttributes (mart.reg)
                     name       description           page
     1  binding_matrix_id    Binding matrix binding_motifs
     2    chromosome_name   Chromosome Name binding_motifs
     3   chromosome_start        Start (bp) binding_motifs
     4     chromosome_end          End (bp) binding_motifs
     5  chromosome_strand            Strand binding_motifs
     6              score             Score binding_motifs
     7      display_label     Display label binding_motifs
     8  feature_type_name      Feature Type binding_motifs
     9       so_accession SO Term Accession binding_motifs
     10           so_name      SO Term Name binding_motifs

   ---- filters
   listFilters (mart.reg)
                           name                                                  description
     1          chromosome_name                                              Chromosome Name
     2                    start                                                   Start (bp)
     3                      end                                                     End (bp)
     4                   strand                                                       Strand
     5       chromosomal_region Chromosome Regions (e.g 1:100:10000000:-1,1:100000:200000:1)
     6               band_start                                                   Band Start
     7                 band_end                                                     Band End
     8             marker_start                                                 Marker Start
     9               marker_end                                                   Marker End
     10           encode_region                                                Encode region
     11 motif_binding_matrix_id                                            Binding Matrix ID
     12 motif_feature_type_name                                            Feature Type Name

     coi <- c("binding_matrix_id", "chromosome_name", "chromosome_start", "chromosome_end", "chromosome_strand",
              "score", "display_label", "feature_type_name", "so_accession", "so_name")
     regions<-c("5:88819630:88835936")  # 16306
     tbl <- getBM(attributes=coi, filters="chromosomal_region", values=regions, mart=mart.reg)

     binding_matrix_id chromosome_name chromosome_start chromosome_end chromosome_strand  score     display_label feature_type_name so_accession         so_name
   1          MA0080.3               5         88827259       88827273                -1 10.029      PU1:MA0080.3               PU1   SO:0000235 TF_binding_site
   2          MA0080.3               5         88827449       88827463                -1 10.484      PU1:MA0080.3               PU1   SO:0000235 TF_binding_site
   3          MA0099.2               5         88828135       88828141                -1  8.468 JUN::FOS:MA0099.2          JUN::FOS   SO:0000235 TF_binding_site
   4          MA0488.1               5         88827357       88827369                 1  9.088     Cjun:MA0488.1              Cjun   SO:0000235 TF_binding_site
   5          MA0080.2               5         88827451       88827457                -1  8.730      PU1:MA0080.2               PU1   SO:0000235 TF_binding_site
   6          MA0489.1               5         88828134       88828147                -1 10.201     Cjun:MA0489.1              Cjun   SO:0000235 TF_binding_site

    ---- fimo, matchPWM and ensembl reg each report different results for chr5:88827259-88827273
         which is in a high-scoring ucsc dnase cluster
         as.character(getSeq(hg38, GRanges("chr5", IRanges(start=88827259, end=88827273)))) # [1] "CCTCTTCCTCCCTCC"
     https://genome.ucsc.edu/cgi-bin/hgTracks?db=hg38&lastVirtModeType=default&lastVirtModeExtraState=&virtModeType=default&virtMode=0&nonVirtPosition=&position=chr5%3A88827259-88827273&hgsid=586099429_KROA05e668cBdV6gQISNhvFfQfeW
     regions<-c("5:88827259:88827273"); getBM(attributes=coi, filters="chromosomal_region", values=regions, mart=mart.reg)
      binding_matrix_id chromosome_name chromosome_start chromosome_end chromosome_strand  score display_label feature_type_name so_accession         so_name
    1          MA0080.3               5         88827259       88827273                -1 10.029  PU1:MA0080.3               PU1   SO:0000235 TF_binding_site

     findHits("CCTCTTCCTCCCTCC", pfms)
       start end width    score    motif             seq      match strand
     2     1  10    10 5.562500 MA0057.1 CCTCTTCCTCCCTCC GGAGGGAGGA      -
     3     5  11     7 4.938776 MA0081.1 CCTCTTCCTCCCTCC    GGAGGAA      -
     1     5  10     6 4.100000 MA0056.1 CCTCTTCCTCCCTCC     GGAGGA      -

     library(FimoClient)
       FIMO_HOST <- "whovian"
       FIMO_PORT <- 5558
       fc <<- FimoClient(FIMO_HOST, FIMO_PORT, quiet=TRUE)
    requestMatch(fc, list(x="CCTCTTCCTCCCTCC"))
     X.pattern.name sequence.name start stop strand   score  p.value  q.value matched.sequence
     1       GTF2I.p2             x     7   15      - 17.4024 2.23e-06 3.12e-05        GGAGGGAGG
     2       MA0079.3             x     4   14      + 10.2308 9.03e-05 9.03e-04      CTTCCTCCCTC

   --- use biomart ensembl reg, not just motifs, but all human regulatory features
  mart.reg2 <- useMart("ENSEMBL_MART_FUNCGEN", dataset="hsapiens_regulatory_feature")
  listAttributes (mart.reg2)   # show what values can be retrieved
  listFilters (mart.reg2)      # show values to search (filter) on

  coi <- c("activity", "regulatory_stable_id", "bound_seq_region_start", "bound_seq_region_end",
           "chromosome_name", "chromosome_start", "chromosome_end",
           "feature_type_name", "feature_type_description",
           "epigenome_name", "epigenome_description", "so_accession", "so_name", "efo_id")
  regions<-c("5:88819630:88835936")  # 16306
  tbl <- getBM(attributes=coi, filters="chromosomal_region", values=regions, mart=mart.reg2)  # 204 x 14
  as.data.frame(t(tbl[1:3,]))
                                                            1                                  2                                                                  3
  activity                                           INACTIVE                             ACTIVE                                                             ACTIVE
  regulatory_stable_id                        ENSR00000183674                    ENSR00000183674                                                    ENSR00000183674
  bound_seq_region_start                             88823801                           88823801                                                           88823801
  bound_seq_region_end                               88830999                           88830999                                                           88830999
  chromosome_name                                           5                                  5                                                                  5
  chromosome_start                                   88823801                           88823801                                                           88823801
  chromosome_end                                     88830999                           88830999                                                           88830999
  feature_type_name                  Promoter Flanking Region           Promoter Flanking Region                                           Promoter Flanking Region
  feature_type_description Predicted promoter flanking region Predicted promoter flanking region                                 Predicted promoter flanking region
  epigenome_name                                         A549                              Aorta                                               B cells (PB) Roadmap
  epigenome_description             Epithelial Lung Carcinoma REMC Epigenome (Class 2) for Aorta REMC Epigenome (Class 5) for Primary B cells from Peripheral Blood
  so_accession                                     SO:0001952                         SO:0001952                                                         SO:0001952
  so_name                            promoter_flanking_region           promoter_flanking_region                                           promoter_flanking_region
  efo_id                                                 <NA>                               <NA>                                                               <NA>
  table(tbl$feature_type_name)

         CTCF Binding Site Promoter Flanking Region
                        68                      136

  --- now chose in ucsc genome browser, this region: chr5:88822502-88837849 about 15kb
      which includes all of the h3k27ac marks, and the obvious tss-proximal dnaseclusters

   mart.motifs <- useMart("ENSEMBL_MART_FUNCGEN", dataset="hsapiens_motif_feature")
   coi <- c("binding_matrix_id", "chromosome_name", "chromosome_start", "chromosome_end", "chromosome_strand",
           "score", "display_label", "feature_type_name", "so_accession", "so_name")
   regions<-c("5:88822502:88837849")
   tbl <- getBM(attributes=coi, filters="chromosomal_region", values=regions, mart=mart.motifs)
   just 7 binding sites.  just 7 ChIP-seq experiments?

     binding_matrix_id chromosome_name chromosome_start chromosome_end chromosome_strand  score     display_label feature_type_name so_accession         so_name
   1          MA0036.2               5         88836679       88836692                 1  9.967    Gata2:MA0036.2             Gata2   SO:0000235 TF_binding_site
   2          MA0080.3               5         88827259       88827273                -1 10.029      PU1:MA0080.3               PU1   SO:0000235 TF_binding_site
   3          MA0080.3               5         88827449       88827463                -1 10.484      PU1:MA0080.3               PU1   SO:0000235 TF_binding_site
   4          MA0099.2               5         88828135       88828141                -1  8.468 JUN::FOS:MA0099.2          JUN::FOS   SO:0000235 TF_binding_site
   5          MA0488.1               5         88827357       88827369                 1  9.088     Cjun:MA0488.1              Cjun   SO:0000235 TF_binding_site
   6          MA0080.2               5         88827451       88827457                -1  8.730      PU1:MA0080.2               PU1   SO:0000235 TF_binding_site
   7          MA0489.1               5         88828134       88828147                -1 10.201     Cjun:MA0489.1              Cjun   SO:0000235 TF_binding_site



*-----------------------------------------------------------------------------------------------------------------------
* ensembl regulatory build  (28 mar 2017)

  http://uswest.ensembl.org/info/genome/funcgen/regulatory_build.html

   The Ensembl Regulatory Build
   Daniel R ZerbinoEmail author, Steven P Wilder, Nathan Johnson, Thomas Juettemann and Paul R FlicekEmail author
   Genome Biology201516:56
   DOI: 10.1186/s13059-015-0621-5©  Zerbino et al.; licensee BioMed Central. 2015
   Received: 6 October 2014Accepted: 4 March 2015Published: 24 March 2015

   Abstract

   Most genomic variants associated with phenotypic traits or disease do not fall within gene coding
   regions, but in regulatory regions, rendering their interpretation difficult. We collected public
   data on epigenetic marks and transcription factor binding in human cell types and used it to
   construct an intuitive summary of regulatory regions in the human genome. We verified it against
   independent assays for sensitivity. The Ensembl Regulatory Build will be progressively enriched
   when more data is made available. It is freely available on the Ensembl browser, from the Ensembl
   Regulation MySQL database server and in a dedicated track hub.




*-----------------------------------------------------------------------------------------------------------------------
* biostrings matchPWM on TERT example

   --- first, get results using the whovian fimo service
      (see below, * microservices on whovian (9 sep 2016)   dna, fimo to test, maybe restart the service)

   library(FimoClient)
   FIMO_HOST <- "whovian"
   FIMO_PORT <- 5558
   fc <- FimoClient(FIMO_HOST, FIMO_PORT, quiet=FALSE)
   sequences <- list(tert_wt1="CCCGGAGGGGG", tert_wt2= "CCCGGGAGGGG", tert_mut="CCCCTTCCGGG")
   tbl <- requestMatch(fc, sequences)

            X.pattern.name sequence.name start stop strand   score  p.value  q.value matched.sequence
    1             MA0076.2      tert_mut     1   11      + 13.1818 2.22e-05 0.000133      CCCCTTCCGGG
    2 ELK1,4_GABP{A,B1}.p3      tert_mut     2   11      - 11.7000 4.50e-05 0.000539       CCCGGAAGGG
    3          ETV6_full_2      tert_mut     2   11      - 10.7245 9.30e-05 0.001120       CCCGGAAGGG
    4             MA0645.1      tert_mut     2   11      - 10.7308 9.54e-05 0.001150       CCCGGAAGGG


   --- create a proper pwm for MA0645.1
     http://jaspar.genereg.net/html/DOWNLOAD/JASPAR_CORE/pfm/individual/MA0645.1.pfm
       >MA0645.1	ETV6
       A  [9414  342 1476    7   21 6687 6687  768  184 2049 ]
       C  [6562 2394 6379    0    0    0   13   52  834  342 ]
       G  [4684 4292  397 6687 6687    7   32 6687  233 3205 ]
       T  [2002  441  308   13   22    0   41    0 6687 1091 ]

      pfm <- matrix(0L, nrow=4, ncol=10, dimnames=list(c("A", "C", "G", "T"), NULL))
      pfm[1,] <- as.integer(c(9414,342,1476,7,21,6687,6687,768,184,2049))
      pfm[2,] <- as.integer(c(6562,2394,6379,0,0,0,13,52,834,342))
      pfm[3,] <- as.integer(c(4684,4292,397,6687,6687,7,32,6687,233,3205))
      pfm[4,] <- as.integer(c(2002,441,308,13,22,0,41,0,6687,1091))
      pwm <- PWM(pfm)   # fails becuase columns do not scale to the same count

   --- explore matchPWM using 1st matrix in MotifDB
     library(MotifDb)
     mdb <- MotifDb
     mtx.1 <- mdb[[1]]
     seq <- consensusString(mtx.1)
     hits <- matchPWM(mdb[[1]], seq, with.score=TRUE)
     mcols(hits)$score    7.769231


   --- now try this with some TERT promoter sequences and the top fimo hit
      grep("MA0076", names(mdb), v=TRUE)  # "Hsapiens-JASPAR_CORE-ELK4-MA0076.1" "Hsapiens-JASPAR_2014-ELK4-MA0076.2"
      elk4.entry <- grep("MA0076", names(mdb))[1]  # first of 2
      mdb[[1994]]
           1 2 3 4 5 6   7    8    9
      A 0.80 0 0 0 0 1 0.8 0.20 0.05
      C 0.05 1 1 0 0 0 0.0 0.05 0.30
      G 0.10 0 0 1 1 0 0.0 0.75 0.00
      T 0.05 0 0 0 0 0 0.2 0.00 0.65

     pfm.1994 <- mdb[[1994]]
     seq <- consensusString(pfm.1994)   # "ACCGGAAGT"
     hits <- matchPWM(pfm.1994, seq, with.score=TRUE)
     mcols(hits)$score    8.0
       # now extend the string: does matchPWM still find it?
     seq2 <- sprintf("AT%sCG", seq)
     hits2 <- matchPWM(pfm.1994, seq2, with.score=TRUE)
       start end width           score
        3  11     9 [ACCGGAAGT]  8
    cbind(as.data.frame(ranges(hits)), score=mcols(hits)$score)
       start end width score
           1   9     9     8
    cbind(as.data.frame(ranges(hits2)), score=mcols(hits)$score)
        start end width score
            3  11     9     8
    seq.rc <- as.character(reverseComplement(DNAString(seq)))
    matchPWM(pfm.1994, seq.rc, with.score=TRUE)   # NONE

     ----  takes < 10 seconds to search 1000 matrices with one 15 base sequence
       need to call matchPWM twice, once for the revcomp sequence.
     search <- function(motifName, mtx, seq){
        hits <- matchPWM(mtx, seq, with.score=TRUE);
        if(length(hits) > 0)
           return(data.frame(ranges(hits), score=mcols(hits)$score, motif=motifName, seq=seq))
        return(data.frame())
        }

      xx <- lapply(1:4, function(i) search(names(mdb)[i], mdb[[i]], seq))
      do.call("rbind", xx)

    --- load and parse the latest jaspar, using utility functions from atSNP package
     text <- scan("http://jaspar.genereg.net/html/DOWNLOAD/JASPAR_CORE/pfm/nonredundant/pfm_all.txt", what=character(), sep="\n")
       Read 5410 items
     url <- "http://jaspar.genereg.net/html/DOWNLOAD/JASPAR_CORE/pfm/nonredundant/pfm_all.txt"
     jaspar_motif <- LoadMotifLibrary(url, tag=">",skiprows=1,skipcols=0,transpose=TRUE,field=1,sep=c(">","\t",""),pseudocount=1)

*-----------------------------------------------------------------------------------------------------------------------
* biostrings matchPWM man page example (24 mar 2017)

     data(HNF4alpha)
     library(BSgenome.Dmelanogaster.UCSC.dm3)
     chr3R <- Dmelanogaster$chr3R
     chr3R

     pfm <- consensusMatrix(HNF4alpha)
     pwm <- PWM(pfm)  # same as 'PWM(HNF4alpha)'

     round(pwm, 2)
     maxWeights(pwm)
     maxScore(pwm)
     reverseComplement(pwm)

     PWMscoreStartingAt(pwm, chr3R, starting.at=1:5)

     hits <- matchPWM(pwm, chr3R)
     nhit <- countPWM(pwm, chr3R)  # same as 'length(hits)'

     ## Use 'with.score=TRUE' to get the scores of the hits:
     hits <- matchPWM(pwm, chr3R, with.score=TRUE)
     head(mcols(hits)$score)
     min(mcols(hits)$score / maxScore(pwm))  # should be >= 0.8

     ## The scores can also easily be post-calculated:
     scores <- PWMscoreStartingAt(pwm, subject(hits), start(hits))

     ## Match the minus strand:
     matchPWM(reverseComplement(pwm), chr3R)

*-----------------------------------------------------------------------------------------------------------------------
* atSNP (24 mar 2017)

  cd ~/github
  git clone https://github.com/chandlerzuo/atSNP.git
  cd atSNP
  R CMD build  .
  R CMD install atSNP_1.0.tar.gz

   [status: abandoning for now, seeing if biostrings matchPWM is good enough]


*-----------------------------------------------------------------------------------------------------------------------
* fix motifdb problems (23 mar 2017)

  --- release
    svn co https://hedgehog.fhcrc.org/bioconductor/branches/RELEASE_3_4/madman/Rpacks/MotifDb
    svn rm Makefile
    svn ci -m "deleted vignette Makefile"
    svn ci -m "deleted vignette Makefile, bumped version" DESCRIPTION

  --- devel


*-----------------------------------------------------------------------------------------------------------------------
* MotifDb/vignettes/Makefile before deletions (23 mar 2017)

pdf:
	"$(R_HOME)/bin/R" CMD Sweave MotifDb.Rnw --pdf

view: pdf
	- kill -9 `ps aux | grep Preview | egrep -v grep | awk '{print $$2}'`
	open MotifDb.pdf

tangle:
	"$(R_HOME)/bin/R"  CMD Stangle MotifDb.Rnw
	"$(R_HOME)/bin/R"  --vanilla < MotifDb.R

*-----------------------------------------------------------------------------------------------------------------------
* TReNA: get regulatory tracks from ucsc using rtracklayer (23 mar 2017)

  --- what tracks are available?
mySession <- browserSession ()
genome(mySession) <- "hg38"
track.names <- trackNames(ucscTableQuery(mySession))  # 113 tracks
   # chose a few tracks at random from this set, and discover how  many tables they hold
grep("dnase", as.character(track.names), ignore.case=TRUE, v=TRUE)
   # [1] "wgEncodeRegDnaseClustered" "wgEncodeRegDnase"  "wgEncodeRegDnaseWig"
grep("dnase", as.character(track.names), ignore.case=TRUE) # 35 26 37
tableNames(ucscTableQuery(mySession, track="wgEncodeRegDnaseClustered"))
  # [1] "wgEncodeRegDnaseClustered"        "wgEncodeRegDnaseClusteredSources"

region <- GRanges("chr6", IRanges(20400587, 20403336))
track <- "wgEncodeRegDnaseClustered"
table <- "wgEncodeRegDnaseClustered"
tbl <- getTable(ucscTableQuery (mySession, track=track, range=region, table=table))   # 6 x 9

--- demo, TReNA proof of concept
library(rtracklayer)
mySession <- browserSession ()
genome(mySession) <- "hg38"
track.names <- trackNames(ucscTableQuery(mySession))  # 113 tracks
grep("dnase", track.names, ignore.case=TRUE, value=TRUE)
             DNase Clusters                    DNase HS                DNase Signal
"wgEncodeRegDnaseClustered"          "wgEncodeRegDnase"       "wgEncodeRegDnaseWig"
track.name <- "wgEncodeRegDnaseClustered"
tableNames(ucscTableQuery(mySession, track=track.name))
   # [1] "wgEncodeRegDnaseClustered"        "wgEncodeRegDnaseClusteredSources"
table.name <- "wgEncodeRegDnaseClustered"
region <- GRanges("chr5", IRanges(88688769, 89002929))
tbl.dhs <- getTable(ucscTableQuery (mySession, track=track.name, range=region, table=table.name))  # 303 9
head(tbl.dhs[, 1:7])
   bin chrom chromStart chromEnd name score sourceCount
1 1261  chr5   88688160 88688770    6   361           8
2 1261  chr5   88688800 88688950    1    57           1
3 1261  chr5   88689060 88689210    1   181           1
4 1261  chr5   88689240 88689450    8   142           8
5 1261  chr5   88689680 88689910    6   174           6
6 1261  chr5   88690160 88690430   36   485          36


grep("h3k2", as.character(track.names), ignore.case=TRUE) # 35 26 37
grep("h3k2", as.character(track.names), ignore.case=TRUE, v=T) # [1] "wgEncodeRegMarkH3k27ac"
track <- "wgEncodeRegMarkH3k27ac"
tableNames(ucscTableQuery(mySession, track="wgEncodeRegMarkH3k27ac"))

   #   "wgEncodeBroadHistoneGm12878H3k27acStdSig"
   #   "wgEncodeBroadHistoneH1hescH3k27acStdSig"
   #   "wgEncodeBroadHistoneHsmmH3k27acStdSig"
   #   "wgEncodeBroadHistoneHuvecH3k27acStdSig"
   #   "wgEncodeBroadHistoneK562H3k27acStdSig"
   #   "wgEncodeBroadHistoneNhekH3k27acStdSig"
   #   "wgEncodeBroadHistoneNhlfH3k27acStdSig"
table <- "wgEncodeBroadHistoneGm12878H3k27acStdSig"  # choose just the first cell line
tbl.h3k27ac.1 <- getTable(ucscTableQuery (mySession, track=track, range=region, table=table))  # 303 9
  # Error in .local(object, ...) : tabular output format not available
query <- ucscTableQuery (mySession, track=track, range=region, table=table)
  # Get table 'wgEncodeBroadHistoneGm12878H3k27acStdSig' from track 'wgEncodeRegMarkH3k27ac' within hg38:chr5:88688769-89002929
  # with that failure, try the table browser directly
  # filtered so that data value > 100, got very tractable example table of ~30 rows


  --- michael's vignette Example 2: DNaseI hypersensitivity regions in the K562 Cell Line
library(rtracklayer)
track.name <- "wgEncodeUwDgf"
table.name <- "wgEncodeUwDgfK562Hotspots"
e2f3.grange <- GRanges("chr6", IRanges(20400587, 20403336))
mySession <- browserSession ()
tbl.k562.dgf.e2f3 <- getTable(ucscTableQuery (mySession, track=track.name,range=e2f3.grange, table=table.name))
tbl.k562.dgf.hg19 <- getTable(ucscTableQuery (mySession, track=track.name,table=table.name))

*-----------------------------------------------------------------------------------------------------------------------
* onlies youtube

  https://www.youtube.com/watch?v=NKwK3xxRnMg  2010 fiddle tunes
  https://www.youtube.com/watch?v=nk-ep3CBNqI  2009 volcanic jig

*-----------------------------------------------------------------------------------------------------------------------
* cellphone simulator: reconstruct network using rcyjs (15 mar 2017)

     cd ~/github/cellphoneJS/networkReconstruction

*-----------------------------------------------------------------------------------------------------------------------
* cellphone simulator: simple bootstrap and nested submenus (14 mar 2017)

   cd ~/github/cellphoneJS/submenu-simple/
   open index.html



*-----------------------------------------------------------------------------------------------------------------------
* biofuels visualization sketch

Interactive visualization tools are essential for modeling and assessing
wild-type and engineered metabolic networks.  Most of the individual dimensions
of metabolic data (genomic, gene expression, regulatory, reaction flux,
proteomic) benefit from having a visualization tool tailored to that specific
data type.  Detecting relationships among the different data types (dimensions)
is a principal activity and goal of research, so the interactive visualizations
must be linked by simple interactive gestures and message passing.  For example,
the modeled or experimental consequences of a gene variant upon transcription,
protein abundance and flux should be viewable in several interlinked views.

The visualization tools, in addition to be richly interactive, must also be
closely tied and responsive to computer scripts, in a variety of common
languages.  By combining interactive point-and-click operation with scripting
(in, for example, Python, R and Matlab), both novice and experienced programmers
will gain extra expressive and exploratory power.

At the current time (Spring 2017) and very like increasingly over the next
decade, the best setting in which to accomplish these many interwoven
visualization goals is the multi-language Jupyter Notebook (and soon, Jupyter
Lab) environment.  Analyses and their visualizations - reproducible research -
can be crafted and shared.

Current work

Design Goals: Multiple linked, interactive and high resolution
visualizations are required to model and assess wild-type and
engineered metabolic networks.   they

*-----------------------------------------------------------------------------------------------------------------------
* alison miRNA trena, first try (10 mar 2017)

  cd ~/s/work/priceLab/alison/trenaFirstTry/


*-----------------------------------------------------------------------------------------------------------------------
* create whole genome skin_hint footprints bedgraph annotation for rich gelinas notebook (10 mar 2017)

   cd ~/github/projects/examples/genomics/tracks/skinHintFootprintsBedGraph
   source("go.R")
   iterate()   # ~75 minutes
   bash combine.sh   # creates unsorted then sorted file

   library(Rsamtools)
   bgzip("skin_hint.bed", "skin_hint.bed.gz")
   print(indexTabix("skin_hint.bed.gz", format="bed"))

      1422752 Mar 10 14:14 skin_hint.bed.gz.tbi
     94576948 Mar 10 14:13 skin_hint.bed.gz
    485670659 Mar 10 14:07 skin_hint.bed

   scp sking_hint.bed.gz* pshannon@whovian:/local/httpd/vhosts/pshannon/annotations/<


*-----------------------------------------------------------------------------------------------------------------------
* make sure that hg38 fasta sequence in rich's skin notebook is now right

  http://whovian:10001/notebooks/skin-PnG/dora-skin.ipynb
  chr17:50,201,616-50,201,654

  library(getDNAClient)
  dnaService = getDNAClient("hg38")
  getSequenceByLoc(dnaService, "chr17", 50201616, 50201654)

*-----------------------------------------------------------------------------------------------------------------------
* igv fasta file, igv.js

   first notebook multiwidget:
      used "http://pshannon.systemsbiology.net/genomes/human_g1k_v37_decoy.fasta"
      actual files:
        /local/httpd/vhosts/pshannon/genomes
            3189750467 Feb 10 11:53 human_g1k_v37_decoy.fasta
            2813 Feb 10 11:53 human_g1k_v37_decoy.fasta.fai   # small since organized by chromosomes,
                                                              # not explicitly names in igv options
           reference: {id: "geneSymbols_hg38",
               fastaURL: "http://pshannon.systemsbiology.net/genomes/human_g1k_v37_decoy.fasta",
               cytobandURL: "http://pshannon.systemsbiology.net/annotations/b37_cytoband.txt"
               },

   --- but need hg38

   ftp://hgdownload.cse.ucsc.edu/goldenPath/hg38/bigZips/
   curl -O ftp://hgdownload.cse.ucsc.edu/goldenPath/hg38/bigZips/hg38.fa.gz
   curl -O http://hgdownload.cse.ucsc.edu/goldenpath/hg38/database/cytoBand.txt.gz
     hg38.fa.gz - "Soft-masked" assembly sequence in one file.
        Repeats from RepeatMasker and Tandem Repeats Finder (with period
        of 12 or less) are shown in lower case; non-repeating sequence is
        shown in upper case.

   googled: ucsc hg38.fa.gz

   --- make index .fai
    cd  /local/httpd/vhosts/pshannon/genomes
    gunzip hg38.fa.gz


*-----------------------------------------------------------------------------------------------------------------------
* jupyter tips, notebook tips

   disable password token:  jupyter notebook --port=10001 --NotebookApp.token=
   %autosave 0
*-----------------------------------------------------------------------------------------------------------------------
* python for loop, python tips

  for x in range(0,5):  # or range(5):
      print(x)


*-----------------------------------------------------------------------------------------------------------------------
* credit score 828, vit intuit mit (9 mar 2017)
*-----------------------------------------------------------------------------------------------------------------------
* from ben heavner, reproducible juypter notebooks (9 mar 2017)

   https://markwoodbridge.com/2017/03/05/jupyter-reproducible-science.html
   https://gitlab.com/mwoodbri/jupyter-ci/tree/master

*-----------------------------------------------------------------------------------------------------------------------
* conda, jupyter, versions, etc

   --- did a fresh install of anaconda from (7 mar 2017) on riptide
      https://www.continuum.io/downloads
      conda install -c r r-essentials
      jupyter --version           # 4.2.1
      jupyter notebook --version  # 4.3.1
      conda update ipywidgets


   --- on whovian (9 mar 2019)
     * before:
        jupyter --version            4.2.0
        jupyter notebook --version   4.2.3
        conda update anaconda
        jupyter --version            4.2.1
        jupyter notebook --version   4.3.1


   --- jupyter lab
       conda install -c conda-forge jupyterlab
       conda update -c conda-forge jupyterlab
       jupyterlab: 0.17.4-py36_0 conda-forge

    --- ipyleaflet in lab


    --- Widgets are not available.  Please install widgetsnbextension or ipywidgets 4.0
       conda update ipywidgets
          ipywidgets:         5.2.2-py36_1 --> 6.0.0-py36_0
        widgetsnbextension: 1.2.6-py36_0 --> 2.0.0-py36_0


       pip install ipywidgets==5.0.0
       jupyter nbextension enable --py widgetsnbextension



*-----------------------------------------------------------------------------------------------------------------------
* jupyterlab ipyleaflet (9 mar 2017)

   jupyter --version     # 4.2.1
   jupyter lab --version # 0.17.4

   cd ~/github/ipyleaflet/
      git pull origin
      grep version js/package.json   # "version": "0.3.0",

   cd ~/github/ipywidgets
      git pull origin
      grep version jupyter-js-widgets/package.json  #  "version": "2.1.4",
      grep version jupyterlab_widgets/package.json  #  "version": "0.6.15",
      grep version widgetsnbextension/package.json  #  "version": "2.0.18",

   cd ~/github/ipywidgets/jupyter-js-widgets/
     npm install
     npm run update
     pip install -e .

   cd ~/github/ipywidgets
     pip install -e .

   cd ~/github/ipywidgets/jupyterlab_widgets
     npm install
     npm run update
     pip install -e .
     jupyter labextension install --py --user --symlink jupyterlab_widgets
        X is not version compatible with installed JupyterLab version 0.17.4
            Expects JupyterLab version ^0.16.2 from packaged module @jupyterlab/nbwidgets@0.6.15/lib/plugin.js
            Expects JupyterLab version ^0.16.2 from packaged module @jupyterlab/nbwidgets@0.6.15/lib/output.js
       found github issue: https://github.com/ipython/ipywidgets/issues/1187

    As it says in the error, ipywidgets is not compatible with JLab
    0.17.x. Right now, it's only compatible with 0.16.2. There was a
    major change on 0.17 that we still need to catch up to.


    jupyter labextension enable jupyterlab_widgets --py --sys-prefix

*------------------------------------------------------------------------------------------------------------------------
* sylvain corlay's guide to installing ipyleaflet for jupyter lab (16 dec 2016)

   So getting ipyleaflet to work in jupyterlab is quite cumbersome for
   now, since it requires installing ipywidgets from source and
   ipyleaflet from source Besides, the jupyterlab team is iterating quite
   rapidly and makes rapid releases with non-backward compatible version
   numbers (0.x.y) before the first 1.0.  Currently getting ipyleaflet in
   jupyterlab requires

jupyterlab 0.11.3.
The current state of master in ipywidgets
In jupyter-js=widgets, run npm install
In widgetsnbextension , run npm install then npm run update then pip install -e .
In ipywidgets run pip install -e .
In jupyterlab_widgets run npm install then npm run update then pip install -e .
jupyter labextension install --py --sys-prefix --symlink jupyterlab_widgets
jupyter labextension enable jupyterlab_widgets --py --sys-prefix
Install ipyleaflet from source
in js: npm install
at the root of the repo: pip install -e .
jupyter labextension install --py --sys-prefix --symlink ipyleaflet
jupyter labextension enable --py --sys-prefix jupyterlab_widgets
yay!

*------------------------------------------------------------------------------------------------------------------------
* new notebook for liz blue's family-UM0463, continued (6 mar 2017)

   cd  ~/github/dora/datasets/AD-family.UM0463F/
   region of interest:   chr1:167,007,138-168,787,658
   databases of interest
     # psql -U trena --host whovian brain_hint
     # psql -U trena --host whovian skin_hint
     # psql -U trena --host whovian lymphoblast_hint

   ~/github/dora/datasets/AD-family.UM0463F/createFootprintTracks.R


   --- create small footprint bed files, load tracks, find intersection with snps
     brain hint chr1 shows sample count in height of display:

         {name: "brain hint fp chr1 all",
           type: "wig",
           format: "bedgraph",
           min: 0,
           max: 10,
           visibilityWindow: 100000,
           indexed: true,
           url: "http://pshannon.systemsbiology.net/annotations/brain_hint_chr1_all.bed.gz",
           indexURL: "http://pshannon.systemsbiology.net/annotations/brain_hint_chr1_all.bed.gz.tbi",
           },

    --- format is simple
    head ~/github/projects/examples/genomics/tracks/brainHintFootprintsBedGraph/brain_hint_chr1_all.bed
      chr1	10100	10119	1
      chr1	10105	10124	1
      chr1	10106	10121	1

   ~/github/projects/examples/genomics/tracks/brainHintFootprintsBedGraph/go.R has function
       condense.footprints, with this comment
         # reduce the footprint table to a bed format, with just one row per unique loc
         # and a score which counts the number of samples at that exact loc.
         # the incoming tbl.fp will also have a unique row for every motif assigned
         # to the loc, and is sometimes further inflated by palindromic motifs
         # mapped to both strands.  ignore all of that.

      tbl.fp <- getFootprintsInRegion(fpf, chrom, 1, end.loc)
      tbl.fpReduced <- condense.footprints(tbl.fp)
      filename <- sprintf("%s.bed", chrom)
      write.table(tbl.fpReduced, sep="\t", quote=FALSE, row.names=FALSE, col.names=FALSE, file=filename)

   --- assay the snps, then create bed9 colored snp track

     for bed9 colored snps: see "dora tips: generate bed9 colored fimo-assayed snps, laptm5 example (20 feb 2017)"
     cd ~/github/dora/notebooks/AD-family.UM0463F/src
     source("fimoUtils.R")
     run.all()


*-----------------------------------------------------------------------------------------------------------------------
* sigda (ongoing package creation) (6 mar 2017)

  cd ~/github/sigda/pkg/sigda
  learned from max: projective.decomposition is used internally AND may be called directly by user.

*-----------------------------------------------------------------------------------------------------------------------
* clustergrammer tips

  --- create the json object, save it as a file
    pip install clustergrammer
    python
from clustergrammer import Network
net = Network()
net.load_file('/Users/paul/github/dora/datasets/AD-family.UM0463F/small.tsv')   # net.dat now exists
net.make_clust()               # net.viz now exists
net.write_json_to_file('viz','small.json')

  --- display it in the new ~/github/clustergrammer_requirejs/
    ~/github/clustergrammer_requirejs/index.html
     in header:   <script data-main="scripts/common" src="scripts/require.js"></script>
     below body:   require(['common'], function(){require(['load_clustergram']);})
     scripts/common.js:
        require.config({
          baseURL: 'scripts/',
          paths: {'underscore': 'underscore-min','jquery': 'jquery-1.11.2.min',},
          shim: {underscore: {exports: '_'}}})

     scripts/load_clustergram.js:
       require(['underscore', 'jquery', 'd3', 'clustergrammer'], function (_, $, d3, clustergrammer) {
         console.log(_)
         console.log($)
         console.log(Clustergrammer)
         make_clust('mat1b.json');
         var about_string = 'Zoom, scroll, and click buttons to interact with the clustergram. <a href="http://amp.pharm.mssm.edu/clustergrammer/help"> <i class="fa fa-question-circle" aria-hidden="true"></i> </a>';
         function make_clust(inst_network){
            d3.json('json/'+inst_network, function(network_data){
              var args = {
                 root: '#container-id-1',
                 'network_data': network_data,
                 'about':about_string,
                 'sidebar_width':150,
                 };
              var screen_width = window.innerWidth;
              var screen_height = window.innerHeight - 20;
              d3.select(args.root)
                .style('width', screen_width+'px')
                .style('height', screen_height+'px');
              cgm = Clustergrammer(args);
              d3.select(cgm.params.root + ' .wait_message').remove();
              console.log('loading clustergrammer')
              });
            }
          }); // require

*-----------------------------------------------------------------------------------------------------------------------
* rpy2

   Downloading rpy2-2.8.5.tar.gz (184kB)
      100% |████████████████████████████████| 184kB 1.5MB/s
   Requirement already satisfied: six in /Users/paul/anaconda/lib/python3.5/site-packages (from rpy2)
   Building wheels for collected packages: rpy2
   Running setup.py bdist_wheel for rpy2 ... done
    Stored in directory: /Users/paul/Library/Caches/pip/wheels/23/9e/ee/0e5f6a00aafef9935d40ebf7657278220139f0101321e30d07
     Successfully built rpy2
     Installing collected packages: rpy2
     Successfully installed rpy2-2.8.5
*-----------------------------------------------------------------------------------------------------------------------
* new notebook for liz blue's family-UM0463

     cd  ~/github/dora/datasets/AD-family.UM0463F/

     source("~/github/snpFoot/R/liftoverHg19BedFiles.R")
     liftoverBedFile.19.38("hg19.bed.file")

    --- need wt/variant for doComparativeFimo
       saved the "vep80" sheet from   ~/github/dora/datasets/AD-family.UM0463F/UM0463F_BonfSNPs.xlsx
       UM0463F_BonfSNPs_vep80.txt | tr '\r' '\n' > UM0463F_BonfSNPs_vep80.tsv


1       167430315       T       1:167430315:C:T 1:167430315_C/T RP11-104L21.2   ENSG00000233411 ENST00000417969 upstream_gene_varia
1       167430315       T       1:167430315:C:T 1:167430315_C/T CD247   ENSG00000198821 ENST00000362089 intron_variant  -       -
1       167430315       T       1:167430315:C:T 1:167430315_C/T CD247   ENSG00000198821 ENST00000392122 intron_variant  -       -
1       167430315       T       1:167430315:C:T 1:167430315_C/T RP11-104L21.3   ENSG00000273160 ENST00000610044 upstream_gene_varia
1       167430315       T       1:167430315:C:T 1:167430315_C/T CD247   ENSG00000198821 ENST00000479979 "intron_variant,non_coding_
1       167430315       T       1:167430315:C:T 1:167430315_C/T CD247   ENSG00000198821 ENST00000483825 "intron_variant,non_coding_
1       167438683       T       1:167438683:C:T 1:167438683_C/T CD247   ENSG00000198821 ENST00000362089 intron_variant  -       -
1       167438683       T       1:167438683:C:T 1:167438683_C/T CD247   ENSG00000198821 ENST00000392122 intron_variant  -       -
1       167438683       T       1:167438683:C:T 1:167438683_C/T CD247   ENSG00000198821 ENST00000479979 "intron_variant,non_coding_*-----------------------------------------------------------------------------------------------------------------------
1       167438683       T       1:167438683:C:T 1:167438683_C/T CD247   ENSG00000198821 ENST00000483825 "intron_variant,non_coding_* cusanovich 2014: The Functional Consequences of Variation in Transcription Factor Binding

    --- hand-check the first variant, hg19?

        head -2 UM0463_snps.bed
        1	167112118	167112118
        1	167430315	167430315

        book.AD-family.UM0463F> head -2 UM0463_snps.hg38.bed
        chr1	167142881	167142881
        chr1	167461078	167461078

        book.AD-family.UM0463F> head -2 UM0463F_BonfSNPs_vep80.tsv
        1	167430315	T	1:167430315:C:T	1:167430315_C/T	RP11-104L21.2	ENSG00000233411	ENST00000417969	upstream_gene_variant	-	-	-	-	-	rs145175987	IMPACT=MODIFIER;DISTANCE=2417;STRAND=-1;VARIANT_CLASS=SNV;SYMBOL=RP11-104L21.2;SYMBOL_SOURCE=Clone_based_vega_gene;BIOTYPE=sense_intronic;CANONICAL=YES;GMAF=T:0.0042;AFR_MAF=T:0;AMR_MAF=T:0.0014;EAS_MAF=T:0;EUR_MAF=T:0.0089;SAS_MAF=T:0.0112
        1	167430315	T	1:167430315:C:T	1:167430315_C/T	CD247	ENSG00000198821	ENST00000362089	intron_variant	-	-	-	-	-	rs145175987	"IMPACT=MODIFIER;STRAND=-1;VARIANT_CLASS=SNV;SYMBOL=CD247;SYMBOL_SOURCE=HGNC;HGNC_ID=1677;BIOTYPE=protein_coding;CANONICAL=YES;CCDS=CCDS1261.1;ENSP=ENSP00000354782;SWISSPROT=CD3Z_HUMAN;TREMBL=H6QVQ5_HUMAN,A9Y844_HUMAN;UNIPARC=UPI0000127362;INTRON=1/7;HGVSc=ENST00000362089.5:c.59-20311G>A;GMAF=T:0.0042;AFR_MAF=T:0;AMR_MAF=T:0.0014;EAS_MAF=T:0;EUR_MAF=T:0.0089;SAS_MAF=T:0.0112"

       source("../../notebooks/AD-trena/src/igapGwasFimoUtils.R")
       doComparativeFimo("chr1", 167461078, "C", "T", 10)
       $status: [1] "loss"
       $table
          X.pattern.name sequence.name start stop strand    score  p.value  q.value matched.sequence
       1        MA0500.1            wt     1   11      - 15.53060 1.17e-06 5.15e-05      GGCAGCTGCAG
       2        MA0499.1            wt     2   14      + 15.18370 3.23e-06 9.62e-05    TGCAGCTGCCACG
       3        MA0521.1            wt     1   11      - 15.10200 3.60e-06 8.29e-05      GGCAGCTGCAG
       4        MA0500.1           mut     1   11      - 15.10200 3.65e-06 8.03e-05      AGCAGCTGCAG
       5        MA0521.1           mut     1   11      - 15.08160 3.77e-06 8.29e-05      AGCAGCTGCAG
       6        MA0499.1           mut     2   14      + 14.83670 5.35e-06 9.62e-05    TGCAGCTGCTACG
       7        MA0816.1           mut     2   11      - 14.37140 1.04e-05 4.20e-04       AGCAGCTGCA
       8        MA0048.2           mut     2   11      - 13.12070 2.03e-05 6.53e-04       AGCAGCTGCA
       9        MA0816.1           mut     2   11      + 13.02860 2.28e-05 4.20e-04       TGCAGCTGCT
       10       MA0816.1            wt     2   11      - 12.74290 2.63e-05 4.20e-04       GGCAGCTGCA
       11       MA0048.2           mut     2   11      + 12.56900 2.76e-05 6.53e-04       TGCAGCTGCT
       12       MA0816.1            wt     2   11      + 12.34290 3.50e-05 4.20e-04       TGCAGCTGCC
       13       MA0048.2            wt     2   11      + 11.84480 4.13e-05 6.53e-04       TGCAGCTGCC
       14        LMO2.p2           mut     1   12      + 11.10530 4.43e-05 9.62e-04     CTGCAGCTGCTA
       15       MA0048.2            wt     2   11      - 11.27590 5.44e-05 6.53e-04       GGCAGCTGCA
       16        LMO2.p2            wt     1   12      - 10.00000 6.56e-05 9.62e-04     TGGCAGCTGCAG
       17       MA0100.2            wt     3   12      + 11.54100 6.58e-05 3.16e-03       GCAGCTGCCA
       18        LMO2.p2            wt     1   12      +  9.73684 7.21e-05 9.62e-04     CTGCAGCTGCCA
       19       MA0824.1            wt     2   11      + 11.04920 7.92e-05 3.80e-03       TGCAGCTGCC


    ---- create a rich bedfile
    tbl.vep80 <- read.table("UM0463F_BonfSNPs_vep80.tsv", sep="\t", header=FALSE, as.is=TRUE)
    colnames(tbl.vep80) <- c ("chrom", "start", "mut", "str1", "str2",
                              "nearbyGene", "ensg", "enst", "classification",
                              "x10", "x11", "x12", "x13", "x14", "rsid", "misc")
    tokens <- strsplit(tbl.vep80$str1, split=":")

*-----------------------------------------------------------------------------------------------------------------------
* cusanovich 2013

   The Functional Consequences of Variation in Transcription Factor Binding
   Darren A. Cusanovich1, Bryan Pavlovic1,2, Jonathan K. Pritchard1,2,3*, Yoav Gilad1*


   One goal of human genetics is to understand how the information for precise and dynamic gene
   expression programs is encoded in the genome. The interactions of transcription factors (TFs)
   with DNA regulatory elements clearly play an important role in determining gene expression
   outputs, yet the regulatory logic underlying functional transcription factor binding is poorly
   understood. Many studies have focused on characterizing the genomic locations of TF binding, yet
   it is unclear to what extent TF binding at any specific locus has functional consequences with
   respect to gene expression output. To evaluate the context of functional TF binding we knocked
   down 59 TFs and chromatin modifiers in one HapMap lymphoblastoid cell line. We then identified
   genes whose expression was affected by the knockdowns. We intersected the gene expression data
   with transcription factor binding data (based on ChIP-seq and DNase-seq) within 10 kb of the
   transcription start sites of expressed genes. This combination of data allowed us to infer
   functional TF binding. Using this approach, we found that only a small subset of genes bound by a
   factor were differentially expressed following the knockdown of that factor, suggesting that most
   interactions between TF and chromatin do not result in measurable changes in gene expression
   levels of putative target genes. We found that functional TF binding is enriched in regulatory
   elements that harbor a large number of TF binding sites, at sites with predicted higher binding
   affinity, and at sites that are enriched in genomic regions annotated as ‘‘active enhancers.’’

   ~/Documents/cusanovich.pdf

*-----------------------------------------------------------------------------------------------------------------------
* create demo tsv, metadata, schema for BDDS

  whovian
  cd ~/github/dora/microservices/AD-trena
  source("server.R")
  region <- "7:101,165,571-101,165,620"   # about 25bp up and downstream from the VGF (minus strand) tss, 2 hint brain footprints
  target.gene <- "VGF"
  result <- createGeneModel(target.gene, region)
  tbl.gm <- result$tbl
  write.table(tbl.gm, quote=FALSE, sep="\t", row.names=FALSE, file="bddsDemo/vgfModel.tsv")

   gene   gene.cor       beta IncNodePurity chrom     start    endpos distance
    MAZ  0.3676506  1.0371150      368.3111  chr7 101165602 101165609        9
   NRF1 -0.2951702 -0.9409768      402.5432  chr7 101165575 101165585      -18

  --- metadata:
    targetGene: VGF
    region: chr7:101,165,571-101,165,620
    footprintDB: postgres://whovian/brain_hint
    genomeDB: postgres://whovian/hg38
    expressionData: rosmap_counts_matrix_normalized_geneSymbols_25031x638.RData

   --- schema
    create table trenaGeneModel(gene varchar, gene.cor real, beta real, IncNodePurity real,
                                start int, endpos int, distance int);



*-----------------------------------------------------------------------------------------------------------------------
* sigda (28 feb 2017)

  cd ~/github/sigda/pkg/sigda/

*-----------------------------------------------------------------------------------------------------------------------
* createIgapFimoTrack aka igap.gwas.SNPassay (27 feb 2017)

   cd  ~/github/dora/notebooks/AD-trena/src/

   just refactored, in completely, so that:

   tbl.trem2 <- igap.gwas.SNPassay(gene="TREM2", upstream=2000, downstream=100, snp.shoulder=10, quiet=TRUE)
   tbl.trem2
    gene chrom      tss gene.strand       rsid     base igap.wt igap.mut sequence.name  matched.sequence             motif start stop strand    score  p.value  q.value      status
   TREM2  chr6 41163186           - rs28654619 41164199       T        C          <NA>              <NA>              <NA>    NA   NA   <NA>       NA       NA       NA     noMotif
   TREM2  chr6 41163186           -  rs6517655 41164319       G        C           mut CCCTGTGCGTAAGTTAG          MA0615.1     1   17      - 11.60530 2.06e-05 0.000411        gain
   TREM2  chr6 41163186           -  rs2210277 41164381       T        C            wt        CTCAAAGGGC sci09.v2_Bbx_3753     5   14      +  4.14151 7.38e-05 0.003540        loss
   TREM2  chr6 41163186           -  rs4822013 41163211       A        G            wt        CTTAATCCCC          MA0891.1     4   13      - 12.40680 4.80e-06 0.000230 lossAndGain
   TREM2  chr6 41163186           -  rs4822013 41163211       A        G            wt         CTTAATCCC          MA0714.1     5   13      - 12.78850 7.34e-06 0.000382 lossAndGain
   TREM2  chr6 41163186           -  rs4822013 41163211       A        G            wt        CTTAATCCCC          MA0648.1     4   13      - 12.81130 9.34e-06 0.000449 lossAndGain
   TREM2  chr6 41163186           -  rs4822013 41163211       A        G            wt          TTAATCCC          MA0682.1     5   12      - 12.14550 1.79e-05 0.001000 lossAndGain
   TREM2  chr6 41163186           -  rs4822013 41163211       A        G           mut       ATTGCTCAATC          MA0102.3     7   17      - 12.79590 2.87e-05 0.001160 lossAndGain
   TREM2  chr6 41163186           -  rs4822013 41163211       A        G           mut        ATTGCTCAAT          MA0838.1     8   17      - 10.97960 4.75e-05 0.002280 lossAndGain
   TREM2  chr6 41163186           -  rs4822013 41163211       A        G            wt       ATTGCTTAATC          MA0102.3     7   17      - 11.89800 5.27e-05 0.001160 lossAndGain
   TREM2  chr6 41163186           -  rs4822013 41163211       A        G            wt          TTAATCCC          MA0712.1     5   12      - 11.85110 5.75e-05 0.003220 lossAndGain
   TREM2  chr6 41163186           -  rs4822013 41163211       A        G            wt          TTAATCCC          MA0711.1     5   12      - 11.36170 6.83e-05 0.003830 lossAndGain
   TREM2  chr6 41163186           -  rs4822013 41163211       A        G            wt       CTGGGGATTAA          MA0467.1     2   12      + 10.91380 8.66e-05 0.003810 lossAndGain
   TREM2  chr6 41163186           -  rs4822013 41163211       A        G            wt          TTAATCCC          MA0719.1     5   12      -  9.98077 9.18e-05 0.005140 lossAndGain

*-----------------------------------------------------------------------------------------------------------------------
* Availability and uptake of inorganic nitrogen in a mixed old-growth coniferous forest

  1980
  http://andrewsforest.oregonstate.edu/pubs/pdf/pub135.pdf

  an ecophysical approach to quantifying nitrogen fixation, andrews and wind river
    https://www.jstor.org/stable/3244571?seq=1#page_scan_tab_contents

  DAVID P. TURNER, PHILLIP SOLLINS, MARY LEUKING and NATHAN RUDD
  Plant and Soil
  Vol. 148, No. 2 (January (II) 1993), pp. 163-174
  Published by: Springer
  Stable URL: http://www.jstor.org/stable/42938784

  https://www.fs.fed.us/pnw/pubs/journals/pnw_1998_bendavid001.pdf
  Fertilization of terrestrial vegetation by spawning Pacific salmon: the role of flooding and predator activity

  Pacific Salmon in Aquatic and Terrestrial Ecosystems
  https://pdfs.semanticscholar.org/7d33/d15752d2a70ef63bc38c26bce45299f4ba99.pdf

  Linking Ecosystems, Food Webs, and Fish Production: Subsidies in Salmonid Watersheds
  http://www.wsl.ch/info/mitarbeitende/scheideg/2016_09_Wipfli_2010.pdf

*-----------------------------------------------------------------------------------------------------------------------
*  The Shaman as a Maker of Worlds: Nelson Goodman in the Amazon

   https://www.jstor.org/stable/2803656?seq=1#page_scan_tab_contents

*-----------------------------------------------------------------------------------------------------------------------
* a deleuzian multiplicity  (manuel dleanda, intensive science and virtual philosophy, p 5
  ...takes as its first defining feature these two traits of a manifold:
     its variable number of dimensions, and
     more importantly, the absence of a supplementary (higher) dimesnion imposing an extrinsic coordinatization,
       and hence, an extreinsiclly defined unity.
*-----------------------------------------------------------------------------------------------------------------------
* jupyterlab install from the web

  (24 feb 2017): 0.16.2
  conda install -c conda-forge jupyterlab
  start:
    cd ~/github/dora/notebooks/AD-trena/
    jupyter lab

  pip install jupyterlab
 jupyter serverextension enable --py jupyterlab --sys-prefix

*-----------------------------------------------------------------------------------------------------------------------
* jupyterlab build and install

  cd ~/github/jupyterlab/
  git clean -fdx   # remove all files not available from the repo
  git pull origin
  npm install
  pip install -e .

   Command "/Users/paul/anaconda/bin/python -c "import setuptools, tokenize;
   __file__='/Users/paul/github/jupyterlab/setup.py';
   f=getattr(tokenize, 'open', open)(__file__);
   code=f.read().replace('\r\n', '\n');
   f.close();
   exec(compile(code, __file__, 'exec'))" develop --no-deps" failed with error code 1 in /Users/paul/github/jupyterlab/

*-----------------------------------------------------------------------------------------------------------------------
* interpreting igap gwas snps (21 feb 2017)

   --- my question to minerva

   CHR  oldPos      BP        SNP Effect_allele Non_Effect_allele    Beta     SE       P     igap igap- dbSNP
  chr1  978193 1042813  rs2710873             A                 G -0.0824 0.0389 0.03412      G/A  C/T    C/T
  chr1  998395 1063015  rs7526076             A                 G -0.0512 0.0229 0.02543      G/A  C/T    A/G
  chr1 1000156 1064776 rs11584349             C                 T -0.0536 0.0224 0.01687      T/C  A/G    C/T

    1) nicely explained by strand (C -> T: MAF  0.0881/441)
        https://www.ncbi.nlm.nih.gov/projects/SNP/snp_ref.cgi?rs=2710873


2) wt and mutant alleles seem to be switched  (A -> G: MAF 0.1777/890)
        https://www.ncbi.nlm.nih.gov/projects/SNP/snp_ref.cgi?rs=7526076

    3) wt and mutant alleles seem to be switched  (C -> T: TMAF 0.2532/1268)
       https://www.ncbi.nlm.nih.gov/projects/SNP/snp_ref.cgi?rs=11584349

   Are not the Effect_allele in cases 2 and 3 in fact in both cases the reference base?

   --- minerva's ultimate response

     Please see below the EUR/CEU MAFs based on dbSNP:

       rs2710873: T allele freq = 0.14810000
       rs7526076: A allele freq = 0.24349999
       rs11584349: C allele freq = 0.25833333

     In each of the three cases, the Minor allele in the EUR/CEU population is the IGAP “Effect allele”.


      Part of what makes it so confusing is the fact that dbSNP
      provides the summary info that you show in the screenshot
      below. That info is not population specific. In order to get the
      population specific MAFs you have to go to the dbSNP page of the
      SNP of interest, and then scroll all the way down to the section
      called “Population Diversity”. As shown in the screenshot
      immediately below for rs11584349:

      Since generally there aren’t that many variants within any given
      21 base pair window, I don’t think that you need to create a
      population-specific 21bp reference sequence.

      I think that the easiest way to generalize your algorithm would
      be to continue using your "naïve" approach that assumes that all
      positions in the human reference sequence are the
      major/ancestral alleles, then annotate the possible impact,
      based on FIMO, of the "effect allele" in your study of
      interest. For example, for rs11584349, your algorithm would
      determine the motif binding score for each of the hg38 reference
      and alternative alleles (in this case C and T, respectively),
      and then determine which of these is labeled in your study of
      interest as the "effect allele", which in the case of IGAP is
      the C allele.

       That would be my "naïve" approach :).


   --- from gustavo
   Historically there has indeed been much confusion with respect to the representation of variants, particularly with respect to strand. dbSNP has a huge number of variants canonically represented using the strand that is the reverse of the reference. This is particularly problematic for A/T and C/G variants of course, as there's almost no way to disambiguate.
   On top of that, some positions changed reference allele between reference versions, particularly from GRCh37 to GRCh38.
There are also triallelic, tetraallelic and multiallelic (complex) sites.

As for igap, I think it encodes relative to the effect allele. In some cases the encoding is backwards but one can tell based on the beta value.

Looking at the examples listed, some observations:
rs2710873 ref=G, alt=A - strand swap in dbSNP
rs7526076 ref=A, alt=G - G is the major allele
rs11584349 ref=C, alts=T,G - triallelic and T is the major allele
rs4970401 ref=G, alt=C - C is the major allele
rs74048003 ref=A, alt=G has positive Beta value (encoding would be consistent if one negated it)
rs4246502 ref=C alt=G - G is the major allele
rs4075116 ref=C alt=T - T is the major allele plus dbSNP is strand-swapped
rs55746161 ref=C alt=A
rs61766321 ref=G alt=A - Kaviar warns me it's seen mostly/only on Illumina, and it overlaps many indel variants
rs61766322 same observations as for previous


*-----------------------------------------------------------------------------------------------------------------------
* dora tips: generate bed9 colored fimo-assayed snps, laptm5 example (20 feb 2017)

  used igv.js (or something else) to learn the TSS
  tss <- 30757828
  start <- tss - 4200
  end   <- tss + 1300
  chrom <- "chr1"
  source("~/github/projects/priceLab/AD/gwasFimo/createIgapFimoTrack.R");
  tbl.b9 <- geneCentric.bed9.snps(chrom, start, end, "LAPTM5", manualEdit=TRUE)

  --- now have APA2.region.bed
   scp AP2A2.region.bed pshannon@whovian:/local/httpd/vhosts/pshannon/annotations/
   display this in dora's igv.js: 11:923,951-927,102 (3152 bp)
   modest levels of regulation seem to come from foxk1, foxp4, hmga1

*-----------------------------------------------------------------------------------------------------------------------
* ap2a2: do the tss-proximal snp-gain motifs bring new TFs into an already weak model? (20 feb 2017)

  cd ~/github/dora/notebooks/AD-trena/explorations/

*-----------------------------------------------------------------------------------------------------------------------
* dora tips: generate bed9 colored fimo-assayed snps, ap2a2 example (20 feb 2017)

  used igv.js (or something else) to learn the TSS
  11:

  cd  ~/github/projects/priceLab/AD/gwasFimo
  source("createIgapFimoTrack.R"); runTests()
  tss <- 924738
  tbl.b9 <- geneCentric.bed9.snps("chr11", tss-1000, tss+1000, "AP2A2", manualEdit=TRUE)

  --- now have APA2.region.bed
   scp AP2A2.region.bed pshannon@whovian:/local/httpd/vhosts/pshannon/annotations/
   display this in dora's igv.js: 11:923,951-927,102 (3152 bp)
   modest levels of regulation seem to come from foxk1, foxp4, hmga1

  --- hypothesis the motif gain snps suggest stronger up-regulatory relationships
    cd ~/github/dora/notebooks/AD-trena/explorations/
    ap2a2.R

*-----------------------------------------------------------------------------------------------------------------------
* run vrk2-pou3f2 notebook on whovian (1 may 2017)

  rs13384219  A->G
  gtcagtagtggtggaaccagcatgc[A/G]aattagacaatgtgacttcatagcc
  Chromosome: 2:57907323
  vrk2 tss at chr2:57908651
  Gene:VRK2 (GeneView) Functional Consequence: upstream variant 2KB Validated: by 1000G,by cluster,by frequency,by
    hapmap Global MAF:G=0.0623/312


  cd ~/github/notebooks
  bash> nohup jupyter notebook --port=10005 --NotebookApp.token= &
  find notebook here:
     http://whovian:10005/notebooks/shared/VRK2-Pou3f2.ipynb
        chrom = "chr2"
     loc = 57907323
  chrom = "chr2"
  loc = 57907323
  shoulder = 7
  snpLocus = "%s:%d-%d" % (chrom, loc-shoulder, loc+shoulder)
  viewRange = "chr2:57,907,026-57,907,985"
*-----------------------------------------------------------------------------------------------------------------------

*-----------------------------------------------------------------------------------------------------------------------

*-----------------------------------------------------------------------------------------------------------------------
* igv.js tips, igv tips

  --- create custom track from within a notebook
   ~/github/notebooks/shared/VRK2-Pou3f2.ipynb


   --- cell 1
     chrom = "chr2"
     loc = 57907323
     shoulder = 7
     snpLocus = "%s:%d-%d" % (chrom, loc-shoulder, loc+shoulder)
    viewRange = "chr2:57,907,026-57,907,985"

   --- cell 2
     igv = IGV(locus=viewRange, reference=Reference(id="hg38"),
               tracks=[Track(
                      name="Genes",
                      url="//s3.amazonaws.com/igv.broadinstitute.org/annotations/hg38/genes/gencode.v24.annotation.sorted.gtf.gz",
                      indexURL="//s3.amazonaws.com/igv.broadinstitute.org/annotations/hg38/genes/gencode.v24.annotation.sorted.gtf.gz.tbi",
                      display_mode="EXPANDED")])
     igv

   --- cell 3
     trackTbl = pd.DataFrame([[chrom, loc-shoulder, loc+shoulder, "snp"]])
     trackTbl.to_csv("vrk2Snp.bed", sep="\t", header=False, index=False)
     newTrack = Track(name="rs13384219 ", format="bed", indexed=False,
                 url="http://whovian:10005/files/shared/vrk2Snp.bed",
                 display_mode='EXPANDED');

   --- cell 4
      igv.load_track(newTrack)


*-----------------------------------------------------------------------------------------------------------------------
* generate new brain hint track, including all singleton reports (20 feb 2017)

   cd   ~/github/projects/examples/genomics/tracks/brainHintFootprintsBedGraph/
   in go.R, condense.footprints, made this change

        tbl.repsOfInterest <- subset(tbl.reps, Freq > 0)  # had been > 1
   source("go.R"); iterate()
      11138167 Feb 19 23:36 chr22.bed
       8528261 Feb 19 23:34 chr21.bed
      14245103 Feb 19 23:33 chr20.bed
      15845622 Feb 19 23:30 chr19.bed
      14546182 Feb 19 23:28 chr18.bed
      21629585 Feb 19 23:26 chr17.bed
      19349110 Feb 19 23:22 chr16.bed
      18786166 Feb 19 23:19 chr15.bed
      19176746 Feb 19 23:15 chr14.bed
      19169683 Feb 19 23:12 chr13.bed
      28643368 Feb 19 23:09 chr12.bed
      30469710 Feb 19 23:05 chr11.bed
      29278953 Feb 19 23:00 chr10.bed
      26406088 Feb 19 22:55 chr9.bed
      28743067 Feb 19 22:50 chr8.bed
      32680693 Feb 19 22:46 chr7.bed
      35176916 Feb 19 22:40 chr6.bed
      35594655 Feb 19 22:34 chr5.bed
      34074375 Feb 19 22:29 chr4.bed
      40189466 Feb 19 22:23 chr3.bed
      50875550 Feb 19 22:17 chr2.bed
      53037626 Feb 19 22:08 chr1.bed

   with many promoter/fp/snps on chr2 (see just below), experiment with indexing and using just it first
   bash> sort -k 1.4,1n -k 2,2n -k 3,3n chr2.bed > brain_hint_chr2_all.bed
   bash> /Users/pshannon-isb/s/src/tabix/tabix-0.2.6/bgzip brain_hint_chr2_all.bed  # 9,465,405
   library(Rsamtools)
   tbl.filename <- indexTabix("brain_hint_chr2_all.bed.gz", format="bed")

    -rw-r--r--   9465405 Feb 20 05:40 brain_hint_chr2_all.bed.gz
    -rw-r--r--    140953 Feb 20 05:42 brain_hint_chr2_all.bed.gz.tbi

   scp brain_hint_chr2_all.bed.gz* pshannon@whovian:/local/httpd/vhosts/pshannon/annotations/

  --- now add chr11, for gene AP2A2, with three gained binding motifs from snps in TSS +/- 1000bp
     sort -k 1.4,1n -k 2,2n -k 3,3n chr11.bed > brain_hint_chr11_all.bed
     /Users/pshannon-isb/s/src/tabix/tabix-0.2.6/bgzip brain_hint_chr11_all.bed
     tbl.filename <- indexTabix("brain_hint_chr11_all.bed.gz", format="bed")

   -rw-r--r--   5616732 Feb 20 14:01 brain_hint_chr11_all.bed.gz
   -rw-r--r--     80060 Feb 20 14:01 brain_hint_chr11_all.bed.gz.tbi
   scp brain_hint_chr11_all.bed.gz* pshannon@whovian:/local/httpd/vhosts/pshannon/annotations/

  --- now add chr1, for gene LAPTM5,
     cd   ~/github/projects/examples/genomics/tracks/brainHintFootprintsBedGraph/

     sort -k 1.4,1n -k 2,2n -k 3,3n chr1.bed > brain_hint_chr1_all.bed
     /Users/pshannon-isb/s/src/tabix/tabix-0.2.6/bgzip brain_hint_chr1_all.bed
     R; library(Rsamtools)
     print(indexTabix("brain_hint_chr1_all.bed.gz", format="bed"))

   -rw-r--r--   5616732 Feb 20 14:01 brain_hint_chr11_all.bed.gz
   -rw-r--r--     80060 Feb 20 14:01 brain_hint_chr11_all.bed.gz.tbi
   scp brain_hint_chr1_all.bed.gz* pshannon@whovian:/local/httpd/vhosts/pshannon/annotations/


*-----------------------------------------------------------------------------------------------------------------------
* ampAD gene lists (19 feb 2017)

  from 9/28/16 email "UFL/ISB/Mayo top20 target nominations

  ---emory
    emory.genes <- c("SNRNP70", "U1-A", "U1-C", "smn1", "SmB", "PLCD1", "PTRHD1", "SFRP1", "PPP1R7", "DNM3", "RTN4", "EPB41L3", "
                     TUBB3", "PLEC", "ANXA5", "MSN", "CD44", "LMNA")

    mtSinai.genes <- c("DOCK2", "GABBR2", "GABRB2", "GIGYF1", "ITGB2", "JPH3", "LAPTM5", "NCKAP1L",
                       "OPCML", "RBM3", "SCAMP1", "SCN2A", "SELT", "SNAP25", "SNAP91", "STXBP1",
                       "SUB1", "SYT1", "TARBP1", "YWHAG")

    ufl.genes <- c("TGFBR1", "BMPR1A", "BMPR1B", "VGF", "CRH/CRHR1", "TREM2", "TYROBP", "S100A8", "S100A9", "P2RY2", "P2RX7",
                   "P2RY12", "P2RY13", "OSMR", "TLR4", "CR1", "CSF1R", "CX3CR1", "SPI1", "TNFRSF10A/B")


    put these into ~/github/projects/priceLab/AD/gwasFimo/prospector.R, looking for igap gwas snps in proximal promoter
    with brain hint footprints, to forge cherry-pick demo for RIP and BDDS

   --- find snps in promoters in footprints
     cd ~/github/projects/priceLab/AD/gwasFimo
     source("prospector.R")
     print(table(tbl.snpsInPromotersInFootprints$gene_name))
      BMPR1B     DOCK2    LAPTM5    P2RY13    PPP1R7     SCN2A      TLR4 TNFRSF10A
           3         1         3         1        36        15         1         5

    print(table(tbl.snpsInPromotersInFootprints$CHR))
      chr1 chr2 chr3 chr4 chr5 chr8 chr9
         3   51    1    3    1    5    1

   these depend (maybe all of them) on footprints found in only one sample
   now: regenerate the hint fp igv track so that these singletons are included, despite the massive size which
        will result

    unique(subset(tbl.snpsInPromotersInFootprints, gene_name=="SCN2A")[, c("SNP", "BP", "strand")])
                SNP        BP strand
     2827 rs6718960 165239218      +

    library(FimoClient)
    if(!exists("fimo.service"))
       fimo.service <-  FimoClient("whovian", 5558, quiet=TRUE)
    library(BSgenome.Hsapiens.UCSC.hg38)
    hg38 = BSgenome.Hsapiens.UCSC.hg38
    library(SNPlocs.Hsapiens.dbSNP144.GRCh38)
    snps <- SNPlocs.Hsapiens.dbSNP144.GRCh38
    rsid <- "rs6718960"
    chrom <- "chr2"
    loc <- 165239218
    ambiguity.code <- snpsById(snps, rsid)$alleles_as_ambig
    elements.string <- IUPAC_CODE_MAP[[ambiguity.code]]
    elements <- strsplit(elements.string,'')[[1]]
    wt <- as.character(getSeq(hg38, chrom, loc, loc))
    mut <- setdiff(elements, wt)
    doComparativeFimo(chrom, loc, wt, mut, 10, quiet=FALSE) # gain
      X.pattern.name sequence.name start stop strand   score  p.value q.value matched.sequence
            MA0040.1           mut     2   12      + 12.4388 3.88e-05 0.00171      AAATGTTTAGA

    rsid <- "rs7596642"
    chrom <- "chr2"
    loc <- 241150035
    ambiguity.code <- snpsById(snps, rsid)$alleles_as_ambig
    elements.string <- IUPAC_CODE_MAP[[ambiguity.code]]
    elements <- strsplit(elements.string,'')[[1]]
    wt <- as.character(getSeq(hg38, chrom, loc, loc))
    mut <- setdiff(elements, wt)
    doComparativeFimo(chrom, loc, wt, mut, 10, quiet=FALSE) # noMotif


    rsid <- "rs7584799"
    chrom <- "chr2"
    loc <-  241150158
    ambiguity.code <- snpsById(snps, rsid)$alleles_as_ambig
    elements.string <- IUPAC_CODE_MAP[[ambiguity.code]]
    elements <- strsplit(elements.string,'')[[1]]
    wt <- as.character(getSeq(hg38, chrom, loc, loc))
    mut <- setdiff(elements, wt)
    doComparativeFimo(chrom, loc, wt, mut, 10, quiet=FALSE) # noMotif




    unique(subset(tbl.snpsInPromotersInFootprints, gene_name=="PPP1R7")[, c("SNP", "BP", "strand")])

                SNP        BP strand
   3279   rs7596642 241150035      +
   3279.1 rs7584799 241150158      +




   ---   cd ~/github/projects/examples/genomics/tracks/brainHintFootprintsBedGraph/

  go.R: crucial function os condense.footprints, which counts samples for each unique footprint
        writes chr[X].bed files
   combine.sh combines all 22 bed files into one, including:

  --- sorting bed file, at the command line, in preparation for indexing
      sort -k 1.4,1n -k 2,2n -k 3,3n brain_hint_unsorted.bed > brain_hint.bed
      /Users/pshannon-isb/s/src/tabix/tabix-0.2.6/bgzip brain_hint.bed

     1.4: sort the first column (n=numerically?) starting at character 4, thus after the chr in chr1, chr10



  --- create tabix file in R
   library(Rsamtools)
   tbl.filename <- indexTabix("brain_hint.bed.gz", format="bed")  #    "brain_hint.bed.gz.tbi"

      18624683 Feb 15 11:19 brain_hint.bed.gz
       1136333 Feb 15 11:19 brain_hint.bed.gz.tbi




*-----------------------------------------------------------------------------------------------------------------------
* dora trem2 example

  cd ~/github/projects/priceLab/AD/gwasFimo
  source("createIgapFimoTrack.R")    # uses bioc getSeq, fimo service, tbl.gwas.level_1.RData
  grep('rs9357347', tbl$SNP) # [1] 170435
  tbl[170432:170437,]
             CHR   oldPos       BP        SNP Effect_allele Non_Effect_allele    Beta     SE        P    score
    2751047 chr6 41136486 41168748 rs57108243             G                 A  0.1883 0.0616 0.002235 2.650722
    2751049 chr6 41140984 41173246  rs9394764             C                 G -0.0525 0.0171 0.002220 2.653647
    2751057 chr6 41148840 41181102 rs58051608             G                 C  0.1891 0.0619 0.002245 2.648784
    2751059 chr6 41150591 41182853  rs9357347             C                 A -0.0554 0.0170 0.001096 2.960189
    2751060 chr6 41152520 41184782  rs9471489             G                 A  0.1295 0.0420 0.002046 2.689094
    2751061 chr6 41152747 41185009  rs9462674             A                 T  0.1293 0.0420 0.002094 2.679023



  as.data.frame(t(subset(tbl, SNP=='rs9357347')))
                      2751059
  CHR                    chr6
  oldPos             41150591
  BP                 41182853
  SNP               rs9357347
  Effect_allele             C
  Non_Effect_allele         A
  Beta                -0.0554
  SE                    0.017
  P                  0.001096
  score              2.960189

    biocGet("SNPlocs.Hsapiens.dbSNP144.GRCh38")
    library(SNPlocs.Hsapiens.dbSNP144.GRCh38)
    snps <- SNPlocs.Hsapiens.dbSNP144.GRCh38
    as.data.frame(snpsById(snps, "rs9357347"))
     seqnames      pos strand RefSNP_id alleles_as_ambig
   1      ch6 41182853      + rs9357347                M    # A or C
   reference is A, must be C (?)
   doComparativeFimo("chr6", 41182853, "A", "C", 7)  # [1] "loss"


  --- penetrating the ambiguity codes, which seem to be used everywher in SNPlocs
    chr6_snps <- snplocs(snps, "ch6", as.GRanges=TRUE)


  * cory, minerva describe rs9357347 possibly affecting TREM2 regulation  (5 apr 2016)
  what footprints do we see?  good test for new LassoSolver?

  ---- email (5 apr 2016) frm minerva carrasquillo, nilufer taner also mentioned

   Yes, it would be great if you could evaluate how this regulatory
   SNP alters TF binding based on TReNA. The SNP is rs9357347, located
   within a DNase hypersensitive site, and it is predicted to alter
   both SP1 and PPAR binding. It is located within sequence reported
   to be subject to enhancer-associated histone marks in the
   hippocampus.


  ---- find footprints

    source("~/github/snpFoot/inst/misc/constrainTFs/lasso/go.R")
    x <- getFootprints("TREM2")

  ---- the snp?  rs9357347
    biocLite("SNPlocs.Hsapiens.dbSNP144.GRCh38")
    library("SNPlocs.Hsapiens.dbSNP144.GRCh38")
    snps <- SNPlocs.Hsapiens.dbSNP144.GRCh38
    s <- snpsById(snps, "rs9357347")  # a GRanges object
    [1]      ch6 [41182853, 41182853]      + |   rs9357347                M

    x <- getFootprints("TREM2")
      [1] --- biomart coordinates for TREM2
       entrezgene chromosome_name start_position end_position strand
     1      54209               6       41158506     41163186     -1
   [1] promoter region chr6:41157506-41158506

   --- distance from minus strand start to snp
     41182853 - 41163186: [1] 19667

   ---- args(getFootprints): (geneSymbol, size.upstream = 1000, size.downstream = 0)

   --- that snp, at chr6: 41182853
      source("~/github/snpFoot/inst/misc/constrainTFs/lasso/go.R")
      tbl.trem2fp <- getFootprints("TREM2", 20000, 0)
      range(c(tbl.trem2fp$mfpStart, tbl.trem2fp$mfpEnd))  # [1] 41163197 41182990
        # found just one motif, in the closest footprint
      unique(subset(tbl.trem2fp, mfpStart >= (loc-65) & mfpEnd <= loc)$motif)   # [1] "MA0479.1"


*-----------------------------------------------------------------------------------------------------------------------
* dora directories

   ms-trenaAD: ~/github/dora/microservices/AD-trena/
   nb-trenaAD: ~/github/dora/notebooks/AD-trena/

*-----------------------------------------------------------------------------------------------------------------------
* 9-column bed file format, useful for categorized snps (16 feb 2017)

  https://genome.ucsc.edu/FAQ/FAQformat#format1

  sample use, on trem2
  cd ~/github/projects/priceLab/AD/gwasFimo

*-----------------------------------------------------------------------------------------------------------------------
* igv.js track tester (16 feb 2017)

   ~/github/projects/examples/js/igvBareBones/trackTester.html

*-----------------------------------------------------------------------------------------------------------------------
* create full fimo track for all gwas snsp

  cd /Users/paul/s/data/priceLab//AD/gwasFimo/
  found that print(load("../tbl.gwas.level_1.RData")) has ref/mut pairs which, allowing for liftover, do not
  match the hg38 reference genome nor dbsnp.  abandanoned in favor of

    scp pshannon@whovian:/local/Cory/IGAP_summary_statistics/IGAP_stage_1.txt .   # 7M lines
    tbl <- read.table("IGAP_stage_1.txt", sep="\t", header=TRUE, as.is=TRUE)  #   7,055,881       8
    Chromosome, Position, MarkerName, Effect_allele, Non_Effect_allele, Beta, SE, Pvalue

   --- huge number of large pvalues, how does it compare to milifur?
     fivenum(tbl$Pvalue)    # [1] 0.0000 0.2299 0.4819 0.7399 1.0000
     hist(tbl$Pvalue)
     print(load("../tbl.gwas.level_1.RData")) # [1] "tbl.gwas"
     colnames(tbl.gwas) #       CHR, oldPos, BP, SNP, Effect_allele, Non_Effect_allele, Beta,  SE, P
     fivenum(tbl.gwas$P) # [1] 1.000e-150  1.005e-02  2.270e-02  3.620e-02  5.000e-02
     -log10(fivenum(tbl.gwas$P)) #  150.000000   1.997834   1.643974   1.441291   1.301030
     dim(subset(tbl, Pvalue <= 0.05)) # [1] 438696      8
     dim(tbl.gwas)  # [1] 438609      9

   --- does this new (and filtered table) lift over to hg38 sensibly?
     tbl.test <- tbl[1:10, c("Chromosome", "Position", "Position", "MarkerName")]
     write.table(tbl.test, sep="\t", quote=FALSE, row.names=FALSE, col.names=FALSE, file="hg19-sample.bed")

     source("~/github/snpFoot/R/liftoverHg19BedFiles.R")
     liftoverBedFile.19.38("hg19.bed.file")

*-----------------------------------------------------------------------------------------------------------------------
* the wt/mut problem with tbl.gwas.level_1.RData

  cd ~/s/data/priceLab/AD/gwasFimo

  found that print(load("../tbl.gwas.level_1.RData")) has ref/mut pairs which, allowing for liftover, do not

   head(tbl.gwas)
    CHR  oldPos      BP        SNP Effect_allele Non_Effect_allele    Beta     SE       P     igap igap-  dbSNP
   chr1  978193 1042813  rs2710873             A                 G -0.0824 0.0389 0.03412      G/A  C/T    C/T
   chr1  998395 1063015  rs7526076             A                 G -0.0512 0.0229 0.02543      G/A  C/T    A/G
   chr1 1000156 1064776 rs11584349             C                 T -0.0536 0.0224 0.01687      T/C  A/G    C/T
   chr1 1001177 1065797  rs4970401             G                 C -0.0530 0.0224 0.018120     C/G  G/C    C/G
   chr1 1002387 1067007 rs74048003             G                 A  0.0609 0.0285 0.032360     A/G  T/C    A/G
   chr1 1002932 1067552  rs4246502             C                 G -0.0505 0.0223 0.023520     G/C  C/G    C/G
   chr1 1003629 1068249  rs4075116             C                 T -0.0497 0.0220 0.023660     T/C  A/G    A/G
   chr1 1004181 1068801 rs55746161             C                 A -0.0693 0.0260 0.007672     A/C  T/G    A/C
   chr1 1004202 1068822 rs61766321             G                 A -0.0717 0.0300 0.016950     A/G  T/C    A/G
   chr1 1004204 1068824 rs61766322             G                 A -0.0711 0.0301 0.018140     A/G  T/C    A/G







*-----------------------------------------------------------------------------------------------------------------------
* personal air quality monitor leads (15 feb 2017)

   Development and evaluation of an ultrasonic personal aerosol sampler.
      https://www.ncbi.nlm.nih.gov/pubmed/27354176?dopt=Citation

   A small, lightweight multipollutant sensor system for ground-mobile and aerial emission sampling from open area sources
         http://www.sciencedirect.com/science/article/pii/S1352231017300298

   smithsonian article, with other devices mentioned:
      http://www.smithsonianmag.com/innovation/with-wearable-devices-that-monitor-air-quality-scientists-can-crowdsource-pollution-maps-180954556/

   nature, july 2016: Validate personal air-pollution sensors
      http://www.nature.com/news/validate-personal-air-pollution-sensors-1.20195

   https://www.ncbi.nlm.nih.gov/pubmed/25621420?dopt=Abstract&holding=npg
      Variability in and agreement between modeled and personal
      continuously measured black carbon levels using novel smartphone
      and sensor technologies.

   http://www.atmos-meas-tech.net/7/3325/2014/
      The next generation of low-cost personal air quality sensors for quantitative exposure monitoring

   http://www.strategyr.com/MarketResearch/Environmental_Sensing_and_Monitoring_Technologies_Market_Trends.asp

*-----------------------------------------------------------------------------------------------------------------------
* create bedGraph files for cory's notebook, brain hint, all chromosomes, sort, index, serve from whovian (15 feb 2017)

  cd ~/github/projects/examples/genomics/tracks/brainHintFootprintsBedGraph/

  go.R: crucial function os condense.footprints, which counts samples for each unique footprint
        writes chr[X].bed files
   combine.sh combines all 22 bed files into one, including:

  --- sorting bed file, at the command line, in preparation for indexing
      sort -k 1.4,1n -k 2,2n -k 3,3n brain_hint_unsorted.bed > brain_hint.bed
      /Users/pshannon-isb/s/src/tabix/tabix-0.2.6/bgzip brain_hint.bed

     1.4: sort the first column (n=numerically?) starting at character 4, thus after the chr in chr1, chr10



  --- create tabix file in R
   library(Rsamtools)
   tbl.filename <- indexTabix("brain_hint.bed.gz", format="bed")  #    "brain_hint.bed.gz.tbi"

      18624683 Feb 15 11:19 brain_hint.bed.gz
       1136333 Feb 15 11:19 brain_hint.bed.gz.tbi

*-----------------------------------------------------------------------------------------------------------------------
* bedToBigBed for brain_hint_footprints, (14 feb 2017)  also bedGraphToBigWig

   http://hgdownload.cse.ucsc.edu/admin/exe/macOSX.x86_64/bedToBigBed
   copied into ~/bin, chmod 755

   cd ~/github/projects/examples/genomics/tracks/bigBed/
   bedToBigBed chr22.bed http://hgdownload.cse.ucsc.edu/goldenPath/hg38/bigZips/hg38.chrom.sizes chr22.bb

       650342 Feb 14 17:09 chr22.bb
      2047007 Feb 14 15:08 chr22.bed

   bedGraphToBigWig chr22.bedGraph http://hgdownload.cse.ucsc.edu/goldenPath/hg38/bigZips/hg38.chrom.sizes chr22.bigwig

*-----------------------------------------------------------------------------------------------------------------------
* condense brain_hint footprints into unique regions, score is sample count, motifs ignored (14 feb 2017)

   cd ~/github/projects/examples/genomics/tracks/brainHintFootprintsBedGraph/
   go.R

*-----------------------------------------------------------------------------------------------------------------------
* notebook-friendly webserver, large genome info, apache cors and indexing (13 feb 2017)
  created by russ ingram

  apache 2.5
  virtual host: pshannon.systemsbiology.net and you can upload your content to. Let me know if you need anything further or you have trouble with what I've set up.
  actual directory:  /local/httpd/vhosts/pshannon/

  some subdirectories of interest
     Feb 10 11:53 annotations/
     Feb 10 11:53 genomes/
     Feb 10 12:42 hg38/
     Feb 10 12:39 nb/


   gwas snps in annotations;


*-----------------------------------------------------------------------------------------------------------------------
* create a bigbed (index, binary) file for igv.js out of all hint_brain footprints(13 feb 2017)

  --- try mef2c on chr5 first
    cd ~/github/projects/examples/genomics/tracks/bigBed

    scp test.bed pshannon@whovian:/local/httpd/vhosts/pshannon/annotations/
library(TReNA)
genome.db.uri    <- "postgres://whovian/hg38"                  # has gtf and motifsgenes tables
footprint.db.uri <- "postgres://whovian/brain_hint"            # has hits and regions tables
fpf <- FootprintFinder(genome.db.uri, footprint.db.uri, quiet=FALSE)
tbl.fp <- getFootprintsInRegion(fpf, "chr5", 88822685, 89011824)
dim(tbl.fp)   # 4105 17
tbl.bed <- tbl.fp[, c("chrom", "start", "endpos", "name", "score3")]
write.table(tbl.bed, sep="\t", quote=FALSE, row.names=FALSE, col.names=FALSE, file="test.bed")

  ---- added this track to igv.js config:
                  {name: "brain hint fp",
                   type: "annotation",
                   format: "bed",
                   sourceType: "file",
                   url: "http://pshannon.systemsbiology.net/annotations/test.bed",
                   indexed: false
                   },



*-----------------------------------------------------------------------------------------------------------------------
* dora todo
  for reverse strand genes, rightward chrom locs, and footprints returned from the trena microservice, should
  be presented as negative locs, transcriptionally upstream.

*-----------------------------------------------------------------------------------------------------------------------
* dora prep: use igv.js with webpack (11 feb 2016)

   script-loader

   This loader evaluates code in the global context, just like you
   would add the code into a script tag. In this mode every normal
   library should work. require, module, etc. are undefined.

   Note: The file is added as string to the bundle. It is not
   minimized by webpack, so use a minimized version. There is also no
   dev tool support for libraries added by this loader.




*-----------------------------------------------------------------------------------------------------------------------
* add css support to webpack (11 feb 2016)

  cd ~/github/projects/examples/js/webpack/igvCyWebGL

  https://webpack.github.io/docs/stylesheets.html
  http://survivejs.com/webpack/handling-styles/loading/

  npm install style-loader css-loader --save-dev
  add this line to webpack.config.js:
      module: {loaders: [{ test: /\.css$/, loader: "style-loader!css-loader" }]},
  --- now entire config looks like this:
     var webpack = require("webpack");
     module.exports = {
         entry: ['./src/index.js'],
         output: {
             path: './dist',
             filename: 'bundle.js'
             },
         module: {loaders: [{ test: /\.css$/, loader: "style-loader!css-loader" }]},
         plugins: [
             new webpack.ProvidePlugin({
                $: "jquery",
                jQuery: "jquery"
             })
         ]
     }

    --- added simple src/style.css
     and this line to src/app.js:
       require("css-loader!./style.css");

     this produced a webpack error:
       ERROR in ./~/css-loader!./src/style.css
       Module build failed: Unknown word (5:1)
     explained here:
       https://github.com/webpack-contrib/css-loader/issues/295

     fixed by removing the preface string in the require statement
        require("./style.css");
      since the "css-loader!" preface is already in the config file:
        module: {loaders: [{ test: /\.css$/, loader: "style-loader!css-loader" }]},


*-----------------------------------------------------------------------------------------------------------------------
* webpack tips: what does "test" mean?

   test — a regular expression that tests what kind of files to run through this loader.
   for example:
      module: {loaders: [{test: /\.css$/, loader: "style-loader!css-loader"}]},


*-----------------------------------------------------------------------------------------------------------------------
* a minimal working webpack/jquery/cyjs app (10 feb 2016)

  cd ~/github/projects/examples/js/webpack/igvCyWebGL/
  make

   --- used these installs

  505  npm install cytoscape --save
  534  npm install jquery --save
  536  npm install jquery-ui --save
  546  npm install jquery-ui --save
  550  npm install --save-dev imports-loader
  553  npm install ProvidePlugin --save
  555  npm install webpack --save
  568  history | grep npm

   cat webpack.config.js
   var webpack = require("webpack");
    module.exports = {
       entry: ['./src/index.js'],
       output: {
           path: './dist',
           filename: 'bundle.js'
           },
       plugins: [
           new webpack.ProvidePlugin({
              'jQuery': 'jquery',
              '$': 'jquery',
              'global.jQuery': 'jquery'
           })
       ]
   }

   jquery and $ not apparently available in src/app.js

but somehow this works
cytoscape = require('cytoscape');
jquery = require('jquery');
jqueryui = require('jquery-ui')


//----------------------------------------------------------------------------------------------------
getCyOptions = function()
{
   var value = {container: $("#cyDiv"),
               elements: {nodes: [{data: {id:'a'}}],
                         edges: [{data:{source:'a', target:'a'}}]},
                         style: cytoscape.stylesheet()
                            .selector('node').style({'background-color': '#d22',
                                                     'label': 'data(id)',
                                                     'text-valign': 'center',
                                                     'text-halign': 'center',
                                                     'border-width': 1})
                            .selector('edge').style({'line-color': 'black',
                                                     'target-arrow-shape': 'triangle',
                                                     'target-arrow-color': 'black',
                                                     'curve-style': 'bezier'})
               };
    return(value);
} // getCyOptions
//----------------------------------------------------------------------------------------------------
addNetwork = function()
{
  var cyDiv = $("#cyDiv")
  return(cytoscape(getCyOptions()))
}
//----------------------------------------------------------------------------------------------------
document.addEventListener('DOMContentLoaded',function(){
  console.log("--- document ready");
  cy = addNetwork();
   console.log("--- after addNetwork");
})


*-----------------------------------------------------------------------------------------------------------------------
* build a non-nb dora app using webpack and commonjs - no AMD require (10 feb 2017)

  status:  this is just a minimal webpack cyjs app

  cd ~/github/projects/examples/js/webpack/igvCyWebGL
  npm init -y
  npm install cytoscape --save

    --- see this in package.json
      "dependencies": {"cytoscape": "^2.7.14"}
    --- see this installed
        node_modules/cytoscape/dist/cytoscape.js

*-----------------------------------------------------------------------------------------------------------------------
* webpack tips, verbose error details

   ./node_modules/.bin/webpack  --display-error-details --config webpack.config.js

*-----------------------------------------------------------------------------------------------------------------------
* webpack and jquery:

  cd github
  git clone https://github.com/jzaefferer/webpack-jquery-ui.git
  npm install      # 65M!
  package.json: {
    "name": "webpack-jquery-ui",
    "version": "1.0.0",
    "description": "How to build an app with jQuery UI and webpack",
    "main": "index.js",
    "scripts": {
       "start": "webpack-dev-server --config webpack-config.js",
       "build": "webpack --config webpack-config.js"
       },
    "keywords": [
      "jquery-ui",
      "webpack"
       ],
   "repository": {
     "type": "git",
     "url": "git://github.com/jzaefferer/webpack-jquery-ui.git"
     },
    "author": "Jörn Zaefferer",
    "license": "MIT",
    "dependencies": {
      "jquery": "^2.1.4",
      "jquery-ui": "1.12.x"
      },
    "devDependencies": {
      "clean-webpack-plugin": "^0.1.3",
      "css-loader": "^0.16.0",
      "extract-text-webpack-plugin": "^0.8.2",
      "file-loader": "^0.8.4",
      "html-webpack-plugin": "^1.6.1",
      "style-loader": "^0.12.3",
      "webpack": "^1.12.2",
      "webpack-dev-server": "^1.11.0"
      }
   }

   ---- webpack-config.js
     var Clean = require('clean-webpack-plugin');
     var ExtractTextPlugin = require('extract-text-webpack-plugin');
     var HtmlWebpackPlugin = require('html-webpack-plugin');
     module.exports = {
        entry: {main: './index.js'},
        output: {path: './dist',filename: 'app.[hash].js'},
        module: {loaders: [{test: /\.css$/,
                            loader: ExtractTextPlugin.extract("style-loader", "css-loader")
                           },
                        {test: /\.(jpg|png)$/,
                         loader: 'file'
                        },
                     ]
              },
        plugins: [
            new Clean(['dist']),
            new ExtractTextPlugin("app.[hash].css"),
            new HtmlWebpackPlugin({title: 'jQuery UI Autocomplete demo, built with webpack'})
             ]
         };

*-----------------------------------------------------------------------------------------------------------------------
* jupyter tips, nbextension tips, jupyter nbextension install --help


   Install Jupyter notebook extensions
   Usage
      jupyter nbextension install path|url [--user|--sys-prefix]
   This copies a file or a folder into the Jupyter nbextensions directory. If a URL
   is given, it will be downloaded. If an archive is given, it will be extracted
   into nbextensions. If the requested files are already up to date, no action is
   taken unless --overwrite is specified.

Options
-------

Arguments that take values are actually convenience aliases to full
Configurables, whose aliases are listed on the help line. For more information
on full configurables, see '--help-all'.

-s
    Create symlink instead of copying files
--python
    Install from a Python package
--py
    Install from a Python package
--overwrite
    Force overwrite of existing files
--debug
    set log level to logging.DEBUG (maximize logging output)
--symlink
    Create symlink instead of copying files
--sys-prefix
    Use sys.prefix as the prefix for installing nbextensions (for environments, packaging)
--user
    Apply the operation only for the given user
--system
    Apply the operation system-wide
--log-level=<Enum> (Application.log_level)
    Default: 30
    Choices: (0, 10, 20, 30, 40, 50, 'DEBUG', 'INFO', 'WARN', 'ERROR', 'CRITICAL')
    Set the log level by value or name.
--nbextensions=<Unicode> (InstallNBExtensionApp.nbextensions_dir)
    Default: ''
    Full path to nbextensions dir (probably use prefix or user)
--config=<Unicode> (JupyterApp.config_file)
    Default: ''
    Full path of a config file.
--prefix=<Unicode> (InstallNBExtensionApp.prefix)
    Default: ''
    Installation prefix
--destination=<Unicode> (InstallNBExtensionApp.destination)
    Default: ''
    Destination for the copy or symlink

To see all available configurables, use `--help-all`

Examples
--------

    jupyter nbextension install /path/to/myextension

*-----------------------------------------------------------------------------------------------------------------------
* jupyter nbextension install tips

  jupyter nbextension install --debug [--user] --py dora

  --- without --user
    Copying: /Users/paul/github/dora/dora/static/extension.js -> /usr/local/share/jupyter/nbextensions/dora/extension.js
    Copying: /Users/paul/github/dora/dora/static/index.js -> /usr/local/share/jupyter/nbextensions/dora/index.js
    Copying: /Users/paul/github/dora/dora/static/index.js.map -> /usr/local/share/jupyter/nbextensions/dora/index.js.map


  --- with --user
    Up to date: /Users/paul/Library/Jupyter/nbextensions/dora/extension.js
    Up to date: /Users/paul/Library/Jupyter/nbextensions/dora/index.js
    Up to date: /Users/paul/Library/Jupyter/nbextensions/dora/index.js.map


  --- remove egg-link in standard python library directory, the module then picked up via sys.path
    something in the install process added this to sys.pth: '/Users/paul/github/dora'

  --- but dora is also a traditional python module:
      /Users/paul/anaconda/lib/python3.5/site-packages/dora.egg-link
     (created afresh with the makefile in ~/github/dora/)
    apparently found by this element in sys.path: '/Users/paul/.local/lib/python3.5/site-packages',
    with one line: /Users/paul/github/dora
    apparently pointing implicitly to /Users/paul/github/dora/dora.egg-info/


   a python egg (though superseded by wheel packaging): A "Python egg"
   is a logical structure embodying the release of a specific version
   of a Python project, comprising its code, resources, and
   metadata. There are multiple formats that can be used to physically
   encode a Python egg, and others can be developed. However, a key
   principle of Python eggs is that they should be discoverable and
   importable. That is, it should be possible for a Python application
   to easily and efficiently find out what eggs are present on a
   system, and to ensure that the desired eggs' contents are
   importable.

   The .egg format is well-suited to distribution and the easy
   uninstallation or upgrades of code, since the project is
   essentially self-contained within a single directory or file,
   unmingled with any other projects' code or resources. It also makes
   it possible to have multiple versions of a project simultaneously
   installed, such that individual programs can select the versions
   they wish to use.

   --- where does python load the dora module from:  python -v -m dora
     lots of output, including this clue
     /Users/paul/github/dora/dora/__pycache__/example.cpython-35.pyc matches /Users/paul/github/dora/dora/example.py

   --- conjecture:
    somehow this is in my default python sys.path
       '/Users/paul/github/dora',

  --- try loading this python module, which contains the javascript, in plain old python
    from dora import *
    hw = HelloWorld()
    hw.value   # 'Hello Dora!'

  --- or from the command line
    python -m dora
    /Users/paul/anaconda/bin/python: No module named dora.__main__; 'dora' is a package and cannot be directly executed


  --- what happens?
    the python directory ~/github/dora/dora/static


*-----------------------------------------------------------------------------------------------------------------------
* ipywidget cookiecutter (7 oct 2017)

  cd ~/github/widget-cookiecutter
  git pull origin
  pip install cookiecutter  # Collecting cookiecutter, Downloading cookiecutter-1.5.1-py2.py3-none-any.whl (44kB)

  jupyter --version            # 4.2.1
  jupyter notebook --version   # 5.1.0

  cookiecutter https://github.com/jupyter/widget-cookiecutter.git
   # answer questions, creates ~/github/jupyWidget


  python setup.py build
  pip install -e .

  jupyter nbextension install --py --symlink --sys-prefix jupyWidget
  jupyter nbextension enable --py --sys-prefix jupyWidget

  jupyter notebook
  from jupyWidget import *
  hw = HelloWorld()
  hw

*-----------------------------------------------------------------------------------------------------------------------
* the dora notebook app (9 feb 2017)

  cd ~/github
  pip install cookiecutter
  cookiecutter https://github.com/jupyter/widget-cookiecutter.git

     author_name []: Paul Shannon
     author_email []: pshannon@systemsbiology.org
     github_project_name [jupyter-widget-example]: dora
     github_organization_name [jupyter]: PriceLab
     python_package_name [ipywidgetexample]: dora
     npm_package_name [jupyter-widget-example]: dora
     project_short_description [A Custom Jupyter Widget Library]: Jupyter Widget for the Domain of (Gene) Regulatory Analysis

  cd ~/github/dora
  cp ../jupyter-cytoscape/makefile .
    # minor edits

  add license to js/package.json:

     "name": "dora",
     "version": "0.0.1",
     "license": "MIT",       # <<--- here
     "description": "Jupyter Widget for the Domain of (Gene) Regulatory Analysis",
     "author": "Paul Shannon",
     "main": "src/index.js",

   make   # builds and installs dora python, dora js

   --- what gets installed, where?
     grep dora /Users/paul/anaconda/etc/jupyter/nbconfig/notebook.json   #  "dora/extension": true,
     /Users/paul/anaconda/lib/python3.5/site-packages/dora.egg-link # one line only: /Users/paul/github/dora
        # this appears to be a consequence of the makefile command
        # jupyter nbextension install --user --py dora

   --- test this currently tiny extension in a jupyter notebook
     from dora import *
     hw = HelloWorld()
     hw.value    # 'Hello World!'
     hw.value = "Hello Dora!"
     hw.value    # 'Hello Dora!'

*-----------------------------------------------------------------------------------------------------------------------
* alison paquette, metabolic network, cy3 and rcyjs (9 feb 2017)

  cd ~/s/work/priceLab/alison/metabolicNetwork/

    Glycolisis&GluconeogenesisFile.xgmml
    glyAndGlu.cyjs
    cp ~/github/BDDS/trenadb/src/style.js .
    started to refine style.js

  library(RCyjs)
  rcy <- RCyjs(10000:10100, graph=graphNEL())
     # make sure "network = {" is the firest line in the json graph file
  send(rcy, list(cmd="httpAddGraph", callback="handleResponse", status="request", payload="glyAndGlu.cyjs"))
  httpSetStyle(rcy, "style.js")

*-----------------------------------------------------------------------------------------------------------------------
* joseph zhou (8 feb 2017)

   cd ~/s/work/leukemiaDrugResistance/
   scp pshannon@osiris:/users/gglusman/proj/hl60/HL60-VCFs.tar .
   cd ~/s/work/josephZhou/leukemiaDrugResistance/GS000035270-ASM-T1/analyses/
   R;
   library(Rsamtools)
   tbi.filename <- indexTabix("Genotype.vcf.gz", format="vcf")
   load file into igv desktop (version 2.3.68)

*-----------------------------------------------------------------------------------------------------------------------
* three.js picking ray (6 feb 2016)

  http://stackoverflow.com/questions/29366109/three-js-three-projector-has-been-moved-to

The THREE.JS raycaster documentation actually gives all the relevant
information that is laid out in these answers as well as all the
   missing points that may be difficult to get your head around.

   var raycaster = new THREE.Raycaster();
   var mouse = new THREE.Vector2();

   function onMouseMove( event ) {
     // calculate mouse position in normalized device coordinates
     // (-1 to +1) for both components
     mouse.x = ( event.clientX / window.innerWidth ) * 2 - 1;
     mouse.y = - ( event.clientY / window.innerHeight ) * 2 + 1;
   }

   function render() {
     // update the picking ray with the camera and mouse position
     raycaster.setFromCamera( mouse, camera );
     // calculate objects intersecting the picking ray var intersects =
     raycaster.intersectObjects( scene.children );

     for ( var i = 0; i < intersects.length; i++ ) {
       intersects[ i ].object.material.color.set( 0xff0000 );
       }
       renderer.render( scene, camera );
      }

   window.addEventListener( 'mousemove', onMouseMove, false );
   window.requestAnimationFrame(render);`

*-----------------------------------------------------------------------------------------------------------------------
* three.js basics: different ways to create scatter plot points (6 feb 2016)

       ParticleSystem and PointCloud has been renamed to Points. In
       addition, ParticleBasicMaterial and PointCloudMaterial has been
       renamed to PointsMaterial.


   --- my approach in app3d/scatterplot
     scene = new THREE.Scene();
     camera = new THREE.PerspectiveCamera(45, 1, 1, 10000);  // view angle, apect, near & far clipping planes
     renderer = new THREE.WebGLRenderer({antialias: true});
     scatterPlot = new THREE.Object3D();
     scene.add(scatterPlot);

     lineGeo = new THREE.Geometry();
     lineGeo.vertices.push(<Vector3's which define path for the bounding box, with some retracing of steps>)
     lineMat = new THREE.LineBasicMaterial({color: 0xFFFFFF, linewidth: 1});
     line = new THREE.Line(lineGeo, lineMat);
     line.type = THREE.Lines;
     scattlerPlot.add(line)

     material = new THREE.PointsMaterial({vertexColors: true, size: 2.5});
     pointGeometry = new THREE.Geometry();
     points = new THREE.Points(pointGeometry, material);
     scatterPlot.add(points);
     renderer.render(scene, camera);

   --- housing data: http://msbarry.github.io/threejs-tool-page/scatterplot.html
      scene = new THREE.Scene();
      camera = new THREE.PerspectiveCamera(45, window.innerWidth / window.innerHeight, 0.1, 1000);
      renderer = new THREE.WebGLRenderer();
      scatterPlot = new THREE.Object3D();
      scene.add(scatterPlot);

      lineGeo = new THREE.Geometry();
      lineGeo.vertices.push(<a bunch of THREE.Vector3 points describing the connected line corners>);
      lineMat = new THREE.LineBasicMaterial({color: 0x808080, lineWidth: 1});
      line = new THREE.Line(lineGeo, lineMat);
      line.type = THREE.Lines;
      scatterPlot.add(line);

      mat = new THREE.ParticleBasicMaterial({vertexColors:true, size: 1.5});
      pointGeo = new THREE.Geometry();
      pointGeo.vertices.push(<all the data points>)
      points = new THREE.ParticleSystem(pointGeo, mat);
      scatterPlot.add(points);

   --- mobile phone accelerometer data  (much whittled down, 2d text code removed)
      renderer = new THREE.WebGLRenderer({antialias: true });
      camera = new THREE.PerspectiveCamera(45, w / h, 1, 10000);
      scene = new THREE.Scene();
      scatterPlot = new THREE.Object3D();
      scene.add(scatterPlot);
      lineGeo = new THREE.Geometry();
      lineGeo.vertices.push(<box x,y pair-pairs defining lines to draw>)
      var lineMat = new THREE.LineBasicMaterial({color: 0x000000, lineWidth: 1});
      line = new THREE.Line(lineGeo, lineMat);
      line.type = THREE.Lines;
      scatterPlot.add(line);

      mat = new THREE.ParticleBasicMaterial({vertexColors: true, size: 10});
      pointGeo = new THREE.Geometry();
      pointGeo.vertices.push(new THREE.Vector3(x, y, z));   // big loop
      pointGeo.colors.push(new THREE.Color().setRGB(...))
      points = new THREE.ParticleSystem(pointGeo, mat);
      scatterPlot.add(points);
      renderer.render(scene, camera);



*-----------------------------------------------------------------------------------------------------------------------
* three.js scatterplot examples

   http://msbarry.github.io/threejs-tool-page/scatterplot.html
   http://bl.ocks.org/phil-pedruco/9852362   # has createTextCanvas demonstration function

*-----------------------------------------------------------------------------------------------------------------------
* require three.js module, for 3d scatterplot (3 feb 2017)

  cd ~/github/projects/examples/nb/mef2cMulti/three/
  open dev3.html
  dir js/
     7178 Feb  5 13:05 app3d.js
      292 Feb  5 12:39 main.js

   used in notebook:
     ~/github/projects/examples/nb/mef2cMulti/igvCyjsTabsThree.ipynb 52512 Feb  5 12:59

    needs CORS, and this line in the require config (note that port will need to be corrected)

              'app3d'     :   'http://localhost:9998/files/three/js/app3d'

*-----------------------------------------------------------------------------------------------------------------------
* cosmic, R, bigQuery, sheila (2 feb 2017)

  http://isb-cancer-genomics-cloud.readthedocs.io/en/latest/sections/workshop/Workshop_R_tut_v2.html
  use my_cloud_project <- "isb-cgc-cosmic"

*-----------------------------------------------------------------------------------------------------------------------
* upton sinclair salary

  It is difficult to get a man to understand something, when his salary depends on his not understanding it.

*-----------------------------------------------------------------------------------------------------------------------
* draft chia blurb for claudia, dean witter foundation (27 jan 2017)

Students from South Seattle's ethnically diverse, largely low-income
STEM Cleveland High School are learning the science which explains the
high asthma rates (double the Seattle average) and shortened life
spans (8 years less, on average) when compared to Seattle as a whole.

Software engineers at the ISB built an interactive web-based mapping
tool, http://chia.systemsbiology.net, accompanined by simple
regression plotting, using data from a small-scaled 2013 EPA study -
whose parameters were determined directly by the South Seattle
residents in community meetings organized by the non-profit Just
Health Action.  The webapp has been enthusiastically received and has
inspired a large Cleveland High School project this May and June, in
which strong AP stats, biology, enviromental science and humanities
teachers guide students in use of the webapp, culminating in visits to
regional middle schools, and a presentation to local elected city
government officials.

The middle school visits will combine age-appropriate field work in
which the middle school students will collect environmental data, and
neighborhood longevity statistics.  These data will become quickly
visible within the webapp, thereby enriching our community's portrain
of environmental health effects, and environmental injustice, and
further motivating the acquisition of data anlysis techniques and
public lobbying for remediation.   Other dimensions of data, and more participants - of all
ages - will help to refine and evolve this community data collection/data visualzation based
effort.  Sscientifically informed participatory democracy will improve the
lives of those who live in South Seattle, and provide a template for related projects
elsewhere in the city, the state, and our country.







*-----------------------------------------------------------------------------------------------------------------------
* rab10 ad alzheimers protective variant (26 jan 2017)

  print(load("~/s/data/priceLab/AD/tbl.gwas.level_1.RData"))
  chrom <- "chr2"
  start <- 25956250
  end <-   26166943

*-----------------------------------------------------------------------------------------------------------------------
* next up, thurs (26 jan 2017)

  cd ~/github/projects/examples/microservices/trenaGeneModel/
  develop and test server, tests in R and python.
  defer layout, just get the structure

   ~/github/projects/examples/microservices/trenaGeneModel/server.R
   main workhorse function: createGeneModel, parameterized on target.gene and footprint region
   using built in mtx expression data, and footprint and motifs/genes  database specified
   in the file itself (for now)

*-----------------------------------------------------------------------------------------------------------------------
* rcy tips: get json text for loading into cy.js

   gjson <- getJSON(rcy)
   out <- file("cellphoneModel.json", "w")
   writeChar(gjson, con=out, eos=NULL)
   close(out)


  validate and fix here:
      https://jsonformatter.curiousconcept.com

    # edit \"info\" to read just "info"  in a
    #   {"selector":"node[type = "info"]","style":{"shape":"roundrectangle",


  infile <- file("vgfModel.json")
  x <- fromJSON(readLines(infile, warn=FALSE))   # no 'incomplete final line' warning
  xx <- fromJSON(x)
  class(xx)  # [1] "list"

   cp vgfModel.json
*-----------------------------------------------------------------------------------------------------------------------
* jquery tips:  tabs({activate: function

    from ~/github/projects/examples/js/igvTabsProblem/index.html

    $("#tabs").tabs({
        activate: function(event,ui){
           var emptyIgv = $("#igvDiv").is(":empty");
           var indexOfActiveTab = $('#tabs').tabs("option", "active");
           var indexOfIgvTab = $("[href='#tab-igv']").parent().index()
           var igvOnTop = (indexOfIgvTab == indexOfActiveTab);
           console.log("empty? " + emptyIgv + "  active: " + indexOfActiveTab + "  igvTab: " + indexOfIgvTab);
            if(emptyIgv & igvOnTop){
              console.log("creating igv ---")
              browser = igv.createBrowser(igvDiv, options);
              }
           }});


*-----------------------------------------------------------------------------------------------------------------------
* jquery tips: raise tab

  --- preferred?
     $("[href='#tab-1']").trigger("click");
    //$("#masterTabsDiv").tabs("option", "active", 1)



    function raiseTab(tabIDString){
      var tabsWidget = $("#chinookTabs");

      if(tabsWidget.length > 0){
         var selectionString = '#chinookTabs a[href="#' + tabIDString + '"]';
         var tabIndex = $(selectionString).parent().JAVASCRIPT_INDEX ();
         if(tabIndex < 0) throw "Module.hub does not recognize tabIDString '" + tabIDString + "'";
         console.log("Module.hub:raiseTab for '" + tabIDString + "' (" + tabIndex + ") set to active'");
         setTimeout(function(){tabsWidget.tabs( "option", "active", tabIndex);}, 0);
         } // if tabs exist
      } // raiseTab


*-----------------------------------------------------------------------------------------------------------------------
* meeting with erik (25 jan 2017)

  blocks are atomic, assembled into useful block groups, which are assembled into tracts, which aim to be 2000 people
  colnames(tbl), eg b01001_001 total, male, under 5
    google b01001005 10-14 years sex by age
    https://www.google.com/url?sa=t&rct=j&q=&esrc=s&source=web&cd=&ved=0ahUKEwjy7Jy19d3RAhVG4WMKHWHfAiAQFggfMAA&url=https%3A%2F%2Fwww.socialexplorer.com%2Fdata%2FACS2014_5yr%2Fmetadata%2F%3Fds%3DACS14_5yr%26var%3DB01001005&usg=AFQjCNHel83lh87sAE4JELqG0AkTDI4dAA


  https://www.cdc.gov/asthma/most_recent_data.htm  <- very helpful!

  CAT table: community air tool, block group level data

  --- permanent air monitors

    15 or 16
    weller and i5
    available airgraphing.psclean.org


  --- temporary, fixed or handheld

*-----------------------------------------------------------------------------------------------------------------------
* zmq/rzmq quick proof of concept for TReNA microservice


   ~/github/projects/examples/rpc/zmq/request-reply/

   --- server.R
     library(rzmq)
     library(jsonlite)
     context = init.context()
     socket = init.socket(context,"ZMQ_REP")
     bind.socket(socket,"tcp://*:5556")
     while(TRUE) {
       printf("top of receive/send loop")
       request = receive.string(socket)
       printf("class of request: %s", class(request))
       response <- toupper(request)
       send.raw.string(socket, response)
       Sys.sleep(1)
       }


   --- client.R
     library(rzmq)
     library(jsonlite)
     context = init.context()
     socket = init.socket(context,"ZMQ_REQ")
     connect.socket(socket,"tcp://localhost:5556")
     i <- 0
     while (i < 5) {
        send.raw.string(socket, sprintf("hello from R: %d", i))
        s <- receive.string(socket)
        print(s)
        i <- i + 1
        }



   ---- client.py
     import zmq
     socketContext = zmq.Context()
     socket = socketContext.socket(zmq.REQ)
     socket.connect("tcp://localhost:%s" % '5556')
     for i in range(5):
        socket.send_string("hello from python: %d" % i)
        print(socket.recv_string())


*-----------------------------------------------------------------------------------------------------------------------
* igv.js tips

   -- current coords
    igv.browser.$searchInput.val()   # eg, "5:88,151,043-88,907,602"
    igv.browser.on('locuschange', function (referenceFrame, label) {console.log(label)})
*-----------------------------------------------------------------------------------------------------------------------
* add three.js demo tab to mef2cMultiDemo (23 jan 2017)

   follow successful three-only demo at ~/github/projects/examples/js/requirejs/tabs/three/

*-----------------------------------------------------------------------------------------------------------------------
* install latest samtools and htslib (21 jan 2016)

   from http://www.htslib.org/download/
   downloaded htslib-1.3.2
   cd ~/source
   bunzip2 htslib-1.3.2.tar.bz2
   cd htslib-1.3.2/
   make
   ~/source/htslib-1.3.2/tabix


   --- on whovian (10 mar 2017)
     ~/src/samtools-1.3.1/samtools

*-----------------------------------------------------------------------------------------------------------------------
* igv tabs bug demo, minimal (23 jan 2017)

  cd ~/github/projects/examples/js/igvTabsProblem/
  open index.html

  --- added this to the github issue

Here - if you have time for it - is a minimal single html file combining igv.js with jQuery tabs.
All of the javascript runs in the document ready function, so the page DOM is ostensibly complete.
The final three lines are currently:

    browser = igv.createBrowser(igvDiv, options);
    //$("#tabs").tabs();
    //setTimeout(function() {$("#tabs").tabs()}, 1000);

   In this code fragment, and in the attached index.html, two ways to call the tabs function are
   disabled, no tabs are used, and igv renders fine.  enable the first form of the tabs() call, and
   if the igvDiv is the front div, then igv renders fine.  If the igvDiv is the second div, then igv
   renders incompletely, reports a failure.  If the setTimeout line is enabled, and if the igvDiv is
   first or second (visible or hidden) then igv has the chance to render before the tabs function is
   called, and everything works fine. From this I conclude that igv is not happy rendering to a
   hidden div...  Because all of the javascript runs in the document ready function, and because of
   that quirky NaN that appears in case 3, for the terminal position of the locus - and maybe
   because of wishful thinking on my part - I think that perhaps this is aspect of igv which could
   maybe be remedied.

   ~/Desktop/stage/igvInJQueryTabs.zip


*-----------------------------------------------------------------------------------------------------------------------
* add all of dbsnp as vcf file to igv.js (22 jan 2016)

  cd ~/http/hg38/variants/

  not from dbsnp, but I think it is their data:

    ftp://ftp.ncbi.nih.gov/snp/organisms/human_9606/VCF/
       All_20161122.vcf.gz 	3,450,543 KB 	11/22/16 	9:33:00 PM
        All_20161122.vcf.gz.tbi  2419 KB 	11/22/16 	9:33:00 PM

*-----------------------------------------------------------------------------------------------------------------------
* add all of igap level 1 snps as track to mef2c igv demo (22 jan 2016)

  cd ~/s/data/priceLab/AD/
  print(load("tbl.gwas.level_1.RData"))  # "tbl.gwas"
dim(tbl.gwas); head(tbl.gwas)
[1] 438609      9
    CHR  oldPos      BP        SNP Effect_allele Non_Effect_allele    Beta     SE       P
71 chr1  978193 1042813  rs2710873             A                 G -0.0824 0.0389 0.03412
81 chr1  998395 1063015  rs7526076             A                 G -0.0512 0.0229 0.02543
84 chr1 1000156 1064776 rs11584349             C                 T -0.0536 0.0224 0.01687
85 chr1 1001177 1065797  rs4970401             G                 C -0.0530 0.0224 0.01812
86 chr1 1002387 1067007 rs74048003             G                 A  0.0609 0.0285 0.03236
88 chr1 1002932 1067552  rs4246502             C                 G -0.0505 0.0223 0.02352

  coi <- c("CHR", "BP", "BP", "SNP", "P")
  write.table(tbl.gwas[, coi], file="~/http/hg38/variants/igap.bed", row.names=FALSE, col.names=FALSE, quote=FALSE, sep="\t")
*-----------------------------------------------------------------------------------------------------------------------
* igv.js tips: create a non-indexed annotation track, hg38, to support the search box

  cd ~/http/hg38/
  createGeneSymbolBedFile.R
    library(RPostgreSQL)
    db.gtf <- dbConnect(PostgreSQL(), user= "trena", password="trena", dbname="gtf", host="whovian")
    query <- "select * from hg38human where moleculetype='gene' and gene_biotype='protein_coding'"
    tbl <- dbGetQuery(db.gtf, query);     # 19797 x 30
    coi <- c("chr", "start", "endpos", "gene_name")
    tbl.bed <- tbl[, coi]
    write.table(tbl.bed, file="geneSymbolSearch.bed", row.names=FALSE, col.names=FALSE, quote=FALSE, sep="\t")

    this works!

        {name: 'geneSymbols_hg38',
         url: 'http://localhost/data/hg38/geneSymbolSearch.bed',
         indexed: false,
         searchable: true,
         visibilityWindow: 1000000,
         displayMode: 'EXPANDED',
         color: "#448844"
         },


*-----------------------------------------------------------------------------------------------------------------------
* igv.js tips:  create a new gtf genome annotation file and index (21 jan 2016)

  cd ~/http/hg38/
  downloaded ftp://ftp.sanger.ac.uk/pub/gencode/Gencode_human/release_25/gencode.v25.annotation.gff3.gz
  gunzip gencode.v25.annotation.gff3.gz
  /Users/pshannon-isb/s/src/tabix/tabix-0.2.6/bgzip gencode.v25.annotation.gff3

  library(Rsamtools)
  38817086 Jan 21 16:09 gencode.v25.annotation.gtf.gz
  gunzip gencode.v25.annotation.gtf.gz
  from <- "gencode.v25.annotation.gtf"
  to <- tempfile()
  zipped <- bgzip(from, to)
  idx <- indexTabix(zipped, format="gff")
  tab <- TabixFile(zipped, idx)


*-----------------------------------------------------------------------------------------------------------------------
* igv.js tips: tracks

  --- inventory, finding tracks for various genomes
    cd ~/s/notes/igvTracks
    examine the xml at http://igv.broadinstitute.org/
    copy & pasted this into  ~/s/notes/igvTracks/allTracks.xml
    we want three files per genome.  using hg38 as the example

    annotations/hg38/cytoBandIdeo.txt
    data/hg38/gencode.v24.annotation.sorted.gtf.gz
    data/hg38/gencode.v24.annotation.sorted.gtf.gz.tbi


  ---- cytobandURL
    1st column is chromosome, must be free of "chr" leading string, ~1000 lines
    at broad, hg19:   cytobandURL: "http://igv.broadinstitute.org/genomes/seq/b37/b37_cytoband.txt"            [works]
    riptide apache:   cytobandURL: "http://localhost/data/annotations/hg38cytobandChrRemoved.txt"  862 lines   [works]
       1	0	2300000	p36.33	gneg
       1	2300000	5400000	p36.32	gpos25
       1	5400000	7200000	p36.31	gneg
       ...

  --- fastaURL  (ATCG only appear at zoom levels below 1000)
    at broad:       fastaURL: "http://igv.broadinstitute.org/genomes/seq/1kg_v37/human_g1k_v37_decoy.fasta"
    riptide apache: fastaURL: "http://localhost/data/genomes/human_g1k_v37_decoy.fasta"     [works] only 86 lines
       on load, browser shows 200 for human_g1k_v327_decoy.fasta.fai
       1	249250621	52	60	61
       2	243199373	253404903	60	61
       3	198022430	500657651	60	61
       ...

   --- the gene annotation bed file
                tracks: [
                  {name: "Genes",
                   //url: "http://igv.broadinstitute.org/annotations/hg19/genes/gencode.v18.collapsed.bed",
                   //index: "http://igv.broadinstitute.org/annotations/hg19/genes/gencode.v18.collapsed.bed.idx",
                    url:   "http://localhost/data/annotations/gencode.v18.collapsed.bed",
                    index: "http://localhost/data/annotations/gencode.v18.collapsed.bed.idx",
                206 status "partial content" reported in chrome network view

          Tabix is the first generic tool that indexes position sorted files in TAB-delimited
          formats such as GFF, BED, PSL, SAM and SQL export, and quickly retrieves features
          overlapping specified regions

    --- jim robinson added gtf and gff3 support in apr 2016
       {name: 'Gencode v24',
        url: 'https://s3.amazonaws.com/igv.broadinstitute.org/data/hg38/gencode.v24.annotation.sorted.gtf.gz',
        indexURL: 'https://s3.amazonaws.com/igv.broadinstitute.org/data/hg38/gencode.v24.annotation.sorted.gtf.gz.tbi',
        format: 'gtf',
        visibilityWindow: 10000000
        }

    ---  my locally hosted gtf file

    --- the fasta file
      got gzipped fasta file from
         ftp://ftp.sanger.ac.uk/pub/gencode/Gencode_human/release_25/GRCh38.p7.genome.fa.gz
         ~/source/samtools-1.3.1/samtools faidx GRCh38.p7.genome.fa
              3281353985 Jan 21 16:26 GRCh38.p7.genome.fa
              18020 Jan 21 17:22 GRCh38.p7.genome.fa.fai
          fastaURL: "http://localhost/data/hg38/GRCh38.p7.genome.fa"   [works]

       alas, including this breaks the cytoband




*-----------------------------------------------------------------------------------------------------------------------
* mef2c chr5:88,717,117-88,904,257
*-----------------------------------------------------------------------------------------------------------------------
* apache use directory in my filesystem

  as root, create symlink

   /Library/WebServer/Documents/data -> /Users/paul/http

<Directory "/Library/WebServer/Documents/data">
   Options Indexes FollowSymLinks
   Require all granted
</Directory>


*-----------------------------------------------------------------------------------------------------------------------
* apache cors

  --- enable mod_headers (enabled by default in /etc/apache2/httpd.conf
     LoadModule headers_module libexec/apache2/mod_headers.so

  --- check
      /usr/sbin/apachectl -M | grep header
        headers_module (shared)

  --- configure in .htaccess
    ~/http/

*-----------------------------------------------------------------------------------------------------------------------
* apache index directories

  need to enable mod_autoindex in /etc/apache2/httpd.conf
  check:
  /usr/sbin/apachectl -M | grep autoindex
      autoindex_module (shared)

  --- according to web search:
    <Directory /usr/local/apache2/htdocs/listme>
      Options +Indexes
    </Directory>
  --- my value
    DocumentRoot "/Library/WebServer/Documents"
    <Directory "/Library/WebServer/Documents">
        Options Indexes FollowSymLinks
        ....
    </Directory>

  in root of the directory for which you want directory listings, add .htacess
    Options Indexes



*-----------------------------------------------------------------------------------------------------------------------
* next up: igv & apache (20 jan 2017)

  https://github.com/igvteam/igv.js/wiki/Data-Server-Requirements
  /usr/sbin/apachectl now seems to work.  use 127.0.0.1 to avoid locahost.com
  directory listing, however, does not work
  want to ensure that does work before verifying byte ranges.
  test area is ~/github/projects/examples/js/igvBareBones

  as root, edit /etc/apache2/httpd.conf
  server root directory is /Library/WebServer/Documents
  don't know quite how the ~/Sites/ works - figure that out!

  goal: serve up index fasta and gtf files files locally

*-----------------------------------------------------------------------------------------------------------------------
* start apache on riptide, mac os

   sudo /usr/sbin/apachectl start
   browse to http://localhost
   displays /Library/WebServer/Documents/index.html.en  <html><body><h1>It works!</h1></body></html>



   cat /etc/apache2/users/paul.conf
   <Directory "/Users/paul/Sites/">
 	Options Indexes MultiViews
	Require all granted
   </Directory>



  To use range-byte requests, which are neccessary for many IGV file formats, we need a full-featured server.  Fortunately
  we have one on MacOS (apache).  The following steps will enable the development html to be run from url
  http://localhost/igv-web/dev/igv-dev.html.   This procedure was verified for MacOS 1.9.5.

  Verify that Apache is running by typing "localhost" in the web browser.  If you get an error start it up from
  a terminal like this

   sudo apachectl start

   The url http://localhost should now display a page.

   Create a symboloic link to the project directory from the Apache home directory.  Modify the paths below as appropriate

cd /Library/WebServer/Documents
sudo ln -s /Users/jrobinso/projects/igv-web igv-web

Now http://localhost/igv-web/dev/igv-dev.html should bring up the app.  Likewise http://localhost/igv-web/<test file>.html will
run the unit tests.



Part 2 -- Enabling PHP
----------------------
PhP is neccessary to use the gene search function, and probably more stuff in the future.  To enable it
edit /etc/apache2/httpd.conf  as root (e.g. sudo emacs /etc/apache2/httpd.conf)  and uncomment the line

#LoadModule php5_module libexec/apache2/libphp5.so

i.e. remove the # symbol.  Save and restart

sudo apachectl restart




*-----------------------------------------------------------------------------------------------------------------------
* igv tips: does the python http.server support byte range requests?  (20 jan 2017)  apache tips

   cd ~/github/projects/examples/js/igvBareBones
   wget --header="Range: bytes=20-40" -t 1 http://localhost:8005/Homo_sapiens.GRCh38.dna.chromosome.5.fa.gz
   returns the whole file

   wget --header="Range: bytes=20-40" -t 1 http://localhost/data/annotations/cytoBand.txt
   --2017-01-20 18:30:22--  http://localhost/data/annotations/cytoBand.txt
    Resolving localhost... ::1, 127.0.0.1
   Connecting to localhost|::1|:80... connected.
   HTTP request sent, awaiting response... 206 Partial Content
   Giving up.



*-----------------------------------------------------------------------------------------------------------------------
* igv tips: create chr5-only fa file and index for experimentation with tracks for the mef2c notebook

  cd ~/github/projects/examples/js/igvBareBones/
  curl -O http://ftp.ensembl.org/pub/release-77/fasta/homo_sapiens/dna/Homo_sapiens.GRCh38.dna.chromosome.5.fa.gz
  55M
  gunzip Homo_sapiens.GRCh38.dna.chromosome.5.fa.gz
  184M
   ~/source/samtools-1.3.1/samtools faidx Homo_sapiens.GRCh38.dna.chromosome.5.fa

   cat Homo_sapiens.GRCh38.dna.chromosome.5.fa.fai
    5	181538259	56	60	61
   gzip Homo_sapiens.GRCh38.dna.chromosome.5.fa
   mv Homo_sapiens.GRCh38.dna.chromosome.5.fa.fai Homo_sapiens.GRCh38.dna.chromosome.5.fa.gz.fai
   dir Homo_sapiens.GRCh38.dna.chromosome.5.fa.*
           21 Jan 20 17:14 Homo_sapiens.GRCh38.dna.chromosome.5.fa.gz.fai
     54479424 Jan 20 17:09 Homo_sapiens.GRCh38.dna.chromosome.5.fa.gz

  --- sample use, with liz blue's chr22 data
    cd   ~/s/work/priceLab/lizBlue/try1/
    curl -O http://ftp.ensembl.org/pub/release-77/fasta/homo_sapiens/dna/Homo_sapiens.GRCh38.dna.chromosome.22.fa.gz
    gunzip Homo_sapiens.GRCh38.dna.chromosome.22.fa.gz
    /Users/paul/source/samtools/samtools-1.3.1/samtools faidx Homo_sapiens.GRCh38.dna.chromosome.22.fa
    gzip Homo_sapiens.GRCh38.dna.chromosome.22.fa
    mv Homo_sapiens.GRCh38.dna.chromosome.22.fa.fai Homo_sapiens.GRCh38.dna.chromosome.22.fa.gz.fai

*-----------------------------------------------------------------------------------------------------------------------
* igv tips: learn how to make a local data server (20 jan 2017)

  --- tiny trial with igv desktop
     cd ~/http
     python -m http.server 8099
     file -> load from url
        http://localhost:8099//annotations/mef2c_igap_gwas_snps.bed

    server log shows:
      127.0.0.1 - - [20/Jan/2017 16:01:21] code 404, message File not found
      127.0.0.1 - - [20/Jan/2017 16:01:21] "HEAD /annotations/mef2c_igap_gwas_snps.bed.idx.gz HTTP/1.1" 404 -
      127.0.0.1 - - [20/Jan/2017 16:01:21] "GET /annotations/mef2c_igap_gwas_snps.bed HTTP/1.1" 200 -


*-----------------------------------------------------------------------------------------------------------------------
* igv tips: the cytoband file

   used in, i.e.,

           var igvOptions = {
               palette: ["#00A0B0", "#6A4A3C", "#CC333F", "#EB6841"],
               //locus: "7:55,085,725 - 55,276,031",
               locus: "5:88,339,746-89,319,611",
               reference: {id: "hg38"
                  //fastaURL: "http://igv.broadinstitute.org/genomes/seq/1kg_v37/human_g1k_v37_decoy.fasta",
                  //cytobandURL: "http://igv.broadinstitute.org/genomes/seq/b37/b37_cytoband.txt"
                  },
             tracks: [
               {name: "Genes hg38",
                format: "gtf",
                //url: "http://s3.amazonaws.com/igv.broadinstitute.org/annotations/hg38/genes/gencode.v24.annotation.sorted.gtf.gz",
                //indexURL: "http://s3.amazonaws.com/igv.broadinstitute.org/annotations/hg38/genes/gencode.v24.annotation.sorted.gtf.gz.tbi",
                url: "http://igv.broadinstitute.org/annotations/hg38/genes/gencode.v24.annotation.sorted.gtf.gz",
                indexURL: "http://igv.broadinstitute.org/annotations/hg38/genes/gencode.v24.annotation.sorted.gtf.gz.tbi",
                displayMode: "EXPANDED"
                 }
                ] // tracks
               }; // igvOptions
             return(igvOptions)
           }, // getIgvOptions


   --- format described here:
      http://software.broadinstitute.org/software/igv/cytoband

      The Cytoband file format is used to specify the cytobands for an
      imported genome. IGV uses this file to draw the chromosome
      ideograms for the genome.

      A cytoband file is a five-column tab-delimited text file. Each
      row of the file describes the position of a cytogenetic
      band. The columns in the file match the columns of the CytoBank
      table in the database underlying the UCSC Genome Browser
      (http://genome.ucsc.edu/):

   --- ucsc genome browser offers one here:

     http://hgdownload.cse.ucsc.edu/goldenpath/hg19/database/cytoBand.txt.gz

*-----------------------------------------------------------------------------------------------------------------------
* igv tips, hosted genomes

   https://software.broadinstitute.org/software/igv/Genomes

*-----------------------------------------------------------------------------------------------------------------------
* city light, uncancelled summit ave bill (19 jan 2017)

  account number 1-141829-378850
  2156910000
  2156910000

  spoke with helpful jeana, direct number 206.615.1172
  they have my request to cancel, will honor that, which will be complete by feb 8
  the history:

    31 aug: -177.99
    26 sep: -112.40
    18 nov: - 55.08
    17 jan: 162.23


  --- 13 feb 2017
    heard nothing
    emily picked up.
    told that "adjustments are 3 months behind, only november adjustments are being addressed right now"
    she corrected my inexact dates:  on 7 sep 2017, i requested service be terminated retroactive to 1 sep 20107

    supervisor, roger, very helpful.

  --- 16 feb 2017 (11am)
    no word from roger, confusing statement.
    left impassioned voice mail with roger after 10 minutes on hold.
   230: no word back from roger
        kelly enright: customer care director: 206-684-3111
        left long message
   2:40 Baggs, James L. (Jim)	206-684-3260
        left long message
*-----------------------------------------------------------------------------------------------------------------------
* douglass adams points at an igv.js tabs bug fix (8 feb 2016)


   cd ~/s/work/priceLab/cory/mef2cMulti/igvDemoFromDouglassTurner/
    dugla-tabs-bug-fix.ipynb   15122 Jan 24 11:22

           setTimeout(function(){
               console.log("about to call tabs()");
               $('#tabContainer').tabs({
                   activate: function (event, ui) {
                       var activeTab = $('#tabContainer').tabs("option", "active");
                       console.log('active tab is ' + activeTab);
                       if (1 === activeTab && $("#igvDiv").is(':empty')) {
//                            console.log('igv - create');
                          window.browser = igv.createBrowser($("#igvDiv"), igvOptions);
                       }
                   }

               });
//                window.browser = igv.createBrowser($("#igvDiv"), igvOptions);
               }, 0);




* the mef2c multiwidget notebook, demo & development (19 jan 2017)

  cd ~/s/work/priceLab/cory/mef2cMulti/
  cp ~/github/BDDS/trenadb/src/style.js .

  --- igv needs to render into a visible tab.  douglass turner provides working demo
    cd ~/s/work/priceLab/cory/mef2cMulti/igvDemoFromDouglassTurner
    jupyter notebook dugla-tabs.ipynb

  --- add cyjs


*-----------------------------------------------------------------------------------------------------------------------
* cory: how to intersect igap snps with footprints, build a gene model (19 jan 2017)

  get the latest BDDS from github: clone if you don’t have it, git pull origin if you do
  get and build the latest Private_Cory_Data:

    cd ~/github/Private_Cory_Data
    git pull origin
    R CMD INSTALL .

  cd ~/github/Private_Cory_Data/inst/demos/igapMef2cFootprintDemo

  execute createGeneModel.R, one line at a time.  a very local gene
  model is built and displayed, bed files are created (which I use in
  igv.js)


*-----------------------------------------------------------------------------------------------------------------------
*  vrk2/pou3f2 bipolar snp fimo summary table (19 jan 2016)

  vrk2 snp: chr2:57907323

  http://whovian:10005/notebooks/shared/VRK2-Pou3f2.ipynb

  updated notebook
    ~/github/notebooks/shared/VRK2-Pou3f2.ipynb
  added postprocessing directory
    ~/github/notebooks/shared/vrk2-publication-prep


*-----------------------------------------------------------------------------------------------------------------------
* igv.js tips:  load a track from a python notebook

  def createTrack(tblHits, trackName):
    tblHits.to_csv("%s.bed" % trackName, sep="\t", header=False, index=False)
    print("wrote %s.bed" % trackName)
    newTrack = Track(name=trackName,
                 format="bed",
                 indexed=False,
                 url="http://whovian:9999/files/%s.bed" % trackName,
                 display_mode='EXPANDED')
   return(newTrack)


   x = createTrack(tbl_piq.subset8, "piq.subset8")
   igv.load_track(x)

  from ~/github/notebooks/paul-shannon/demos/footprints/piqAndHINT-compared-chr21.ipynb


*-----------------------------------------------------------------------------------------------------------------------
* igv.js tips: load track programmitcally (18 jan 2016)

  ~/github/igv.js/examples/api.html
  igv.browser.loadTrack({
      format: 'bed',
      url: 'https://data.broadinstitute.org/igvdata/annotations/hg19/dbSnp/snp137.hg19.bed.gz',
      indexURL: 'https://data.broadinstitute.org/igvdata/annotations/hg19/dbSnp/snp137.hg19.bed.gz.tbi',
      visibilityWindow: 200000,
      label: 'dbSNP 137'})

*-----------------------------------------------------------------------------------------------------------------------
* nih biosketch (18 jan 2016)

   ~/Documents/Biosketch-P. Shannon_2017.01.17 (new format).docx
*-----------------------------------------------------------------------------------------------------------------------
* create gene regulatory model from footprints & and gene expression (17 jan 2017)

  this is a summary of work done for cory in (nov 2016)
  source("~/github/BDDS/trenadb/src/renderGeneModel.R") has a few things which need to be parameterized

    databases for the FootprintFinder
    asinh normalization removed, but need for it must be tested
    assay.matrix - must be from same system as the footprints

    one solution: fpf not created by the renderGeneModel script if it already exists.
    so before sourcing it, create the fpf:

      genome.db.uri    <- "postgres://whovian/hg38"                  # has gtf and motifsgenes tables
      footprint.db.uri <- "postgres://whovian/brain_hint"            # has hits and regions tables
      fpf <- FootprintFinder(genome.db.uri, footprint.db.uri, quiet=FALSE)

  --- run a quick demo
    create new directory, i.e., cd ~/s/work/priceLab/cory/mef2cMulti
    cp ~/github/BDDS/trenadb/src/style.js .
    source("~/github/BDDS/trenadb/src/renderGeneModel.R")
    demo()
      #    target.gene <- "TREM2"
      #    tbl <- createModel(target.gene, promoter.shoulder=100,
      #                       mtx.expression=mtx.rosmap,
      #                       absolute.lasso.beta.min=0.3,
      #                       randomForest.purity.min=6,
      #                       absolute.expression.correlation.min=0.3)



*-----------------------------------------------------------------------------------------------------------------------
* cory's notebook demo, mef2cMulti, gwas snps in igv (17 jan 2017)

*-----------------------------------------------------------------------------------------------------------------------
* cory's notebook demo, mef2cMulti (17 jan 2017)

  cd ~/s/work/priceLab/cory/mef2cMulti/
  cp ~/github/BDDS/trenadb/src/style.js .

  --- set the stage (may use expression matrix and footprint database other that what you need)

    source("~/github/BDDS/trenadb/src/renderGeneModel.R")
    runTests()   # in
    demo()       # same


  --- createGeneModel.R

    library(TReNA)
    genome.db.uri    <- "postgres://whovian/hg38"                  # has gtf and motifsgenes tables
    footprint.db.uri <- "postgres://whovian/brain_hint"            # has hits and regions tables
    fpf <- FootprintFinder(genome.db.uri, footprint.db.uri, quiet=FALSE)
    source("~/github/BDDS/trenadb/src/renderGeneModel.R")
    target.gene <- "MEF2C"
    stopifnot(is.matrix(mtx.rosmap))
    assay.matrix <- asinh(mtx.rosmap)

    tbl.fp <- getFootprintsForGene(fpf, "MEF2C", size.upstream=1000, size.downstream=1000)

    tbl <- createModel(target.gene, promoter.shoulder=900,
                       mtx.expression=assay.matrix,
                       absolute.lasso.beta.min=0.1,
                       randomForest.purity.min=3,
                       absolute.expression.correlation.min=0.2)

    rcy <- renderAsNetwork(tbl, target.gene)
    layoutByFootprintPosition(rcy)

   --- learn promoter region from igap gwas (and put igap gwas into a browser version of igv)

*-----------------------------------------------------------------------------------------------------------------------
* adult children of alcoholics (16 jan 2016)

  http://www.adultchildren.org/lit-Laundry_List
  the "other laundry list":
    3. We frighten people with our anger and threat of belittling criticism.

*-----------------------------------------------------------------------------------------------------------------------
* exploring a jupyter-multiwidget (16 jan 2016)

 cd ~/s/examples/js/requirejs/tabs/


*-----------------------------------------------------------------------------------------------------------------------
* cyjs minimal demo (27 jan 2017)

cy.json({elements:[
      {data: {id:'a'}},
      {data: {id: 'e1', source: 'a', target: 'a'}}
      ]})

   g <- graphNEL(nodes="a", edgemode="directed")
   g <- graph::addEdge("a", "a", g)
   tViz <- TrenaViz()
   httpAddGraph(tViz, g);



*-----------------------------------------------------------------------------------------------------------------------
* cyjs/require minimal demo (18 jan 2017)

  ~/s/examples/js/requirejs/singles/cyjs/
      index.html
      app.js

require.config({
    'paths': {
        'jquery'    :   'http://code.jquery.com/jquery-1.12.4.min',
        'cytoscape' :   'http://cytoscape.github.io/cytoscape.js/api/cytoscape.js-latest/cytoscape.min'

         }
   });

require(['jquery', 'cytoscape'], function ($, cytoscape) {
    var cyDiv;
    $(function(){
       console.log("--- entering onReady");
       cyDiv = $("#cyDiv");
       console.log("--- about to create window.cy");
       window.cy = cytoscape({container: $("#cyDiv"),
                              elements:{nodes:[{data:{id:'a'}}],
                                        edges:[{data:{source:'a', target:'a'}}]},
                              style: cytoscape.stylesheet()
                                        .selector('node').style({'background-color': '#d22',
                                                                 'label': 'data(id)',
                                                                 'text-valign': 'center',
                                                                 'text-halign': 'center',
                                                                 'border-width': 1})
                                         .selector('edge').style({'line-color': 'black',
                                                                  'target-arrow-shape': 'triangle',
                                                                  'target-arrow-color': 'black',
                                                                  'curve-style': 'bezier'})
                              }); // cytoscape()
       }); // onready function
    }); // require


*------------------------------------------------------------------------------------------------------------------------
* folk metaphysics

  http://takimag.com/article/deconstructing_folk_metaphysics/print#axzz4VkrqbUVL

*-----------------------------------------------------------------------------------------------------------------------
* nef2c multiwidget prototype for cory (13 jan 2016)

  cd ~/s/examples/js/requirejs/tabs/mef2c/
  has igv, cytoscape and (empty) sigda tabs
  resize works okay.  need to track, then restore, cyjs view when raising the tab

*-----------------------------------------------------------------------------------------------------------------------
* javascript variables, reference vs value

  x = 3
  y = x   # The = operator creates a new reference to the same data.
  (seems now to be only true of objects.  ?)

  --- using jquery
  p0 = $.extend({}, cy.pan())

*-----------------------------------------------------------------------------------------------------------------------
* sat prep, sat testing, sarita (13 jan 2017)

  --- uw women's cetner stat prep, february

    Dates: February 16, 23, and March 2, Time: 5:30-8:30 PM
   - See more at: http://depts.washington.edu/womenctr/programs/lifelonglearning/#sthash.gHH8tcCI.dpuf

   --- the tests

     http://blog.prepscholar.com/sat-test-dates-2017-2018

test         reg           late reg      scores

Mar 11, 2017 Feb 10, 2017 Feb 28, 2017  Apr 13, 2017
May 6, 2017 Apr 7, 2017 Apr 25, 2017 Jun 8, 2017
Jun 3, 2017 May 9, 2017 May 24, 2017 Jul 12, 2017



Aug 26, 2017 Jul 28, 2017 Aug 11, 2017 Sept 14, 2017
Oct 7, 2017 Sep 8, 2017 Sep 22, 2017 Oct 27, 2017
Nov 4, 2017 Oct 6, 2017 Oct 20, 2017 Nov 23, 2017
Dec 2, 2017 Nov 3, 2017 Nov 17, 2017 Dec 21, 2017
Mar 10, 2018 Feb 9, 2018 Feb 23, 2018 Mar 29, 2017
May 5, 2018 Apr 6, 2018 Apr 20, 2018 May 24, 2018
Jun 2, 2018 May 4, 2018 May 18, 2018 Jun 21, 2018

*-----------------------------------------------------------------------------------------------------------------------
* Stanford research shows Aboriginal hunting practice increases animal populations

   The way that Aboriginal people in Australia go about hunting
   monitor lizards for food, based on "dreaming," leads to many more
   of the lizards, rather than fewer.

   http://news.stanford.edu/news/2013/october/fire-aborigines-wildlife-102913.html


   Niche construction and Dreaming logic: aboriginal patch mosaic
   burning and varanid lizards (Varanus gouldii) in Australia
   http://rspb.royalsocietypublishing.org/content/280/1772/20132297

   Rebecca Bliege Bird, Nyalangka Tayor, Brian F. Codding, Douglas W. Bird
   Published 23 October 2013.DOI: 10.1098/rspb.2013.2297

   Abstract: Anthropogenic fire is a form of ecosystem engineering
   that creates greater landscape patchiness at small spatial scales:
   such rescaling of patch diversity through mosaic burning has been
   argued to be a form of niche construction, the loss of which may
   have precipitated the decline and extinction of many endemic
   species in the Western Desert of Australia. We find evidence to
   support this hypothesis relative to one keystone species, the sand
   monitor lizard (Varanus gouldii). Paradoxically, V. gouldii
   populations are higher where Aboriginal hunting is most
   intense. This effect is driven by an increase in V. gouldii
   densities near successional edges, which is higher in landscapes
   that experience extensive human burning. Over time, the positive
   effects of patch mosaic burning while hunting overwhelm the
   negative effects of predation in recently burned areas to produce
   overall positive impacts on lizard populations. These results offer
   critical insights into the maintenance of animal communities in the
   desert, supporting the hypothesis that the current high rate of
   endemic species decline among small animals may be linked to the
   interaction between invasive species and mid-century removal of
   Aboriginal niche construction through hunting and patch mosaic
   burning.

*-----------------------------------------------------------------------------------------------------------------------
* suzanne simard
  the science, art and meaning of forest wisdom

     https://www.youtube.com/watch?v=pLU9EPo1iwQ

  part of 3.8 Billion Years of Wisdom: Exploring the Genius of Nature
   http://www.btci.org/consciousness/archive/2014/videos/default.html

*-----------------------------------------------------------------------------------------------------------------------
* acs (american community survey block group data) (15 jan 2016)

  cd ~/s/work/cleveland/asthmaDetails/acs
  curl -O "http://www2.census.gov/acs2010_1yr/summaryfile/2010_ACSSF_All_In_1_Giant_File(Experienced-Users-Only)/All_Geographies.zip"
  unzip All_Geographies.zip

  wildcard *20101wa0013*   # 144 lines each

  -rw-rw-r--  1 paul  staff  112934 Sep  7  2011 e20101wa0013000.txt
ACSSF,2010e1,wa,000,0013,0000001,6744496,3358423,225961,221191,224470,139821,96171,52104,46130,141920,245636,231637,226522,235405,242609,246028,222655,79657,110100,57623,74373,87878,62732,45839,41961,3386073,212248,216031,211636,132225,89990,52614,44269,132058,234007,224763,225638,223530,246199,249775,231489,85822,113807,59913,79322,99259,77471,65246,78761,5308097,2639964,156738,158235,160650,103204,70278,175998,182336,173960,355209,409755,358425,197516,98716,38944,2668133,145323,155787,150893,97058,67278,170161,174300,170021,345249,409292,371539,210609,127520,73103,239112,129053,10089,10234,8187,5247,4387,12660,10148,11016,20220,18462,11407,4454,2424,118,110059,9796,8467,9152,4697,3312,9498,8041,8572,14934,14507,11412,4358,2387,926,99736,50208,4458,3872,4598,2054,1481,4244,4388,3690,7211,5232,5673,2141,1035,131,49528,4017,2822,4145,2465,1479,4498,4624,3046,6784,7125,4780,2118,1181,444,485029,222718,14773,14164,14342,9686,7327,17337,20576,17953,36158,30574,22259,11472,4147,1950,262311,14872,15323,14372,8874,6016,16934,23234,22515,45034,37978,30480,15272,8556,2851,5308097,2639964,578827,1725961,335176,2668133,549061,1707840,411232,239112,129053,33757,88300,6996,110059,32112,70276,7671,99736,50208,14982,31919,3307,49528,13449,32336,3743,485029,222718,52965,152184,17569,262311,53441,182191,26679
ACSSF,2010e1,wa,000,0013,0000002,5394703,2672522,183599,176589,172532,108282,79056,43782,40228,123129,210630,194422,184972,191685,190669,191601,168455,58969,81582,41583,51985,62653,46695,35154,34270,2722181,172196,170375,167620,101142,76098,46170,38597,115843,203545,189546,182827,180617,193998,191658,175604,66496,84715,45778,58607,75391,62335,54877,68146,4127183,2041404,121929,121885,119366,76115,55974,149993,154707,143174,283648,312416,260736,136619,73343,31499,2085779,113577,118696,114037,70820,55808,146874,149166,139762,270599,310482,274832,155227,103192,62707,227071,122060,9884,9839,7676,4969,4322,11890,9669,10117,18616,17396,11008,4319,2269,86,105011,9389,8275,8133,4201,3013,9114,7906,8385,14601,13902,10768,4142,2305,877,64418,32434,2611,2267,2968,1510,959,2575,2724,2466,5060,3823,3476,1196,710,89,31984,2216,1468,2856,1832,846,3284,3448,2054,4503,3975,2826,1364,904,408,455407,210338,14246,13198,12896,9112,6862,16865,19983,16912,33675,28427,21597,10920,3844,1801,245069,13448,13756,13071,8227,5995,16537,22110,21173,41804,35089,28577,14318,8132,2832,4127183,2041404,439295,1360648,241461,2085779,417130,1347523,321126,227071,122060,32368,83018,6674,105011,29998,67689,7324,64418,32434,9356,21083,1995,31984,8372,20936,2676,455407,210338,49452,144321,16565,245069,48502,171285,25282
ACSSF,2010e1,wa,000,0013,0000003,1349793,685901,42362,44602,51938,31539,17115,8322,5902,18791,35006,37215,41550,43720,51940,54427,54200,20688,28518,16040,22388,25225,16037,10685,7691,663892,40052,45656,44016,31083,13892,6444,5672,16215,30462,35217,42811,42913,52201,58117,55885,19326,29092,14135,20715,23868,15136,10369,10615,1180914,598560,34809,36350,41284,27089,14304,26005,27629,30786,71561,97339,97689,60897,25373,7445,582354,31746,37091,36856,26238,11470,23287,25134,30259,74650,98810,96707,55382,24328,10396,12041,6993,205,395,511,278,65,770,479,899,1604,1066,399,135,155,32,5048,407,192,1019,496,299,384,135,187,333,605,644,216,82,49,35318,17774,1847,1605,1630,544,522,1669,1664,1224,2151,1409,2197,945,325,42,17544,1801,1354,1289,633,633,1214,1176,992,2281,3150,1954,754,277,36,29622,12380,527,966,1446,574,465,472,593,1041,2483,2147,662,552,303,149,17242,1424,1567,1301,647,21,397,1124,1342,3230,2889,1903,954,424,19,1180914,598560,139532,365313,93715,582354,131931,360317,90106,12041,6993,1389,5282,322,5048,2114,2587,347,35318,17774,5626,10836,1312,17544,5077,11400,1067,29622,12380,3513,7863,1004,17242,4939,10906,1397


  -rw-rw-r--  1 paul  staff  100000 Sep  7  2011 m20101wa0013000.txt
ACSSF,2010m1,wa,000,0013,0000001,0,3276,1964,6141,6551,1725,2753,3936,3195,5155,2480,2359,7627,7426,2097,2049,5611,3917,4426,2835,3156,3115,2900,2737,2512,3276,2110,5822,5509,1987,2791,4375,3299,4277,2242,2194,5344,4909,2008,1705,4941,4010,3930,2775,3252,2864,3928,3515,3862,14719,7857,2533,5293,4863,1349,2048,2566,2442,1743,2640,1839,1278,683,2362,2337,8405,2258,5276,4951,1433,2388,3150,2173,1928,1825,1962,1208,681,3913,3795,6439,3947,1188,1610,1328,873,924,2349,1106,1201,1530,1023,529,550,443,147,3939,1135,1388,1718,899,720,1261,801,972,1217,1031,1065,485,420,360,5296,3482,930,1118,739,733,686,973,918,897,1202,808,857,660,455,134,3359,901,686,936,627,589,1240,1205,822,1341,1051,942,493,523,249,6968,4536,1613,1709,1886,1023,811,1264,1754,1458,1436,1206,783,657,735,664,3951,1449,1432,1413,761,632,1562,1219,1182,1593,1150,1086,817,928,789,14719,7857,4136,5175,701,8405,4676,4823,1051,6439,3947,2666,2467,608,3939,2311,2547,657,5296,3482,1870,2575,751,3359,1292,2666,703,6968,4536,2748,2947,738,3951,2300,2770,926
ACSSF,2010m1,wa,000,0013,0000002,23437,13359,3423,5526,6286,2759,3667,3664,3192,5419,3954,3015,6454,6916,3166,3370,5402,3627,4132,2797,2853,3037,2545,2415,2387,12844,3461,5366,5249,3282,2705,4042,3543,4027,3294,2749,4952,4784,3241,3242,4986,3404,3221,2588,3239,2854,3692,3072,3640,25975,14228,3507,4644,5033,2765,2574,3212,3206,2539,4196,4482,3385,2794,2289,2189,14015,3059,4420,4493,2853,2435,3599,2928,2572,3761,3807,3430,2803,3642,3610,6642,4033,1233,1556,1317,848,886,2370,1071,1197,1428,1074,578,544,426,135,4094,1104,1405,1564,879,714,1327,776,999,1150,1083,1009,444,402,343,4843,3255,844,1032,674,648,648,766,1005,771,1086,733,811,529,388,112,3081,759,499,683,613,474,1197,1034,756,1127,904,711,450,459,259,9357,5469,1635,1656,1850,955,851,1260,1735,1452,1531,1328,786,657,707,624,5157,1491,1593,1461,792,636,1530,1273,1434,1698,1334,1037,797,849,790,25975,14228,7299,9679,3011,14015,6613,9165,3553,6642,4033,2718,2399,655,4094,2300,2699,587,4843,3255,1606,2474,634,3081,1182,2669,659,9357,5469,2991,3562,778,5157,2583,3478,946
ACSSF,2010m1,wa,000,0013,0000003,23437,13658,2887,3662,4008,2870,2206,1573,1219,2519,3249,2422,3672,3222,2729,3114,2761,1915,2076,1648,2064,1999,1499,1320,1046,12392,2880,3592,3052,2779,1789,1340,1507,2052,2701,2431,2944,2912,2960,2937,2565,1981,2133,1620,1852,1877,1661,1409,1467,20531,11492,2688,3192,3353,2487,1967,2840,2548,2158,3383,3850,2966,2702,1871,1042,11454,2603,2957,2645,2602,1488,2713,2464,2147,3370,3242,3315,2825,1717,1432,2393,1429,211,303,371,224,78,458,305,395,864,493,348,178,170,52,1520,244,270,678,302,299,391,142,245,233,436,438,198,105,82,3893,2262,631,605,455,290,319,560,547,514,643,482,510,422,200,67,2138,601,514,623,263,339,592,692,471,626,652,570,301,228,56,4604,2413,325,435,586,402,517,326,407,625,878,746,379,288,198,183,2780,671,607,563,359,37,333,647,659,880,818,822,354,328,37,20531,11492,6109,8071,2957,11454,6001,7601,3612,2393,1429,582,1248,242,1520,911,875,279,3893,2262,1178,1311,448,2138,1041,1420,372,4604,2413,1035,1706,350,2780,1428,1735,515

  "the estimate file for Maryland (e20131md0001000.txt)"

  excel templates, from http://www.census.gov/programs-surveys/acs/data/summary-file.html
  the excel template may reveal column metadata:

     http://www2.census.gov/programs-surveys/acs/summary_file/2015/documentation/tech_docs/ACS_SF_Excel_Import_Tool.pdf

   cd ~/s/work/cleveland/asthmaDetails/acs/templates

*-----------------------------------------------------------------------------------------------------------------------
* extrapolating asthma incidence from hospitalization rates (2014 paper)

   https://cste.confex.com/cste/2014/webprogram/Paper3717.html

*-----------------------------------------------------------------------------------------------------------------------
* asthma rates, CATtable, erik (16 jan 2016)

   cd ~/s/work/cleveland/asthmaDetails/
   tbl <- read.table("catTable.tsv", header=TRUE, as.is=TRUE, sep="\t")
   range(subset(tbl, county=="King County")$Asthma.Risk.per.million.per.year)  # [1]   83 2156

   --- a long tail:
     fivenum(subset(tbl, county=="King County")$Asthma.Risk.per.million.per.year)  # [1]   83.0  361.0  437.0  574.5 2156.0
    as.data.frame(t(subset(tbl, county=="King County" & Asthma.Risk.per.million.per.year > 2000)))
                                                                1301         1302
                                                 south of pioneer sq          slu
    GEOID                                               530330093002 530330093001
    INTPTLAT                                                47.58927     47.59066
    INTPTLON                                               -122.3359    -122.3214
    county                                               King County  King County
    Population                                                   663          710
    Percent.less.than.18.yo                                      3.0         12.7
    Rank.of.less.than.18.yo                                        0            0
    Percent.greater.than.64.yo                                  13.7         12.4
    Rank.of.greater.than.64.yo                                     2            2
    Percent.no.high.school.diploma                              14.0          9.1
    Rank.no.high.school.diploma                                    3            2
    Percent.single.female.head.of.household                        0            0
    Rank.female.head.of.household                                  0            0
    Percent.minority                                            37.3         72.1
    Minority.rank                                                  2            3
    Median.income                                             215809        42750
    Income.rank                                                    0            3
    Percent.English.not..well.                                   0.0         14.4
    Language.rank                                                  0            3
    Percent.use.wood.as.primary.source.of.heat                  <NA>         <NA>
    Wood.rank                                                      0            0
    Count.of.registered.sources.in.block.group.boundary            0            5
    Rank.count.of.registered.air.pollution.sources                 0            3
    Distance.to.major.sources..unitless.                       0.007        0.009
    Rank.distance.to.major.sources                                 3            3
    Distance.to.traffic.volume..unitless.                      11000       147000
    Rank.distance.to.traffic.volume                                0            3
    Cardiac.Hospitalization.Risk.per.million.per.year          29617        25198
    Rank.Cardiac                                                   3            3
    COPD.Risk.per.million.per.year                              1756         1452
    Rank.COPD                                                      3            3
    Asthma.Risk.per.million.per.year                            2156         2020
    Rank.Asthma                                                    3            3
    Sum.of.ranks                                                  19           31
    Population.weighted.sum.of.ranks                           12597        22010


*-----------------------------------------------------------------------------------------------------------------------
* R access to ACS data (18 jan 2016): Median Age By Sex for all census block groups in Seattle

  ~/s/work/cleveland/asthmaDetails/acs.R

    library(acs)
    data(fips.state)
    king.county <- geo.make(state="WA", county=33)
    subset(fips.state, STUSAB=="WA")
      #     STATE STUSAB STATE_NAME STATENS
      # 48    53     WA Washington 1779804
    acs.lookup(endyear=2010, span=5, table.number="B01001")
    tbl.age <- results(acs.lookup(endyear=2010, keyword="age", case.sensitive=FALSE))
    dim(tbl.age)   # 1283 5
    length(unique(tbl.age$table.name))  #  123
      #  [10] "Median Age by Sex"
    dim(subset(tbl.age, table.name=="Median Age by Sex")) # 3 4
    subset(tbl.age, table.name=="Median Age by Sex")
    #    variable.code table.number        table.name        variable.name
    # 28    B01002_001       B01002 Median Age by Sex Median age -- Total:
    # 29    B01002_002       B01002 Median Age by Sex   Median age -- Male
    # 30    B01002_003       B01002 Median Age by Sex Median age -- Female

    x <- acs.fetch(geo=king.county, table.name="Median Age by Sex", endyear=2011, key="")
    x@estimate
    #                         B01002_001 B01002_002 B01002_003 B23013_001 B23013_002 B23013_003
    # King County, Washington         37       36.2       37.9       39.6       39.5       39.6
    chs.bgid <- 530330104021


    x <- acs.fetch(geography=king.county, table.number="B01002", endyear=2010, key="")
    x@estimate
    #                         B01002_001 B01002_002 B01002_003
    # King County, Washington       36.9         36       37.7
    kingCoBlockGroups.geo <- geo.make(state="WA", county="King County", tract=10402, block.group="*", check=TRUE, key="")
    tbl <- acs.fetch(geo=kingCoBlockGroups.geo, table.number="B01001", endyear=2010, key="")
    dim(estimate(tbl)) # [1]  4 49
    colnames(estimate(tbl))
    #  [1] "B01001_001" "B01001_002" "B01001_003" "B01001_004" "B01001_005"
    #  [6] "B01001_006" "B01001_007" "B01001_008" "B01001_009" "B01001_010"
    # [11] "B01001_011" "B01001_012" "B01001_013" "B01001_014" "B01001_015"
    # [16] "B01001_016" "B01001_017" "B01001_018" "B01001_019" "B01001_020"
    # [21] "B01001_021" "B01001_022" "B01001_023" "B01001_024" "B01001_025"
    # [26] "B01001_026" "B01001_027" "B01001_028" "B01001_029" "B01001_030"
    # [31] "B01001_031" "B01001_032" "B01001_033" "B01001_034" "B01001_035"
    # [36] "B01001_036" "B01001_037" "B01001_038" "B01001_039" "B01001_040"
    # [41] "B01001_041" "B01001_042" "B01001_043" "B01001_044" "B01001_045"
    # [46] "B01001_046" "B01001_047" "B01001_048" "B01001_049"


    kingCoAllBlockGroups.geo <- geo.make(state="WA", county="King County", tract="*", block.group="*", check=TRUE, key="")
    tbl <- acs.fetch(geo=kingCoAllBlockGroups.geo, table.number="B01001", endyear=2010, key="")
    dim(estimate(tbl)) # [1]  1422 49



*-----------------------------------------------------------------------------------------------------------------------
* R access to ACS block data? (16 jan 2016)

  http://ejanalysis.github.io/ACSdownload/

   The ACSdownload package for R has functions helping to download and
   parse raw data files from the United States Census Bureau dataset
   called the American Community Survey (ACS) 5-year summary file. In
   particular, this package allows you to obtain all of the block
   group and tract-level data for any or all US States/DC/PR, rather
   than one State or one County at a time, for specified variables in
   specified tables.

   In contrast, other tools such as the acs package
   or the American Fact Finder, tend to provide more limited subsets
   such as one US County at a time, when working with block group or
   tract resolution tables.

   --- fips code
      Federal Information Processing Standards Code for King County, WA: 53033.

   --- acs
    https://cran.r-project.org/web/packages/acs/index.html
    https://www.r-bloggers.com/4-tips-to-learn-more-about-acs-data/
    http://dusp.mit.edu/sites/dusp.mit.edu/files/attachments/publications/glenn_acs_users_conf_paper_20150403_0.pdf
    http://eglenn.scripts.mit.edu/citystate/wp-content/uploads/2013/06/wpid-working_with_acs_R3.pdf

    library(acs)
    king.county <- geo.make(state="WA", county=33)
    x.b01003 <- acs.fetch(geography=king.county, table.number="B01003", endyear=2010, key="")

    x <- acs.fetch(geo=king.county, table.name="People Reporting Ancestry", endyear=2011, col.names="pretty", key="")
    head(t(x@estimate))
                                        King County, Washington
    People Reporting Ancestry: Total:                   1908379
    People Reporting Ancestry: Afghan                       499
    People Reporting Ancestry: Albanian                     552
    People Reporting Ancestry: Alsatian                     106
    People Reporting Ancestry: American                   59375
    People Reporting Ancestry: Arab:                       8346


    x <- acs.fetch(geo=king.county, table.name="People Reporting Ancestry", endyear=2011, key="")
    head(t(x@estimate))
               King County, Washington
    B04006_001                 1908379
    B04006_002                     499
    B04006_003                     552
    B04006_004                     106
    B04006_005                   59375
    B04006_006                    8346


     # table names?

       Strings passed to the table.name argument provide search terms
       to match in the table names of the ACS: for example, “Sex” or
       “Age” or “Age by Sex”. Note: these include words that describe
       types of categories, not the categories themselves

     # but neither of these worked
        x <- acs.fetch(geo=king.county, table.name="asthma", endyear=2011, case.sensitive=FALSE, key="")
        x <- acs.fetch(geo=king.county, keyword = "asthma", endyear=2011, case.sensitive=FALSE, key="")



    acs.lookup(keyword="Urdu", endyear=2015) #   endyear= 2015  ; span= 5
       variable.code table.number                                                                    table.name                             variable.name
     1    B16001_057       B16001 Language Spoken at Home by Ability to Speak English for the Population 5+ Yrs                                     Urdu:
     2    B16001_058       B16001 Language Spoken at Home by Ability to Speak English for the Population 5+ Yrs           Urdu: Speak English 'very well'
     3    B16001_059       B16001 Language Spoken at Home by Ability to Speak English for the Population 5+ Yrs Urdu: Speak English less than 'very well'



  data(fips.state)
  subset(fips.state, STUSAB=="WA")
     STATE STUSAB STATE_NAME STATENS
  48    53     WA Washington 1779804
  args(acs.lookup)
  acs.lookup(endyear=2010, span=5, table.number="B01001")
     An object of class "acs.lookup"
     endyear= 2010  ; span= 5

     results:
        variable.code table.number table.name             variable.name
     1     B01001_001       B01001 Sex by Age                    Total:
     2     B01001_002       B01001 Sex by Age                     Male:
     3     B01001_003       B01001 Sex by Age       Male: Under 5 years
     4     B01001_004       B01001 Sex by Age        Male: 5 to 9 years
     5     B01001_005       B01001 Sex by Age      Male: 10 to 14 years
     6     B01001_006       B01001 Sex by Age      Male: 15 to 17 years
     7     B01001_007       B01001 Sex by Age     Male: 18 and 19 years



*-----------------------------------------------------------------------------------------------------------------------
* census block, block group, tract (18 jan 2017)

  https://en.wikipedia.org/wiki/Census_block

  A census block is the smallest geographic unit used by the United
  States Census Bureau for tabulation of 100-percent data (data
  collected from all houses, rather than a sample of houses). The
  number of blocks in the United States, including Puerto Rico, for
  the 2010 Census was 11,155,486.[1]

  Census blocks are grouped into block groups, which are grouped into
  census tracts. There are on average about 39 blocks per block
  group. Blocks typically have a four-digit number; the first number
  indicates which block group the block is in. For example, census
  block 3019 would be in block group 3.

  Blocks are typically bounded by streets, roads or creeks. In cities,
  a census block may correspond to a city block, but in rural areas
  where there are fewer roads, blocks may be limited by other
  features. The population of a census block varies greatly. As of the
  2010 census, there were 4,871,270 blocks with a reported population
  of zero,[2] while a block that is entirely occupied by an apartment
  complex might have several hundred inhabitants.

  Census blocks covering the entire country were introduced with the
  1990 census. Before that, back to the 1940 census, only selected
  areas were divided into blocks.

   --- cleveland high school for example

   http://www.seattle.gov/dpd/cityplanning/populationdemographics/geographicfilesmaps/2010census/default.htm

    census tract map: http://www.seattle.gov/dpd/cs/groups/pan/@pan/documents/web_informational/dpdd017051.pdf
       tract # 104.02?
    block map index: block # 52 seems to straddle I5 at the write latitude
    chs, at lucelle and 15th: census block 1005, voting district 331600, census tract 104.02
    http://www.seattle.gov/dpd/cs/groups/pan/@pan/documents/web_informational/dpdd017071.zip

*------------------------------------------------------------------------------------------------------------------------
* try to align asthma CAT data and PSRC census block group ids, 2nd try (15 jan 2017)

   cd ~/s/work/cleveland/asthmaDetails/shapefiles
   curl -O http://www.psrc.org/assets/5720/king10bg.zip
   ogr2ogr -f GeoJSON -t_srs crs:84 king10bg.geojson king10bg.shp
   cp king10bg.geojson ~/github/chia/geography/

   cleveland high school appears to have bgid 530330104021
   tbl <- read.table("catTable.tsv", header=TRUE, as.is=TRUE, sep="\t")
   chs.bgid <- 530330104021
   chs.bgid %in% tbl$GEOID  # [1] TRUE   yay!

   now wish to coordinate that map, and catTable.tsv, with  American Community Survey (ACS) Block Group Data
   10481412 Jan 15 12:07 SummaryFileDataRetrievalTool.zip

   --- user's guide

     This tool allows users to load tables from the American Community
     Survey Summary File into an Excel spreadsheet, then sort or
     manipulate it as needed. This tool works best for users who need
     data for a few tables. Users who need data for more than 20
     tables are encouraged to access the ACS Summary File directly on
     the FTP site at http://www2.census.gov/.  Please note users must
     have MS Excel 2007 or newer to run this tool. It is recommended
     that you close all other applications when using this tool.

     This software was developed and tested for use in PC environments
     with mid to high-end PC hardware, up to date software, and a mid
     to high speed internet connection such as those found in
     governments, educational institutions, and businesses. Ensure
     that your computing environment conforms to the minimum
     requirementslisted in this document before launching this
     application.

     The American Community Survey (ACS) Summary File Retrieval Tool
     will be discontinued starting with the 2014 ACS Data Releases in
     fall 2015. Due to the addition of block groups in American
     FactFinder (AFF) starting with the 2009-2013 ACS 5-year data
     release and similar functionality of the AFF Download Center, the
     Census Bureau no longer believes that it is necessary to maintain
     the retrieval tool. In addition, the 2013 ACS 1-year, 3-year, and
     5-year estimates will be removed from the ACS Summary File
     Retrieval Tool due to technical and software compatibility
     issues. You can still access older years of data using the ACS
     Summary File Retrieval Tool and view detailed instructions on
     using the AFF Download Center by visiting the ACS Summary File
     page at

        http://www.census.gov/acs/www/data_documentation/summary_file/.

*-----------------------------------------------------------------------------------------------------------------------
* my email to erik about non-matching tract numbers, his reply (13 jan 2017)

    cd ~/s/work/cleveland/asthmaDetails


   I have made some progress, creating geojson from shape files (from
   http://www.psrc.org/data/gis/shapefiles) and putting them on
   github:

      https://github.com/paul-shannon/chia/tree/master/geography/


  I have run into a familiar problem, and you can probably set me
  straight.  I seem to be confusing/conflating census tract and block
  groups.  So I cannot quite get the identifiers to sync up.

  By inspection, in the king10ct.geojson, Cleveland High School’s
  census tract has GEOID10 53033010402.  From your CATtable, all of the
  GEOIDs are an order of magnitude larger, with one extra digit,
   i.e. 530330104023

  If I track down the census block group shape/geojson file for King
  County, will that solve my problem?  Any idea where I can find that,
  from the same year as the CATtable file?

  --- erik's reply

    Yes, the block group file would work (the tract wouldn’t).

    Census tracts are larger than census block groups (perhaps 4 block
    groups in 1 tract).  They fit entirely within the Tract.  I don’t
    think you need to work on a tract level up front.  We can always
    aggregate later as another option if needed.

    Like you are referencing, the other variable is that (some of) the
    shapes are physically different between the different years (2000
    vs 2010 shapes).  I think for simplicity, perhaps you can just try
    the 2010 first and use recent census data to come up with the
    age-adjustment.  Obviously not perfect since the health data was
    older.

    My plan if we wanted to do it “perfectly” was to go back to the
    old census shapes (2000), and use the original health data I
    compiled at ZIP code level (attached), and re-break it out into
    the respective shapes, but the way I did it takes a few more
    steps.  I would actually assign the 2000 census blocks (even
    smaller than block group) the health value for that ZIP that the
    year 2000 block has a centroid in, then combine the year 2000
    blocks into their respective year 2000 block groups via an
    average.  Clear as mud, right?

   The PSRC also has the Census Block Groups (which the 2010 shapefile
   should match the GEOID10 in the CAT data) and the Census Blocks for
   2000 if you think we should do the “perfect” approach.

   Also, you could do the “region” instead of King County if you are
   interested and then you have all of Puget Sound (which matches the
   CAT data too).



*-----------------------------------------------------------------------------------------------------------------------
* census block group asthma data, erik sagonic (13 jan 2016)

  --- get gis shapefiles
    cd ~/s/work/cleveland/asthmaDetails
    http://www.psrc.org/data/gis/shapefiles
    get 2010 king county census block groups
    1149020 Jan 13 10:12 king10ct.zip


  --- convert gis shape files
    http://ben.balter.com/2013/06/26/how-to-convert-shapefiles-to-geojson-for-use-on-github/
    brew install gdal
    ogr2ogr -f GeoJSON -t_srs crs:84 king10ct.geojson king10ct.shp

    book.shapefiles> head king10ct.geojson
    {
    "type": "FeatureCollection",
    "crs": { "type": "name", "properties": { "name": "urn:ogc:def:crs:OGC:1.3:CRS84" } },

    "features": [
    { "type": "Feature", "properties": { "STATEFP10": "53", "COUNTYFP10": "033", "TRACTCE10": "022006", "GEOID10": "53033022006",
    { "type": "Feature", "properties": { "STATEFP10": "53", "COUNTYFP10": "033", "TRACTCE10": "032320", "GEOID10": "53033032320",
    { "type": "Feature", "properties": { "STATEFP10": "53", "COUNTYFP10": "033", "TRACTCE10": "031703", "GEOID10": "53033031703",
    { "type": "Feature", "properties": { "STATEFP10": "53", "COUNTYFP10": "033", "TRACTCE10": "031206", "GEOID10": "53033031206",
    { "type": "Feature", "properties": { "STATEFP10": "53", "COUNTYFP10": "033", "TRACTCE10": "032102", "GEOID10": "53033032102",


  --- my initial look
   cd ~/s/work/cleveland/asthmaDetails/
   cat CATtable.txt | tr '\r' '\n' > catTable.tsv
   tbl <- read.table("catTable.tsv", header=TRUE, as.is=TRUE, sep="\t")
   dim(tbl) #  2638   35

   tbl[1:5, c(1:5,32)]
            GEOID INTPTLAT  INTPTLON        county Population Asthma.Risk.per.million.per.year
   1 530530721061 47.19196 -122.5239 Pierce County        563                              829
   2 530530724072 47.29683 -122.5580 Pierce County       1546                              425
   3 530530730015 46.99222 -122.5341 Pierce County       1410                              340
   4 530530730062 46.92124 -122.4922 Pierce County        738                              413
   5 530530730013 46.98719 -122.5092 Pierce County        896                              410

   --- cleveland high school census block group
	   https://github.com/paul-shannon/chia/blob/master/geography/king90bg.geojson:  530330104004 ('STFID')
           https://github.com/paul-shannon/chia/blob/master/geography/king00bg.geojson:  530330104004 ('SFTID')
           https://github.com/paul-shannon/chia/blob/master/geography/king10ct.geojson:  53033010402  ('GEOID10')

   > as.data.frame(t(subset(tbl, county=="King County" & GEOID > 530330104020 & GEOID < 530330104030)))
                                                                 905          906          907         1649
    GEOID                                               530330104022 530330104024 530330104021 530330104023
    INTPTLAT                                                47.55783     47.55700     47.55085     47.55047
    INTPTLON                                               -122.3087    -122.3149    -122.3117    -122.3038
    county                                               King County  King County  King County  King County
    Population                                                  1189         1141          692         1432
    Percent.less.than.18.yo                                     14.3         16.9         27.2         29.7
    Rank.of.less.than.18.yo                                        0            1            2            3
    Percent.greater.than.64.yo                                  28.7          8.7         13.4         13.3
    Rank.of.greater.than.64.yo                                     3            1            2            2
    Percent.no.high.school.diploma                              14.9          7.0         27.4         24.5
    Rank.no.high.school.diploma                                    3            2            3            3
    Percent.single.female.head.of.household                     17.1          4.0         54.8          0.0
    Rank.female.head.of.household                                  2            1            3            0
    Percent.minority                                            67.8         67.7         81.5         85.3
    Minority.rank                                                  3            3            3            3
    Median.income                                              59219        98159        38750        90205
    Income.rank                                                    2            0            3            0
    Percent.English.not..well.                                  23.3          2.4         18.6         28.5
    Language.rank                                                  3            1            3            3
    Percent.use.wood.as.primary.source.of.heat                  <NA>         <NA>         <NA>            2
    Wood.rank                                                      0            0            0            1
    Count.of.registered.sources.in.block.group.boundary            0            0            0            0
    Rank.count.of.registered.air.pollution.sources                 0            0            0            0
    Distance.to.major.sources..unitless.                       0.020        0.018        0.013        0.014
    Rank.distance.to.major.sources                                 3            3            3            3
    Distance.to.traffic.volume..unitless.                     187000       187000       187000       187000
    Rank.distance.to.traffic.volume                                3            3            3            3
    Cardiac.Hospitalization.Risk.per.million.per.year          10110        10110        10230        10128
    Rank.Cardiac                                                   2            2            2            2
    COPD.Risk.per.million.per.year                               487          487          495          487
    Rank.COPD                                                      2            2            2            2
    Asthma.Risk.per.million.per.year                             921          921          931          919
    Rank.Asthma                                                    3            3            3            3
    Sum.of.ranks                                                  29           22           32           28
    Population.weighted.sum.of.ranks                           34481        25102        22144        40096



       not in  ~/s/work/cleveland/asthmaDetails/catTable.tsv from erik (but is generally in range)
       range(subset(tbl, county=="King County")$GEOID)  # [1] 530330001001 530330328003

      STATEFP10	53
      COUNTYFP10	033
      TRACTCE10	010402
      GEOID10	53033010402
      NAME10	104.02
      NAMELSAD10	Census Tract 104.02
      MTFCC10	G5020
      FUNCSTAT10	S
      ALAND10	1798894
      AWATER10	0
      INTPTLAT10	+47.5537876
      INTPTLON10	-122.3102256



   colnames(tbl)

    [1] "GEOID"
    [2] "INTPTLAT"
    [3] "INTPTLON"
    [4] "county"
    [5] "Population"
    [6] "Percent.less.than.18.yo"
    [7] "Rank.of.less.than.18.yo"
    [8] "Percent.greater.than.64.yo"
    [9] "Rank.of.greater.than.64.yo"
   [10] "Percent.no.high.school.diploma"
   [11] "Rank.no.high.school.diploma"
   [12] "Percent.single.female.head.of.household"
   [13] "Rank.female.head.of.household"
   [14] "Percent.minority"
   [15] "Minority.rank"
   [16] "Median.income"
   [17] "Income.rank"
   [18] "Percent.English.not..well."
   [19] "Language.rank"
   [20] "Percent.use.wood.as.primary.source.of.heat"
   [21] "Wood.rank"
   [22] "Count.of.registered.sources.in.block.group.boundary"
   [23] "Rank.count.of.registered.air.pollution.sources"
   [24] "Distance.to.major.sources..unitless."
   [25] "Rank.distance.to.major.sources"
   [26] "Distance.to.traffic.volume..unitless."
   [27] "Rank.distance.to.traffic.volume"
   [28] "Cardiac.Hospitalization.Risk.per.million.per.year"
   [29] "Rank.Cardiac"
   [30] "COPD.Risk.per.million.per.year"
   [31] "Rank.COPD"
   [32] "Asthma.Risk.per.million.per.year"
   [33] "Rank.Asthma"
   [34] "Sum.of.ranks"
   [35] "Population.weighted.sum.of.ranks"


  --- erik's description (email 9 jan 2016)

   We can discuss how you want to split up the work for it.  I’m
   willing to do a lot of it, but of course time is of the essence.

   We need to download the census age data in each census block group
   in Puget Sound
   (http://www.census.gov/programs-surveys/acs/data/tools/summary-file-retrieval-tool.html).

   I believe the age is reported in these bins:

   Under 5 years
   5 to 9 years
   10 to 14 years
   15 to 19 years
   20 to 24 years
   25 to 29 years
   30 to 34 years
   35 to 39 years
   40 to 44 years
   45 to 49 years
   50 to 54 years
   55 to 59 years
   60 to 64 years
   65 to 69 years
   70 to 74 years
   75 to 79 years
   80 to 84 years
   85 years and over

    The asthma rate data for our region is in the attachment as the
    column labelled “Asthma Risk per million per year” for each census
    block group.

    Since the health data is from 2001-2010, we may need to pull older
    census data to make it “apples-to-crab apples” (almost the same).
    However, the file I attached is with the 2010+ census block group
    shapes (they change).  Therefore, we may stick to newer data to
    avoid the step of geographically marrying them.  I could do it
    still but it is a lot of hoops and I’m not sure the age
    distributions are that different from then to now.  But if I feel
    energized enough to make sure it is as best as it can be, I’ll go
    ahead and do this extra step.

    Then, we’ll adjust for the national asthma prevalence by age
    group: https://www.cdc.gov/asthma/most_recent_data.htm

    We’ll have to aggregate the data to match these bins for age
    adjustment:

       0-4 years
       5-14 years
      15-19 years
      20-24 years
      25-34 years
      35-64 years
      65+ years

   In the end, high youth populations may end up with lower age
   adjusted rates.  We’ll see if it makes much difference, but it’ll
   be nice to see if it starts to show even stronger correlations.



*-----------------------------------------------------------------------------------------------------------------------
* requirejs & tabs

   --- (12 jan 2016) igv
      cd ~/s/examples/js/requirejs/tabs/
      -> igv.html
         global include of css for jquery-ui, font-awesome, igv-1.0.6
         no jquery and jquery-ui <script src=> include

      -> in igvTab.js
        bootstrap and igv shimmed
        jquery, jquery-ui, bootstrap: no are explicitly required, none are exported

         require.config({
             'shim' : {
                 'bootstrap': {'deps' :['jquery']},
                 'igv': {'deps' :['jquery', 'jquery-ui', 'bootstrap']}
                  },
              'paths': {
                 'jquery'    :   'http://code.jquery.com/jquery-1.12.4.min',
                 'jquery-ui' :   'http://code.jquery.com/ui/1.12.1/jquery-ui.min',
                 'bootstrap' :   'http://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/js/bootstrap.min',
                 'igv'       :   'http://igv.org/web/release/1.0.6/igv-1.0.6'
                 }
               });
         require(['igv'], function (igv) {

    --- (12 jan 2016) leaflet
      leaflet.html: has css links for jquery-ui.css and leaflet.css
      leafletTab.js: has shim which (misleadingly but effectively) says leaflet depends on jquery/ui, which
          causes them to be loaded.  only require(['leaflet'], function(L) needed, $ is available

    --- (12 jan 2016) cyjs

*-----------------------------------------------------------------------------------------------------------------------
* musical instrument insurance (11 jan 2016)

   managed by hartford insurance

   --- leo
      1936 Gibson L7, $4000
      1930 German violin, $1600
      2015 Champlin L-00 copy, $2000
      2016 enoch tradesman banjo, $1300

   --- me
      doc banjo

   heritage insurance services
   http://www.musicins.com/
   1-800-289-8837

   --- this year's values

     1936 Gibson L7 guitar, $4000
     1930 German violin, $1600; bow, $500
     2015 Champlin L-00 guitar copy, $2000
     2016 Enoch Tradesman banjo, $1300
     2013 Custom Doc open back banjo, $3200
     total: $10,600
     last year's total value (for comparison): $11,297


     Confirmed updates, thank you for sending. We will endorse the
     current policy, the premium and coverages will remain the
     same. Thank you!

     Robin Riotto
     Musical Instrument Department
     Heritage Insurance Services, Inc.
     826 Bustleton Pike, Suite 203
     Feasterville, PA 19053



*-----------------------------------------------------------------------------------------------------------------------
* SummaryFileDataRetrievalTool from census.gov

   We need to download the census age data in each census block group
   in Puget Sound
   (http://www.census.gov/programs-surveys/acs/data/tools/summary-file-retrieval-tool.html).

   cd ~/apps/censusTools
   /Users/paul/apps/censusTools/SummaryFileDataRetrievalTool.zip,  10481412 Jan  9 06:33

  tutorial video: http://www.census.gov/library/video/acs_block_group.html

*-----------------------------------------------------------------------------------------------------------------------
* asthma data and ideas from erik saganic (9 jan 2017)

   cd ~/s/work/cleveland/asthmaDetails/
   cat CATtable.txt | tr '\r' '\n' > catTable.tsv
   tbl <- read.table("catTable.tsv", header=TRUE, as.is=TRUE, sep="\t")
   dim(tbl) #  2638   35
   colnames(tbl)

    [1] "GEOID"
    [2] "INTPTLAT"
    [3] "INTPTLON"
    [4] "county"
    [5] "Population"
    [6] "Percent.less.than.18.yo"
    [7] "Rank.of.less.than.18.yo"
    [8] "Percent.greater.than.64.yo"
    [9] "Rank.of.greater.than.64.yo"
   [10] "Percent.no.high.school.diploma"
   [11] "Rank.no.high.school.diploma"
   [12] "Percent.single.female.head.of.household"
   [13] "Rank.female.head.of.household"
   [14] "Percent.minority"
   [15] "Minority.rank"
   [16] "Median.income"
   [17] "Income.rank"
   [18] "Percent.English.not..well."
   [19] "Language.rank"
   [20] "Percent.use.wood.as.primary.source.of.heat"
   [21] "Wood.rank"
   [22] "Count.of.registered.sources.in.block.group.boundary"
   [23] "Rank.count.of.registered.air.pollution.sources"
   [24] "Distance.to.major.sources..unitless."
   [25] "Rank.distance.to.major.sources"
   [26] "Distance.to.traffic.volume..unitless."
   [27] "Rank.distance.to.traffic.volume"
   [28] "Cardiac.Hospitalization.Risk.per.million.per.year"
   [29] "Rank.Cardiac"
   [30] "COPD.Risk.per.million.per.year"
   [31] "Rank.COPD"
   [32] "Asthma.Risk.per.million.per.year"
   [33] "Rank.Asthma"
   [34] "Sum.of.ranks"
   [35] "Population.weighted.sum.of.ranks"


   We need to download the census age data in each census block group
   in Puget Sound
   (http://www.census.gov/programs-surveys/acs/data/tools/summary-file-retrieval-tool.html).

   I believe the age is reported in these bins:

      .Under 5 years
      .5 to 9 years
      .10 to 14 years
      .15 to 19 years
      .20 to 24 years
      .25 to 29 years
      .30 to 34 years
      .35 to 39 years
      .40 to 44 years
      .45 to 49 years
      .50 to 54 years
      .55 to 59 years
      .60 to 64 years
      .65 to 69 years
      .70 to 74 years
      .75 to 79 years
      .80 to 84 years
      .85 years and over

    The asthma rate data for our region is in the attachment as the
    column labelled “Asthma Risk per million per year” for each census
    block group.

    Since the health data is from 2001-2010, we may need to pull older
    census data to make it “apples-to-crab apples” (almost the same).
    However, the file I attached is with the 2010+ census block group
    shapes (they change).  Therefore, we may stick to newer data to
    avoid the step of geographically marrying them.  I could do it
    still but it is a lot of hoops and I’m not sure the age
    distributions are that different from then to now.  But if I feel
    energized enough to make sure it is as best as it can be, I’ll go
    ahead and do this extra step.

    Then, we’ll adjust for the national asthma prevalence by age
    group: https://www.cdc.gov/asthma/most_recent_data.htm

    We’ll have to aggregate the data to match these bins for age
    adjustment:

      0-4 years
      5-14 years
      15-19 years
      20-24 years
      25-34 years
      35-64 years
      65+ years

   In the end, high youth populations may end up with lower age
   adjusted rates.  We’ll see if it makes much difference, but it’ll
   be nice to see if it starts to show even stronger correlations.




*-----------------------------------------------------------------------------------------------------------------------
* merge dockerfile pr from kozo (12 jan 2016)

  cd ~/tmp
  git clone -b patch-1 https://github.com/kozo2/jupyter-cytoscape
  docker build -t jupytercy jupyter-cytoscape/
  docker images
     REPOSITORY                TAG                 IMAGE ID            CREATED             SIZE
     jupytercy                 latest              cbaca634e55b        5 minutes ago       867.3 MB
     ...

   --- now run the image
     docker rm -f sick_euclid   # needed if docker ps shows sick_euclid operating on same port
     docker run -d -p 8888:8888 jupytercy  #   1401a8489f464932611ab8583b96186bbd5ffbd0dd1f2527d72f39e9e0526e18

   --- check status
      docker ps
     CONTAINER ID        IMAGE               COMMAND                  CREATED
     1401a8489f46        jupytercy           "/usr/bin/tini -- jup"   About a minute ago
     STATUS              PORTS                    NAMES
     Up About a minute   0.0.0.0:8888->8888/tcp   high_hawking

   --- exec the image
     docker exec -it high_hawking jupyter notebook list
        # http://0.0.0.0:8888/?token=6a289dce11b07fc815c8c1aa4c03e55990af487700854827 :: /workdir
     browse to http://0.0.0.0:8888/?token=6a289dce11b07fc815c8c1aa4c03e55990af487700854827
     click through to examples/smallNetwork/smallNetwork.ipynb


*-----------------------------------------------------------------------------------------------------------------------
*  stop & restart docker container

   docker ps
     CONTAINER ID        IMAGE                     COMMAND                  CREATED
     304d57938a0e        kozo2/jupyter-cytoscape   "/usr/bin/tini -- jup"   5 hours ago

     STATUS              PORTS                    NAMES
     Up 5 hours          0.0.0.0:8888->8888/tcp   clever_goldwasser

   docker stop clever_goldwasser
   docker rm clever_goldwasser

   docker run -d -p 8888:8888 kozo2/jupyter-cytoscape
     8f23ee29a6f82f4c3219b3ad7a3ee001d33e038629e4d216b7f7db91d4f5fb0b

   docker ps  # shows NAE is sick_euclid
   docker exec -it sick_euclid jupyter notebook list
   Currently running servers:
     http://0.0.0.0:8888/?token=5d2c9faf04d9134b726437c414532f8c026164addbd5e5f4 :: /workdir
   browser to the url preceeding ' :: /workdir'
   shows up using python 2
   uncertain about meaning of /workdir


*-----------------------------------------------------------------------------------------------------------------------
* mike smoot chimes in on jupyter-cytoscape docker (9 jan 2016)

   Paul, docker is looking for the name of the container, not the
   host, which is "clever_goldwasser" in your case. The command should
   be: docker exec -it clever_goldwasser jupyter notebook list

   the whole process (sans build)

     docker pull kozo2/jupyter-cytoscape
     docker run -d -p 8888:8888 kozo2/jupyter-cytoscape
     docker ps
       CONTAINER ID        IMAGE                     COMMAND
       304d57938a0e        kozo2/jupyter-cytoscape   "/usr/bin/tini -- jup"

       CREATED             STATUS              PORTS                    NAMES
       15 seconds ago      Up 14 seconds       0.0.0.0:8888->8888/tcp   clever_goldwasser

     then
        docker exec -it clever_goldwasser jupyter notebook list

     jupyter notebook list
     currently running servers:
       http://localhost:9998/?token=f3200464825cbe97e2c7b6b0972afab5ea60bc7b5b70d176

*-----------------------------------------------------------------------------------------------------------------------
* kozo's updated advice

   @paul-shannon If you have any trouble running the above commands, please try the following instead.

   docker pull kozo2/jupyter-cytoscape
     Using default tag: latest
     latest: Pulling from kozo2/jupyter-cytoscape
     Digest: sha256:534b39c1d83ae7afb65f57aafdfe44cc463d968750d223dcf6ea8f88f265c7a2
     Status: Downloaded newer image for kozo2/jupyter-cytoscape:latest

   --- see this via  docker images
     REPOSITORY                TAG                 IMAGE ID            CREATED             SIZE
     kozo2/jupyter-cytoscape   latest              f00908207708        35 minutes ago      867.5 MB



   docker run -d -p 8888:8888 kozo2/jupyter-cytoscape
      304d57938a0e5c4e66ef0da6f8b13a22fb9c7f36a0952303a54f6e9c9656a478

   docker ps
      CONTAINER ID        IMAGE                     COMMAND                  CREATED             STATUS              PORTS                    NAMES
      304d57938a0e        kozo2/jupyter-cytoscape   "/usr/bin/tini -- jup"   15 seconds ago      Up 14 seconds       0.0.0.0:8888->8888/tcp   clever_goldwasser

    hostname # riptide.local

     docker exec -it THE_NAME_OF_YOUR_CONTAINER jupyter notebook list
     docker exec -it riptide.local jupyter notebook list

*-----------------------------------------------------------------------------------------------------------------------
* jupyter-cytoscape docker file updated (9 jul 2016)

  from kozo nishida, email and github issue:

     I have no idea about your npm error but I found a missing Debian
     package in my Dockerfile (and updated it in b8c46f6).  Could you try
     the following commands?

    git clone -b patch-1 https://github.com/kozo2/jupyter-cytoscape
   docker build -t jupytercy jupyter-cytoscape/
   docker run -d -p 8888:8888 jupytercy
   a47db3898fbf42350749805551436733f3998044928782363751347e1ddc3b4c
   docker ps
   CONTAINER ID        IMAGE               COMMAND                  CREATED             STATUS              PORTS                    NAMES
   a47db3898fbf        jupytercy           "/usr/bin/tini -- jup"   2 seconds ago       Up 1 seconds        0.0.0.0:8888->8888/tcp   big_montalcini
   docker exec -it big_montalcini jupyter notebook list
   Currently running servers:
   http://0.0.0.0:8888/?token=5243b38a5bf9f711bd489f67bcaa05b420f420f329183bec :: /workdir
   Please note that

   big_montalcini will be different name in your env.
   You need the token 5243b38a5bf9f711bd489f67bcaa05b420f420f329183bec to login Jupyter Notebook. Please refer to https://jupyter-notebook.readthedocs.io/en/latest/security.html

*-----------------------------------------------------------------------------------------------------------------------
* initial jupyter-cytoscape docker fails


   @kozo2 Thanks very much for this! Presenting a notebook as a docker container is very sensible. I am pretty new to docker, having only run a few simple tutorial examples previously. Here's the error trace I get when I run docker build .. Any suggestions?

   npm ERR! Linux 4.4.39-moby
   npm ERR! argv "/usr/bin/nodejs" "/usr/bin/npm" "update"
   npm ERR! node v4.2.6
   npm ERR! npm  v3.5.2
   npm ERR! path /workdir/js/node_modules/@types/jquery
   npm ERR! code EXDEV
   npm ERR! errno -18
   npm ERR! syscall rename

   npm ERR! EXDEV: cross-device link not permitted, rename '/workdir/js/node_modules/@types/jquery' -> '/workdir/js/node_modules/@types/.jquery.DELETE'
   npm ERR!
   npm ERR! If you need help, you may report this error at:
   npm ERR!     <https://github.com/npm/npm/issues>

   npm ERR! Please include the following file with any support request:
   npm ERR!     /workdir/js/npm-debug.log


*-----------------------------------------------------------------------------------------------------------------------
* examine docker file pull request from kozo (9 jan 2017)

  cd ~/github/jupyter-cytoscape/

  Step 1: From your project repository, check out a new branch and test the changes.
    git checkout -b kozo2-patch-1 master
    git pull https://github.com/kozo2/jupyter-cytoscape.git patch-1

  Step 2: Merge the changes and update on GitHub.
   git checkout master
   git merge --no-ff kozo2-patch-1
   git push origin master


  git checkout -b kozo2-patch-1 master
  git pull https://github.com/kozo2/jupyter-cytoscape.git patch-1

*-----------------------------------------------------------------------------------------------------------------------
* forest time-lapse movies

  ~/Movies/exported/LostLake03.mp4: 3 frames only, posted to fb

*-----------------------------------------------------------------------------------------------------------------------
* leo's warren wilson money budget (6 jan 2016)

   see ~/s/notes/money
   "* planning for leo's college expenses"
   updated today

*-----------------------------------------------------------------------------------------------------------------------
* capitol hill fedex/kinkos (5 jan 2016)

  usa5146@fedex.com

*-----------------------------------------------------------------------------------------------------------------------
* clean air, climate change, local seattle references

  http://frontandcentered.org/2952-2  (22 oct 2015) clean air rule letter to ecology by communities of climate justice
  http://frontandcentered.org/   climate justice video

  cd ~/s/data/cleanAir
  CommunityAirTool12-14-2012.kmz  4117040 Jan  4 09:29
  open CommunityAirTool12-14-2012.kmz

  --- andrea rogers harris, rebecca soldanya (new state rep). climate justice.
    got green. jill mangalaman?  director
    welc: lawyer for the kids, our children's trust
    public trust doctrine (chicago case)
    mary christa wood: nature's law, u of o, attorney



*-----------------------------------------------------------------------------------------------------------------------
* michael yadrick's seed sowing instructions (3 jan 2016)

  I encourage you to wait until March 1 to lay down the seed.

1. Mix seed with soil.  Mix the seed with a generous amount of damp
soil or sand that will bond the seed together and provide some
initial soil contact for germination.

2. Pick a site, and rough up small areas with a rake. Scatter the seeds
over no more than 5,000 square feet.  Not too much raking! Too much
disturbance may also provide a place for weeds to germinate too.

3. Distribute across the site. GSP provided approximately 1 pound of
seed. The key is to distribute it evenly. Walk across the site,
scattering seed mixed with soil/sand evenly across the area. You can
spread it amongst other plants. Lightly cover any seed that remains
uncovered.

4. Wait and Monitor Remember where you scattered the seed. Some of the
species may take longer than you think to establish. A combination of
moisture and temperature will jumpstart germination; some species may
not appear until Spring.  Inform GSP staff of your progress. Send
photos if you can.



*-----------------------------------------------------------------------------------------------------------------------
* leaflet.js: a requirejs shim (9 jan 2016)
require.config({
    paths: {
        'leaflet': '../../libs/leaflet/leaflet-src',
        'markercluster': '../../libs/leaflet/plugins/markercluster/leaflet.markercluster-src',
    },
    shim: {
        leaflet: {
            exports: 'L'
        },
        markercluster: {
            deps: ['leaflet']
        }
    }
});
*------------------------------------------------------------------------------------------------------------------------
* three.js: a requirejs shim (5 jan 2016)

  http://stackoverflow.com/questions/30358323/require-js-not-loading-three-js
     requirejs.config({
         baseUrl: "src",
         paths: {
             "main": "../main",
             "test": "../test",
             "three": "../three/three",
             "sizzle": "/src/sizzle/dist/sizzle"
         },
         shim: {
             three: {
                 exports: 'THREE'
             }
         }
     });


*-----------------------------------------------------------------------------------------------------------------------
* requirejs learning continued +=2 (5 jan 2016): shims

  a shim allows us to treat a non-AMD library as if it were actually AMD

  good, deep explanations at
     http://aaronhardy.com/javascript/javascript-architecture-requirejs-dependency-management/

  --- got this require.config from igv's douglass turner:
     require.config({
         'shim' : {
             'bootstrap' : {
                 'deps' :['jquery']
             },
             'igv' : {
                 'deps' :['jquery', 'jquery-ui', 'bootstrap']
             }
         },
         'paths': {
             'jquery'    :   'http://code.jquery.com/jquery-1.12.4.min',
             'jquery-ui' :   'http://code.jquery.com/ui/1.12.1/jquery-ui.min',
             'bootstrap' :   'http://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/js/bootstrap.min',
             'igv'       :   'http://igv.org/web/release/1.0.6/igv-1.0.6'
         }
     });

     require(['jquery', 'igv'], function ($, igv) {
     ....

*-----------------------------------------------------------------------------------------------------------------------
* learning requirejs continued++ (3 jan 2016)

  optimizer concatenates and minifies, guy from bahrain, useful.

   part 1:  https://www.youtube.com/watch?v=m6VNhqKDM4E
   part 2:  https://www.youtube.com/watch?v=_n4-zAhaHSM


   --- very simple

     https://www.youtube.com/watch?v=VGlDR1QiV3A#t=2.538684
     cd ~/s/examples/js/requirejs/Tutorial-RequireJS-TheBasics

   ---- install require
     sudo npm install -g requirejs
     type -a r.js   # r.js is /usr/local/bin/r.js

  --- now optimize this very simple project
     r.js -o name=main out=main-built.js baseUrl=. optimize=none  # no minification


  --- optimize (concatenate) main.css
    cat main.css:
        @import url("bootstrap.css");
    r.js -o cssIn=main.css out=main-built.css
       56339  bootstrap.css
       54597  main-built.css
          31  main.css


   --- make sure this is truly self-contained


*-----------------------------------------------------------------------------------------------------------------------
* learning requirejs continued (2 jan 2016)

   suggested by the requirejs website, a small singlepage app.
   cd ~/s/examples/js/requirejs

    git clone https://github.com/volojs/create-template.git
    cd create-template
    node tools/r.js -o tools/build.js

*-----------------------------------------------------------------------------------------------------------------------
* needing clustergrammer and igv to be requirejs-compliant: learn requirejs basics (2 jan 2016)

  cd ~/s/examples/js/requirejs/simple
     index.html
        <script data-main="js/main" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.2/require.min.js"></script>
     js
     js/main.js
        require.config({
           paths: {
             'jQuery': 'vendor/jquery-1.12.4.min',
             'underscore': 'vendor/underscore-1.8.3-min'
             },
            shim: {
              'jQuery': {
                  exports: '$'
                  },
              'underscore': {
                  exports: '_'
                 }}});
        require(['module1', 'subdir/module2', 'jQuery'], function (module1ref, module2ref, $) {
           var module1 = new module1ref(), module2 = new module2ref();
           console.log(module1.getName() === module2.getModule1Name()); // true
           console.log('jQuery version:', $.fn.jquery); // 1.9.0
           });

     js/module1.js
     js/subdir
     js/subdir/module2.js
     js/vendor
     js/vendor/jquery-1.12.4.min.js
     js/vendor/underscore-1.8.3-min.js
     lib
     lib/modules




*-----------------------------------------------------------------------------------------------------------------------
* jupyter tips, python tips, ipywidgets tips: ensure localhost devel js library actually available

# ensure the library is available
# ensure libraries are available
import requests
assert(requests.get('http://localhost:8099/js/cytoscape-2.7.10.js').status_code == 200)
assert(requests.get('https://igv.org/web/beta/igv-beta.min.js').status_code == 200)

*-----------------------------------------------------------------------------------------------------------------------
* clustergrammer js library, try2: webpack the ipywidgets version to produce ~/http/js/clustergrammer.js (2 jan 2016)

  cd ~/github/clustergrammer-widget/js
  npm install
  webpack
  cp dist/index.js ~/http/js/clustergrammer.js

  cd ~/s/examples/js/clustergrammer
  abandonded for now

*-----------------------------------------------------------------------------------------------------------------------
* clustergrammer js library, explorations in preparation for an ipyhb cyjs/clustergrammer tabbed notebook widget

  https://github.com/MaayanLab/clustergrammer#clustergrammer-javascript-library

   cd ~/github/clustergrammer
   create shell, http-9001
   python -m http.server 9001

   cd  ~/s/examples/js/clustergrammer
   cp ~/github/clustergrammer/index.html
   modify all appropriate script and css links to be http://localhost:9001

   modify ~/github/clustergrammer/js/load_clustergram.js so that it reads

      function make_clust(inst_network){
        d3.json('http://localhost:9001/json/'+inst_network, function(network_data){

   even then, needs (in chrome) cors toggle on


*-----------------------------------------------------------------------------------------------------------------------
* vasque breeze iii low gtx hiking shoes, boots, size 10.5, $150 (11 mar 2017)

  returned boots shoes merrell moab size 10 (returned)

   rei: (29 dec 2016):  $140


*-----------------------------------------------------------------------------------------------------------------------
* cellphoneJS, work in progress (6 jan 2016)

  cd ~/github/cellphoneJS/pojs

*-----------------------------------------------------------------------------------------------------------------------
* figure out bootstrap navbar dropdown menu for pojs cellphone simulator (27 dec 2016)

  ~/s/examples/js/bootstrap/menu/index3.html

*-----------------------------------------------------------------------------------------------------------------------
* pojs cellphone simulator (26 dec 2016)

  cd ~/github/cellphoneJS/pojs
  try this out next: ~/s/examples/js/jquery/pulldownMenuEasyAsPie/

*-----------------------------------------------------------------------------------------------------------------------
* minimal cyjs, created from console: 1 node, 1 self-looped edge

   $("#").append("<div id='newCyDiv' style='border:1px solid red; height:200px;'>cyDiv coming soon</div>");

   --- new, with 3.0.0 (22 apr 2017)
      var cy = cytoscape({container: $('#newCyDiv'), elements:{nodes:[{data:{id:'a'}}], edges:[{data:{source:'a', target:'a'}}]}})

   --- old, before 3.0 (22 apr 2017)
     $("#newCyDiv").cytoscape({elements:{nodes:[{data:{id:'a'}}], edges:[{data:{source:'a', target:'a'}}]}})


*-----------------------------------------------------------------------------------------------------------------------
* minimal cyjs in html, minimal cytoscape
     <!DOCTYPE html>
     <html>
     <head>
        <meta charset="UTF-8">
        <title>cyjse </title>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/2.2.0/jquery.min.js"></script>
        <script src="http://cytoscape.github.io/cytoscape.js/api/cytoscape.js-latest/cytoscape.min.js"></script>
        <script src="network.json"></script>
        <script src="vizmap.json"></script>
     <style>
     #cyDiv {
       margin: auto;
       width: 500px;
       height: 500px;
       border: 1px solid #444;
       border-radius:5px;
       display: block;
       }
     </style>
     <script>
     //----------------------------------------------------------------------------------------------------
     $(document).ready(function() {
        console.log("document ready");
        cyDiv = $("#cyDiv");
        cyDiv.cytoscape({
        elements: {
           nodes: [
             {data: {id: 'a', name: 'Node A', type: 'big' }},
             {data: {id: 'b', name: 'Node B', type: 'little'}},
             ],
          edges: [
            {data: {source: 'a', target: 'b'}},
            {data: {source: 'b', target: 'a'}}
            ]
          },
       ready: function(){
          cyjs = this;
          console.log("small cyjs network ready, with " + cyjs.nodes().length + " nodes.");
          } // ready
        }) // cytoscape()
     }); // document ready
     //----------------------------------------------------------------------------------------------------
     </script>
     </head>
     <body>
     <div id="cyDiv"></div>
     </body>
     </html>


*-----------------------------------------------------------------------------------------------------------------------
* webpack tips

  --- npm install --save-dev imports-loader

  --- create a new project: use cellphoneJS as example
     git clone https://github.com/paul-shannon/cellphoneJS.git
     cd ~/github/cellphoneJS
     create .gitignore:
          dist/
          build/
          node_modules/
          .DS_Store
     npm init -y    # creates minimal package.json
     npm i webpack --save-dev    # make sure that ./node_modules/.bin is prepended to PATH
     npm i html-webpack-plugin --save-dev
     npm i cytoscape  --save
     npm i jQuery --save
     npm i jQuery-ui --save

  ---- build and view
     make   # --> npm run build  && open build/index.html
     webpack --display-modules   # shoes hidden modules only alluded to be webpack implicit 'pack' command

*-----------------------------------------------------------------------------------------------------------------------
* merrell shoes/boots

  my currently about to degrade pair appear to be merrell chameleons, waterproof

*-----------------------------------------------------------------------------------------------------------------------
* webpack tips

  cd ~/s/examples/js/bootstrap/cellphoneWithWebpack
  npm install --save-dev style-loader
  npm install --save-dev css-loader

  cat entry.js
    require("!style!css!./style.css");
    document.write(require("./content.js"));

  cat style.css
    body{background: yellow;}
   webpack ./entry.js bundle.js
   open index.html

  --- now simpliyfy the style require line to
     require("./style.css");
   and build:
      webpack ./entry.js bundle.js --module-bind 'css=style!css'

   --- now use a config file
     module.exports = {
         entry: "./entry.js",
         output: {
            path: __dirname,
            filename: "bundle.js"
            },
         module: {
           loaders: [
               { test: /\.css$/, loader: "style!css" }
               ]
          }
       };

   --- serious tutorial
      https://webpack.js.org/get-started/

*-----------------------------------------------------------------------------------------------------------------------
* bootstrap intro and examples (23 dec 2016)

  http://tutorialzine.com/2015/10/learn-the-bootstrap-grid-in-15-minutes/
  got zip, installed to
  cd ~/s/examples/js/bootstrap/learnGrid/

*-----------------------------------------------------------------------------------------------------------------------
* ractive tutorial

  https://www.toptal.com/javascript/ractive-js-web-apps-made-easy
  ~/github/toptal-blog-ractive
  open index.html
  seems to use bootstrap for appearance.

  big database, but small and simple code.  study this!



*-----------------------------------------------------------------------------------------------------------------------
* phosphor, first look (22 dec 2016)

  cd ~/github/phosphor
  git pull origin
  npm install
*-----------------------------------------------------------------------------------------------------------------------
* uw air monitoring, joel kaufman's lab

  http://deohs.washington.edu/faculty/kaufman_joel
  http://deohs.washington.edu/mesaair/home

  alison has grad student contact in that lab who reports "only 3 monitoring stations in Seattle"
  from which she concludes that road proximity measures would be a better surrogate than these sparse reports

*-----------------------------------------------------------------------------------------------------------------------
* asking visitors to help, sam ham, the forest floor is alive signs, seward park (22 dec 2016)

  ~/Documents/askingVisitorsToHelpSamHam.pdf
  ~/Documents/theForestFloorIsAlive-kioskPoster.pages

*-----------------------------------------------------------------------------------------------------------------------
* image nodes requested by richard silva (20 dec 2016)

  cd ~/s/examples/cyjs/imageNodes/
  downloaded max's gist

  this assignment from the console worked, making the cat node into grains of wheat
    cy.nodes()[0].style({"background-image":"https://farm3.staticflickr.com/2660/3715569167_7e978e8319_b.jpg"})

   "background-fit": "cover"  probably needed as well


*-----------------------------------------------------------------------------------------------------------------------
* javascript tips mousewheel event

  see ~/s/examples/js/mouseWheel/index.html

window.addEventListener('mousewheel', mouseWheelEvent);     // For Chrome
window.addEventListener('DOMMouseScroll', mouseWheelEvent); // For Firefox
function mouseWheelEvent(e) {
   console.log(" --- mouseWheelEvent");
   var delta = e.wheelDelta ? e.wheelDelta : -e.detail;
   if(delta > 0)
     console.log("positive");
   else
     console.log("negative");
   }

*-----------------------------------------------------------------------------------------------------------------------
* three.js, webgl: loading binary model data directly the gpu (19 dec 2016)

  http://n-e-r-v-o-u-s.com/blog/?p=2738
  http://www.informit.com/articles/article.aspx?p=1613551&seqNum=4
  https://www.html5rocks.com/en/tutorials/webgl/million_letters/
*-----------------------------------------------------------------------------------------------------------------------
* asking visitors to help: Research to Guide Strategic Communication for Protected Area Management

  https://scholar.google.com/scholar?q=asking+visitors+to+help&btnG=&hl=en&as_sdt=0%2C48

*-----------------------------------------------------------------------------------------------------------------------
* three.js demos

   https://stemkoski.github.io/
   ~/s/examples/js/three/minimal/sphere/index.html   # no controls, just mouse events

*-----------------------------------------------------------------------------------------------------------------------
* three.js: get reacquainted with 3d scatter points, use mds multi-dimensional scaling (18 dec 2016)

  inspired by: http://datacratic.com/site/blog/visualizing-high-dimensional-data-browser-svd-t-sne-and-threejs
  also see: http://potree.org/demo/potree_1.3/showcase/eclepens.html

  cd ~/s/examples/js/three/scatterPlot/jsfiddleDemo/
  ~/s/examples/js/three/scatterPlot/jsfiddleDemo/index.html reads data.js

  --- get some gene expression data from tcga
     ~/s/examples/R/pca/forCory
     some criteria had been used (long forgotten) for these 38 row (genes) mtx.other, mtx.8
     cbind and transposed to create 544 patient, 31 gene matrix
        mtx <- t(cbind(mtx.8, mtx.other))
        mtx.mds <- cmdscale(d,eig=FALSE,k=3)
        dim(mtx.mds)  # [1] 544   3
        21 of these 544 rows are from the somehow-separated mtx.8
        all(colnames(mtx.8) %in% rownames(mtx.mds))
        all(colnames(mtx.other) %in% rownames(mtx.mds))

  --- task: display these in three.js, then in pythree.js
     tbl <- as.data.frame(mtx.mds)
     colnames(tbl) <- c("x", "y", "z")
     write.table(tbl, file="mds3.tsv", sep="\t", quote=FALSE)
     library(jsonlite)
     toJSON(head(tbl))
        [{"x":-10.0702,"y":2.9884,"z":2.5338,"_row":"TCGA-12-5295"},{"x":-6.4289,"y":6.7034,"z":-1.4899,"_row":"TCGA-06-5414"},
         {"x":-5.2761,"y":1.2942,"z":2.2008,"_row":"TCGA-26-5132"},{"x":-8.2969,"y":2.5362,"z":1.855,"_row":"TCGA-06-5415"},
         {"x":-6.6708,"y":-0.7047,"z":-1.6303,"_row":"TCGA-12-1597"},{"x":-8.7031,"y":-1.0863,"z":1.0107,"_row":"TCGA-19-2624"}]

    should be able to use this w/o much difficulty in
       ~/s/examples/js/three/scatterPlot/jsfiddleDemo/index.html, drawScattterPlot, where


*-----------------------------------------------------------------------------------------------------------------------
* genomic data from max robinson (18 dec 2016)

   Each line describes a minor allele of a biallelic single
   nucleotide variant occurring in a particular person's genome,
   written out in tab-separated value format from an R data.frame (and
   then edited). "an" is the number of times the allele occurs, 1 or
   2. "af" stands for allele frequency but this column is misnamed, it
   should be called "scale". The frequency of the minor allele in the
   1000 Genomes cohort is scale/2 (the minor allele cannot have a
   frequency over 0.5; if it did, it would be the major allele, and
   the other allele would be the minor one). (Please read on; the
   important note at the end makes the rest relevant.) For display,
   you can either use the allele frequency as a percentage (af =
   50*scale %), OR the estimated age of the allele: g =
   -4*Ne*ln(f)*f/(1-f) where f = scale/2, the allele frequency as a
   fraction. "Ne" is the effective population size, which for humans
   is estimated at Ne = 5000 (and that value is debated). The age as I
   have described it is in _generations_ (g); to convert to years,
   multiply by the number of years per generation. For humans,
   years/generation is also debated; the estimates range from 20 to
   25. I usually use 20. Finally, for human history the right
   timescale is "thousands of years (into the past)", "kya". Putting
   all of this together, kya = g * 20/1000 =
   -80*(5000/1000)*(f/(1-f))*ln(f) = -200 * scale * ln(scale/2) /
   (1-scale/2) IMPORTANT PART: the data is much more interesting on an
   allele age scale (g or kya) than on an allele frequency scale,
   because on a frequency scale the majority of the data is bunched at
   the low frequency end, and on an allele age scale it is more
   conveniently spread.

  cd ~/s/work/priceLab/maxRobinson/allelicVariationViz/
  print(load("one-chr6.ecp.RData")) # tbl
  dim(tbl) #   173172     20

   tbl[1:4, 1:15]
      chr    pos an       af     EC1     EC2     EC3     EC4    EC5     EC6    EC7     EC8     EC9    EC10    EC11
    1   6 147596  1 0.981230  0.0244 -0.4071 -0.0710 -0.1304 0.0220  0.0004 0.0018  0.0005 -0.0057  0.0126 -0.0631
    2   6 148039  1 0.788738 -0.1367 -0.2192 -0.1038 -0.2270 0.0745  0.0032 0.0049  0.0015 -0.0154 -0.0145 -0.0750
    3   6 149691  1 0.202077  0.2345 -0.4900  0.0303 -0.6268 0.0979 -0.0013 0.0109 -0.0033  0.0037 -0.0434 -0.0540
    4   6 149901  1 0.214856  0.2226 -0.4981  0.0325 -0.6123 0.1218 -0.0015 0.0088 -0.0051  0.0015 -0.0458 -0.0539


*-----------------------------------------------------------------------------------------------------------------------
* pypi tips (python package index)

  To use a package from this index either "pip install package" (get pip) or download, unpack and "python setup.py install" it.

  --- pip
  pip list | grep jupyterlab
     jupyterlab (0.11.2, /Users/paul/anaconda/lib/python3.5/site-packages)
     jupyterlab-widgets (0.6.3, /Users/paul/github/ipywidgets/jupyterlab_widgets)
  pip install 'jupyterlab>=0.11.3'
   pip list | grep jupyterlab
    jupyterlab (0.11.3, /Users/paul/anaconda/lib/python3.5/site-packages)
    jupyterlab-widgets (0.6.3, /Users/paul/github/ipywidgets/jupyterlab_widgets)


*-----------------------------------------------------------------------------------------------------------------------
* jupyterlab: install 0.11.3

   https://pypi.python.org/pypi/jupyterlab
   pip install 'jupyterlab>=0.11.3'   # pip list | grep jupyterlab

*-----------------------------------------------------------------------------------------------------------------------
* sylvain corlay's instructions: grokked and executed

   1) jupyterlab 0.11.3 (from 12/14):  pip install 'jupyterlab>=0.11.3'
   2) The current state of master in ipywidgets
       git clone https://github.com/ipython/ipywidgets.git
       cd jupyter-js-widgets
       grep version package.json  #   "version": "2.0.17",
       npm install   # added 697 packages in jupyter-js-widgets/node_modules
       cd ../~widgetsnbextension
       npm install
       npm run update
       pip install -e .
   3) cd ../ipywidgets
      pip install -e .
   4) cd jupyterlab_widgets/
      npm install
      npm run update
      pip install -e .
   5) jupyter labextension install --py --sys-prefix --symlink jupyterlab_widgets
      jupyter labextension enable jupyterlab_widgets --py --sys-prefix


    maybe see: /Users/paul/.jupyter/labconfig/jupyterlab_config.json   # Dec  2 17:49

*-----------------------------------------------------------------------------------------------------------------------
* sylvain corlay's guide to installing ipyleaflet for jupyter lab (16 dec 2016)


   So getting ipyleaflet to work in jupyterlab is quite cumbersome for
   now, since it requires installing ipywidgets from source and
   ipyleaflet from source Besides, the jupyterlab team is iterating quite
   rapidly and makes rapid releases with non-backward compatible version
   numbers (0.x.y) before the first 1.0.  Currently getting ipyleaflet in
   jupyterlab requires

jupyterlab 0.11.3.
The current state of master in ipywidgets
In jupyter-js=widgets, run npm install
In widgetsnbextension , run npm install then npm run update then pip install -e .
In ipywidgets run pip install -e .
In jupyterlab_widgets run npm install then npm run update then pip install -e .
jupyter labextension install --py --sys-prefix --symlink jupyterlab_widgets
jupyter nbextension enable --py --sys-prefix jupyterlab_widgets
  --> jupyter labextension enable jupyterlab_widgets --py --sys-prefix
Install ipyleaflet from source
in js: npm install
at the root of the repo: pip install -e .
jupyter labextension install --py --sys-prefix --symlink ipyleaflet
jupyter nbextension enable --py --sys-prefix jupyterlab_widgets
yay!



*-----------------------------------------------------------------------------------------------------------------------
* jupyterlab tips

   --- install latest
     conda install -c conda-forge jupyterlab  # jupyterlab-0.11.2

*-----------------------------------------------------------------------------------------------------------------------
* priyanka's first cyjs notebook (15 dec 2016)

  --- developed here, on laptop riptide
    cd ~/s/work/priceLab/priyanka/metabolicNetworks/firstNotebook/
    nb1.ipynb
    uses
      network structure: glycolysis.tsv
      nodes and their types: nodes.tsv
      edge attributes: edgeFlux.tsv
      node attributes: Genes_glycolysis_file_values.tsv
      style: style.js

  --- deployed here, private in priceLab github repo, on riptide and whovian

    cd ~/github/notebooks/shared/priyanka/glycolysis/
      nb1.ipynb
      style.js
      Genes_glycolysis_file_values.tsv
      nodes.tsv
      glycolysis.tsv
      edgeFlux.tsv

  http://whovian:10005/notebooks/shared/priyanka/glycolysis/nb1.ipynb

*-----------------------------------------------------------------------------------------------------------------------
* getting nbextension cyjs working on whovian (14 dec 2016)

   --- this may be all that is needed:

   conda update anaconda
      jupyter --version # 4.2.0
      jupyter notebook --version # 4.2.3


   git clone https://github.com/ipython/ipywidgets.git
   cd ipywidgets/
   pip install -e .

   git clone https://github.com/jupyter/jupyter_core.git
   cd jupyter_core/
   pip install -e .

  git clone
  pip install -e .
  npm install webpack    # maybe better: sudo npm install -g webpack
  ln -s /users/pshannon/github/cyjs-jupyter/cyjs-jupyter/node_modules/webpack/bin/webpack.js ~/bin/webpack

  pip install setuptools
  pip install python-igraph

  git clone https://github.com/paul-shannon/cyjs-jupyter.git
  cd cyjs-jupyter/
  git pull origin
  make

  git clone https://github.com/jupyter/notebook.git
  cd notebook
  pip install -e .

  --- still no go:
    Widgets are not available.  Please install widgetsnbextension or ipywidgets 4.0


   --- current state (419p, 14 dec 2016)
    jupyter --version           # 4.1.0       # 4.3.0.dev on riptide
    jupyter notebook --version  # 4.2.1       # 5.0.0.dev on riptide
    cat  ~/github/ipywidgets/ipywidgets/_version.py
      version_info = (6, 0, 0, 'beta5')
      __frontend_version__ = '^2.0.9'

*-----------------------------------------------------------------------------------------------------------------------
* Kitsap Forest NAP (Washington State Natural Area Program and Stavis Creek Preserve)

  This 572-acre forested site on the Kitsap Peninsula became a natural area preserve in 1998. Mature
  and old growth douglas fir and western hemlock dominate this forest with rhododendron, evergreen
  huckleberry, and sword fern in the forest understory. This is one of the few extensive unlogged
  mature forests remaining in the central or southern Puget Trough ecoregion. The site also protects
  portions of Stavis Creek, which supports coho and chum salmon spawning grounds, a blue heron
  rookery, and nesting osprey.

*-----------------------------------------------------------------------------------------------------------------------
* sword fern literature, sword fern disease

  http://ir.library.oregonstate.edu/xmlui/bitstream/handle/1957/50077/SandenoJamesL1962.pdf;sequence=1
  ~/Downloads/SandenoJamesL1962.pdf: masters thesis, diesease of wester sword fern, 1962

  https://www.fs.fed.us/pnw/pubs/gtr285/gtr2852a.pdf
   climate change and the origin of old-growth forests
   in the puget sound lowland.  just 6000 years? no precedent?

  Because climate is driven by a complex set of boundary
  conditions that do not change in unison, new conditions
  constantly arise and disappear on time scales of several
  thousand years. Over these broad time scales, tree species
  continuously reassemble in different combinations that
  follow the rhythm of changing climate.


   --- Identifying Mature and Old Forests In Western Washington
   http://file.dnr.wa.gov/publications/lm_hcp_west_oldgrowth_guide_full_lowres.pdf

   --- the inventory, the report
   http://file.dnr.wa.gov/publications/lm_ess_westside_oldgrowth_rpt.pdf
   see map 4, pg 73/74
*-----------------------------------------------------------------------------------------------------------------------
* possums and raccoons temporal niche: seattle parks field committee meeting (14 dec 2016)

  I am just back from the Seattle Parks Field Committee meeting, at
  which Destiny Mimms presented a study, “Temporal Niche Partitioning
  Between Urban Possums & Raccoons”, which was conducted under the
  supervision of Mark Jordan of Seattle University:

     https://www.seattleu.edu/scieng/biology/faculty-and-staff/mark-jordan-phd.html

  The work, though interesting, does not seem so relevant to the sword
  fern die-off.  Her camera traps and scent-based hair-collection
  traps caught no evidence of mountain beavers.

  Very brief summary: 2074 trap-nights throughout south and west
  seattle greenspaces.  275 distinct raccoon events, 295 possum
  events.  Both were equally nocturnal, same median camera capture
  time (about midnight), but raccoon capture time distributions were
  tilted towards the pre-midnight hours.  In recent rural studies of
  the same two species, no temporal niche separation was seen.

  One passing comment: Mark Jordan’s work includes (if I got this
  right) some population genetics studies which suggest that there is
  one possum population, but that raccoons are divided into two, one
  on each side of I5.

  I imagine that Mark Jordan might have other data relevant to small
  mammals at Seward, but the structure of today’s meeting did not
  allow me to ask.



*-----------------------------------------------------------------------------------------------------------------------
* add probe-level heatmap to cory's skin gene model visualization (13 dec 2016)

  cd ~/github/BDDS/trenadb/src/coryPGskin/

  --- first, build (retrieve?) probe level matrix
    pushd  ~/s/work/priceLab/cory/pgSkin/red

*-----------------------------------------------------------------------------------------------------------------------
* nbextension tips:  delete an extension (13 dec 2016)

  --- two possible installations
    jupyter nbextension list
    Known nbextensions:
      config dir: /Users/paul/.jupyter/nbconfig
        notebook section
      config dir: /Users/paul/anaconda/etc/jupyter/nbconfig
        notebook section
          cyjs/extension  enabled
            - Validating: OK


    grep -C1 cyjs ~/anaconda/etc/jupyter/nbconfig/notebook.json
       "jupyter-js-widgets/extension": true,
       "cyjs/extension": true,
       "jupyter-leaflet/extension": true,

   jupyter nbextension uninstall  cyjs
     Removing: /usr/local/share/jupyter/nbextensions/cyjs
       # does not update notebook.json: do that via manual editing





*-----------------------------------------------------------------------------------------------------------------------
* jupyter widget tips, ipywidgets tips: cell size, widget size (13 dec 2016)

  cd ~/s/examples/jupyter/resizeDiv/
  jupyter notebook resize.ipynb

*-----------------------------------------------------------------------------------------------------------------------
* jupyter widget tips, ipywidgets tips: basic template (12 dec 2016)

  cd ~/s/examples/jupyter/basicAllInNotebookTemplates

    resize.ipynb
    tabs.ipbynb


*-----------------------------------------------------------------------------------------------------------------------
* priyanka's first notebook (12 dec 2016)

   cd ~/s/work/priceLab/priyanka/metabolicNetworks/firstNotebook/

   --- email (9 dec 2016)

     Please find attached tab delimited text files containing the
     information in the format that you specified. I have currently
     considered only few reactions involved in glycolysis.  The flux file
     has flux values for the edge type.

   I have 2 queries:

      1) In some cases due to filtering step we might not capture a
      particular reaction. In such cases should we put a "0" value or
      a minimum value for the flux. In the file attached, I have
      currently given a minimum value for the reaction. But wanted to
      know what you think will be best to represent the missing
      values.

      2) For the connections of gene ---> reaction, should I give the
      expression value of the gene or the flux value of a reaction. In
      the attached file I have currently given the flux value.

*-----------------------------------------------------------------------------------------------------------------------
* Particulate Matter Exposure and Preterm Birth: Estimates of U.S. Attributable Burden and Economic Costs

  saved as ~/Documents/airQuality/pm25andPreTermBirth.pdf,   march 2016
  also Seattle Comprehensive Plan Update Draft EIS May 4, 2015, 3.2, Air Quality and Greenhouse Gas Emissions

     665110 Dec 12 12:45 pm25andPreTermBirth.pdf
    4301330 Dec 12 12:58 seattleAirQuality-EIS.pdf

*-----------------------------------------------------------------------------------------------------------------------
* for a sign in the nest bare ground spots


   --- version 1
the old growth forest floor is alive.

these trees depend upon it:  plants, fungi, insects, bacteria
and small mammals which live in and among fallen logs and branches
in all stages of decay.

we admire your devotion to the forest
but the form your devotion takes has here created a dead zone:
please refrain from revisiting this spot.
permit this old growth forest floor to return to life

  --- version 2
 The forest floor is alive.

 These trees depend upon the plants and fungi, insects and bacteria
 and small mammals which live among fallen logs and branches
 on undisturbed ground.

 We admire your devotion to the forest.
 But the form your devotion takes has here created a dead zone.
 Please refrain from revisiting this spot.  Please do not gather wood.
 Allow this old growth forest floor to return to life.

  --- version 3
 The forest floor is alive.

 The trees are connected and fed by earthen networks of fungi, moss
 and plants, of small mammals, microbes and insects, of leaf litter,
 logs and branches in all states of decay.

 We admire your devotion to the forest.
 But the form your devotion takes has here created a dead zone.
 Please refrain from revisiting this spot.  Please do not gather wood.
 Help this old growth forest floor to return to life.

  --- version 4
 The forest floor is alive.

 The trees are linked by earthen networks of fungi, moss,
 flowering plants, microbes, insects and small mammals. Leaf litter,
 logs and branches, in all states of decay, nourish this network.

 We admire your devotion to the forest.

 But the form your devotion takes has created a dead zone.
 Please refrain from revisiting this spot.  Please do not gather wood.
 Help this old growth forest floor to return to life.




*-----------------------------------------------------------------------------------------------------------------------
* the pearl harbor day bug, jupyter notebook, simple.ipynb, a pretty good self-contained python/js cyus widget (10 dec 2016)

   Jason Grout @jasongrout, Dec 09 18:48
   Sorry, I should be more specific. When working with dev versions, it helps to know the git commit hashes.
   But often even more important in these cases is the output of jupyter nbextension list
   @paul-shannon - often we find that there are multiple versions installed, and one version is masking another.
   to show the git commit, you can use git log -n 1


   cd ~/github/ipywidgets/

git log -n 1
commit 269a71f7d7ead1b6210f83bc8c71e6b27867bbd9
Author: Sylvain Corlay <sylvain.corlay@gmail.com>
Date:   Fri Dec 9 16:48:29 2016 +0100
    Fix environment

jupyter nbextension list
Known nbextensions:
  config dir: /Users/paul/.jupyter/nbconfig
    notebook section
      jupyter-js-widgets/extension  enabled
      - Validating: OK
      igv/igv-jupyter  enabled
      - Validating: OK
      bqplot/extension  enabled
      - Validating: OK
      jupyter-d3-circle-widget/extension  enabled
      - Validating: OK
      circle_npm/extension  enabled
      - Validating: OK
      jupyter-widget-example/extension  enabled
      - Validating: OK
      jupyter-threejs/extension  enabled
      - Validating: OK
  config dir: /Users/paul/anaconda/etc/jupyter/nbconfig
    notebook section
      nbpresent/js/nbpresent.min  enabled
      - Validating: OK
      circles-pkg/extension  enabled
      - Validating: OK
      jupyter-leaflet/extension  enabled
      - Validating: OK
      clustergrammer_widget/extension  enabled
      - Validating: OK
      nb_conda/main  enabled
      - Validating: OK
      jupyter-js-widgets/extension  enabled
      - Validating: OK
      nb_anacondacloud/main  enabled
      - Validating: OK
      cyjs/extension  enabled
      - Validating: OK
    tree section
      nb_conda/tree  enabled
      - Validating: OK


   --- possible answer:  i installed an  ill-formed cyjs nbextension which conflicts with every
       attempt to run simple.
       jupyter nbextension list
       jupyter nbextension --help
       jupyter nbextension uninstall --py cyjs
       jupyter nbextension list
       jupyter nbextension disable --py cyjs
       jupyter nbextension list

Known nbextensions:
  config dir: /Users/paul/.jupyter/nbconfig
    notebook section
      cyjs/extension disabled

  config dir: /Users/paul/anaconda/etc/jupyter/nbconfig
    notebook section
      cyjs/extension  enabled
      - Validating: problems found:
        - require?  X cyjs/extension

       test: rename the simple cyjs to cyjs2

  ---  find /Users/paul/anaconda/lib/python3.5 | grep -i cyjs
     /Users/paul/anaconda/lib/python3.5/site-packages/cyjs.egg-link
      46 Dec  9 09:21 /Users/paul/anaconda/lib/python3.5/site-packages/cyjs.egg-link
  cat /Users/paul/.jupyter/nbconfig/notebook.json
     {
       "load_extensions": {
         "jupyter-threejs/extension": true,
         "igv/igv-jupyter": true,
         "cyjs/extension": false,
         "jupyter-js-widgets/extension": true,
         "jupyter-widget-example/extension": true,
         "circle_npm/extension": true,
         "jupyter-d3-circle-widget/extension": true,
         "bqplot/extension": true
       }
     }

   cat /Users/paul/anaconda/etc/jupyter/nbconfig/notebook.json
     {
       "load_extensions": {
         "nb_anacondacloud/main": true,
         "jupyter-leaflet/extension": true,
         "nbpresent/js/nbpresent.min": true,
         "cyjs/extension": true,
         "circles-pkg/extension": true,
         "nb_conda/main": true,
         "jupyter-js-widgets/extension": true,
         "clustergrammer_widget/extension": true
       }
     }


*-----------------------------------------------------------------------------------------------------------------------
* a working cyjs-jupyter self-contained notebook (10 dec 2016)
  could not find
*-----------------------------------------------------------------------------------------------------------------------
* "error_stack" jupyter widget bug, in cyjs: create reproducible version for ipywidget guys, jason (9 dec 2016)

  --- problem occurs in simple:
    cd ~/github/cyjs-jupyter/self-contained-notebooks/simple/
    jupyter notebook simple.ipynb

  --- but more useful to jason will be in minimal version
     cd ~/github/cyjs-jupyter/self-contained-notebooks/pythonAdded/
     jupyter notebook errorStackBug.ipynb

  --- running simple in chrome gives more errors: related to latest 5.0.0 notebook?
     pip list | egrep 'notebook|widgets'
       ipywidgets (6.0.0b5, /Users/paul/github/ipywidgets)
       jupyterlab-widgets (0.6.3, /Users/paul/github/ipywidgets/jupyterlab_widgets)
       notebook (5.0.0.dev0, /Users/paul/github/notebook)
       widgetsnbextension (2.0.0b7, /Users/paul/github/ipywidgets/widgetsnbextension)

   cd ~/github/ipywidgets
   bash dev-install.sh


*-----------------------------------------------------------------------------------------------------------------------
* cookiecutter project for dora as nbextension (9 feb 2017)

  cd ~/github
  pip install cookiecutter  # all requirements already satisfied

*-----------------------------------------------------------------------------------------------------------------------
* cookiecutter project for cyjs as nbextension (8 dec 2016)

  cd ~/github/cyjs-jupyter
  pip install cookiecutter   # all requirements already satisfied
  cookiecutter https://github.com/jupyter/widget-cookiecutter.git
    author_name []: Paul Shannon
    author_email []: paul.thurmond.shannon@gmail.com
    github_project_name [jupyter-widget-example]: cyjs-jupyter
    github_organization_name [jupyter]:
    python_package_name [ipywidgetexample]: cyjs
    npm_package_name [jupyter-widget-example]: cyjs
    project_short_description [A Custom Jupyter Widget Library]: cytoscape.js in a Jupyter widget

  cd ~/github/cyjs-jupyter/cyjs-jupyter

   MANIFEST.in:  already (and only) specifies "recursive-include cyjs/static *.*"
   in cyjs/  (the python source directory) copied in code, dividing simple.ipynb into
        igraphHelpers.py
        cyjs.py:    added this, "@widgets.register('cyjs.cyjs')", may not be needed. does not solve jupyter lab problem
      __init__.py:   from .cyjs import *

   skipping RELEASE.md for now (for releasing via PyPI)
   setup.cfg: no changes needed
   setup.py:  no changes needed, "cyjs" well-represented.  note
       install_requires:[ 'ipywidgets>=5.1.5',]   # maybe need a later version for jupyter lab

   compare https://github.com/ipython/ipywidgets/blob/master/jupyter-js-widgets/package.json
   with ~/github/cyjs-jupyter/cyjs-jupyter/js/package.json, especially, these two fields.  at top
     {"name": "jupyter-js-widgets",
      "version": "2.0.12",

  "dependencies": {
    "@jupyterlab/services": "^0.34.2",
    "jupyter-widgets-schema": "^0.1.1",
    "@types/backbone": "^1.3.33",
    "@types/semver": "^5.3.30",
    "ajv": "^4.9.0",
    "backbone": "1.2.0",
    "d3-format": "^0.5.1",
    "font-awesome": "^4.5.0",
    "jquery": "^3.1.1",
    "jquery-ui": "^1.12.1",
    "lolex": "^1.4.0",
    "phosphor": "^0.7.0",
    "scriptjs": "^2.5.8",
    "semver": "^5.1.0",
    "underscore": "^1.8.3"}



*-----------------------------------------------------------------------------------------------------------------------
* python url exists (7 dec 2016)

   import requests
   r = requests.get('http://localhost:8099/js/cytoscape-2.7.10.js')
   assert(r.status_code == 200)

*-----------------------------------------------------------------------------------------------------------------------
* cory proctor & gamble skin footprints, col1a1 (6 dec 2016)

  cd ~/github/BDDS/trenadb/src/coryPGskin/
  col1a1.R

  expression data, osiris:/proj/pngisb/rk/red  -- copied to
  ~/s/work/priceLab/cory/pgSkin/red/

   file: assembleMatrix.R

*-----------------------------------------------------------------------------------------------------------------------
* hamid's celgene network (5 dec 2016)

  cd ~/s/work/hamid/celgene01
  see renderNetwork.R, layout.RData, style.js
  sent celgene.tar to hamid (22 dec 2016)

*-----------------------------------------------------------------------------------------------------------------------
* igraph layout problem with directed graph (5 dec 2016)

posted to https://github.com/igraph/python-igraph/issues/106

from igraph import *
tbl = [['R1', 'a'],
       ['R1',  'b'],
       ['R1',  'c']]
#       ['g1',  'R1'],
#       ['R2',  'a']]
#       ['R2',  'd'],
#       ['R2',  'e'],
#       ['g2',  'R2'],
#       ['g3',  'R2'],
#       ['R3',  'c'],
#       ['R3',  'f'],
#       ['R3',  'h'],
#       ['R3',  'i'],
#       ['g4',  'R3'],
#       ['g5',  'R3'],
#       ['R4',  'x'],
#       ['R4',  'y'],
#       ['R4',  'z'],
#       ['R4',  'w'],
#       ['g6',  'R4'],
#       ['R5',  'z'],
#       ['R5',  'z1']]

vertices = list(set([x for row in tbl for x in row]))
gDirected = Graph(directed=True)

gDirected.add_vertices(vertices)
gDirected.add_edges(tbl)
ftd = gDirected.layout("reingold_tilford")
print("--- reingold_tilford layout of a directed graph")
for i in range(len(ftd)):   # just the y coordinaes, to display the problem
    print("%f, %f" % (ftd[i][0], ftd[i][1]))

gUndirected = Graph(directed=False)
gUndirected.add_vertices(vertices)
gUndirected.add_edges(tbl)
ftu = gUndirected.layout("reingold_tilford")
print("--- reingold_tilford layout of the same graph, this time undirected")
for i in range(len(ftu)): # again, just the y
    print("%f, %f" % (ftu[i][0], ftu[i][1]))


*-----------------------------------------------------------------------------------------------------------------------
* sdot, annualpermits, signs, audubon

  from carol, at
   Annualpermits@seattle.gov  | Public Space Management | Seattle Department of Transportation |
                                 Street Use Division| 206-684-5267 (Tel)

  This is in response to your recent voicemail.  I consulted with my supervisor who suggested you address the SDOT letter to:

  Audra Brecher, Team Lead
  Public Space Management, Street Use Division
  Seattle, Department of Transportation
   P.O. Box 34996
   Seattle, WA 98124-4996

   Ms. Brecher can also be emailed at audra.brecher@seattle.gov.


*------------------------------------------------------------------------------------------------------------------------
* phytophthora sampling from 2016 1-gallon pots (3 dec 2016)


   1) just one sample per species? 4 plants per species and one sample
   per plant, with good representation of nurseries. I have attached
   the file with the sample numbers. Fill this out and email it back
   to me when you get the info. The nurseries can be identified by
   number if you don’t have names. The names will be kept confidential
   in any publications or reports.

   2) water the sample plants (in their pots) the evening before
   sampling

   3) each sample plant is represented by one bag of leachate,
   captured from below when I pour 300ml into the potted plant at the
   base of the plant (the center of the pot). Correct. The easiest way
   is to put the pot inside the bag and allow the water to flow
   through the drainage holes into the bag.

   4) I label each bag for species, nursery, and collection time.  I
   place a Rhododendron macrophylla leaf in each bag.  The bags may
   need to be doubled to protect against leakage. Yes. The leaf should
   be cut in half and both halves put in the bag.

   5) I drive the bags to WSU Puyallup next Wednesday morning,
   arriving about 10 am. I will be out of the office on weds at the
   native plant conference but maybe Katie will be here. The samples
   should go in the SOD lab. I will be back on Friday if weds doesn’t
   work. Or you can mail the samples to me.

  COCO	Corylus cornuta, beaked hazelnut
  MANE	Mahonia nervosa, dwarf Oregon grape
  OECE	Oemleria cerasiformis, indian plum
  PSME	Pseudotsuga menziesii, Douglas fir
  RUPA	Rubus parviflorus, thimbleberry
  RUSP	Rubus spectabilis, salmonberry
  RUUR	Rubus ursinus, trailing blackberry


*-----------------------------------------------------------------------------------------------------------------------
* clustergrammer, create simple demo (3 dec 2016)

  cd ~/github/clustergrammer-widget/
  make
  tbl <- data.frame(cond1=100 * runif(10, -1, 1), cond2=100 * runif(10, -1, 1), cond3=100 * runif(10, -1, 1), cond4=100 * runif(10, -1, 1))
  tbl$cond5 <- jitter(tbl$cond3, amount=30)
  rownames(tbl) <- LETTERS[1:10]
  write.table(tbl, file="tiny.tsv", quote=FALSE, sep="\t")

  mtx <- matrix(runif(2500, -10, 10), nrow=50, ncol=50)
  colnames(mtx) <- sprintf("cond%02d", 1:50)
  rownames(mtx) <- sprintf("gene%02d", 1:50)
  tbl <- as.data.frame(mtx)
  tbl$cond05 <- jitter(tbl$cond03, amount=30)
  tbl$cond11 <- jitter(tbl$cond03, amount=20)
  tbl$cond16 <- jitter(tbl$cond03, amount=10)
  tbl$cond22 <- jitter(tbl$cond03, amount=2)
  write.table(tbl, file="tbl50x50.tsv", quote=FALSE, sep="\t")

  mtx <- matrix

*------------------------------------------------------------------------------------------------------------------------
* circles won't run in latest jupyter lab (2 dec 2016)

   --- my question at gitter
     my extension (https://github.com/paul-shannon/jupyter-widget-demo-nbextension) runs fine in classic notebook,
     but fails in the latest jupyter lab, with this error message:
       [IPKernelApp] WARNING | Widget Javascript not detected. It may not be installed or enabled properly.
     Any suggestions on how I can track this down?

   --- to which jason grout replies
     what version of the notebook, of ipywidgets, and jupyterlab_widgets do you have installed?
     likely one is out of date with another, so the widgets aren't loading in jupyterlab

     jupyter --version            # 4.1.0
     jupyter notebook --version   # 4.2.3
     cat ~/github/ipywidgets/ipywidgets/_version.py   # version_info = (6, 0, 0, 'beta4')

   --- updated jupyter_core
      git clone https://github.com/jupyter/jupyter_core.git
      pip install -e .
      jupyter --version           # 4.3.0.dev

   --- updated ipywidgets
      cd ~/github/ipywidgets
      git pull origin
      cat ipywidgets/_version.py
         version_info = (6, 0, 0, 'beta5')
         __frontend_version__ = '^2.0.9'

   --- updated jupyterlab
      cd ~/github/jupyterlab/
      git pull origin
      cat jupyterlab/_version.py   # __version__ = "0.11.1"
      npm install
      pip install -e .
      npm test       # some failures reported at end

   --- does it work with circles?

*------------------------------------------------------------------------------------------------------------------------
* python tips: unique elements of a 2d array

   vertices = set([x for row in tbl for x in row])

*------------------------------------------------------------------------------------------------------------------------
python tips: learn versions of all loaded  modules:

     import sys
     for name, module in sorted(sys.modules.items()):
        if hasattr(module, '__version__'):
           print(name, module.__version__)

   --- in circles (cd ~/github/jupyter-widget-demo-nbextension; make | jupyter notebook circles.ipynb)
       circles                                       lab
     IPython 4.1.2                                Python 4.1.2
     IPython.core.release 4.1.2                   IPython.core.release 4.1.2
     _ctypes 1.1.0                                _ctypes 1.1.0
     _curses b'2.2'                               _curses b'2.2'
     argparse 1.1                                 argparse 1.1
     circles 0.1.2.dev                            ctypes 1.1.0
     circles._version 0.1.2.dev                   ctypes.macholib 1.0
     ctypes 1.1.0                                 decorator 4.0.9
     ctypes.macholib 1.0                          distutils 3.5.2
     decorator 4.0.9                              ipykernel 4.5.1
     distutils 3.5.2                              ipykernel._version 4.5.1
     ipykernel 4.5.1                              ipython_genutils 0.1.0
     ipykernel._version 4.5.1                     ipython_genutils._version 0.1.0
     ipython_genutils 0.1.0                       ipywidgets 6.0.0.beta4
     ipython_genutils._version 0.1.0              ipywidgets._version 6.0.0.beta4
     ipywidgets 6.0.0.beta4                       json 2.0.9
     ipywidgets._version 6.0.0.beta4              jupyter_client 4.2.2
     json 2.0.9                                   jupyter_client._version 4.2.2
     jupyter_client 4.2.2                         jupyter_core 4.1.0
     jupyter_client._version 4.2.2                jupyter_core.version 4.1.0
     jupyter_core 4.1.0                           logging 0.5.1.2
     jupyter_core.version 4.1.0                   optparse 1.5.3
     logging 0.5.1.2                              parser 0.5
     optparse 1.5.3                               path 0.0.0
     parser 0.5                                   pexpect 4.0.1
     path 0.0.0                                   pickleshare 0.5
     pexpect 4.0.1                                pkg_resources._vendor.packaging.__about__ 16.5
     pickleshare 0.5                              pkg_resources._vendor.six 1.10.0
     pkg_resources._vendor.packaging.__about__ 16.pkg_resources.extern.packaging 16.5                           5
     pkg_resources._vendor.six 1.10.0             pkg_resources.extern.pyparsing 2.0.6
     pkg_resources.extern.packaging 16.5          pkg_resources.extern.six 1.10.0
     pkg_resources.extern.pyparsing 2.0.6         platform 1.0.7
     pkg_resources.extern.six 1.10.0              ptyprocess 0.5
     platform 1.0.7                               re 2.2.1
     ptyprocess 0.5                               six 1.10.0
     re 2.2.1                                     traitlets 4.3.1
     six 1.10.0                                   traitlets._version 4.3.1
     traitlets 4.3.1                              zlib 1.0
     traitlets._version 4.3.1                     zmq 15.2.0
     zlib 1.0                                     zmq.sugar 15.2.0
     zmq 15.2.0                                   zmq.sugar.version 15.2.0
     zmq.sugar 15.2.0
     zmq.sugar.version 15.2.0



*-----------------------------------------------------------------------------------------------------------------------
* install jupyter lab development version (2 dec 2016)

   conda install -c javascript nodejs     # nodejs: 4.4.0-0 javascript
   conda install notebook                 # notebook: 4.2.1-py35_0 --> 4.2.3-py35_0
   conda install nb_conda_kernels         #      _nb_ext_conf:     0.3.0-py35_0
                                          #    nb_anacondacloud: 1.2.0-py35_0
                                          #    nb_conda:         2.0.0-py35_0
                                          #    nb_conda_kernels: 2.0.0-py35_0
                                          #    nbpresent:        3.0.2-py35_0
   cd ~/github
   git clone https://github.com/jupyterlab/jupyterlab.git
   cd jupyterlab
   npm install
   pip install -e . # will take a long time to build everything
   jupyter serverextension enable --py jupyterlab
   npm test
      these tests failed:
       console/content
         ConsoleContent
           ✖ "before each" hook for "should create a new console content widget"
           ✖ "after each" hook for "should create a new console content widget"
       console/foreign
         ForeignHandler
           #enabled
             ✖ "before each" hook for "should default to `true`"
             ✖ "after each" hook for "should default to `true`"
           #kernel
             ✖ should be resettable
           #onIOPubMessage()
             ✖ "before each" hook for "should be called when messages come through"
             ✖ "after each" hook for "should be called when messages come through"
       console/history
         ✖ "before each" hook for "should create a new console history object"
         ✖ "after all" hook

    --- run examples
         jupyter --version  # 4.1.0
         jupyter lab --version  # 0.11.1


*------------------------------------------------------------------------------------------------------------------------
* test circles nbextension widget with latest jupyter and ipywidgets (30 nov 2016)

  cd ~/github/jupyter-widget-demo-nbextension
  cd circles.egg-info
  PKG-INFO has this line:
    Version: 0.1.1.dev    # my new value, today
  ~/github/jupyter-widget-demo-nbextension/circles/_version.py has this line
      version_info = (0, 1, 1, 'dev')
      __version__ = '.'.join(map(str, version_info))

  experimented with this line in the makefile:
  #	npm install
	pip install -e .

  --- po

  --- could not force a new installation, saw that old circle-pkg still used:
    jupyter nbextension install --py circles
    Installing /Users/paul/s/examples/jupyter/hello-cookieCutter/jupyter-d3-circles-widget/circles/static -> circles-pkg

  --- possible explanation, from the ipython/ipywidgets gitter board (5 dec 2016)

    @ssunkara1 I'm not sure about Windows and your specific situation,
    but using the --sys-prefix flag when installing/uninstalling packages
    using pip (which is what most of the Jupyter docs suggest doing) will
    use the sys.prefix path (which for me is
    /Users/grant/anaconda/etc/jupyter) while omitting it will use the user
    path (which for me is /Users/grant/.jupyter). I recommend using one or
    the other exclusively to avoid these types of issues. I also recommend
    uninstalling your jupyter installation extensions from whichever path
    you decide not to use.  _

  --- looking for remedy
     chmod 0 /Users/paul/s/examples/jupyter/hello-cookieCutter/jupyter-d3-circles-widget/circles/static/
   did not help
     mv ~/s/examples/jupyter/hello-cookieCutter ~/s/examples/jupyter/hello-cookieCutter-hidden

   jupyter nbextension install --py circles
   Installing /Users/paul/github/jupyter-widget-demo-nbextension/circles/static -> circles-pkg
   Out of date: /usr/local/share/jupyter/nbextensions/circles-pkg/extension.js
   Copying: /Users/paul/github/jupyter-widget-demo-nbextension/circles/static/extension.js -> /usr/local/share/jupyter/nbextensions/circles-pkg/extension.js
   Out of date: /usr/local/share/jupyter/nbextensions/circles-pkg/index.js
   Copying: /Users/paul/github/jupyter-widget-demo-nbextension/circles/static/index.js -> /usr/local/share/jupyter/nbextensions/circles-pkg/index.js
   Out of date: /usr/local/share/jupyter/nbextensions/circles-pkg/index.js.map
   Copying: /Users/paul/github/jupyter-widget-demo-nbextension/circles/static/index.js.map -> /usr/local/share/jupyter/nbextensions/circles-pkg/index.js.map
   - Validating: OK

   --- disposition: now fixed
     never did track down why ~/s/examples/jupyter/hello-cookieCutter/jupyter-d3-circles-widget/circles/static was used
     must be that this information was cached in the python library directory structures.

*-----------------------------------------------------------------------------------------------------------------------
* update all jupyter after latest pull of ~/github/ipywidgets (30 nov 2016)

  --- update notebook   (8 dec 2016, 4.2.3; took steps below: 5.0.0.dev
    cd ~/github/notebook/
    git pull origin
    pip install -e . --user

  ---- update anaconda
     conda --version  # 4.1.11
     conda update anaconda
     https://www.continuum.io/downloads   # chose the python 3.5 installer  this fails with suggestion to do "conda update ..."
     conda --version 4.2.13

  ---- try to update jupyter with conda
  conda update jupyter
  jupyter --version   # 4.1.0

   --- jupyter 4.2?

   ---- resolution
   pip list | egrep 'notebook|widgets'
     ipywidgets (6.0.0b4, /Users/paul/github/ipywidgets)
     jupyterlab-widgets (0.6.1, /Users/paul/github/ipywidgets/jupyterlab_widgets)
     notebook (4.2.1)
     widgetsnbextension (2.0.0b4, /Users/paul/github/ipywidgets/widgetsnbextension)


*------------------------------------------------------------------------------------------------------------------------
* igraph tips

   --- get id (index) for nodes by name
    g.vs.find("R5").index   # 4
    [g.vs.find(x).index for x in g.vs['name']]

   --- great dict map for resolving names to ids
     names = g.vs['name']
     ids = [g.vs.find(name).index for name in g.vs['name']]
     nodeMap = dict(zip(names, ids))
     nodeMap["R3"] # 2

   --- create graph from tab delimited sif file, and type.noa, assign random numerical edge attribute
      from igraph import *
      import random
      networkFile = "toynetwork.tsv"
      nodeAttributesFile = "type.noa"
      lines = open("toynetwork.tsv").readlines()
      tbl_rel = []
      for line in lines:
         tokens = line.rstrip("\n").split("\t")
         tokens = [x.strip() for x in tokens]
         if(len(tokens) == 3):
            tbl_rel.append(tokens)
      lines = open("type.noa").readlines()
      nodeTypes={}
      for line in lines:
         (node, type) = line.rstrip("\n").split("\t")
         nodeTypes[node.strip()] = type.strip()
      g = Graph()
      nodeNames = [x for x in iter(nodeTypes)]
      nodeTypeValues = [x for x in nodeTypes.values()]
      g.add_vertices(nodeNames)
      g.vs['type'] = nodeTypeValues
      for row in tbl_rel:
        g.add_edge(row[0], row[2])
      g.es['edgeType'] = [x[1] for x in tbl_rel]
      g.es()['flux'] = random.sample(range(0, 1000), len(g.es()))
      from_igraph(g)


   --- create from tab-delimited edge file
   from igraph import *
   import itertools
   lines = open("test.tsv").readlines()
   ab = []
   for line in lines:
      ab.append(line.split("\t"))
   g = Graph()
   nodes = set(list(itertools.chain(*ab)))
   g.add_vertices(nodes)
   len(g.vs)  # 9
   len(g.es)  # 0

   --- better yet
    g2 = Graph.TupleList(ab)
    summary(g2, full=True)   # header line and list of edges
      IGRAPH UN-- 9 7 --
      + attr: name (v)
      + edges (vertex names):
      M_10fthf6glu_m--R_FPGS9m
      , R_FPGS9m
      --M_glu_DASH_DASH_DASH_L_m, R_FPGS9m--M_10fthf7glu_m
      , R_FPGS9m--M_pi_m
      , M_pi_m
      --R_PPCOACm, M_pi_m
      --R_SUCOAS1m, M_pi_m
      --R_SUCOASm

   --- learn vertex names
   for v in g.vs:
      print(v['name'])

   --- get them all at once
      g.vs['name'] #  ['A1', 'B1', 'B2']

   --- assign node attributes
      g.vs['type'] = ["tf", "target", "target"]

   --- what attributes are defined?
     g.vs.attribute_names()  # ['name', 'type']
     g.es.attribute_names()  # []
     g.vs['name']            # ['A1', 'B1', 'B2']
     g.vs['type']            # ['tf', 'target', 'target']

   --- get indices of node (vertex) names which match a pattern
   b_indices = [i for i, j in enumerate(g.vs['name']) if re.search("^B", j)]
   a_indices = [i for i, j in enumerate(g.vs['name']) if re.search("^A", j)]
   g.vs()[b_indices]['type'] = 'Btype'
   g.vs()[a_indices]['type'] = 'Atype'
   g.vs()['type']   # ['Atype', 'Btype', 'Btype']
   g.vs()['id'] = g.vs()['name']


  --- igraph assign nodes (assign vertices) from the keys of a dict
    nodeNames = [x for x in iter(nodeTypes)]
    nodeTypes = [x for x in nodeTypes.values()]
    g = Graph()
    g.add_vertices(nodeNames)


*------------------------------------------------------------------------------------------------------------------------
* python igraph tips (29 nov 2016)

  http://igraph.org/python/ suggests:

     Instead of letting pip compile the C core for you, you can
     install Homebrew and the homebrew/science/igraph formula. This
     will ensure that the C core is found by pip so running pip
     install python-igraph will compile the Python interface only and
     link it to the C core.

   /usr/local/bin/brew   # version 0.9.9 2016-07-02
   brew install homebrew/science/igraph
      Warning: homebrew/science/igraph-0.7.1_3 already installed

    brew install cairo --use-clang
    brew install py2cairo



*------------------------------------------------------------------------------------------------------------------------
* priyanka's initial demo, drives cyjs jupyter widget development "simple", a first self-contained cyjs notebook (5 dec 2016)

   cd ~/github/cyjs-jupyter/self-contained-notebooks/simple/
   data:
      22 line toynetwork.tsv
      26 line type.noa

    head toynetwork.tsv
      R1	consumes	a
      R1	consumes	b
      R1	produces	c
      g1	catalyzes	R1
      R2	consumes	a
      R2	consumes	d
      R2	produces	e
      g2	catalyzes	R2
      g3	catalyzes	R2
      R3	consumes	c

    head type.noa
      R1	reaction
      R2	reaction
      R3	reaction
      R4	reaction
      R5	reaction
      a	metabolite
      b	metabolite
      c	metabolite


    ---- build a toy & fake flux table
    reactions <- subset(read.table("type.noa", sep="\t", as.is=TRUE), V2=="reaction")$V1   # [1] "R1" "R2" "R3" "R4" "R5"
    conds <- paste("cond", 1:3, sep="")
    count <- length(reactions) * length(conds)
    set.seed(17)
    mtx <- matrix(data=as.integer(1000 * runif(count)), nrow=length(reactions),
                  dimnames=list(reactions, conds))
    tbl.flux <- as.data.frame(matrix(data=as.integer(1000 * runif(count)),
                              nrow=length(reactions), dimnames=list(reactions, conds)))

    write.table(tbl.flux, file="flux.tsv", sep="\t", row
*------------------------------------------------------------------------------------------------------------------------
* igraph to json

  https://gist.github.com/jboynyc/11dcd73b84f8da02490e6654d5c07700
  https://rpubs.com/keiono/cyrest2
  https://github.com/idekerlab/py2cytoscape/blob/develop/py2cytoscape/util/util_igraph.py
  ~/github/py2cytoscape/

   --- ~/s/work/priceLab/priyanka/metabolicNetworks/try0/try0.ipynb
from igraph import *
import json
exec(open("/Users/paul/github/py2cytoscape/py2cytoscape/util/util_igraph.py").read())
g = Graph.Read_Ncol("test.tsv")
g.json = from_igraph(g)


*------------------------------------------------------------------------------------------------------------------------
* priyanka, a metabolic network (29 nov 2016)

   cd ~/s/work/priceLab/priyanka/metabolicNetworks/try0/
   a 4494 line metabolic network.  but see jupyter notebook

   --- from email
     Please find attached the file containing metabolic network. I have
     removed the edges with very high connectivity since they consisted
     of nodes such as h2o, atp, nad etc.

     I have the data related to reaction fluxes which needs to be
     mapped. I will take your advice whether to represent that as node
     weight or edge weight in the network.

     We can discuss this in more details to get meaningful results from
     this analysis :)

   --- 4494 lines, appears to be
      grep R_FPGS9m Network_for_metabolic_model_removing_highnodes.txt
         M_10fthf6glu_m	R_FPGS9m
         M_glu_DASH_DASH_DASH_L_m	R_FPGS9m
         R_FPGS9m	M_10fthf7glu_m
         R_FPGS9m	M_pi_m


   ---- create a 7 line, 8 node graph
     grep R_FPGS9m Network_for_metabolic_model_removing_highnodes.txt  > test.tsv
     grep M_pi_m Network_for_metabolic_model_removing_highnodes.txt | tail -3 >> test.tsv
     from igraph import *
     g = Graph.Read_Ncol("test.tsv")

   --- ~/s/work/priceLab/priyanka/metabolicNetworks/try0/try0.ipynb
     from igraph import *
     import json
     exec(open("/Users/paul/github/py2cytoscape/py2cytoscape/util/util_igraph.py").read())
     g = Graph.Read_Ncol("test.tsv")
     g.json = from_igraph(g)

   --- now use this json in the under-development, all-in-notebook cyjs-jupyter


*------------------------------------------------------------------------------------------------------------------------
* ipython_thread.py: does work in a thread, updates a progressbar.  runs in ipython.  study this! (28 nov 2016)

   https://gist.github.com/maartenbreddels/3378e8257bf0ee18cfcbdacce6e6a77e
   cd ~/s/examples/ipython/threads
   must be in a notebook:
   jupyter notebook maartenbreddels.ipynb

*------------------------------------------------------------------------------------------------------------------------
* convert notebook to, eg, html (28 nov 2016)

  cd ~/github/cyjs-jupyter/self-contained-notebooks/simple/

  jupyter nbconvert --to html --execute --ExecutePreprocessor.timeout=60 --output out_file simple.ipynb
   [NbConvertApp] Converting notebook simple.ipynb to html
   [NbConvertApp] Executing notebook with kernel: python3
   [NbConvertApp] Writing 258638 bytes to out_file.html
  book.simple> open out_file.html

   ---- error
    cy = cyjsWidget()
    cy

    Widget Javascript not detected.  It may not be installed
    properly. Did you enable the widgetsnbextension? If not, then run
    "jupyter nbextension enable --py --sys-prefix widgetsnbextension"


*------------------------------------------------------------------------------------------------------------------------
* jason grout: new versions ipywidgets, widgetsnbextension, and jupyterlab_widgets (29 nov 2016)

  tried again after jason suggested

      Can you delete your node_modules directory and run npm install
      again? The logs we want to see are in the install phase, not the
      build phase.

    cd ~/github/ipywidgets/jupyter-js-widgets
    rm -rf node_modules
    cd ..
    git pull origin # to get the lodash downgrade mentioned at
        https://gitter.im/ipython/ipywidgets
     bash dev-install.sh
         Installed /Users/paul/github/ipywidgets
         Successfully installed ipykernel-4.5.1 ipywidgets traitlets-4.3.1
      and
      Installing /Users/paul/github/ipywidgets/widgetsnbextension/widgetsnbextension/static -> jupyter-js-widgets
     - Validating: OK
       jupyter nbextension enable widgetsnbextension --py
       Enabling notebook extension jupyter-js-widgets/extension...
      - Validating: OK
       0.8.0
       jupyter lab is installed


*------------------------------------------------------------------------------------------------------------------------
* jason grout: new versions ipywidgets, widgetsnbextension, and jupyterlab_widgets (28 nov 2016)

  at jason's (implied) suggestion, i upgraded node from 4.4.7 to 6.9.1, which comes with npm version 3.10.8

  cd ~/github/ipywidgets/
  bash dev-install.sh --sys-prefix

  --- fails with missing underscore
   > jupyter-js-widgets@2.0.7 build:src /Users/paul/github/ipywidgets/jupyter-js-widgets
   > tsc --project src

src/manager-base.ts(4,20): error TS2307: Cannot find module 'underscore'.


  jupyter notebook --version  # 4.2.1
  cd ~/github/jupyterlab; git pull origin
*-----------------------------------------------------------------------------------------------------------------------
* jason grount: new versions ipywidgets, widgetsnbextension, and jupyterlab_widgets (28 nov 2016)

  jupyter notebook --version  # 4.2.1
  cd ~/github/jupyterlab; git pull origin
  cd ~/github/ipywidgets; git pull origin   # included widgetsnbextension/

   grep version ~/github/ipywidgets/jupyter-js-widgets/package.json   #   "version": "2.0.7",
   grep version ~/github/ipywidgets/widgetsnbextension/package.json   #   "version": "2.0.7",
   grep version ~/github/jupyterlab/package.json                      #   "version": "0.10.0",

  --- installing new version of ipywidgets via github (the "developer install")
    need npm version 3.x or later   # npm -v -> 2.15.8
    therefore:
       sudo  npm install -g npm    # 4.0.2
   cd ~/github/ipywidgets
   bash dev-install.sh --sys-prefix
     failed in jupyter-js-widgets; npm install, npm dedupe, hanging with this message
      ⸨░░░░░░░░░░⠂⠂⠂⠂⠂⠂⠂⠂⸩ ⠦ loadAllDepsIntoIdealTree: sill loadAllDepsIntoIdealTree  C-c C-c

  ---  therefore falling back to non-developer install:
     pip install ipywidgets   # reports that all requirements are already satisfied, but they are OLD!
        ipywidgets in /Users/paul/anaconda/lib/python3.5/site-packages
        traitlets>=4.2.1 in /Users/paul/anaconda/lib/python3.5/site-packages (from ipywidgets)
        ipython>=4.0.0 in /Users/paul/anaconda/lib/python3.5/site-packages (from ipywidgets)
        widgetsnbextension>=1.2.6 in /Users/paul/anaconda/lib/python3.5/site-packages (from ipywidgets)
        ipykernel>=4.2.2 in /Users/paul/anaconda/lib/python3.5/site-packages (from ipywidgets)
        notebook>=4.2.0 in /Users/paul/anaconda/lib/python3.5/site-packages (from widgetsnbextension>=1.2.6->ipywidgets)
     jupyter nbextension enable --py widgetsnbextension




*-----------------------------------------------------------------------------------------------------------------------
* expression matrices for cory's AD talk (27 nov 2016)

  --- email (15 nov 2016)
    The new datasets are on whovian: /local/Cory/Alzheimers/repo_counts
    There are 3 separate data sets that are uniformly processed:
      mayo_CBE_counts_matrix_normalized.txt
      mayo_TCX_counts_matrix_normalized.txt
      rosmap_counts_matrix_normalized.txt

  --- consider using ~/s/work/priceLab/cory/module-109/digestExpressionMatrices.R
     236591678 Nov 21 18:58 /Volumes/local/Cory/Alzheimers/repo_counts/mayoCBE_quant_matrix_normalized.txt  # no
     268194591 Nov 15 12:27 /Volumes/local/Cory/Alzheimers/repo_counts/mayo_TCX_counts_matrix_normalized.txt
     589655335 Nov 15 12:55 /Volumes/local/Cory/Alzheimers/repo_counts/rosmap_counts_matrix_normalized.txt


*-----------------------------------------------------------------------------------------------------------------------
* single gene and meta network rcyjs for cory, nov 2016 AD talk (27 nov 2016)

  cd  ~/github/BDDS/trenadb/src/coryADpresentationNov2016/
  sources ~/github/BDDS/trenadb/src/renderGeneModel.R
      2743 Nov 23 15:38 metaNetwork.R
       463 Nov 27 11:55 singleGeneModelDemo.R
      2732 Nov 27 11:27 metaNetwork-top-10-tfs-hits-39-genes.R

  --- style files
    2161 Nov 27 11:53 style-purityControlsNodeSize.js
    2753 Nov 23 15:38 style-reducedGraph-footprintCountsIgnored.js
    2745 Nov 23 15:38 style-reducedGraph.js
    2175 Nov 23 15:38 style.js


*-----------------------------------------------------------------------------------------------------------------------
* code for cory and his washington AD talk (23 nov 2016)
  cd ~/github/RCyjs; git pull origin; R CMD install .
  cd ~/github/BDDS/trenadb/src; git pull origin
  cd ~/github/BDDS/trenadb/src/coryADpresentationNov2016
  start R
 source(“metaNetwork.R”)

  The only adjustment you need is that the script reads your data from
  a path you will probably need to change.  I mount whovian /local via
  vpn and smb (using my macbook’s Finder):

   table.names <- load("/Volumes/local/Cory/for_Paul/all_targets.RData”)

   (this takes advantage of the load command, which reads in all of
   the serialized in your all_targets.RData file, and returns the
   variable names).

   fix that path, and it should all just work.

   Make sure that this is true for you:  packageVersion("RCyjs”) >= ‘1.7.5'

*-----------------------------------------------------------------------------------------------------------------------
* rcyjs tips:  align selected nodes horizontall or vertically, hAlign, vAlign (22 nov 2016)

  see also: ~/github/BDDS/trenadb/src/renderGeneModel.R

   hAlign <- function(rcy) {
     selected.node.ids <- getSelectedNodes(rcy)$id
     if(length(selected.node.ids) == 0){
         printf("no nodes selected, nothing to hAlign")
         return()
         }
     tbl.pos <- getPosition(rcy, selected.node.ids)
     tbl.pos$y <- mean(tbl.pos$y)
     setPosition(rcy, tbl.pos)
     } # hAlign

   vAlign <- function(rcy){
     selected.node.ids <- getSelectedNodes(rcy)$id
     if(length(selected.node.ids) == 0){
        printf("no nodes selected, nothing to vAlign")
        return();
        }
     tbl.pos <- getPosition(rcy, selected.node.ids)
     tbl.pos$x <- mean(tbl.pos$x)
     setPosition(rcy, tbl.pos)
     } # vAlign


*-----------------------------------------------------------------------------------------------------------------------
* meta-network for cory's AD nov2016 talk (22 nov 2016)

  cd ~/s/work/priceLab/cory/ADtalk-nov2016/
  file: metaNetwork.R

*-----------------------------------------------------------------------------------------------------------------------
* update jupyter widgets

   cd ~/github/ipywidgets/
   git pull origin
   bash dev-install.sh --sys-prefix

*-----------------------------------------------------------------------------------------------------------------------
* renderGeneModel, revisited (21 nov 2016)

  also see below renderGeneModel (18 nov 2016)

  --- archived and subsequently maintained as
    ~/github/BDDS/trenadb/src/renderGeneModel.R

  --- working area
    cd ~/s/work/priceLab/cory/module-109/anyGene.R

  --- cory reports bug: just one gene drawn in one footprint, even if the gene likely binds in multiple footprints

    I have a couple points on the visualization to ask about. I've
    built a model of TREM2 with several different shoulder lengths. If
    the shoulder is 5,000 (or even 2,000), then ELF4 has some nice
    beta and purity scores at position 1413. If I build TREM2 with a
    10,000 shoulder, ELF4 has great scores but is now at position
    7879.

    This is interesting biology. The more motifs a given TF has in
    close proximity to the TSS, the greater the likelihood it's
    active. Would there be a way to visualize the the multiple
    positions of a TF potentially binds to? Another interesting test
    case might be TYROBP which has great scores for SPI1 at -1063. I'm
    guessing the SPI1 motif is found multiple time in that
    promoter. It might be an edge case of when there are too many
    motifs (based on my knowledge of SPI1 frequency).


*-----------------------------------------------------------------------------------------------------------------------
* python threading: does it work in a jupyter notebook (20 nov 2016)

  cd ~/s/examples/python/threads

  2 console experiments:
     demo.py
     ThreadSubclass.py
     exec(open("ThreadSubclass.py").read())

  jupyter notebook: threadExperiments.ipynb

  --- now turn to cyjs demo


*-----------------------------------------------------------------------------------------------------------------------
 A World Made by Men: Cognition and Society, 400-1200 by Charles M. Radding
  Review by: John J. Contreni,    Speculum, Vol. 63, No. 3 (Jul., 1988), pp. 709-714
*-----------------------------------------------------------------------------------------------------------------------
* pemco, auto insurance for leo (18 nov 2016)

  1‑800‑467‑3626
  leo's wa driver license: SHANNLD023L2, Expires 06-22-2021
  I never got any accident summary but my agent is David Wenzler at Met Life 425-614-1112

*-----------------------------------------------------------------------------------------------------------------------
* renderGeneModel (18 nov 2016)

  --- developed originally as
    ~/s/work/priceLab/cory/module-109/anyGene.R

  --- archived and subsequently maintained as
    ~/github/BDDS/trenadb/src/renderGeneModel.R
    uses RCyjs, style.js, transformed (cleaned up) expression matrices, starting with
       rosmap_rnaseq_fpkm_geneSymbols_24593x638.RData
    using ~/github/BDDS/trenadb/src/digestExpressionMatrices.R
    from
   dir /Volumes/local/Cory/Alzheimers/repo_counts/*normalized.txt
      267M  Nov 15 12:29 /Volumes/local/Cory/Alzheimers/repo_counts/mayo_CBE_counts_matrix_normalized.txt
      268M  Nov 15 12:27 /Volumes/local/Cory/Alzheimers/repo_counts/mayo_TCX_counts_matrix_normalized.txt
      589M  Nov 15 12:55 /Volumes/local/Cory/Alzheimers/repo_counts/rosmap_counts_matrix_normalized.txt


*-----------------------------------------------------------------------------------------------------------------------
* some notebooks of interest

   --- d3 circle jupyter widget tutorials and demos, offered publicly (11 nov 2016)

     Two repos, both present a simple jupyter widget: a d3 canvas on
     which circles are drawn in response to python function calls, or
     by directly clicking on the d3 canvas.

     The first demo (possibly useful as a tutorial also) is simple,
     with all code self-contained in one notebook:

        https://github.com/paul-shannon/jupyter-widget-demo-all-in-notebook

     The second demo - to my mind, pretty complex - should be useful
     if you want to learn how to make installable notebook widget
     extensions and have little prior understanding of the mechanisms
     involved:

       https://github.com/paul-shannon/jupyter-widget-demo-nbextension

   --- circle, jupyter tutorial
     as extension:
        cd ~/s/examples/jupyter/hello-cookieCutter/jupyter-d3-circles-widget; make
     as self-contained with javascript magic:
       cd ~/github/jupyter-js-widget-demo-d3circles/selfContainedNotebook; make


   --- circleViewer, simpleD3circle, a learning project
     cd ~/s/examples/jupyter/javascriptMagic
     create shell jup-10001; jupyter notebook --port 10001
     creates shell sh-circleViewer (for RCS checkins, etc)
     code, maininted with rcs cd ~/s/examples/jupyter/javascriptMagic/simpleD3circle/
     also in github: https://github.com/paul-shannon/notebooks/blob/master/study/CircleView.ipynb

  --- cleaned up demo & tutorial
      ~/github/jupyter-widget-demos/d3circles/minimal/notebook/simple.ipynb

  --- lab meeting (4 nov 2016) demo
     ~/s/examples/jupyter/javascriptMagic/cyjs/igap-snp4GenesetEnrichmentDemo.ipynb
     added "on select" and "on unselect" event handlers (7 nov 2016)

  --- vrk2/pou3f2 bipolar snp


*-----------------------------------------------------------------------------------------------------------------------
* evolve jupyter cyjs demo to proper jupyter widget (16 nov 2016)

  sh-cyjupdev

  cd ~/github/cyjs-jupyter    # the repo for self-contained and the eventual nbextension

  cd ~/github/cyjs-jupyter/self-contained-notebooks/simple;
  jupyter notebook simple.ipynb

  --- prerequisite: an http server providing cytoscape.js
     cd ~/http
     python -m http.server 8099
     this supports: require.config({paths: {cytoscape: 'http://localhost:8099/js/cytoscape-2.7.10'}})

  --- start from igap demo
      ~/s/examples/jupyter/javascriptMagic/cyjs/igap-snp4GenesetEnrichmentDemo.ipynb
      cd  ~/s/examples/jupyter/javascriptMagic
      jupyter notebook cyjs/igap-snp4GenesetEnrichmentDemo.ipynb
*-----------------------------------------------------------------------------------------------------------------------
* vineet's 263 compounds, gene/TF model network, create png slides

  cd ~/s/work/priceLab/vineet/screen/
  source("go.R")


*-----------------------------------------------------------------------------------------------------------------------
* tss for all genes

  library(RPostgreSQL)
  db.gtf <- dbConnect(PostgreSQL(), user= "trena", password="trena", dbname="gtf", host="whovian”)
  query <- "select * from hg38human where moleculetype='gene' and gene_biotype='protein_coding'"
  tbl <- dbGetQuery(db.gtf, query)[, c("chr", "gene_name", "start", "strand”)]

*-----------------------------------------------------------------------------------------------------------------------
* rcyjs tips

  current working copy: ~/s/RCyjs  (16 nov 2016)

*-----------------------------------------------------------------------------------------------------------------------
* rcyjs tips: some style (vizmap) files to build upon

   ~/s/work/priceLab/mattRichards/style.js
   ~/s/examples/jupyter/javascriptMagic/cyjs/style.js
   ~/s/examples/jupyter/javascriptMagic/cyjs/igap4snpGenesetEnrichment-style.js

*-----------------------------------------------------------------------------------------------------------------------
* cyjs tips: filter on node attributes, cellphone email property

    cy.filter(function(e){return (e.isNode() && e.data("email"))}).length   // 29
    cy.filter(function(e){return (e.isNode() && !e.data("email"))}).length  // 6

*-----------------------------------------------------------------------------------------------------------------------
* rcyjs tips, cyjs tips: png

  var png64 = cy.png()
  $('#png-eg').attr('src', png64)   // this part not yet successful

  --- added getPNG to RCyjs, then improvised these commands to successfully write it out as a valid png
    library(base64enc)
    png <- getPNG(x$rcy)
    png.parsed <- fromJSON(png)
    substr(png.parsed, 1, 30) # [1] "data:image/png;base64,iVBORw0K"
    nchar(png.parsed)  # [1] 768714
    png.parsed.headless <- substr(png.parsed, 23, nchar(png.parsed))  # chop off the uri header
    png.parsed.binary <- base64decode(png.parsed.headless)
    conn <- file("x.png", "wb")
    writeBin(png.parsed.binary, conn)
    close(conn)


   --- as a function (from ~/s/work/priceLab/vineet/screen/go.R)

      writePNG <- function(rcy, filename) {
         png <- getPNG(rcy)
         png.parsed <- fromJSON(png)
         #substr(png.parsed, 1, 30) # [1] "data:image/png;base64,iVBORw0K"
         #nchar(png.parsed)  # [1] 768714
         png.parsed.headless <- substr(png.parsed, 23, nchar(png.parsed))  # chop off the uri header
         png.parsed.binary <- base64decode(png.parsed.headless)
         conn <- file(filename, "wb")
         writeBin(png.parsed.binary, conn)
         close(conn)
         } # writePNG

*-----------------------------------------------------------------------------------------------------------------------
* new AD expression data from cory, via sage (15 nov 2016)

    dir /Volumes/local/Cory/Alzheimers/repo_counts/*normalized.txt
      267M  Nov 15 12:29 /Volumes/local/Cory/Alzheimers/repo_counts/mayo_CBE_counts_matrix_normalized.txt
      268M  Nov 15 12:27 /Volumes/local/Cory/Alzheimers/repo_counts/mayo_TCX_counts_matrix_normalized.txt
      589M  Nov 15 12:55 /Volumes/local/Cory/Alzheimers/repo_counts/rosmap_counts_matrix_normalized.txt


    the rosmap normalized, with gene symbol rownames, as a matrix:
    dim(tbl) # 24593   638
    mtx <- as.matrix(tbl)
    mtx[1:5, 1:5]
    #         s01_120405 s02_120405 s03_120405 s04_120405 s05_120405
    # TSPAN6     4.321084   2.550606   2.626589   3.685091   3.442105
    # TNMD       0.076254   0.067835   0.056486   0.057805   0.034769
    # DPM1       3.380612   6.227278   4.462377   6.734323   4.207018
    # SCYL3      2.897668   4.884139   5.224935   4.899003   3.720255
    # C1orf112   0.432108   0.624084   0.536615   0.881532   0.451994
    range(mtx) # [1]      0.0 239943.8
    ~/s/work/priceLab/cory/module-109/rosmap_rnaseq_fpkm_geneSymbols_24593x638.RData
*-----------------------------------------------------------------------------------------------------------------------
* cory's module 109 (14 nov 2016) for AMPAD, ROSMAP talk, late November

   cd ~/s/work/priceLab/cory/module-109/

   --- script emulating trem2 notebook
      ~/github/notebooks/shared//trem2/anyGene.R
      mv /Users/paul/github/notebooks/shared//trem2/anyGene.R ~/s/work/priceLab/cory/module-109/
      mv'ing this to module-109
      mount via the finder:
         wc -l /Volumes/local/Cory/Alzheimers/ROSMAP/ROSMAP_RNAseq_FPKM_gene.tsv    # 55890


   --- expression data
   /local/Cory/Alzheimers/ROSMAP/ROSMAP_RNAseq_FPKM_gene.tsv
     The id_key and clinical data file in the same directory are what are used to identify which files
     are AD and which are control.

   --- gene list

   from Chris Gaiteri, Rush university medical center
   390 genes

   We'll be very interested in your results with TReNA on the
   module109 genes, since it's a rather novel system and Phil's lab
   has been doing experiments on these genes for the past six months.
   It's wonderful to be able to benefit from your extensive pipeline,
   and I certainly understand that the results aren't final, but it
   will help our groups to get a rough idea of what is possible with
   your method.  I included all genes in the module, as I didn't want
   to limit the definition of what constituted a TF.


  --- prep work on expression data
    cd ~/s/work/priceLab/cory/module-109/

    f <- "module109genes.csv"
    genes <- scan(f, sep="\n", what=character(0))
    f <- "/Volumes/local/Cory/Alzheimers/ROSMAP/ROSMAP_RNAseq_FPKM_gene.tsv"
    tbl <- read.table(f, sep="\t", nrows=-1, header=TRUE, as.is=TRUE)    # 642 columns
    colnames(tbl) <- sub("^X", "s", colnames(tbl))
    ensembl.geneIDs <- sub("\\..*$", "", tbl$gene_id)
    tbl.map <- select(org.Hs.eg.db, keys=ensembl.geneIDs, keytype="ENSEMBL", columns=c("ENSEMBL", "SYMBOL"))
    if(length(dups) > 0)
       tbl.map <- tbl.map[-dups,]
    tbl <- cbind(tbl.map, tbl)

    unmapped <- which(is.na(tbl$SYMBOL))
    length(unmapped)    # 31848
    if(length(unmapped) > 0)
      tbl <- tbl[-unmapped,]
    dim(tbl) # 24041  644
    save(tbl, file="rosmap_rnaseq_fpkm_geneSymbols.RData")

    setdiff(genes, tbl$SYMBOL) # 39
    #  "AC135178.1"    "AL133458.1"    "BAHCC1"        "C10orf114"     "C22orf32"      "C6orf3"
    #  "C9orf114"      "CTB-171A8.1"   "CTC-205M6.2"   "CTC-428G20.3"  "CTD-2380F24.1" "FAM48A"
    #  "FAM59A"        "FAM59B"        "GPER"          "hsa-mir-6723"  "KIAA1009"      "KRT8P12"
    #  "LINC00263"     "MLLT6"         "MT-ND5"        "NARG2"         "RAB7L1"        "RP11-226L15.5"
    #  "RP11-349A22.5" "RP11-45M22.1"  "RP11-552D4.1"  "RP11-632K20.7" "RP11-644F5.11" "RP11-742N3.1"
    #  "RP4-773N10.4"  "SETD8"         "SMEK1"         "STRA13"        "SYNRG"         "WAPAL"
    #  "ZEB1-AS1"      "ZFP106"        "ZNF271"


*-----------------------------------------------------------------------------------------------------------------------
* my checks to stuart
   31 jul 2016: 1040
   22 mar 2016: 1500

*-----------------------------------------------------------------------------------------------------------------------
* jocelyn mm9 intersect fimo + chipseq (14 nov 2016)

  cd ~/s/work/priceLab/jocelyn/chipseq/fimoIntersect/


*-----------------------------------------------------------------------------------------------------------------------
* fill mm9 fimo for jocelyn (10 nov 2016)

  --- from (12 sep 2016, see below): fimo first: it is needed by other fillers
    cd ~/github/BDDS/trenadb/fimo/mm9
    create.sql, fill.sql, index.sql
    fill.sql:
       \connect trena;
       \copy fimo_hg38 from '/local/Cory/for_Paul/fimo_out/newGRCh38.fimo.txt' delimiter E'\t' CSV header NULL as 'NULL';

     45M lines, takes < 20 minutes to fill on whovian

   whovian: /local/Cory/for_Paul/fimo_out/mouse/GRCm37
      1299452958 Nov 10 09:41 10.fimo.txt
      1252944130 Nov 10 09:41 11.fimo.txt
      1181876908 Nov 10 09:41 12.fimo.txt
      1167381583 Nov 10 09:41 13.fimo.txt
      1211073318 Nov 10 09:41 14.fimo.txt
      1017363669 Nov 10 09:41 15.fimo.txt
       950075794 Nov 10 09:42 16.fimo.txt
       941213191 Nov 10 09:42 17.fimo.txt
       875372209 Nov 10 09:42 18.fimo.txt
       594806863 Nov 10 09:42 19.fimo.txt
      1907157570 Nov 10 09:41 1.fimo.txt
      1802487549 Nov 10 09:42 2.fimo.txt
      1536181727 Nov 10 09:42 3.fimo.txt
      1535193467 Nov 10 09:42 4.fimo.txt
      1522074329 Nov 10 09:42 5.fimo.txt
      1450777665 Nov 10 09:43 6.fimo.txt
      1427168753 Nov 10 09:43 7.fimo.txt
      1265332973 Nov 10 09:43 8.fimo.txt
      1215575766 Nov 10 09:43 9.fimo.txt
          150608 Nov 10 09:43 MT.fimo.txt
      1532250955 Nov 10 09:43 X.fimo.txt
        24276570 Nov 10 09:43 Y.fimo.txt


   --- validate, examine, timing tests
     from laptop: psql -U trena --host whovian   # password trena
     on whovian: psql trena
     \dt         # fimo_mm9 among others
     select count(*) from fimo_mm9;    #  400,785,924
     select * from fimo_mm9 limit 3;
      motifname | chrom |  start  | endpos  | strand | motifscore |   pval   | empty |  sequence
     -----------+-------+---------+---------+--------+------------+----------+-------+-------------
      MA0002.2  | 1     | 3002343 | 3002353 | -      |    12.0862 | 3.83e-05 |       | CACTGTGGTCT
      MA0002.2  | 1     | 3004382 | 3004392 | +      |    12.6724 | 2.19e-05 |       | CTCTGTGGTTC
      MA0002.2  | 1     | 3006403 | 3006413 | +      |    10.9655 | 8.63e-05 |       | GTCTCTGGTTT

   --- jocelyn's initial requests

    Paul - here is a list of 5 favorites for he first 'feature maps' we would like to pull:
       all motif instances of TFAP2A
       all motif instances of TFAP2C
       all motif instances of EGR1
       all motif instances of SMAD3
       all motif instances of KLF16
       CTCF motif instances would also be very nice!

    ---- quickLook.R before indexing
      library(RPostgreSQL)
      library(RUnit)
      db <- dbConnect(PostgreSQL(), user= "trena", password="trena", dbname="trena", host="whovian")
      system.time(tbl <- dbGetQuery(db, "select * from fimo_mm9 where motifname='MA0014.2'"))
      #   user  system elapsed
      #  2.422   0.138  81.740
      dim(tbl)  # [1] 489250      9

   --- index: about 5 hours
   whovian.mm9> date; psql -f index.sql; date
                Fri Nov 11 12:06:14 PST 2016
                You are now connected to database "trena" as user "pshannon".
                CREATE INDEX
                CREATE INDEX
                CREATE INDEX
                CREATE INDEX
                Fri Nov 11 16:47:21 PST 2016

   system.time(tbl <- dbGetQuery(db, "select * from fimo_mm9 where motifname='MA0014.2'"))
       user  system elapsed
      2.422   0.138  81.740
   dim(tbl)   [1] 489250      9
   # after indexing
   system.time(tbl <- dbGetQuery(db, "select * from fimo_mm9 where motifname='MA0014.2'"))
      user  system elapsed
     1.503   0.034   3.132

*-----------------------------------------------------------------------------------------------------------------------
* jupyter notebooks, plotly, 3d interactive plots (10 nov 2016)

  http://nbviewer.jupyter.org/github/richardagalvez/Exo_list/blob/master/3dplot_plotly.ipynb

*-----------------------------------------------------------------------------------------------------------------------
* jupyter widgets howto: build and install logic (11 nov 2016)

  where to put and mention external javascript libraries?

  --- d3 mentioned at top of js source file Circles.js
    var widgets = require('jupyter-js-widgets');
    var _ = require('underscore');
    var d3 = require('d3');
  --- d3 mentioned in js/package.json
  --- d3 code in js/node_modules/d3/*
  --- is webpack'ed into circles/static/index.js, maybe via recursive descent of require
     webpack.config.js exports three bundles (three modules) including one containing
     the custom widget views, an amd module.  the entry is src/index.js, with this
     primary and important line:
        module.exports = require('./Circles.js');
     and, as noted above, Circles.js requires d3 (along with underscore and jupyter-js-widgets)



  cd ~/s/examples/jupyter/hello-cookieCutter/jupyterHello
  default target in makefile:
    (cd js; webpack --config webpack.config.js)
     pip install -e .
    jupyter nbextension install --py hellow
    jupyter nbextension enable --py --sys-prefix hello
    jupyter notebook basicDemo.ipynb

  --- trace build process
    add some recognizable text to hello/example.py, js/src/example.js
    touch timestamp
    (cd js; webpack --config webpack.config.js)  # 3 bundles specified, writtent to hello/static/
                                                 # nb standard: extension.js, embedder.js
                                                 # index.js is small, this crucial line: module.exports = require('./example.js');
    find . -newer timestamp
       ./hello/static/extension.js   # from js/src/extensions.js
       ./hello/static/index.js       # assembled by webpack, lots of require-ish module loading code, and example.js
       ./hello/static/index.js.map   # all on one line, larger by 10k, created before index.js (surprisingly)
       ./js/dist/index.js            # intermediate ubuild directory?
       ./js/dist/index.js.map

    touch timestamp
    pip install -e .     # -e, editable, "install the package in develop mode, meaning it will just link back to where the sources are"
       Installing collected packages: hello
         Found existing installation: hello 0.1.0.dev0
           Uninstalling hello-0.1.0.dev0:
             Successfully uninstalled hello-0.1.0.dev0
         Running setup.py develop for hello
       Successfully installed hello

    find . -newer timestamp
      ./hello.egg-info/dependency_links.txt
      ./hello.egg-info/PKG-INFO
      ./hello.egg-info/requires.txt
      ./hello.egg-info/SOURCES.txt
      ./hello.egg-info/top_level.txt

    find /Users/paul/anaconda -newer timestamp
       /Users/paul/anaconda/lib/python3.5/site-packages
       /Users/paul/anaconda/lib/python3.5/site-packages/easy-install.pth
       /Users/paul/anaconda/lib/python3.5/site-packages/hello.egg-link
       cat /Users/paul/anaconda/lib/python3.5/site-packages/hello.egg-link
          /Users/paul/s/examples/jupyter/hello-cookieCutter/jupyterHello

    touch timestamp
    jupyter nbextension install --py hello
       Installing /Users/paul/s/examples/jupyter/hello-cookieCutter/jupyterHello/hello/static -> helloNPM
       Copying: hello/static/extension.js -> /usr/local/share/jupyter/nbextensions/helloNPM/extension.js
       Copying: hello/static/index.js -> /usr/local/share/jupyter/nbextensions/helloNPM/index.js
       Copying: hello/static/index.js.map -> /usr/local/share/jupyter/nbextensions/helloNPM/index.js.map



*-----------------------------------------------------------------------------------------------------------------------
* jupyter widgets howto: webpack

   --- on whovian
    cd ~/github/cyjs-jupyter/cyjs-jupyter/
    npm install webpack
    ln -s /users/pshannon/github/cyjs-jupyter/cyjs-jupyter/node_modules/webpack/bin/webpack.js ~/bin/webpack


   http://webpack.github.io/docs/installation.html


   sudo npm install webpack -g
   now type -a webpack: webpack is /usr/local/bin/webpack
   cd ~/s/examples/jupyter/hello-cookieCutter/jupyterHello/js/
   webpack --config webpack.config.js

    {// Bundle for the notebook containing the custom widget views and models
     //
     // This bundle contains the implementation for the custom widget views and
     // custom widget.
     // It must be an amd module
     //
        entry: './src/index.js',
        output: {
            filename: 'index.js',
            path: '../hello/static',
            libraryTarget: 'amd'
        },


*------------------------------------------------------------------------------------------------------------------------
* jupyter widgets howto: step 1, change HelloWorld cookiecutter to a new Model/View name (10 nov 2016)

  example.py is where the main hello world python code lives.
  remove "@widgets.register('hello.Hello')" line from circles/examples.py
  remove circles/static/directory  # this apparently gets regenerated.

  --- circles/example.py:
     class Circles(widgets.DOMWidget):
       """"""
       _view_name = Unicode('CircleView').tag(sync=True)
       _model_name = Unicode('CircleModel').tag(sync=True)
       _view_module = Unicode('circles-pkg').tag(sync=True)
       _model_module = Unicode('circles-pkg').tag(sync=True)
       value = Unicode('Circle World!').tag(sync=True)

  --- js/src/example.js
    var CircleModel = widgets.DOMWidgetModel.extend({
       defaults: _.extend({}, widgets.DOMWidgetModel.prototype.defaults, {
        _model_name : 'CircleModel',
        _view_name : 'CircleView',
        _model_module : 'circles-pkg',
        _view_module : 'circles-pkg',
        value : 'Circle World'
    })
});


// Custom View. Renders the widget model.
var CircleView = widgets.DOMWidgetView.extend({
    render: function() {
        this.value_changed();
        this.model.on('change:value', this.value_changed, this);
    },

    value_changed: function() {
        this.el.textContent = this.model.get('value');
    }
});


module.exports = {
    CircleModel : CircleModel,
    CircleView : CircleView
};

   ---- change filenames
      circles/example.py -> Circles.py
      js/src/example.js  -> Circles.js
      circles/__init__.py: from .Circles import *

*-----------------------------------------------------------------------------------------------------------------------
* CircleWidget still fails (see message below): now try to evolve Hello into Circles (10 nov 2016)

  cd ~/s/examples/jupyter/hello-cookieCutter/
  cookiecutter https://github.com/jupyter/widget-cookiecutter.git

    author_name []: Paul Shannon
    author_email []: pshannon@systemsbiology.org
    github_project_name [jupyter-widget-example]: jupyter-d3-circles-widget
    github_organization_name [jupyter]:
    python_package_name [ipywidgetexample]: circles
    npm_package_name [jupyter-widget-example]: circles-pkg
    project_short_description [A Custom Jupyter Widget Library]:

   cd ~/s/examples/jupyter/hello-cookieCutter/jupyter-d3-circles-widget
   cat makefile
     default:
	pip install -e .
	jupyter nbextension install --py circles
	jupyter nbextension enable --py --sys-prefix circles
	jupyter notebook circles.ipynb



  cookiecutter https://github.com/jupyter/widget-cookiecutter.git
    author_name []: Paul Shannon
    author_email []: pshannon@systemsbiology.org
    github_project_name [jupyter-widget-example]: helloBecomesCircles
    github_organization_name [jupyter]:
    python_package_name [ipywidgetexample]: helloCircles
    npm_package_name [jupyter-widget-example]: helloCircles-pkg
    project_short_description [A Custom Jupyter Widget Library]:

   cd ~/s/examples/jupyter/hello-cookieCutter/helloBecomesCircles
   now in makefile:
      pip install -e .
      jupyter nbextension install --py helloCircles
      jupyter nbextension enable --py --sys-prefix helloCircles
      jupyter notebook helloCircles.ipynb

   now add d3 to package.json:
     "dependencies": {"jupyter-js-widgets": "^1.1.1", "d3": "^3.5.8", "underscore": "^1.8.3"}



*-----------------------------------------------------------------------------------------------------------------------
* CircleWidget: added d3 to package.json, got further, but still failed (10 nov 2016)

   [status: see above.  hoping to evolve hello -> circle]

   pip install -e .
   jupyter nbextension install --py circles
   jupyter nbextension enable --py --sys-prefix circles
   jupyter notebook

    cw

    Widget Javascript not detected.  It may not be installed
    properly. Did you enable the widgetsnbextension? If not, then run
    "jupyter nbextension enable --py --sys-prefix widgetsnbextension"


*-----------------------------------------------------------------------------------------------------------------------
* build a cookiecutter nbextension for CircleWidget (9 nov 2016)

  cd ~/github/jupyter-widget-demos/d3circles/minimal
  cookiecutter https://github.com/jupyter/widget-cookiecutter.git
     author_name []: Paul Shannon
     author_email []: pshannon@systemsbiology.org
     github_project_name [jupyter-widget-example]: circleWidget
     github_organization_name [jupyter]:
     python_package_name [ipywidgetexample]: circles
     npm_package_name [jupyter-widget-example]: circle_npm
     project_short_description [A Custom Jupyter Widget Library]: demonstrate simple d3 widget

   --- replace circles/example.py with my CircleWidget class
   --- replace js/src/example.js with my CircleModel and CircleView code

   --- try building
      cd ~/github/jupyter-widget-demos/d3circles/minimal/circleWidget
      pip install -e .
          Running setup.py develop for circles;  Successfully installed circles
      jupyter nbextension install --py circles
         Installing /Users/paul/github/jupyter-widget-demos/d3circles/minimal/circleWidget/circles/static -> circle_npm
         Up to date: /usr/local/share/jupyter/nbextensions/circle_npm/extension.js
         Up to date: /usr/local/share/jupyter/nbextensions/circle_npm/index.js
         Up to date: /usr/local/share/jupyter/nbextensions/circle_npm/index.js.map
         - Validating: OK
      jupyter nbextension enable circles --py
        - Validating: OK


*-----------------------------------------------------------------------------------------------------------------------
* HelloWorld, grok try2 continued, the nbextension cookiecutter (9 nov 2016): try to install, then run.  success

   cd ~/s/examples/jupyter/hello-cookieCutter
   cookiecutter https://github.com/jupyter/widget-cookiecutter.git
   cd ~/s/examples/jupyter/hello-cookieCutter/jupyterHello
   touch timestamp
   pip install -e .
   find . -newer timestamp  | egrep -v node_modules
      ./hello
      ./hello/static
      ./hello/static/extension.js
      ./hello/static/index.js
      ./hello/static/index.js.map
      ./hello.egg-info
      ./hello.egg-info/dependency_links.txt
      ./hello.egg-info/not-zip-safe
      ./hello.egg-info/PKG-INFO
      ./hello.egg-info/requires.txt
      ./hello.egg-info/SOURCES.txt
      ./hello.egg-info/top_level.txt
      ./js
      ./js/dist
      ./js/dist/index.js
      ./js/dist/index.js.map

   touch timestamp
   jupyter nbextension install --py hello
       Installing /Users/paul/s/examples/jupyter/hello-cookieCutter/jupyterHello/hello/static -> helloNPM
       Making directory: /usr/local/share/jupyter/nbextensions/helloNPM/
       Copying: /Users/paul/s/examples/jupyter/hello-cookieCutter/jupyterHello/hello/static/extension.js -> /usr/local/share/jupyter/nbextensions/helloNPM/extension.js
       Copying: /Users/paul/s/examples/jupyter/hello-cookieCutter/jupyterHello/hello/static/index.js -> /usr/local/share/jupyter/nbextensions/helloNPM/index.js
       Copying: /Users/paul/s/examples/jupyter/hello-cookieCutter/jupyterHello/hello/static/index.js.map -> /usr/local/share/jupyter/nbextensions/helloNPM/index.js.map

       dir /usr/local/share/jupyter/nbextensions/
          170 Nov  9 16:49 helloNPM/
          136 Jul 29 12:59 igv/
          442 Nov  9 16:14 jupyter-leaflet/

   find . -newer timestamp
      ./hello/__pycache__
      ./hello/__pycache__/__init__.cpython-35.pyc
      ./hello/__pycache__/_version.cpython-35.pyc
      ./hello/__pycache__/example.cpython-35.pyc

   jupyter nbextension enable --py --sys-prefix hello
      Enabling notebook extension helloNPM/extension...   Validating: OK


   --- try it out:
     jupyter notebook --port=30003 --debug
     from hello import HelloWorld
     HelloWorld()  # works!

*-----------------------------------------------------------------------------------------------------------------------
* grok (try 2) the nbextension cookiecutter (9 nov 2016): structure and commentary upon it

  cd ~/s/examples/jupyter/hello-cookieCutter
  cookiecutter https://github.com/jupyter/widget-cookiecutter.git
    author_name []: pshannon
     author_email []: pshannon@systemsbiology.org
     github_project_name [jupyter-widget-example]: jupyterHello
     github_organization_name [jupyter]:
     python_package_name [ipywidgetexample]: hello
     npm_package_name [jupyter-widget-example]: helloNPM
     project_short_description [A Custom Jupyter Widget Library]:

   creates directory "jupyterHello"
      jupyterHello/MANIFEST.in       # a template, how to generate MANIFEST, used by "python setup.py sdist" (source distribution)
      jupyterHello/hello/            # the python package (aka, module)
                   hello/__init__.py #

    --- __init__.py notes
      ~/github/ipyleaflet/ipyleaflet/__init__.py is minimal, helpful
      from ._version import version_info, __version__  # import two symbols from ./version.py
      from .leaflet import *                           # from ./leaflet.py (in this directory) import all symbols
      def _jupyter_nbextension_paths():
        return [{
          'section': 'notebook',
          'src': 'static',
          'dest': 'jupyter-leaflet',
          'require': 'jupyter-leaflet/extension'
          }]



*-----------------------------------------------------------------------------------------------------------------------
* nbextension tips

   jupyter nbextension list         # reports config dirs (why two?)
   jupyter serverextension list     # currently just jupyterlab,
   jupyter bundlerextension list    # not a command


   --- where to specify javascript libraries?

    ~/github/clustergrammer-widget/js/package.json, dependencies: clustergrammer, d3, jupyter-js-widgets, underscore
    ~/s/examples/jupyter/hello-cookieCutter/jupyterHello/js/package.json: "jupyter-js-widgets": "^1.1.1", "underscore": "^1.8.3"

   --- nbextension lists config.dir, which contain notebook.json, of which this is a sample:
     cat ~/.jupyter/nbconfig/notebook.json
        {
        "load_extensions": {
           "igv/igv-jupyter": true,
           "jupyter-threejs/extension": true,
           "jupyter-widget-example/extension": true,
           "bqplot/extension": true,
           "jupyter-d3-circle-widget/extension": true
           }}


   --- javascript
     js/ is at same level as the python module directory (eg, ~/github/ipyleaflet/ipyleaflet)
      js/package.json
      js/webpack.config.js
      ms/README.md
      js/src
     cat package.json
        {
          "name": "jupyter-leaflet",
          "version": "0.2.1",
          "description": "jupyter - leaflet bridge",
          "author": "Brian Granger",
          "license": "MIT",
          "main": "src/index.js",
          "repository": {
            "type": "git",
            "url": "https://github.com/ellisonbg/ipyleaflet.git"
          },
          "scripts": {
            "prepublish": "webpack",
            "test": "echo \"Error: no test specified\" && exit 1"
          },
          "devDependencies": {
            "css-loader": "^0.23.1",
            "file-loader": "^0.8.5",
            "json-loader": "^0.5.4",
            "rimraf": "^2.4.1",
            "style-loader": "^0.13.1",
            "webpack": "^1.12.14"
          },
          "dependencies": {
            "jquery": "^2.1.4",
            "jupyter-js-widgets": "^1.0.0",
            "leaflet": "^0.7.7",
            "leaflet-draw": "^0.3.0",
            "underscore": "^1.8.3"
          }
        }

    head  ipyleaflet/js/webpack.config.js
       var version = require('./package.json').version;
       var leaflet_marker_selector = /leaflet\/dist\/images\/marker-.*\.png/;
       var loaders = [
          { test: /\.json$/, loader: 'json-loader' },
          { test: /\.css$/, loader: 'style-loader!css-loader' },
           // Generic file loader, Should be used for anything but leaflet's
           // marker-icon.png, marker-icon-2x.png or marker-shadow.png
          { test: /\.(jpg|png|gif|svg)$/, loader: 'file', exclude: leaflet_marker_selector },
         ...

    --- ipyleaflet/js/src
        12 embed.js
        16 extension.js
        15 index.js
       813 jupyter-leaflet.js

    --- ipyleaflet/js/src/embed.js
     require('leaflet/dist/leaflet.css');
     require('leaflet-draw/dist/leaflet.draw.css');
          // Forcibly load the marker icon images to be in the bundle.
     require('leaflet/dist/images/marker-shadow.png');
     require('leaflet/dist/images/marker-icon.png');
     require('leaflet/dist/images/marker-icon-2x.png');
        // Export everything from jupyter-leaflet and the npm package version number.
     module.exports = require('./jupyter-leaflet.js');
     module.exports['version'] = require('../package.json').version;



   --- ~/github/clustergrammer-widget/js/src/embed.js
     // Entry point for the npmcdn bundle containing custom model definitions.
     // It differs from the notebook bundle in that it does not need to define a
     // dynamic baseURL for the static assets and may load some css that would
     // already be loaded by the notebook otherwise.
     // Export widget models and views, and the npm package version number.
        module.exports = require('./example.js');    # where all the clustergrammer code actuallylives
        module.exports['version'] = require('../package.json').version;

*-----------------------------------------------------------------------------------------------------------------------
* grok nbextension install process (9 nov 2016): the unadorned (or minimally adorned) basic notebook extension

    cd ~/s/examples/jupyter/hello-cookieCutter/jupyterHello

*-----------------------------------------------------------------------------------------------------------------------
* grok nbextension install process (9 nov 2016)

  cd ~/github/ipyleaflet
  git pull origin
  pip install -e .
    creates: /Users/paul/anaconda/lib/python3.5/site-packages/ipyleaflet.egg-link
             -> /Users/paul/github/ipyleaflet

   jupyter nbextension install --py ipyleaflet
      ~/github/ipyleaflet/js/node_modules/leaflet/
      ~/github/ipyleaflet/js/node_modules/leaflet-draw/

      this also (part of jupyterlab?)
         dir ~/github/ipyleaflet/js/node_modules/@jupyterlab/nbwidgets/node_modules/jupyterlab/lib/leafletwidget/

   jupyter nbextension enable --py --sys-prefix ipyleaflet
   cd ~/github/ipyleaflet/examples
   jupyter notebook --port 30003 --debug
   choose examples/GeoJSON.ipynb
   import ipyleaflet
    from ipyleaflet import (
       Map,
       Marker,
       TileLayer, ImageOverlay,
       Polyline, Polygon, Rectangle, Circle, CircleMarker,
       GeoJSON,
       DrawControl
       )

   all cells work!

*-----------------------------------------------------------------------------------------------------------------------
* grok the nbextension cookiecutter (9 nov 2016)

  cd ~/s/examples/jupyter/hello-cookieCutter
  type cookiecutter   # cookiecutter is /Users/paul/anaconda/bin/cookiecutter
  cookiecutter https://github.com/jupyter/widget-cookiecutter.git
     You've cloned /Users/paul/.cookiecutters/widget-cookiecutter before. Is it okay to delete and re-clone it? [yes]: yes
     Cloning into 'widget-cookiecutter'...
     remote: Counting objects: 98, done.
     remote: Total 98 (delta 0), reused 0 (delta 0), pack-reused 98
     Unpacking objects: 100% (98/98), done.
     Checking connectivity... done.
     author_name []: Paul Shannon
     author_email []: pshannon@systemsbiology.org
     github_project_name [jupyter-widget-example]:
     github_organization_name [jupyter]:
     python_package_name [ipywidgetexample]:
     npm_package_name [jupyter-widget-example]:
     project_short_description [A Custom Jupyter Widget Library]:

   pip install -e .
   jupyter nbextension install --py --user ipywidgetexample   # where ipywidgetexample is the python directory (module name?)
        To initialize this nbextension in the browser every time the notebook (or other app) loads:
   jupyter nbextension enable ipywidgetexample --user --py
        Enabling notebook extension jupyter-widget-example/extension...
          - Validating: OK

    jupyter notebook --log-level=0 --port=16666
    in notebook, this works
        import ipwidgetexample
    but nothing else does;

   **** next: grok python module structure


  --- from ipyleaflet
     $ jupyter nbextension install --py --symlink --sys-prefix ipyleaflet
     $ jupyter nbextension enable --py --sys-prefix ipyleaflet

   Note for developers: the --symlink argument on Linux or OS X allows
   one to modify the JavaScript code in-place. This feature is not
   available with Windows.

*-----------------------------------------------------------------------------------------------------------------------
* the d3 CircleWidget demo, packaging with cookiecutter (8 nov 2016)



  cd ~/github/jupyter-widget-demos/d3circles/minimal
  cookiecutter https://github.com/jupyter/widget-cookiecutter.git

    --- new try
        pip install -e .
        jupyter nbextension install --py --user CircleWidget
        jupyter nbextension enable CircleWidget --user --py
          # in new notebook:
        from CircleWidget import *
        CircleWidget
           <module 'CircleWidget' from
             '/Users/paul/github/jupyter-widget-demos/d3circles/minimal/jupyter-d3-circle-widget/CircleWidget/__init__.py'>

    Paul Shannon
    pshannon@systemsbiology.org
    jupyter-d3-circle-widget
    CircleWidget
    jupyter-d3-circle-widget
    Small and Simple Jupyter Widget Demo Using d3

   ---  emulate what works for igv.
       "igv" below seems to be the python module name
        def _jupyter_server_extension_paths():
          return [{ "module": "igv"}]
        def _jupyter_nbextension_paths():


   --- build and install?
      pip install -e .
      jupyter nbextension install --prefix ~/jupyter.extensions --py CircleWidget
      jupyter nbextension enable --py CircleWidget    # - Validating: OK
          Enabling notebook extension jupyter-d3-circle-widget/extension...
            - Validating: problems found:
               - require?  X jupyter-d3-circle-widget/extension

           "clustergrammer_widget": "nbextensions/clustergrammer_widget/index",
           "jupyter-d3-circle-widget": "nbextensions/jupyter-d3-circle-widget/index",
           "jupyter-leaflet": "nbextensions/jupyter-leaflet/index",

   --- where is jupyter-leaflet mentioned in ~/github/ipyleaflet?  no filename
   find ~/github/ipyleaflet/ -name "*.js" -print -exec grep "jupyter-leaflet" {} ';'
    /Users/paul/github/ipyleaflet//js/src/embed.js
    // Export everything from jupyter-leaflet and the npm package version number.
       module.exports = require('./jupyter-leaflet.js');
    /Users/paul/github/ipyleaflet//js/src/extension.js
                "jupyter-leaflet": "nbextensions/jupyter-leaflet/index",
   /Users/paul/github/ipyleaflet//js/src/index.js
      __webpack_public_path__ = document.querySelector('body').getAttribute('data-base-url') + 'nbextensions/jupyter-leaflet/';
     // Export everything from jupyter-leaflet and the npm package version number.
    module.exports = require('./jupyter-leaflet.js');
    /Users/paul/github/ipyleaflet//js/src/jupyter-leaflet.js
        _view_module : 'jupyter-leaflet',
        _model_module : 'jupyter-leaflet',
        _view_module : 'jupyter-leaflet',
        _model_module : 'jupyter-leaflet',
        _model_module : "jupyter-leaflet",
        _view_module : "jupyter-leaflet",
    /Users/paul/github/ipyleaflet//js/webpack.config.js
       {// jupyter-leaflet bundle for the notebook
       {// embeddable jupyter-leaflet bundle
              publicPath: 'https://unpkg.com/jupyter-leaflet@' + version + '/dist/'

   --- where is   "clustergrammer_widget": "nbextensions/clustergrammer_widget/index",
       mentioned in ~/github/c
    find ~/github/clustergrammer-widget -name "*.js" -print -exec grep "clustergrammer_widget" {} ';'

      /Users/paul/github/clustergrammer-widget/clustergrammer_widget/static/extension.js
	                "clustergrammer_widget": "nbextensions/clustergrammer_widget/index",
      /Users/paul/github/clustergrammer-widget/clustergrammer_widget/static/index.js
	__webpack_require__.p = document.querySelector('body').getAttribute('data-base-url') + 'nbextensions/clustergrammer_widget/';
	    _view_module : 'clustergrammer_widget',
	    _model_module : 'clustergrammer_widget',
		"name": "clustergrammer_widget",
		"description": "clustergrammer_widget",
			"url": "https://github.com/maayanlab/clustergrammer_widget.git"
       /Users/paul/github/clustergrammer-widget/js/dist/index.js
           /******/ 	__webpack_require__.p = "https://npmcdn.com/clustergrammer_widget@0.0.1/dist/";
	    _view_module : 'clustergrammer_widget',
	    _model_module : 'clustergrammer_widget',
		"name": "clustergrammer_widget",
		"description": "clustergrammer_widget",
			"url": "https://github.com/maayanlab/clustergrammer_widget.git"






   --- test it out, with the supplied notebook

     ~/github/igv.js-jupyter/examples/DoubleClick.ipynb



*-----------------------------------------------------------------------------------------------------------------------
* cory ampAD talk: 80 genes in R/python notebooks, for trena models (9 nov 2016)

   on riptide, cd ~/github/notebooks

     15375 Nov  8 07:16 ./shared/trem2/trena-stage1-R.ipynb
     14091 Nov  7 17:13 ./shared/trem2/trena-stage2-python.ipynb
     17559 Nov  7 10:25 ./shared/VRK2-Pou3f2.ipynb    # for jocelyn and dani

*------------------------------------------------------------------------------------------------------------------------
* early notebooks for cory (sep/oct 2016)

  whovian
  dir ~/github/notebooks/paul-shannon/trena/*.ipynb

     19175 Sep 13 15:57 chipseq-motifTFmap-fimoDatabase-demo.ipynb
     24914 Sep 21 11:09 findTranscriptFactorsAnnotatedToOneMotifOnly-Copy1.ipynb
     23545 Sep 21 11:06 findTranscriptFactorsAnnotatedToOneMotifOnly.ipynb
     25368 Oct  3 09:53 firstFeatureTable.ipynb
     46297 Sep 23 11:08 forCory.ipynb
      8575 Oct  7 12:55 Testing out the liftover function-Copy1.ipynb
     14850 Oct  7 14:25 Testing out the liftover function.ipynb
     10356 Oct  7 13:18 Testing out the liftover function-John Debug.ipynb
    239877 Oct  7 11:49 trena-TREM2-ad-Cory.ipynb
    137638 Oct 10 07:35 trena-TREM2-ad.ipynb



*-----------------------------------------------------------------------------------------------------------------------
* new/old notebook for cory: trem2 (7 nov 2016)

    ~/github/TReNA/inst/demos/trem2/go.R   # 85 lines

*-----------------------------------------------------------------------------------------------------------------------
* findOverlaps GenomicRanges example for rory (7 nov 2016)

   ~/s/examples/bioc/GenomicRanges/go.R

library(GenomicRanges)
source("~/github/BDDS/trenadb/src/utils.R”)
# get tbl  from somewhere
f <- "~/s/work/priceLab/cory/lymphoblastFeatureTable/chr19-31oct2016/featureTableLymphoblast-chr19-entire.RData"
load(f) # tbl
x <- locStringToBedTable(head(tbl$loc, n=100))
gr1 <- GRanges(seqnames=x$chrom, IRanges(start=x$start, end=x$end))
gr2 <- GRanges(seqnames=x$chrom, IRanges(start=x$start-50, end=x$end+50))
head(as.data.frame(findOverlaps(gr1, gr2, type='any')))
#
#  queryHits subjectHits
# 1         1           3
# 2         1           4
# 3         1           5
# 4         1           1
# 5         1           2
# 6         2           3

*-----------------------------------------------------------------------------------------------------------------------
* fill mouse fimo, file from cory, for jocelyn (7 nov 2016)

  cory says files are here.  these, though, are mm10, and jocelyn needs mm9.

    whovian:/local/Cory/for_Paul/fimo_out/mouse/
    dir /local/Cory/for_Paul/fimo_out/mouse/*.fimo.txt   eg
       1911014244 Nov  6 08:01 1.fimo.txt

   create new table in trena, which now has:
      bash> psql trena
      psql> \dt
                  List of relations
        Schema |   Name    | Type  |  Owner
       --------+-----------+-------+----------
        public | fimo_hg38 | table | pshannon
        public | hits      | table | pshannon
        public | regions   | table | pshannon
        public | tfmotifs  | table | pshannon


     * genome-wide fimo files from Cory (8 aug 2016)

        cd ~/s/data/postgres-fill/fimo

        dir /local/Cory/for_Paul/fimo_out/*.fimo.txt
          28672130668 Aug  6 20:02 /local/Cory/for_Paul/fimo_out/GRCh38.fimo.txt
          26516524484 Aug  6 20:11 /local/Cory/for_Paul/fimo_out/GRm38.fimo.txt

       /local/Cory/for_Paul/fimo_out/GRCh38.fimo.txt

        head -10 /local/Cory/for_Paul/fimo_out/GRCh38.fimo.txt
        #pattern name	sequence name	start	stop	strand	score	p-value	matched sequence
        MA0002.2	10	12880	12890	+	11.4483	6.04e-05		GCTTGTGGCCT
        MA0002.2	10	18991	19001	-	12.4655	2.73e-05		TTCTGTGGTTC
        MA0002.2	10	19478	19488	-	13.3448	1.17e-05		TTCTGTGGTTG

        --- the two-tab problem: don't want to sed two 30G files!
          see if we can fill from
          head -10 /local/Cory/for_Paul/fimo_out/GRCh38.fimo.txt > tiny.txt

        createdb -U pshannon fimo
        psql fimo -f create.sql
          DROP TABLE
          CREATE TABLE
         psql fimo -f fill.sql   # tiny.txt
           COPY 9

       --- next problem: the big file is actually 12 files combined, thus 12 header lines,
          and this bug:

           whovian.fimo> psql -f fill.sql
             You are now connected to database "fimo" as user "pshannon".
             psql:fill.sql:2: ERROR:  invalid input syntax for integer: "start"
             CONTEXT:  COPY hg38, line 20583881, column start: "start"

          remedy: cory will grep -v start on the file, give me a new one.

       --- timing (no indices yet)

         system.time(dbGetQuery(db, "select * from hg38 where chr='10' and start < 19000"))
           user  system elapsed
           0.008   0.001  55.610

       --- built 3 indices
        index.sql:
          \connect fimo;
          create index on hg38 (chr);
          create index on hg38 (start);
          create index on hg38 (endpos);

        system.time(dbGetQuery(db, "select * from hg38 where chr='10' and start < 19000"))
          user  system elapsed
         0.013   0.000  17.456


*-----------------------------------------------------------------------------------------------------------------------
* install clustergrammer jupyter widget (7 nov 2016)


    cd ~/github/clustergrammer-widget/
    git pull origin
      # install the python package, symlink from install dir so javascript can be modified live, just for current user
      # symlink:  cat /Users/paul/anaconda//lib/python3.5/site-packages/clustergrammer-widget.egg-link
      #     /Users/paul/github/clustergrammer-widget
    jupyter nbextension install --py --symlink --user clustergrammer_widget
      # python package, Use sys.prefix as the prefix for installing nbextensions (for environments, packaging)
    jupyter nbextension enable --py --sys-prefix widgetsnbextension


    sys.prefix

       A string giving the site-specific directory prefix where the
       platform independent Python files are installed; by default,
       this is the string '/usr/local'. This can be set at build time
       with the --prefix argument to the configure script. The main
       collection of Python library modules is installed in the
       directory prefix/lib/pythonX.Y while the platform independent
       header files (all except pyconfig.h) are stored in
       prefix/include/pythonX.Y, where X.Y is the version number of
       Python, for example 2.7.

    python
    import sys
    sys.prefix  # '/Users/paul/anaconda'

     ls -lat ~/anaconda/lib/python3.5/site-packages/widgetsnbextension

         136 Jul 24 16:24 __pycache__
         136 Jul 24 16:24 static
         937 Jul 24 16:24 __init__.py
          72 Jul 24 16:24 _version.py


  --- lots of trouble, all the steps below failed
 git clone https://github.com/maayanlab/clustergrammer-widget.git
 cd clustergrammer-widget
 pip install -e .
 jupyter nbextension install --py --symlink --user clustergrammer-widget

 File "/Users/paul/anaconda/bin/jupyter-nbextension", line 6, in <module>
   sys.exit(notebook.nbextensions.main())
 File "/Users/paul/anaconda/lib/python3.5/site-packages/jupyter_core/application.py", line 267, in launch_instance
   return super(JupyterApp, cls).launch_instance(argv=argv, **kwargs)
 File "/Users/paul/anaconda/lib/python3.5/site-packages/traitlets/config/application.py", line 596, in launch_instance
   app.start()
 File "/Users/paul/anaconda/lib/python3.5/site-packages/notebook/nbextensions.py", line 961, in start
   super(NBExtensionApp, self).start()
 File "/Users/paul/anaconda/lib/python3.5/site-packages/jupyter_core/application.py", line 256, in start
   self.subapp.start()
 File "/Users/paul/anaconda/lib/python3.5/site-packages/notebook/nbextensions.py", line 739, in start
   self.install_extensions()
 File "/Users/paul/anaconda/lib/python3.5/site-packages/notebook/nbextensions.py", line 718, in install_extensions
   **kwargs
 File "/Users/paul/anaconda/lib/python3.5/site-packages/notebook/nbextensions.py", line 225, in install_nbextension_python
   m, nbexts = _get_nbextension_metadata(module)
 File "/Users/paul/anaconda/lib/python3.5/site-packages/notebook/nbextensions.py", line 1123, in _get_nbextension_metadata
   m = import_item(module)
 File "/Users/paul/anaconda/lib/python3.5/site-packages/traitlets/utils/importstring.py", line 41, in import_item
   return __import__(parts[0])
ImportError: No module named 'clustergrammer-widget'


   --- a fresh start: first the basic package, not the notebook widget
      sudo npm install -g clustergrammer
      pip install clustergrammer
         /Users/paul/anaconda/lib/python3.5/site-packages/clustergrammer/
   --- try it out

     "The easiest way to visualize a matrix of your own data is to
      follow the example Python workflow that demonstrates how to use
      the Python library clustergrammer.py."

      cd ~/s/examples/clustergrammer
      mkdir json

      python

        from clustergrammer import Network
        net = Network()


        net.load_file('/Users/paul/github/clustergrammer/txt/rc_two_cats.txt')
        net.make_clust(dist_type='cos',views=['N_row_sum', 'N_row_var'])
        net.write_json_to_file('viz', 'json/mult_view.json')



   cd ~/github/clustergrammer-widget/
   pip install -e .

   pip install clustergrammer  # prerequisite
   pip install -e .
   jupyter nbextension enable --py --sys-prefix clustergrammer_widget


*-----------------------------------------------------------------------------------------------------------------------
* binder: Turn a GitHub repo into a collection of interactive notebooks (9 nov 2016)

   Have a repository full of Jupyter notebooks? With Binder, you can
   add a badge that opens those notebooks in an executable
   environment, making your code immediately reproducible by anyone,
   anywhere.

   http://mybinder.org/

*-----------------------------------------------------------------------------------------------------------------------
* python postgres jupyter problem on riptide (7 nov 2016)

     # but works ok on whovian, so not pursuing this right now

   riptide> python   # macos 10.11.6, El Capitan

   Python 3.5.2 |Anaconda custom (x86_64)| (default, Jul  2 2016, 17:52:12)
   [GCC 4.2.1 Compatible Apple LLVM 4.2 (clang-425.0.28)] on darwin
    >>> import pandas as pd, psycopg2 as psql
     ImportError: dlopen(/Users/paul/anaconda/lib/python3.5/site-packages/psycopg2/_psycopg.cpython-35m-darwin.so, 2): Library not loaded: libssl.1.0.0.dylib
     Referenced from: /Users/paul/anaconda/lib/python3.5/site-packages/psycopg2/_psycopg.cpython-35m-darwin.so
     Reason: image not found



*-----------------------------------------------------------------------------------------------------------------------
* dani's vrk2/pou3f2 notebook (7 nov 2016)

  I was thinking that another interesting micro-study we could try out
  with this new tool is related to the Bipolar work around a SNP in
  the promotor region of the VRK2 gene, where the transcription factor
  Pou3f2 binds. You might remember Jocelynn discussing this in her
  committee meeting talk, and we both also presented this a while back
  to the Hood lab.

  The SNP lies in the binding site of Pou3f2. I believe we saw a
  reduction of VRK2 expression while the SNP present. I attached a
  screenshot of this result--look at the first two groups to see the
  reduction.

  Anyway--I would be happy to do a trial run through that part of the
  notebook if you think its a good case study. I was thinking about
  how interesting it would be if we could see maybe additional TF
  motifs created from the SNP--maybe creating competition for Pou3f2
  to bind. That might be hopeful wishing, but it could be neat to
  check.


  --- query motifsgenes table from python
    import pandas as pd, psycopg2 as psql
    # R version db <- dbConnect(PostgreSQL(), user= "trena", password="trena", dbname="hg38", host="whovian")
    # this fails:  conn = psql.connect("dbname=hg38 user=trena")
    # and this works
   db = psql.connect("dbname=hg38 user=pshannon")
   pd.read_sql_query("select * from motifsgenes limit 3", db)
         motif      tf
   0  MA0002.2   RUNX1
   1  MA0003.3  TFAP2A
   2  MA0004.1    ARNT

   --- the snp loses all pou-family tfs, picks up pax3,4,6,7

   http://whovian:10005/notebooks/shared/VRK2-Pou3f2.ipynb   and ~/github/notebooks/shared/VRK2-Pou3f2.ipynb


*-----------------------------------------------------------------------------------------------------------------------
* seward park restoration

  --- plants for november 2016


                                    blakeley cliffs/lost lake trail


Corylus cornuta, beaked hazelnut                  4/36
Mahonia nervosa, dwarf Oregon grape               0/60
Oemleria cerasiformis, indian plum                5/25
Pseudotsuga menziesii, Douglas fir                0/40
Rubus parviflorus, thimbleberry                   5/35
Rubus spectabilis, salmonberry                    5/35
Rubus ursinus, trailing blackberry                5/40


*-----------------------------------------------------------------------------------------------------------------------
* movie candidates

  slum dog millionaire
  tom hanks east hudson airplane crash

*-----------------------------------------------------------------------------------------------------------------------
* sequence tips, fasta tips  (for rory and jocelyn) (3 nov 2016)

source(“http://bioconductor.org/biocLite.R”)
biocLite("BSgenome.Hsapiens.UCSC.hg38")
library(BSgenome.Hsapiens.UCSC.hg38)
hg38 = BSgenome.Hsapiens.UCSC.hg38

as.character(getSeq(hg38, "chr5", 1295228, 1295250))

# you can also gang up your requests
x <- getSeq(hg38, rep("chr5", 3), rep(1295228,3), rep(1295250, 3))

# and write them all out in fasta format
writeXStringSet(x, filepath="foo.fa")

*-----------------------------------------------------------------------------------------------------------------------
* python regex for chromloc strings, chromosomal locations (3 nov 2016)

snp = 'chr16:55508991-55508991'
regex = re.compile('(chr.*):(\d+)-(\d+)')
m = regex.match(snp)
assert(len(m.groups()) == 3)
(chrom, start, end) = m.groups()
start = int(start)
end = int(end)
print("%s  %d  %d" % (chrom, start, end))

def parseChromLoc(s):
  regex = re.compile('(chr.*):(\d+)-(\d+)')
  m = regex.match(snp)
  assert(len(m.groups()) == 3)
  (chrom, start, end) = m.groups()
  start = int(start)
  end = int(end)
  return((chrom, start, end))


(chrom, start, end) = parseChromLoc("chr19:32-64000")


*-----------------------------------------------------------------------------------------------------------------------
* add microservices to jupyter notebook (3 nov 2016)

  for background, see below:  microservices on whovian (9 sep 2016)   dna, fimo

  --- from notebook
   import sys
   sys.path.append("/Users/paul/github/fimoService/client-python")
   from FimoClient import *
   sys.path.append("/Users/paul/github/getDNAService/client-python")
   from GetDNAClient import *
fimo = FimoClient("whovian", 5558)
assert(fimo.getHost() == 'whovian:5558')
dnaService = GetDNAClient("hg19")
assert(dnaService.getSequence("chr1", 1, 5) == 'NNNNN')
sequences = {"tert_wt1": "CCCGGAGGGGG", "tert_wt2": "CCCGGGAGGGG", "tert_mut": "CCCCTTCCGGG"}
fimo.request(sequences)

 	#pattern name 	matched sequence 	p-value 	q-value 	score 	sequence name 	start 	stop 	strand
0 	MA0076.2 	CCCCTTCCGGG 	0.000022 	0.000133 	13.1818 	tert_mut 	1 	11 	+
1 	ELK1,4_GABP{A,B1}.p3 	CCCGGAAGGG 	0.000045 	0.000539 	11.7000 	tert_mut 	2 	11 	-
2 	ETV6_full_2 	CCCGGAAGGG 	0.000093 	0.001120 	10.7245 	tert_mut 	2 	11 	-
3 	MA0645.1 	CCCGGAAGGG 	0.000095 	0.001150 	10.7308 	tert_mut 	2 	11 	-

*-----------------------------------------------------------------------------------------------------------------------
* putting cyjs into jupyter notebook as a js widget, with javascript magic (15 oct 2016)

  --- need http webserver, cytoscape.js
     now: cd ~/http
     python -m http.server 8099
     this supports
       require.config({paths: {cytoscape: 'http://localhost:8099/js/cytoscape-2.7.10'}})

  --- need jupyter server
    cd ~/s/examples/jupyter/javascriptMagic/
    jupyter notebook --port 10001

  --- simple demo notebook: this has magic only, no jupyter widgets, no python
    cd ~/s/examples/jupyter/javascriptMagic/cyjs/
    jupyter notebook cyjsSimpleDemoWithMagic.ipynb

*-----------------------------------------------------------------------------------------------------------------------
* ChIPseq figures for jocelyn (2 nov 2016)

   --- jocelyn's email (1 nov 2016)

    cc'ing Dani here as well.  Attached are two papers that have some
    beautiful ChIPseq figures.  I'd love to generate a few similar
    figs for our Htt ChIPseq dataset.

    Malik - Fig 1A, 1D, 2D, 4A, 4D
     Prescott - Fig 1A, 1E, 2C, 2D, 4F

    Currently we are using IGV to generate similar figures to what you
    see in Malik 2D.  We convert our bed files to big wigs and view
    them there.  What I really love about the Prescott paper is the
    flow of the way the data is laid out - it makes it really easy to
    follow.  I'm not sure exactly how they create the smaller 'zoom'ed
    overlay of chipseq data such as in Prescott 1E but I think that is
    really nice.


   --- more info from a followup email


    In Prescott 2C they show heat maps with ChIPseq reads centered
    over a type of genomic feature.*

    For our purposes, we would want to generate heat maps comparing
    raw ChIPseq counts for all known motifs of EGR1 and TFAP2A across
    the mouse genome (mm9).  These are common figures in ChIPseq
    papers and help visually convey differences in groups of samples
    (in our case, wildtype vs mutant) for the enrichment of specific
    kinds of sites in the peaks from those samples.  Usually the peaks
    get sorted by enrichment value, with highest at the top and lowest
    at the bottom.

    It looks like deeptools is an attractive candidate for generating
    these: https://www.biostars.org/p/180314/ - they have a new color
    option that could help us with the different motifs such as shown
    in Prescott.  But I have no experience using any of these tools!

    Data requirement: INPUT: BigWig files of ChIP-seq marks, and feature dataset in BED format.
    BigWigs located here: /proj/price1/jpearl/ChIPseq/EPR5526/individualsamplefiles/*.bw
    feature dataset I'm guessing is the list of motif locations

    If this interests you, cool!  But if not I'm sure we can work on it in a week when our time frees up.

    Best,
     Jocelynn

    *[showing: (C) Heatmap of raw ChIP-seq and ATAC-seq counts across
     species-biased and invariant CNCC enhancers for two human and two
     chimp genetic backgrounds.  Each row represents a 2 kb window (1
     kb each direction) centered around the middle of human-biased (n
     = 598, q < 0.0001), chimp-biased (n = 691, q < 0.0001), or
     invariant (n = 584 representative subset, q > 0.95) enhancers for
     H3K27ac (green), p300 (red), TFAP2A (yellow), K4me1 (blue), and
     ATAC-seq (gray). All reads were aligned to hg19.]

*-----------------------------------------------------------------------------------------------------------------------
* new run of createFeatureTable on whovian, chr19 lymphoblast, wellington, hint, piq, chipSeq (2 nov 2016)

  whovian
  cd ~/s/work/priceLab/cory/lymphoblastFeatureTable/chr19-31oct2016/
  use runLocal.R
  encountered mysterious empty chipseq regions around 24M.  modified (with new tests)
  ~/github/BDDS/trenadb/src/createFeatureTable.R - though more exploration of the empty
  contributing table matter is definitely needed.

   grabbed first version of the RData combiner:
   cp ~/s/work/priceLab cory/lymphoblastFeatureTable/combine.R ~/s/work/priceLab/cory/lymphoblastFeatureTable/chr19-31oct2016/

   files <- sort(list.files(".", pattern="ftClean.*"))
   length(files) #  [1] 119
   added start and end columns, producing 1,382,248 rows x 21 columns

   tbl.hit.all: 9655
   tbl.cs.only: 13603
   tbl.w.only: 129657
   tbl.h.only: 644425
   tbl.p.only: 256429
   tbl.wh.only: 182241
   tbl.wc.only: 5579
   tbl.hc.only: 33184
   tbl.wp.only: 5945
   tbl.cp.only: 1297
   tbl.hp.only: 3333
   tbl.hpw.only: 9655

  f <- "~/s/work/priceLab/cory/lymphoblastFeatureTable/chr19-31oct2016/featureTableLymphoblast-chr19-entire.RData"
  save(tbl, file=f)


*-----------------------------------------------------------------------------------------------------------------------
* neo4j, igap, gustavo's fcm, demo for price lab meeting (29 oct 2016)

  cd ~/s/data/priceLab/functionalConnectionMaps/ad-igap-demo

  --- scheme
   1) 203 snp chromLocs (from neo4j; originally from
         load("snpsInFootprintsWith5kbOfGene.RData")  # 5110 x 9
   2) the gdb has relations
       (snpLoc)-[near]-(gene)-[inGeneSet]-(geneset)    # where geneset size is reported as score
       genesetsForSnp(snp.loc, maxScore=50)
                                         id score
       1                 KANG_GLIS3_TARGETS    37
       6              GRADE_COLON_CANCER_DN    33
       14               GOLUB_ALL_VS_AML_UP    24
       18 MANTOVANI_VIRAL_GPCR_SIGNALING_DN    49
       26                   PID_IL3_PATHWAY    27
       27               KEGG_PROTEIN_EXPORT    24
   3) doing this at scale, in test.getAllSnpLocsGenesets
      x <- getAllSnpLocs()
      tbl.list <- getAllSnpLocsGenesets(x, maxScore=100)
      all.genesets <- unlist(lapply(tbl.list, function(df) df$id))
      tbl.dist <- subset(data.frame(table(all.genesets)), Freq > 3)

                                    all.genesets Freq
   352                    LEE_AGING_NEOCORTEX_UP    4
   586 REACTOME_GLYCEROPHOSPHOLIPID_BIOSYNTHESIS    4



*-----------------------------------------------------------------------------------------------------------------------
* neo4j for igap snps and msigdb, and gustavo's fcm (29 oct 2016)

  --- start database
    neo4j is /Users/paul/apps/neo4j/neo4j-community-3.0.6/bin/neo4j
    neo4j start
       Starting Neo4j.
       Started neo4j (pid 9320). By default, it is available at http://localhost:7474/
       There may be a short delay until the server is ready.
       See /Users/paul/apps/neo4j/neo4j-community-3.0.6/logs/neo4j.log for current status.

    browse to localhost:7474  user: neo4j  password isb
    gdb <- startGraph("http://localhost:7474/db/data/", username="neo4j", password="isb");

  --- fill neo4j database:
    cd ~/s/data/public/human/msigdb-oct2016; make
    cd ~/s/data/priceLab/functionalConnectionMaps/ad-igap-demo; make rebuild

  --- R script for exploration
   cd ~/s/data/priceLab/functionalConnectionMaps/ad-igap-demo/
   explore.R

*-----------------------------------------------------------------------------------------------------------------------
* backbone learning, with python flask and rethinkdb: my own installation in ~/s/examples (31 oct 2016)

  sh-learnBackbone
  cd ~/s/examples/js/backbone/todoAppWithPythonFlaskRethinkdbServer

    # take working example from ~/github/rethinkdb-example-flask-backbone-todo, copy it to ~/s/examples/....
        newTodo.py
        templates/
           todo.html   # has flask micro markup
        static/
           todos.js
           assets/
              destroy.png
              todos.css
              vendor/
                backbone-min.js
                jquery.js
                json2.js
                underscore.js

   ---- make sure no other version of todo.py is running:
*-----------------------------------------------------------------------------------------------------------------------
* python flask and rethinkdb: a demo of backbone's Todos app (28 oct 2016)

  git clone git://github.com/rethinkdb/rethinkdb-example-flask-backbone-todo.git
  pip install Flask
  pip install rethinkdb

  also macos installed RethinkDB v2.3.5 from dmg

  rethinkdb &

  ---- now to the app
     python todo.py --setup   # added print() for python 3
     python todo.py
        * Running on http://127.0.0.1:5000/ (Press CTRL+C to quit)
        * Restarting with stat
        * Debugger is active!
        * Debugger pin code: 736-156-344

   browse to localhost:5000 see (somewhat stripped down) Todos app

   writes to rethinkdb at http://localhost:28015,
   human interface at http://localhost:8080

   --- go to the Data Explorer tab

    r.dbList();   #      rethinkdb, test, todoapp    # use shift-return to execute
    r.db("todoapp").tableList();   # "todos"

  --- query current contents:
     r.db("todoapp").table("todos");

*-----------------------------------------------------------------------------------------------------------------------
* python flask and backbone (28 oct 2016)

  http://simplectic.com/blog/2014/flask-todomvc-part1/
  cd ~/s/work
  mkdir flask-todomvc
  cp -R ~/github/todomvc/examples/backbone flask-todomvc/
  python -m http.server
  browse to http://localhost:8000/backbone/


  --- now install Flask
    pip install Flask --upgrade

    python server.py
    browse to localhost:8000 # see "hello world"
    browse to http://localhost:8000/backbone/#/   see (all javascript?) backbone todo list

  mkdir static
  mkdir templates
  mv backbone/js static
  mv backbone/index.html templates/
  mv backbone backbone-hidden
  python server.py, browse to 8000, libraries (jquery et al not found)

*-----------------------------------------------------------------------------------------------------------------------
* python virtual environment (28 oct 2016)

  status:  abandoned, python virturalenv setuptools pip wheel failed with error code -11

  pip install virtualenv

*-----------------------------------------------------------------------------------------------------------------------
* backbone tips, javascript tips: bind bindAll, call, apply

  http://blog.bigbinary.com/2011/08/18/understanding-bind-and-bindall-in-backbone.html

  function Developer(skill) {
     this.skill = skill;
     this.says = function(){
        alert(this.skill + ' rocks!');
        }
     }

   var john = new Developer('R');
   var func = john.says;
   func(); // undefined rocks!
   func.apply(john) // R rocks

   var john = new Developer('Ruby');
   var func = _.bind(john.says, john);
   func(); // Ruby rocks!

   var john = new Developer('python');
   _.bindAll(john, 'says');
   var func = john.says;
   func(); // python rocks!

   The first big difference is that we do not have to worry about the
   returned value of bindAll . In case of bind we must use the
   returned function. In bindAll we do not have to worry about the
   returned value but it comes with a price. bindAll actually mutates
   the function. What does that mean.

   The john object has an attribute called 'says' which returns a
   function. bindAll changes the attribute 'says' so that when
   it returns a function, that function is already bound to john.



  --- from http://stackoverflow.com/questions/15455009/javascript-call-apply-vs-bind

    Use .bind() when you want that function to later be called with a
    certain context, useful in events. Use .call() or .apply() when you
    want to invoke the funciton immediately, and modify the context.

    Call/apply call the function immediately, whereas bind returns a
    function that when later executed will have the correct context set
    for calling the original function. This way you can maintain
    context in async callbacks, and events.

  --- javascript models tips, this

   https://rainsoft.io/gentle-explanation-of-this-in-javascript/

    In JavaScript, this is the current execution context of a
    function. Because the language has 4 function invocation types:

      function invocation: alert('Hello World!')
      method invocation: console.log('Hello World!')
      constructor invocation: new RegExp('\\d')
      indirect invocation: alert.call(undefined, 'Hello World!')

   and each one defines its own context, this behaves slight different than developer expects.
   Moreover strict mode also affects the execution context.

  'this' is the object that owns the method in a method invocation
   When invoking a method on an object, 'this' becomes the object itself.

   Creating a bound function (using .bind(), see 6.) fixes the
   context, making it the object that owns the method.

*-----------------------------------------------------------------------------------------------------------------------
* marianne elliott, wsu puyallup plant pathology visit (27 oct 2016)

  cd ~/s/work/fatnose/marianneElliott/

    Attached are a brief description of the native plant project and
    preliminary results and the APHIS protocol for soil sampling.

    I have included our protocol for baiting from potted plants (NP
    methods). When you send me the list of plants you are getting,
    then we will come up with a sampling plan like we discussed. We
    will send you the bait leaves to use. We have a planting of
    rhododendrons for that purpose.

    The conference is Dec 6-8 and I have attached the info about it,
    in case you or someone from your group is able to go.


*-----------------------------------------------------------------------------------------------------------------------
* dead simple backbonejs tutorial (28 oct 2016)

  https://github.com/arturadib/hello-backbonejs.git

*-----------------------------------------------------------------------------------------------------------------------
* python tips **

  in Python, ** is a notation that means that any extra keyword
  arguments passed to the function should be put in a dictionary
  called attrs where the keys are the parameter names and the values
  are their corresponding values.

*-----------------------------------------------------------------------------------------------------------------------
* assess footprints (26 oct 2016)

  cd ~/github/BDDS/footprints/assess

  --- load existing files
    ~/github/BDDS/footprints/functionalTests/data/ENCSR000DBY.19.chr.bam    # 48M
    zoom to APOE, then chr19:44,859,094-44,956,080


*-----------------------------------------------------------------------------------------------------------------------
* franklin et al summary: ecological characteristics of old-growth douglas-fir forests

  https://www.fs.fed.us/pnw/pubs/pnw_gtr118.pdf

  The major ecological features of old- growth coniferous forests in the Douglas-fir region are
  reviewed. Special attention is given to characteristics that distinguish old- growth forests from
  managed and unmanaged (natural) young stands. The primary exemplary type is 350- to 750-year-old
  Douglas-fir-western hemlock forest typical of the western slopes of the Cascade Range, but other
  types and locales are discussed. Management techniques for maintenance of old- growth forests are
  also considered. Major conclusions are:

  1. Approximately 175 to 250 years are required to develop old-growth forests under natural
  conditions in both Coast and Cascade Ranges. Development of old growth is faster on good sites
  than on poor sites.

  2. Few plant or animal species are solely confined to old-growth forests, although many species-
  including several vertebrates, saprophytic plants, and epiphytic lichens-find optimum habitats in
  such forests. Some organisms, however, may require old growth to maintain viable
  populations. Moreover, there are substantial dif- ferences in composition and relative abundance
  of species between young- and old-growth forests.

  3. Gross productivity is maintained at high levels in most old-growth stands, but mortality
  generally balances growth. Thus, the merchan- table board-foot volume tends to re- main constant
  for several centuries or gradually decreases because the amount of defect increases. Total organic
  matter keeps increasing because of accumulated masses of dead tree boles, mostly as down logs.

  4. Old-growth forests are highly retentive of nutrients; large amounts are incorporated into
  living and dead organic matter. Losses of limiting nutrients, such as nitrogen, are low.

  5. Nitrogen-fixing epiphytes are abundant in old-growth trees, and bacterial nitrogen fixation
  appears to be common in the large woody debris characteristic of old-growth forests.

  6. Small- to medium-size streams in old-growth forests depend mainly on forest litter for an
  energy base. These materials are invariably par- tially utilized before they are ex- ported
  downstream.

  7. The structure of old-growth forest is more heterogenous than that of young forests;
  coefficients of varia- tion in tree sizes are greater, and understory patchiness is much higher
  than in young-growth stands.


  6. Most of the distinctive features of old-growth forests can be related to four structural
  features: (1) large, live old-growth trees, (2) large snags, (3) large logs on land, and (4) large
  logs in streams. The struc- tural features are related over time.

  9. A large, old-growth Douglas-fir is individualistic and commonly has an irregularly arranged,
  large, coarse branch system, and often, a long crown. It is ideal habitat for specialized
  vertebrates, such as the red tree vole, northern spotted owl, and northern flying squirrel, as
  well as nitrogen-fixing lichens.

  10. Large snags are valuable as habitat for a variety of vertebrates and invertebrates and as a
  future source of logs.

  11. Logs on the forest floor are im- portant habitats for small mammals, including species that
  disperse spores of mycorrhiza-forming fungi. They also are sites for substantial bacterial
  nitrogen fixation and are essential as seedbeds for some trees and shrubs.

  12. Logs are critical to maintenance of physical and biological stability in headwater
  streams. Debris dams create stepped stream profiles that dissipate energy otherwise used for
  transportingsedimentandlateral- cutting and downcutting of stream channels. Such dams, with their
  associated plunge pools and beds of trapped gravels and fine sedi- ments, provide a range of
  habitats needed to maintain a full array of stream and stream-margin organ- isms. Logs are an
  important source of energy, and the bulk of the ntirogen supply of a stream comes from woody
  debris.

  13. Foresters wishing to maintain or create ecosystems with old-growth characteristics can tie
  management schemes to maintenance or develop ment of the four key structural com- ponents-large
  live, old-growth trees, large snags, and large logs on land and in streams.


  14. Watersheds are probably best suited as management units for old- growth ecosystems. A small
  drain- age usually has greater terrestrial habitat variability than occurs in a single stand, as
  well as a complete stream system. The size of a man- agement unit will vary but probably should be
  at least 300 acres (120 hectares) to reduce effects of edges and susceptibility to damaging
  agents, such as wind, as well as to maintain viable populations of some birds and small mammals.


  15. Buffer or leave strips along streams are also useful areas to manage as old-growth sites
  because woody debris is provided to the stream, and the riparian zone, a par- ticularly rich and
  critical wildlife habitat, is protected. Such buffers, along with roadside strips of old- growth
  forest, also provide migra- tion routes for wildlife between otherwise isolated patches of mature
  or old-growth forest.


  16. Some ecological aspects of old- growth forests can be maintained by managing for individual
  attributes; for example, leaving scattered old- growth trees, rotten logs, or snags on cutover
  lands. The linked nature of these key structural components, as well as the requirements of some
  organisms for the total environment of an old-growth stand, makes management of entire stands a
  simpler approach to retention of such ecological features.

*------------------------------------------------------------------------------------------------------------------------
* update sword fern die-off maps, from nelson and from tristan & kramer (26 oct 2016)

   cd ~/s/work/fatnose/swordFerns/
   two new directories:
    ~/s/work/fatnose/swordFerns/before.15jun2016/
    ~/s/work/fatnose/swordFerns/october.2016/fromNelson

    (17 oct 2016) updates from kramer & tristan:
       https://docs.google.com/spreadsheets/d/1WldC-Np3hJRwLzVop9EpgssBSpMZZJssLNc64qqu0X4

     ~/s/work/fatnose/swordFerns/october.2016/fromKramer/sewardParkFernDataSheet1.tsv

    my corrections to the loaded kmz files (loaded into google maps)
       ~/s/work/fatnose/swordFerns/october.2016/fromNelson/myRevisionOf10-16.map.key

*-----------------------------------------------------------------------------------------------------------------------
* getDnaSequence for jocelyn (25 oct 2016)

  cd   ~/s/examples/bioc/bsgenome.hg38/
  go.R:

  library(BSgenome.Hsapiens.UCSC.hg38)
  hg38 = BSgenome.Hsapiens.UCSC.hg38
  as.character(getSeq(hg38, "chr5", 1295228, 1295250))


*-----------------------------------------------------------------------------------------------------------------------
* trena demo: find trem2 regulators (25 oct 2016)

   https://github.com/PriceLab/TReNA/tree/master/inst/demos/trem2
   ~/github/TReNA/inst/demos/trem2/go.R

*-----------------------------------------------------------------------------------------------------------------------
* cleveland, ann stukenberg (aka Elizabeth Morris)

  http://snap.berkeley.edu/snapsource/snap.html
  EdgeEdX: pshannon@systemsbiology.org
  alex: unit 1 lab 3 or 4 is where she is working.

*-----------------------------------------------------------------------------------------------------------------------
* rcyjs: load json file exported from cytoscape (24 oct 2016)

   import sif   # a regulates b, tab delimited
   library(RCyjs)
   rcy <- RCyjs(10000:10100, graph=graphNEL())
     # make sure "network = {" is the firest line in the json graph file
   send(rcy, list(cmd="httpAddGraph", callback="handleResponse", status="request", payload="models.cyjs"))
      # must control c after graph appears: normal browserResponseReady loop not made available here

*-----------------------------------------------------------------------------------------------------------------------
* cy3 + cyjs + RCyjsfor layout

    save sif file from R
    import to Cy3
    export as cyjs json to new file

    rcy <- display(g=graphNEL())
      # make sure "network = {" is the firest line in the json graph file
    send(rcy, list(cmd="httpAddGraph", callback="handleResponse", status="request", payload="newFile.cyjs"))
      # must control c after graph appears: normal browserResponseReady loop not made available here

*-----------------------------------------------------------------------------------------------------------------------
* lymphoblast chr19:42-47M feature table, piq added to wellington and hint and chipseq (24 oct 2016)

  whovian, cd ~/s/work/priceLab/cory/lymphoblastFeatureTable

for easy access:  whovian:/tmp/featureTableLymphoblast42.47M.RData   (file is 2.5M in size)


dim(tbl) # 121607     19

tbl.hit.all: 850
tbl.cs.only: 1283
tbl.w.only: 10972
tbl.h.only: 55273
tbl.p.only: 21962
tbl.wh.only: 16947
tbl.wc.only: 451
tbl.hc.only: 3400
tbl.wp.only: 466
tbl.cp.only: 105
tbl.hp.only: 294
tbl.hpw.only: 916
tbl.cwh.only: 6654
 >
   --- compare to previous run, without piq (1 oct 2016)

The latest feature table, for lymphoblast chr19:42000000-47000000 is in the PriceLab/BDDS github repo

<yourGithubRoot>/BDDS/trenadb/featureTable/lymphoblast/ftClean.Fri.Sep.30.2016-18:02:21.RData

print(load("ftClean.Fri.Sep.30.2016-18:02:21.RData")) # ft.clean,  96825 rows, 11 columns

The first two rows, transposed into columns for legibility:

R> as.data.frame(t(ft.clean[1:2,]))
                                       1                       2
loc              chr19:42000006-42000014 chr19:42000007-42000019
motif                           MA0738.1                MA0872.1
samplecount.w                          0                       0
score.w                              -99                     -99
samplecount.h                          1                       1
score.h                               16                      16
csTF                                <NA>                    <NA>
csscore                                0                       0
motifscore                       11.1636                 10.1967
motifpval                       6.51e-05                7.15e-05
totalsamplecount                      18                      18

The rows break out like this:

  cwh:        7172       locations with chipseq, wellington and hint hits
  cs.only:    1315
  w.only:    10775
  h.only:    56424
  wh.only:   17241
  wc.only:     441
  hc.only:    3457
  sum:       96825
*-----------------------------------------------------------------------------------------------------------------------
* resuscitate yfiles layout service, using yfiles 2.7 from 2010 (24 oct 2016)


*-----------------------------------------------------------------------------------------------------------------------
* jupyter widgets intSlider: study, extract from nbextension form into a single web page (24 oct 2016)

  ~/github/ipywidgets/jupyter-js-widgets/src/widget_int.ts   # 762 lines
  ~/github/ipywidgets/ipywidgets/widgets/widget_int.py       # 269 lines


   too many configuration options about which I am ignorant: cannot compile ts into js
   abandoning this project, but hoping that this code can answer some of
   the questions which arise with

      ~/s/examples/jupyter/javascriptMagic/simpleD3circle


*-----------------------------------------------------------------------------------------------------------------------
* nohup tips


  nohup R -f createFeatureTable.R  >ft.run.22oct2016 2>&1  &

*-----------------------------------------------------------------------------------------------------------------------
* getDNAService, retrieve multiple sequences, needed by jocelyn (21 oct 2016)

   http://genome.ucsc.edu/cgi-bin/das/hg19/dna?segment=chr5:1295260,1295262;segment=chr5:1295260,1295270
   chunk up multiple requests into some optimal size (10 segments per request?)

   ~/github/getDNA/client-R/getDNAClient/inst/unitTests/

*-----------------------------------------------------------------------------------------------------------------------
* try to make a persistent svg in the simple CircleView learning jupyter-js-widgets notebook (19 oct 2016)

  cd ~/s/examples/jupyter/javascriptMagic/simpleD3circle/

  --- made this change:
      _radius_changed: function() {
         console.log("CircleView:_radius_changed called")
         var newRadius= this.model.get('radius');
         //var canvas = this.createCanvasDrawCircle(newRadius);
         window.canvas =  this.createCanvasDrawCircle(newRadius);

   in console, found this for window.canvas:

    [Array[1]0: svg#svgassignedSlot: null
    attributes: NamedNodeMapbaseURI: "http://localhost:10001/notebooks/simpleD3circle/current-1.9.ipynb"
    childElementCount: 1
    childNodes: NodeList[1]
    children: HTMLCollection[1]
    classList: DOMTokenList[0]
    className: SVGAnimatedString
    clientHeight: 300
    clientLeft: 0
    clientTop: 0
    clientWidth: 600
    currentScale: 1
    currentTranslate: SVGPoint
    currentView: SVGViewSpec
    farthestViewportElement: null
    firstChild: circle
    firstElementChild: circle
    height: SVGAnimatedLength
    id: "svg"
    innerHTML: "<circle r="80" cx="300" cy="150" style="stroke: gray; fill: white;"></circle>"
    ....





*-----------------------------------------------------------------------------------------------------------------------
* ipywidgets, jason grout: custom widget composed of parent/child widgets (19 oct 2016)

   see https://github.com/ipython/ipywidgets/issues/700
*-----------------------------------------------------------------------------------------------------------------------
* rcs client for macos (18 oct 2016)

  got dmg from http://rudix.org/packages/rcs.html
   806 Apr  9  2016 /usr/local/bin/ci
*-----------------------------------------------------------------------------------------------------------------------
* R tips: switch statement, R switch

   solver <- "hoopla"
   switch(solver,
          randomForest={
             printf("randomForest")
             },
          printf("unrecognized solver: %s", solver )
          )

* R tips: regex, gregexpr

   library(stringr)
   extractChromStartEndFromChromLocString <- function(chromlocString) {
      mtx.match <- str_match(chromlocString, ("(.*):(\\d+)-(\\d+)"))
      chromosome <- tolower(mtx.match[1, 2])
      if(!grepl("chr", chromosome))
          chromosome <- sprintf("chr%s", chromosome)
      start <- as.integer(mtx.match[1, 3])
      end <- as.integer(mtx.match[1, 4])
      return(list(chrom=chromosome, start=start, end=end))
      }

   test.extractChromStartEndFromChromLocString <- function(){
      checkEquals(extractChromStartEndFromChromLocString("7:1010165577-101165615"),
                  list(chrom="chr7", start=1010165577, end=101165615))
      checkEquals(extractChromStartEndFromChromLocString("chr7:1010165577-101165615"),
                  list(chrom="chr7", start=1010165577, end=101165615))
      checkEquals(extractChromStartEndFromChromLocString("CHR7:1010165577-101165615"),
                  list(chrom="chr7", start=1010165577, end=101165615))
      }




*-----------------------------------------------------------------------------------------------------------------------
* R tips: a compendium of visually rich, cleanly-coded graphs

  http://shinyapps.org/apps/RGraphCompendium/index.php

*-----------------------------------------------------------------------------------------------------------------------
* learning jupyter-js-widgets (ipywidgets) - a simple d3 experiment (18 oct 2016)

   working in ~/s/examples/jupyter/javascriptMagic/simpleD3circle
   start jupyter notebook --port 10001  --log-level=0

   when ready to checkin:
      ci -l current.ipynb
      cp current.ipynb /Users/paul/github//notebooks-pshannon/study/CircleView.ipynb
      cd ~/github//notebooks-pshannon/study/
  in hopes of getting guidance from https://github.com/ipython/ipywidgets, jason grout
  at issue https://github.com/ipython/ipywidgets/issues/838#issuecomment-254367449
  checked in here:

    https://github.com/paul-shannon/notebooks/tree/master/study
      CircleView.ipynb

*-----------------------------------------------------------------------------------------------------------------------
* putting cyjs into jupyter notebook, with javascript magic (15 oct 2016)  no js-widget yet, for that see above

  --- need http webserver, cytoscape.js
     now: cd ~/http
     python -m http.server 8099
     this supports
       require.config({paths: {cytoscape: 'http://localhost:8099/js/cytoscape-2.7.10'}})

  --- need jupyter server
    cd ~/s/examples/jupyter/javascriptMagic/
    jupyter notebook --port 10001

  --- simple demo notebook
    http://localhost:10001/notebooks/cyjs/cyjsSimpleDemoWithMagic.ipynb
    cd ~/s/examples/jupyter/javascriptMagic/cyjs
    cyjsSimpleDemoWithMagic.ipynb   # tracked in RCS, working on (2 nov 2016)

*-----------------------------------------------------------------------------------------------------------------------
* learning jupyter-js-widgets (ipywidgets) - a simple d3 experiment (15 oct 2016)


  --- need jupyter
    cd ~/s/examples/jupyter/javascriptMagic
    jupyter notebook --port 10001
    d3circle-in-ipywidget.ipynb

    navigate to simpleD3circle

  --- a bastardized working version (d3 made avaialable through a require hack.
      canvas created only out of a post rendering callback

%%javascript
require.config({paths: {d3: '//cdnjs.cloudflare.com/ajax/libs/d3/3.4.8/d3.min'}});
import ipywidgets as widgets
from traitlets import Int, Unicode, validate
class CircleWidget(widgets.DOMWidget):
    _view_name = Unicode('CircleView').tag(sync=True)
    _view_module = Unicode('circle').tag(sync=True)
    value = Unicode('Hello Circle!').tag(sync=True)
    count = Int(0).tag(sync=True)
%%javascript
require.undef('circle');

define('circle', ["jupyter-js-widgets"], function(widgets) {

    var CircleView = widgets.DOMWidgetView.extend({

        createCanvasDrawCircle: function(){
           var svg = window.d3.select("#circleDiv").append("svg").attr("width", 600).attr("height", 300);
           svg.append("circle")
              .style("stroke", "gray")
              .style("fill", "white")
              .attr("r", 100)
              .attr("cx", 300)
              .attr("cy", 150)
              .on("mouseover", function(){d3.select(this).style("fill", "aliceblue");})
              .on("mouseout", function(){d3.select(this).style("fill", "white");});
           console.log("render, appended circle")
            return(svg)
           },

        createView: function(){
           console.log("hola, CircleView ctor")
           require(["d3"], function(d3){
              console.log(d3.version);
              window.d3 = d3;
              });
            var div = $("<div style='border:1px solid red; height: 300px; width: 600px'>").html("my own private div");
            div.append("<div id='circleDiv'>circle div 5</div>");
              //div.append("<div id='foo'> div foo</div>");
            //div.append("<div id='bar'> div bar</div>");
            //div.append("<div id='gam' style='border:1px solid black; height: 200px;'> div gam</div>");
            return(div);
            },
         render: function() {
            this.$el.append(this.createView());
              // no circle, no canvas when called from here
            //var svg2 = this.createCanvasDrawCircle();
            this._count_changed();
            this.listenTo(this.model, 'change:count', this._count_changed, this);
           },
        _count_changed: function() {
           var newCount = this.model.get('count');
           var canvas = this.createCanvasDrawCircle();
           this.$el.append("<h3>" + newCount + "</h3>");
           this.$el.append("<h3>" + window.d3.version + "</h3>");
           }
      });
    return {
        CircleView : CircleView
    };
});

cw = CircleWidget(height=300, width=500)
cw

cw.count = 10  // only here does the circle get drawn


*-----------------------------------------------------------------------------------------------------------------------
* vineet's 98 compound, gene model  network (15 oct 2016)
*-----------------------------------------------------------------------------------------------------------------------
* vineet's 98 compound, gene model  network (15 oct 2016)

  cd ~/s/work/priceLab/vineet/screen/

  --- from email
    Each line represent a gene interaction model which reads as follows:
       G = TF1, TF2,TF3 ...
      G1 = Gene 1
     TF1 = Transcription Factor 1
     TF2 = Transcription Factor 2

   Objective is to figure out how many network modules do we get out
   of these equations. Also how do we visualize the modules for 98
   compounds.

  --- first look

*-----------------------------------------------------------------------------------------------------------------------
* jupyter notebook ipywidgets detailed examples (15 oct 2016)

  listed here: https://github.com/ipython/ipywidgets
    https://github.com/bloomberg/bqplot
    https://github.com/jovyan/pythreejs
    https://github.com/ellisonbg/ipyleaflet

  --- bqplot: good example for cyjs?  too many interconnected widgets
   cd  ~/github/bqplot/

  --- ipyleaflet: not yet transparent to me...

*-----------------------------------------------------------------------------------------------------------------------
* Selfhood and Identity in Confucianism, Taoism,   Buddhism, and Hinduism: Contrasts With the West
   DAVID Y. F. HO

  saved with approximately that name in ~/Documents
  among things seen on a quick scan: decentering, sovereignty

*-----------------------------------------------------------------------------------------------------------------------
* IPython in-depth Tutorial, first presented at PyCon 2012, updated as recently as 2016 (15 oct 2016)
  https://github.com/ipython/ipython-in-depth
  very useful, it seems, for laying out how to build a widget

*-----------------------------------------------------------------------------------------------------------------------
* ipywidgets, prep for cyjs, using cookie cutter with hello world demo (14 oct 2016)

  cd ~/github
  git clone https://github.com/jupyter/widget-cookiecutter.git
  pip install cookiecutter
  cookiecutter https://github.com/jupyter/widget-cookiecutter.git
  cd jupyter-hello

  --- 8 nov 2016: revisit, in preparation for using this for the d3 circle demo

*-----------------------------------------------------------------------------------------------------------------------
* add \donttest to all RCytoscape man pages (14 oct 2016)

  cd   /Users/paul/s/examples/python/regex/rcytoscapeManPages

*-----------------------------------------------------------------------------------------------------------------------
* neo4j for igap snps and msigdb (13 oct 2016)

  --- fill neo4j database:
    cd ~/s/data/public/human/msigdb-oct2016; make
    cd ~/s/data/priceLab/functionalConnectionMaps/ad-igap-demo; make rebuild

  --- R script for exploration
   cd ~/s/data/priceLab/functionalConnectionMaps/ad-igap-demo/
   explore.R

  test out with n4j (neo-4j-sh)>

    match(a)-[r]-(b) where a.id="SRP9" and b.score < 50 return(b);

    | Node[53119]{score:1,id:"chr1:225777805-225777805",type:"loc"}        |
    | Node[75636]{type:"curatedGeneSet",id:"GOLUB_ALL_VS_AML_UP",score:24} |
    | Node[76190]{type:"curatedGeneSet",id:"KEGG_PROTEIN_EXPORT",score:24} |
    | Node[77284]{type:"curatedGeneSet",id:"PID_IL3_PATHWAY",score:27}     |



  --- now choose some distant snps, look for a path between them
      match(a) where a.type="loc" return(a) limit 5;
         +---------------------------------------------------------------+
         | Node[53111]{score:1,id:"chr1:108746614-108746614",type:"loc"} |
         | Node[53112]{score:1,id:"chr1:11909729-11909729",type:"loc"}   |
         | Node[53113]{score:1,id:"chr1:160400615-160400615",type:"loc"} |
         | Node[53114]{score:1,id:"chr1:182615194-182615194",type:"loc"} |
         | Node[53115]{score:1,id:"chr1:201719605-201719605",type:"loc"} |
         +---------------------------------------------------------------+

  --- shortest path example
    MATCH (f:Airport {code: "LTN"}), (t:Airport {code: "WAW"}), p = shortestPath((f)-[]-(t)) RETURN p
    match (a:Entity {id: "chr1:108746614-108746614"}), (b:Entity {id: "chr1:201719605-201719605"}), p=shortestPath((a)-[]-(b)) return p;

    MATCH p=shortestPath((keanu:Person)-[:KNOWS*]-(kevin:Person) ) WHERE keanu.name="Keanu Reeves" and kevin.name = "Kevin Bacon" RETURN length(p)

*-----------------------------------------------------------------------------------------------------------------------
* postgres tips, psql tips (10 oct 2016)

  on riptide, after whovian instance went south
  psql is /Library/PostgreSQL/9.3/bin/psql
  /Library/PostgreSQL/9.3/bin/createdb, dropdb, dropuser, etc

  ~/.pgpass
  localhost:5432:*:pshannon:pshannon
  localhost:5432:*:trena:trena

*-----------------------------------------------------------------------------------------------------------------------
* alison paquettes rma/oligo problem (8 oct 2016)

  riptide, cd ~/s/work/priceLab/alison/affyAndRMA
  https://www.ncbi.nlm.nih.gov/geo/query/acc.cgi?acc=GSE75010

   Preeclampsia (PE) is a complex, heterogeneous disorder of
   pregnancy, demonstrating considerable variability in observed maternal
   symptoms and fetal outcomes. We hypothesized that this heterogeneity
   is due to the existence of multiple molecular forms of PE. To address
   our hypothesis, we created a large (N=330) human placental microarray
   data set consisting of seven previously published studies (GSE30186,
   GSE10588, GSE24129, GSE25906, GSE43942, GSE4707, and GSE44711) and 157
   highly annotated samples from a BioBank (below).  Applying
   unsupervised clustering to this combined data set revealed multiple
   distinct molecular groups of placentas, including three clinically
   relevant potential origins of PE based on gene expression and
  correlating patient records.

  Platforms (1):  GPL6244 [HuGene-1_0-st] Affymetrix Human Gene 1.0 ST Array [transcript (gene) version]

library(oligo)
filenames <- list.celfiles(listGzipped=TRUE)
affyGeneFS<- read.celfiles(filenames)
dim(affyGeneFS)  # Features  Samples
                 #  1102500      157
head(rownames(affyGeneFS))
genePS <- rma(affyGeneFS, target = "probeset")
fivenum(exprs(genePS)[1:10, 1:10])
  # [1]  3.223160  4.599119  5.381530  7.482819 11.235501

sessionInfo()
# R version 3.3.1 (2016-06-21)
# Platform: x86_64-apple-darwin13.4.0 (64-bit)
# Running under: OS X 10.11.6 (El Capitan)
#
# locale:
# [1] C
#
# attached base packages:
# [1] stats4    parallel  stats     graphics  grDevices utils     datasets  methods   base
#
# other attached packages:
#  [1] pd.hugene.1.0.st.v1_3.14.1 RSQLite_1.0.0              DBI_0.5-1                  oligo_1.37.2               Biostrings_2.41.4
#  [6] XVector_0.13.7             IRanges_2.7.17             S4Vectors_0.11.18          Biobase_2.33.4             oligoClasses_1.35.1
# [11] BiocGenerics_0.19.2        BiocInstaller_1.23.9
#
# loaded via a namespace (and not attached):
#  [1] affxparser_1.45.1           splines_3.3.1               GenomicRanges_1.25.94       zlibbioc_1.19.0
#  [5] bit_1.1-12                  lattice_0.20-34             foreach_1.4.3               GenomeInfoDb_1.9.13
#  [9] tools_3.3.1                 SummarizedExperiment_1.3.82 grid_3.3.1                  ff_2.2-13
# [13] iterators_1.0.8             preprocessCore_1.35.0       affyio_1.43.0               Matrix_1.2-7.1
# [17] codetools_0.2-15            compiler_3.3.1



*-----------------------------------------------------------------------------------------------------------------------
* new liz blue snps, look for footprints in cory's wellington brain footprints (10 oct 2016)

  on riptide:

  cd ~/s/work/priceLab/lizBlue/chr1.snps

*-----------------------------------------------------------------------------------------------------------------------
* response to melody kraff's social determinants of health spreadsheets and powerpoint slides (8 oct 2016)

  --- CORE data science overview slides

  CHNA - "community health needs assessment"
  CORE - "clinical outcomes research & education" addresses social determinants and is contracted for
          data analytics by Medicaid / Medicare.
  ACH  - "accountable community of health"
  SDH  - "social determinants of health"

  The opening CORE slide is titled "multi-sector approach to data":
     1) health services and systems (organization and delivery of care)
     2) beyond the walls of health care (non-health care systems & perspectives)
        social services, housing, education, criminal justice system, community health worker
        public health data, self report (survey), and then this group
            - PLACE/NEIGHBORHOOD DATA
            - CENSUS DATA
            - BUILT ENVIRONMENT
            - TRANSPORTATION
            - CRIME & SAFETY

   --- CORE overview for Melody

     slide 1,  3 lines of work: research, program evaluation, data science (are these are separate?)
               3 areas of focus:
                  state & local health policy
                  health care delivery
                  population health & social determinants
                     housing
                     environments
                     adverse life events
                     population health needs assessment

    slide 2, a model ("connections") which shapes all of their work
        institutional: health policy, payment & finance
        clinical: screenings & treatment
        social: social structure, culture
                biographies, life events
                built environment
                physical environment

   slide 4: three things that might help providence right now
     a) community data systems
     b) population health surveys
     c) sdh research (how housing, food, built and social environments interact
        with (institutional and clinical aspects of) health care to shape
        the "triple aim"  (which is ?)


   --- worth noting
     pages 8 and 9 of
         http://www.swedish.org/~/media/images/swedish/s/swedish%20first%20hill%20and%20cherry%20hill%20chna%20pdf.pdf
      list, as factors associated with higher concentration of chronic disease and lower access to health care

      health measures:
        obesity
        uninsured
        smoking
        (not mentioned: childhood asthma hospitalizations, life expectancy)

      demographics:
        people of color
        low income
        low educational attainment
         (not mentioned: environmental factors (toxic sites, highway: see chia app)

*-----------------------------------------------------------------------------------------------------------------------
* add cory's wellington brain (wholeBrain?) footprints to a new database on whovian (8 cot 2016)

  --- creating new database, "wholeBrain-wellington"
    sh-wwb
    cd ~/github/BDDS/trenadb/wellington/wholeBrain/
    createdb -U pshannon wholeBrain-wellington
    adapted fill.R, and the .sql files
    ran first on chr19, 45 minutes, databaseSummary():
       1,514,672 hits in 387,362 regions



*-----------------------------------------------------------------------------------------------------------------------
* state of the postgres database, index creation timings (14 oct 2016)

  wellington, with only

  db.hint, regions: 60,521,694   hits 1,576,550,964

*-----------------------------------------------------------------------------------------------------------------------
* psql: index piq database on whovian (14 oct 2016)

  cd ~/github/BDDS/trenadb/piq/
  psql piq
  \di (only the regions table is indexed on its pkey

   | public | regions_pkey | index | pshannon | regions

  this was, I think, a poor choice on my part, because it is only the hits table
  which is accessed by the loc field: regions is queried by chrom, start, endpos

  --- edited this file, indexRegions.sql
  \connect piq;
  create index regionsPos_index on regions (chrom, start, endpos);
  which I hope will be used as an index

  (14 october 12:00) whovian.piq> nohup psql -f indexRegions.sql&
                    finished at (14 oct 12:25): 25 minutes
  (14 october 12:20) whovian.piq> nohup psql -f indexHits.sql > indexHits-nohup.out &
                    finished at (16 oct 0200): 14 hours

   whovian.piq> psql piq  # psql (9.4.7)
   piq=> \di
                       List of relations
      Schema |       Name       | Type  |  Owner   |  Table
     --------+------------------+-------+----------+---------
      public | hits_index       | index | pshannon | hits
      public | regions_pkey     | index | pshannon | regions
      public | regionspos_index | index | pshannon | regions

*-----------------------------------------------------------------------------------------------------------------------
* psql tips: list indexes

  by example, on whovian:
     psql piq
     \di

 piq=> \di
   | Schema |     Name     | Type  |  Owner   |  Table
   |--------+--------------+-------+----------+---------
   | public | regions_pkey | index | pshannon | regions

*-----------------------------------------------------------------------------------------------------------------------
* state of the postgres database (8 oct 2016)

   psql> \list

   ---- all lymphoblast

    chipseq:
       regions:  "regions_pkey" PRIMARY KEY, btree (loc)
                 "regions_index" btree (loc, start, endpos)
       hits:     "hits_index" btree (loc)

    gtf: hg38human
    hint:
       regions: regions_pkey on loc, regions_index on (loc, start, endpos)
       hits: "hits_index" btree (loc)

    wellington:
       regions: Indexes:     "regions_pkey" PRIMARY KEY, btree (loc)
       hits:   no indexes yet

    piq:
      regions: "regions_pkey" PRIMARY KEY, btree (loc)
      hits: no indexes yet

    trena:  fimo_hg38, tfmotifs

   --- other, older, earlier one-table schema

    chipseqTest
    enhancers.hg38
    fimo
    footprints
    fptest
    gtf-hsapiens-hg38
    hg38
    hint-test
    hintTest2
    lymphoblast
    mm10
    piq
    piqTest
    postgres
    pshannon
    template0
    template1
    trena
    wellington-test
    wellington2
    wholeBrain: footprints, motifsgenes

*-----------------------------------------------------------------------------------------------------------------------
* gustavo's fcm exploration, iGap snps and msigdb, polished up (12 oct 2016)

  cd ~/s/data/priceLab/functionalConnectionMaps/ad-igap-demo
  makefile loads nodes and edges, igap and msigdb, populates neo4j

  --- start looking for interesting relationships
    source("createNetworkFromIgapSnps.R")
    runTests()
    tbl <- readSnpsInFootprints()
    head(subset(tbl, distance < 10))
    cherry-picked this entry:
       chrom     start       end width strand   tfs     motif  nearby.gene distance                      loc
        chr1 225777805 225777805     1      *  CTCF  MA0139.1         SRP9        7 chr1:225777805-225777805

    --- find the snp of interest
       match(n) where n.id="chr1:225777805-225777805" return(n);
         Node[26474]{id:"chr1:225777805-225777805",type:"loc"}

    --- find all of its immediate neighbors
      match(a)-[r]-(b) where a.id="chr1:225777805-225777805" return(b);
         Node[26294]{id:"MA0095.2",type:"motif"}
         Node[26288]{id:"MA0014.2",type:"motif"}
         Node[26293]{id:"MA0139.1",type:"motif"}

    --- find all matches of second neighbors which have type="gene"
       match(a)-[r]-(b)-[r2]-(c) where a.id="chr1:225777805-225777805" and c.type="gene" return(c);
       18 rows, 41766 ms
      +---------------------------------------------+
      | Node[26672]{id:"RP11-317P15.4",type:"gene"} |
      | Node[26677]{id:"SRP9",type:"gene"}          |
      | Node[26677]{id:"SRP9",type:"gene"}          |
      | Node[26677]{id:"SRP9",type:"gene"}          |
      | Node[26704]{id:"MIR564",type:"gene"}        |
      | Node[26719]{id:"OTULIN",type:"gene"}        |
      | Node[26735]{id:"PSORS1C2",type:"gene"}      |
      | Node[26774]{id:"RP11-732A19.8",type:"gene"} |
      | Node[26782]{id:"AACS",type:"gene"}          |
      | Node[26785]{id:"RP3-416H24.4",type:"gene"}  |
      | Node[26791]{id:"MARK3",type:"gene"}         |
      | Node[26792]{id:"IGHV3-72",type:"gene"}      |
      | Node[26815]{id:"ANKRD13B",type:"gene"}      |
      | Node[26816]{id:"MIR423",type:"gene"}        |
      | Node[26819]{id:"RP11-707O23.1",type:"gene"} |
      | Node[26820]{id:"MAPT",type:"gene"}          |
      | Node[26833]{id:"CLUL1",type:"gene"}         |
      | Node[26845]{id:"ZNF17",type:"gene"}         |
      +---------------------------------------------+

neo4j-sh (?)$
    wanted: shortest path from this loc to any other loc

*-----------------------------------------------------------------------------------------------------------------------
* gustavo's fcm, add msigdb (11 oct 2016)

   cd ~/s/data/priceLab/functionalConnectionMaps/ad-igap-demo/
   got msigdb-edges.tsv, msigdb-nodes.tsv  from
      ~/s/data/public/human/msigdb-oct2016
   checkNodes.R finds all nodes identified in
      create-snpTfGeneGraphEdges.R and msigdb, creates allNodes.tsv

   cp allNodes.tsv /Users/paul/Documents/Neo4j/default.graphdb/import/
   cp *edges* /Users/paul/Documents/Neo4j/default.graphdb/import/
   neo4j36 -file fillNodes.cql
   neo4j36 -file fillEdges.cql
   neo4j36 -file fillEdges.cql

   match ()-[r]-() return count(r)  #810k
   match (n)return count(n)         # 31k

*-----------------------------------------------------------------------------------------------------------------------
* msigdb, curated gene sets (11 oct 2016)

  cd ~/s/data/public/human/msigdb-oct2016
  "all curated gene sets, gene symbols" from http://software.broadinstitute.org/gsea/downloads.jsp
  http://software.broadinstitute.org/gsea/msigdb/download_file.jsp?filePath=/resources/msigdb/5.2/c2.all.v5.2.symbols.gmt

  4729 lines

  concludes thus:
   dim(tbl.edges) # [1] 387776      5
   tbl.genes <- data.frame(id=all.genes, type="gene", source="msigdb-2016-oct")
   tbl.processes <- data.frame(id=tbl[,1], type="curatedGeneSet", source="msigdb-2016-oct")
   tbl.nodes <- rbind(tbl.genes, tbl.processes)
   printf("about to write %d rows to nodes.tsv", nrow(tbl.nodes))
       [1] about to write 30712 rows to nodes.tsv
   write.table(tbl.nodes, file="nodes.tsv", row.names=FALSE, col.names=TRUE, quote=FALSE, sep="\t")
    printf("about to write %d rows to edges.tsv", nrow(tbl.edges))
      [1] about to write 387776 rows to edges.tsv
  write.table(tbl.edges, file="edges.tsv", row.names=FALSE, col.names=TRUE, quote=FALSE, sep="\t")

   tbl.edges[sample(1:nrow(tbl.edges), 10),]
           a                                    b             type score          source
   62    GPI      KEGG_GLYCOLYSIS_GLUCONEOGENESIS inCuratedGeneSet     0 msigdb-2016-oct
   74   SDHD         KEGG_CITRATE_CYCLE_TCA_CYCLE inCuratedGeneSet     0 msigdb-2016-oct
   178 TSTA3 KEGG_FRUCTOSE_AND_MANNOSE_METABOLISM inCuratedGeneSet     0 msigdb-2016-oct
   150   MPI KEGG_FRUCTOSE_AND_MANNOSE_METABOLISM inCuratedGeneSet     0 msigdb-2016-oct
   242 ACADM           KEGG_FATTY_ACID_METABOLISM inCuratedGeneSet     0 msigdb-2016-oct
   38   PFKM      KEGG_GLYCOLYSIS_GLUCONEOGENESIS inCuratedGeneSet     0 msigdb-2016-oct
   154  PFKM KEGG_FRUCTOSE_AND_MANNOSE_METABOLISM inCuratedGeneSet     0 msigdb-2016-oct
   279  SQLE            KEGG_STEROID_BIOSYNTHESIS inCuratedGeneSet     0 msigdb-2016-oct
   170 MTMR2 KEGG_FRUCTOSE_AND_MANNOSE_METABOLISM inCuratedGeneSet     0 msigdb-2016-oct
   31   PCK2      KEGG_GLYCOLYSIS_GLUCONEOGENESIS inCuratedGeneSet     0 msigdb-2016-oct


   wc -l *.tsv
     387777 ~/s/data/public/human/msigdb-oct2016/edges.tsv
      30713 ~/s/data/public/human/msigdb-oct2016/nodes.tsv


*-----------------------------------------------------------------------------------------------------------------------
* review gustavo's fcm, functionalConnectionMaps, first try continued, with igap AD gwas snps (11 oct 2016)

  cd ~/s/data/priceLab/functionalConnectionMaps/ad-igap-demo
  R -f stats.R #  [1]  6365 nodes,  17702 edges
  head nodes.tsv
      id	type	source
      MA0696.1	motif	footprinting
      MA0697.1	motif	footprinting
      MA0736.1	motif	footprinting
  tbl.nodes <- read.table("nodes.tsv", header=TRUE, sep="\t")
  as.data.frame(table(tbl.nodes$type))
    #  Var1 Freq
    #  gene 2553
    #   loc 3348
    # motif  464

   tbl.edges <- read.table("edges.tsv", header=TRUE, sep="\t")
   head(tbl.edges)
                              a        b       type distance       source
     1 chr1:101323692-101323692 MA0696.1 snpInMotif        0 footprinting
     2 chr1:101323692-101323692 MA0697.1 snpInMotif        0 footprinting
     3 chr1:101323692-101323692 MA0736.1 snpInMotif        0 footprinting
  as.data.frame(table(tbl.edges$type))
                            Var1 Freq
     1 candidateProximalPromoter 8851
     2                snpInMotif 8851


*-----------------------------------------------------------------------------------------------------------------------
* gustavo's fcm, functionalConnectionMaps, first try, with igap AD gwas snps (7 oct 2016)

  neo4j version 3.0.1 lacks the neo4j, so got the tarball,
  cat ~/bin/neo4j   # ~/Downloads/neo4j-community-3.0.1/bin/neo4j-shell $*
  oddly, needs cql files to be in  /Users/paul/dbs/neo4j-v0/import/
  cd ~/s/data/priceLab/functionalConnectionMaps/ad-igap-demo


  cp nodes.tsv /Users/paul/dbs/neo4j-v0/import/
  cp edges.tsv /Users/paul/dbs/neo4j-v0/import/

  --- nodes.tsv
       id	type	source
     MA0696.1	motif	footprinting
     MA0697.1	motif	footprinting
     MA0736.1	motif	footprinting
     MA0751.1	motif	footprinting

   --- edges.tsv
  				   a	b	type	distance	source
     chr1:101323692-101323692	MA0696.1	snpInMotif	0	footprinting
     chr1:101323692-101323692	MA0697.1	snpInMotif	0	footprinting

   --- fillNodes.cql
     create constraint on (entity:Entity) assert entity.id is unique;
     LOAD CSV WITH HEADERS FROM
       "file:///nodes.tsv"
        AS line FIELDTERMINATOR '\t'
        create (:Entity {id: line.id, type: line.type, source: line.source});

   --- fillEdges.cql
     USING PERIODIC COMMIT
     LOAD CSV WITH HEADERS FROM
       "file:///edges.tsv"
        AS line FIELDTERMINATOR '\t'
        MATCH (a:Entity {id: line.a}), (b:Entity {id: line.b})
        CREATE (a)-[:Interaction {type: line.type, distance: line.distance, source: line.source}]->(b);

   --- success
    R -f stats.R #   6365 nodes,  17702 edges

*-----------------------------------------------------------------------------------------------------------------------
* cyjs in jupyter notebooks, a second try (6 oct 2016)

  --- simple javascriptMagic in simple notebooks
    ~/s/examples/jupyter/javascriptMagic/
       simpleD3circle
       xyplotter
       cyjs

  --- in preparation, create a standalone html file
    loads latest cytoscape.js from python http server at localhost:8099
      cd ~/s/examples/jupyter/javascriptMagic/cyjs/
      python -m http.server 8099

   ~/s/examples/jupyter/javascriptMagic/cyjs/small.html
   file:///Users/paul/s/examples/jupyter/javascriptMagic/cyjs/small.html

  --- now in a notebook with javascript magic building upon "simpleD3circle"
    cd  ~/s/examples/jupyter/javascriptMagic
    jupyter notebook --port 12000
    ~/s/examples/jupyter/javascriptMagic/cyjsSimpleDemoWithMagic.ipynb

   --- with this text:

%%javascript

require.config({
   paths: {cytoscape: 'http://localhost:8099/cytoscape'}
   })

%%javascript

require(['cytoscape'], function(cytoscape){
    $("#cyDiv").remove();
    element.append("<div id='cyDiv'></div>")
    $("#cyDiv").width("800px");
    $("#cyDiv").height("600px");

    cy = cytoscape({
      container: document.getElementById('cyDiv'),
      elements: {
         nodes: [
           {data: {id: 'a', name: 'Node A', type: 'big' }},
           {data: {id: 'b', name: 'Node B', type: 'little'}},
           ],
        edges: [
           {data: {source: 'a', target: 'b'}},
           {data: {source: 'b', target: 'a'}}
           ]
        },

     style: [
        {selector: 'node',
           style: {
              'text-valign': 'center',
              'text-halign': 'center',
              'border-color': 'red',
              'background-color': 'white',
              'border-width': 1,
              'label': 'data(name)',
              'height': 100,  // defaults
              'width': 100
              }},
        {selector: "node[type='big']",
          style: {
             'height': 150,
             'width': 150,
             'shape': 'roundrectangle'
             }},
        {selector: "node[type='little']",
          style: {
             'height': 50,
             'width': 80
             }},
        {selector: 'edge',
           style: {
             'width': '1px',
             'line-color': 'blue',
             'target-arrow-shape': 'triangle',
             'target-arrow-color': 'black',
             'curve-style': 'bezier'
             }}
         ],

     ready: function(){
        console.log("small cyjs network ready");
        } // ready
       }); // cytoscape

});
*-----------------------------------------------------------------------------------------------------------------------
* cyjs in jupyter notebooks, a first try (22 jul 2016) (revisited to improve the historical record: 6 oct 2016)

  cd ~/s/examples/jupyter/cyjs/firstTry
  jupyter notebook --port 12000

*-----------------------------------------------------------------------------------------------------------------------
* rcyjs: updated to version 1.5.9, adding browserless R CMD check (6 oct 2016)

  now keeping the package in ~/s/RCyjs

*-----------------------------------------------------------------------------------------------------------------------
* jupyter notebooks javascript magic - some demos with d3 (6 oct 2016)

   cd ~/s/examples/jupyter/javascriptMagic
   juipyter
* cyjs in a jupyter notebook (5 oct 2016)

     git clone https://github.com/cytoscape/jupyter-cytoscape.git
     git clone https://github.com/cytoscape/cytoscape.js.git
     git clone https://github.com/cytoscape/cytoscape.js-rpc.git

*-----------------------------------------------------------------------------------------------------------------------
* venn diagram in R: venneuler (17 nov 2016), produces proportional diagrams

  maintained by simon urbanek, on cran

*-----------------------------------------------------------------------------------------------------------------------
* venn diagram in R, the VennDiagram package (5 oct 2016)

  library(VennDiagram)
  w.locs <- subset(tbl, samplecount.w > 0)$loc
  h.locs <- subset(tbl, samplecount.h > 0)$loc
  cs.locs <- subset(tbl, csscore > 0)$loc
  length(cs.locs); length(h.locs); length(w.locs)
  130711; 984449; 414590
  draw.triple.venn(length(w.locs), length(h.locs), length(cs.locs),
                   length(intersect(w.locs, h.locs)),
                   length(intersect(w.locs, cs.locs)),
                   length(intersect(h.locs, cs.locs)),
                   length(intersect(w.locs, intersect(h.locs, cs.locs))),
                   category=c("Wellington", "HINT", "ChIPseq"),
                   col=c("red", "green", "blue"))

  venn.diagram(list(Wellington=w.locs, HINT=h.locs, ChIPseq=cs.locs), fill=c("red", "green", "blue"), filename="venn.tiff")
*-----------------------------------------------------------------------------------------------------------------------
* neo4j fresh install 3.0.6 (12 oct 2016)

  download unix tarball from
     https://neo4j.com/download/community-edition/

  cd ~/apps/neo4j
  tar xvf ~/Downloads/neo4j-community-3.0.6-unix.tar.gz
  edit ~/apps/neo4j/neo4j-community-3.0.6/conf/neo4j.conf, disabling one line, enabling another:

     #dbms.directories.import=import
     dbms.security.allow_csv_import_from_file_urls=true

  add to ~/.bashrc
   PATH=$PATH:$HOME/apps/neo4j/neo4j-community-3.0.6/bin
   alias n4j="/Users/paul/Downloads/neo4j-community-3.0.6/bin/neo4j-shell"

  start the database server:
     ~/apps/neo4j/neo4j-community-3.0.6/bin/neo4j start
     Started neo4j (pid 51118). By default, it is available at
     http://localhost:7474/
     default username/password is neo4j/neo4j.  prompts to replace password: isb

   in .bashrc:
      alias n4j="/Users/paul/Downloads/neo4j-community-3.0.6/bin/neo4j-shell"

*-----------------------------------------------------------------------------------------------------------------------
* neo4j tips

  cypher delete all neo4j nodes and edges:

        MATCH (n) DETACH DELETE n;

   see ~/s/data/priceLab/functionalConnectionMaps/ad-igap-demo/deleteDB.cql


  cypher get node and edge counts, must be executed separately

     match (n) return count (n)
     match ()-[r]-() return count(r)

  R -f ~/s/data/priceLab/functionalConnectionMaps/ad-igap-demo/stats.R

  --- load csv, file-url confusion

  --- delete all  (might need to run this several times)
  bash> neo4j
  neo4j-sh (?)

MATCH (n)
OPTIONAL MATCH (n)-[r]-()
WITH n,r LIMIT 50000
DELETE n,r
RETURN count(n) as deletedNodesCount;

check for 0 nodes, 0 edges with
  R -f ~/s/data/priceLab/functionalConnectionMaps/ad-igap-demo/stats.R


  --- get node & edge counts
    library(RNeo4j)
    gdb <- startGraph("http://localhost:7474/db/data/", username="neo4j", password="isb");
    node.count <- getNodes(gdb, "match(n) return count(n)")[[1]]
    edge.count <- getRels(gdb, "match(n)-[r]->(t) return count(r)")[[1]]
    printf("%5d nodes, %6d edges", node.count, edge.count)

  --- bash fill molecules (nodes) from tsv file: ~/s/work/priceLab/neo4j/genemania/neo4jReady/fill-molecules.cql
    cd ~/s/work/priceLab/neo4j/genemania/neo4jReady/
    create constraint on (molecule:Molecule) assert molecule.id is unique;
    LOAD CSV WITH HEADERS FROM
       "file:///Users/paul/s/work/priceLab/neo4j/genemania/neo4jReady/molecules.tsv"
        AS line FIELDTERMINATOR '\t'
        create (:Molecule {id: line.ensg, name: line.symbol, type: 'molecule', subtype: 'gene'});
     head ~/s/work/priceLab/neo4j/genemania/neo4jReady/molecules.tsv
        ensg	symbol
        ENSG00000000003	TSPAN6
        ENSG00000000005	TNMD
        ENSG00000000419	DPM1
        ENSG00000000457	SCYL3
        ENSG00000000460	C1orf112
        ENSG00000000938	FGR
        ENSG00000000971	CFH
        ENSG00000001036	FUCA2
        ENSG00000001084	GCL

  --- bash fill interactions from tsv file ~/s/work/priceLab/neo4j/genemania/neo4jReady/fill-interactions-1455562395.89307.sql
    cd ~/s/work/priceLab/neo4j/genemania/neo4jReady/
    create constraint on (interaction:Interaction) assert interaction.id is unique;
    USING PERIODIC COMMIT
    LOAD CSV WITH HEADERS FROM
       "file:///Users/paul/s/work/priceLab/neo4j/genemania/neo4jReady/Physical_interactions.Chen-Ge-2013.txt"
       AS line FIELDTERMINATOR '\t'
       MATCH (a:Molecule {name: line.Gene_A}), (b:Molecule {name: line.Gene_B})
       CREATE (a)-[:Interaction {type: line.Network_Group_Name, pmid: line.Pubmed_ID, source: line.Source, weight: line.Weight}]->(b);
    book.neo4jReady> head Physical_interactions.Chen-Ge-2013.txt
    Gene_A	Gene_B	Weight	Network_Group_Name	Network_Name	Source	Pubmed_ID	sym_A	sym_B
    ENSG00000004455	ENSG00000151929	0.052	Physical interactions	Chen-Ge-2013	IREF	23824909	AK2	BAG3
    ENSG00000004776	ENSG00000151929	0.052	Physical interactions	Chen-Ge-2013	IREF	23824909	HSPB6	BAG3
    ENSG00000005022	ENSG00000151929	0.052	Physical interactions	Chen-Ge-2013	IREF	23824909	SLC25A5	BAG3
    ENSG00000006534	ENSG00000151929	0.052	Physical interactions	Chen-Ge-2013	IREF	23824909	ALDH3B1	BAG3

*-----------------------------------------------------------------------------------------------------------------------
* igv.js:  disabling double-click to zoom (5 oct 2016)

   cd ~/github/igv.js-jupyter
   git pull orgin
   pip install -e .
   jupyter nbextension install --prefix ~/jupyter.extensions --py igv
   jupyter nbextension enable --py igv    # - Validating: OK

   --- test it out, with the supplied notebook

     ~/github/igv.js-jupyter/examples/DoubleClick.ipynb

   --- test it out with my own
     cd ~/github/notebooks/paul-shannon/demos/igv
     jupyter notebook
     igvDisplaySimplePandaBedTable.ipynb


*-----------------------------------------------------------------------------------------------------------------------
* jupyter lab demos (5 oct 2016)

  cd ~/s/work/priceLab/jupyterLabDemos/cory

*-----------------------------------------------------------------------------------------------------------------------
* create feature table for all of chr19 for rory (4 oct 2016)

  whovian, cd ~/github/BDDS/trenadb/src/
  nohup R -f createFeatureTable.R &
  started at 318pm

*-----------------------------------------------------------------------------------------------------------------------
* create-snpTFGeneGraphEdges: an exploration for "extended compound heterozygosity" (cory & gustavo) (4 oct 2016)

   cd ~/s/data/priceLab/AD/
   R script:  ~/s/data/priceLab/AD/create-snpTfGeneGraphEdges.R
   R script for neo4j: ~/s/data/priceLab/AD/fill-neo4j.R (see further below)

   library(RPostgreSQL)
   library(GenomicRanges)
   if(!exists("db.gtf"))
      db.gtf <- dbConnect(PostgreSQL(), user= "trena", password="trena", dbname="gtf", host="whovian")

   tbl.genes <- dbGetQuery(db.gtf, "select chr, start, endpos, strand,  gene_name from hg38human where moleculetype='gene'")
   tbl.genesPlus  <- subset(tbl.genes, strand=="+")  # [1] 9986    5
   tbl.genesMinus <- subset(tbl.genes, strand=="-") # [1] 9811    5
   gr.genesPlus <- with(tbl.genesPlus,  GRanges(seqnames=chr, IRanges(start=start, end=start), strand=strand))
   gr.genesPlus$gene <- tbl.genesPlus$gene_name

   gr.genesMinus <- with(tbl.genesMinus,  GRanges(seqnames=chr, IRanges(start=start, end=start), strand=strand))
   gr.genesMinus$gene <- tbl.genesMinus$gene_name
   gr.genes <- c(gr.genesPlus, gr.genesMinus)

   print(load("tbl.gwasADsnpsInFp.05pval.igap2013.RData")) # tbl.gwasADsnpsInFp

   gr.snp <- with(tbl.gwasADsnpsInFp, GRanges(seqnames=chr, IRanges(start=snp, end=snp)))
   gr.snp$tfs <- tbl.gwasADsnpsInFp$tfsMatched
   gr.snp$motif <- tbl.gwasADsnpsInFp$name
   tbl.distances <- as.data.frame(distanceToNearest(gr.snp, gr.genes))
   tbl.genes <- as.data.frame(gr.genes)
   dim(tbl.distances) # 28404     3
   tbl.near <- subset(tbl.distances, distance < 5000) # 4501
   gr.snp[tbl.near[1, "queryHits"]]
   gr.genes[tbl.near[1, "subjectHits"]]
   tbl.gwasADsnpsInFp[111, ]
   tbl.genes[1095,]
   tbl.gwasADsnpsInFp[1095, ]
   tbl.genes[111,]
   tbl <- cbind(as.data.frame(gr.snp[tbl.near[, "queryHits"]]), as.data.frame(gr.genes[tbl.near[, "subjectHits"]]$gene))
   tbl$distance <- tbl.near$distance
   colnames(tbl) <- c("chrom", "start", "end", "width", "strand", "tfs", "motif", "nearby.gene", "distance")
   save(tbl, file="snpsInFootprintsWith5kbOfGene.RData")

*-----------------------------------------------------------------------------------------------------------------------
* minimal information about protein-coding genes: chrom, start, end, strand, gene symbol (4 oct 2016)

   library(RPostgreSQL)
   library(GenomicRanges)
   if(!exists("db.gtf"))
     db.gtf <- dbConnect(PostgreSQL(), user= "trena", password="trena", dbname="gtf", host="whovian")


   query <- "select chr, start, endpos, strand,  gene_name from hg38human where moleculetype='gene' and gene_biotype='protein_coding'")
   tbl.genes <- dbGetQuery(db.gtf, query) #  19797     5

*-----------------------------------------------------------------------------------------------------------------------
* neo4j, a fresh start (sort of) (4 oct 2016)

  see below, from january: "installed, db in ~/dbs/neo4j
       user neo4j, pw=isb
       northwind example:
         cd ~/s/examples/neo4j
       pip install py2neo
   in PATH: /Applications/Neo4j\ Community\ Edition.app/Contents/Resources/app/bin
    start server from the launcher  (version 2.3.1)
    neo4j-shell -version

  --- fresh download of community neo4j, version 3.0.6


*-----------------------------------------------------------------------------------------------------------------------
* install samtools on riptide macos (3 oct 2016)

  got version 1.3.1  http://www.htslib.org/download/



*-----------------------------------------------------------------------------------------------------------------------
* functional testing for wellington pipeline (3 oct 2016)

  cd ~/github/BDDS/footprints/functionalTests/wellington/
  installed bedtools from github v 2.26.0-19
  cd ~/github
  git clone https://github.com/arq5x/bedtools2.git
  make
  make install
  /usr/local/bin/bamToBed --version # unrecognized, but got version info: Version: v2.26.0-19-g6bf23c4

  ---- could not get past this error, moved to whovian
  book.data>  /usr/local/bin/bedtools bamtobed -i ENCSR000DBY.19.bam > tmp.bed
    libc++abi.dylib: terminating with uncaught exception of type std::out_of_range: basic_string
   Abort trap: 6





*-----------------------------------------------------------------------------------------------------------------------
* trenadb feature table improvements, todo (29 sep 2016)

    extract.R:ensemble function has these arguments
         chrom, start, end, test.motifs=NA, test.locs=NA)
    consider putting them in, all the way down:
        1) createWellingtonTable
        2) createHintTable
        3) getHits  (called by 1 and 2)

     1 & 2 now have and use collapseOnStrand=FALSE argument but in each case it is the following duplicate which
     is deleted, which may lead to random results.

    utils.R:  make these two consistent:

         createHintTable <- function(chrom, start, end, motif=NA, sample=NA, loc=NA, collapseOnStrand=FALSE)
   createWellingtonTable <- function(chrom, start, end, motif=NA, sampleID=NA, collapseOnStrand=FALSE)

*-----------------------------------------------------------------------------------------------------------------------
* trenadb feature table cleanup continued (28 sep 2016)

  cd ~/github/BDDS/trenadb/featureTable/fimoLocVsMethodScores
  extract.R

  just added these two tests:
       test.ensemble_hint_wellington_empty_chipseq()
       test.ensemble_hint_wellington_chipseq()

  in which all w & h hits match, just one loc per test.
  now add 2 locs per test, one with only h, one with only w


*-----------------------------------------------------------------------------------------------------------------------
* run trena on trem2 for cory, ampAD trip (28 sep 2016)

  cd ~/github/TReNA/inst/demos/trem2/
  using ~/s/data/priceLab/AD/ampADMayo.64253genes.278samples.RData  # 3,1864,131 Apr 22 12:07

  ~/github/TReNA/inst/demos/trem2/go.R
  notebook:   /users/pshannon/github/notebooks/paul-shannon/trena/trena-TREM2-ad.ipynb
  http://whovian:9999/notebooks/trena/trena-TREM2-ad.ipynb

*-----------------------------------------------------------------------------------------------------------------------
* trenadb feature table cleanup (28 sep 2016)

  cd ~/github/BDDS/trenadb/featureTable/fimoLocVsMethodScores
  extract.R

      # todo, next up (in test.ensemble)
      # make sure this no-TF table cleans up
      # devise a second TF-included table, make sure it cleans up

*-----------------------------------------------------------------------------------------------------------------------
* trenadb feature table cleanup (27 sep 2016)

  cd ~/github/BDDS/trenadb/featureTable/fimoLocVsMethodScores
  extract.R

   ft <- cleanFeatureTable(tbl)
      #  chr19:45423537-45423550 & MA0512.2 should have only one fimo score/pval pair, and appear as just one row
   ft.sub <-subset(ft, loc=="chr19:45423537-45423550" & motif=="MA0512.2")
      # 4 rows, wellington can be flattened to just one motif score and pval (3.64634; 5.64e-05)
      #         hint has sensible score1, but 4 values each for score2, 3 for score3.  just the last score3 (pval) matches wellington
      # next up: see why all this variety in hint fimo (?) score 2 and score 3

   try to use this case in a test-args createHintTable, test.createHintTable
                       loc  samplecount.h score1.h.median score1.h.best score2.h.median score2.h.best score3.h.median score3.h.best csmotif csTF csscore    motif motiflength
55 chr19:45423537-45423550              2            56.5            84         8.95455       8.95455        6.06e-05      6.06e-05      NA   NA       0 MA0512.2          14
56 chr19:45423537-45423550              2            56.5            84         2.17021       2.17021        6.09e-05      6.09e-05      NA   NA       0 MA0512.2          14
57 chr19:45423537-45423550              2            56.5            84         2.83636       2.83636        3.90e-05      3.90e-05      NA   NA       0 MA0512.2          14
58 chr19:45423537-45423550              2            56.5            84         3.64634       3.64634        5.64e-05      5.64e-05      NA   NA       0 MA0512.2          14

> tbl.h   # looks like I am not matching, for hint, on loc and motif:
                      loc               motif.h samplecount.h length.h score1.h.median score1.h.best score2.h.median score2.h.best score3.h.median score3.h.best
2 chr19:45423539-45423550 LEF1_TCF7_TCF7L1,2.p2             2       12            56.5            84        12.20970      12.20970        4.19e-05      4.19e-05
3 chr19:45423537-45423550              MA0512.2             2       14            56.5            84         3.64634       3.64634        5.64e-05      5.64e-05
5 chr19:45423537-45423550              MA0677.1             2       14            56.5            84         8.95455       8.95455        6.06e-05      6.06e-05
7 chr19:45423537-45423550              MA0855.1             2       14            56.5            84         2.83636       2.83636        3.90e-05      3.90e-05
9 chr19:45423537-45423550              MA0856.1             2       14            56.5            84         2.17021       2.17021        6.09e-05      6.09e-05



*-----------------------------------------------------------------------------------------------------------------------
* metazoan intercellular communication: before brains, before nervous systems, pace dennett (24 sep 2016)

   put some of these into ~/Documents
  6499814 Sep 25 14:08 animal_evolution-book.pdf
   604249 Sep 25 14:04 molecularOriginsOfMultiCellularOrigins.pdf
   388751 Sep 25 14:00 rtkAndAnimalOrigins.pdf


  ---- Werner E.G Muller

  The Origin of Metazoan Complexity: Porifera as Integrated Animals
  http://icb.oxfordjournals.org/content/43/1/3.full

  Ecological Facilitation May Drive Major Evolutionary Transitions
     http://bioscience.oxfordjournals.org/content/59/5/399.full

  The chemokine networks in sponges: potential roles in morphogenesis, immunity and stem cell formation

   Bauplan of Urmetazoa: Basis for Genetic Complexity of Metazoa

  Molecular cloning of a tyrosine kinase gene from the marine sponge
  Geodia cydonium: a new member belonging to the receptor tyrosine
  kinase class II family

  Tyrosine kinase signaling and the emergence of multicellularity, W. Todd Miller  (got pdf)



   The Genomic and Cellular Foundations of Animal Origins
   Annual Review of Genetics
   Vol. 47: 509-537 (Volume publication date November 2013)

  The molecular origins of multicellular transitions, Antonis Rokas (got pdf) 2008


  ---- from animal evolution book
     Genomic, phylogenetic, and cell biological insights into metazoan origins
    Scott A. Nichols, Mark J. Dayel, and Nicole King.
    chapter 3

   Over 600 million years ago (Ma), the first multicellular metazoans
   evolved from their single- celled ancestors. Although not recorded
   in the fossil record, the earliest events in metazoan evolution
   can be inferred by integrating ndings from phylo- genetics,
   genomics, and cell biology. Comparisons of choano agellates
   (microeukaryote relatives of metazoans) with sponges (the earliest
   known metazoans) reveal genetic innovations associated with
   metazoan origins. Among these are the evolu- tion of the gene
   families required for cell adhesion and cell signalling, the
   presence of which catalysed the evolution of multicellularity and
   the functions of which have since been elaborated to regulate cell
   differentiation, developmental patterning, morphogenesis, and the
   functional integration of tissues. The most ancient
   tissues—differentiated epithelia—are found in sponges and evolved
   before the origin and diversi cation of modern phyla.

*-----------------------------------------------------------------------------------------------------------------------
* build latest jupyter lab (24 sep 2016)

  on riptide

  --- my improvisation
      git clone https://github.com/jupyter/jupyterlab.git
      cd jupyterlab
      npm install
      npm run build
      jupyter serverextension enable --py jupyterlab
      npm test
      jupyter lab

   --- looked at src/imagewidget
     cd ~/github/jupyterlab
     created symlink ln -s ~/Desktop/hazelnutBranch.jpg branch.jpg



   --- add geojson leaflet widget
     http://jupyterlab-tutorial.readthedocs.io/en/latest/adding_content.html
     npm search leaflet # lots found. npm WARN Building the local index for the first time, please be patient

      --> leaflet       JavaScript library for mobile-friendly interactive maps      =mourner             2016-08-05 0.7.7       gis map

     npm install --save leaflet


    Adding Content
       As an example: Add a leaflet viewer plugin for geoJSON files.
       Go to npm: search for leaflet (success!).
       Go to jupyterlab top level source directory: npm install --save leaflet. This adds the file to the dependencies in package.json.

      Install the tsd node package globally, in order to fetch typings files: npm install -g tsd.
      Try to install the typings files from the top level source directory: tsd install leaflet. (success!)
      If there are no typings, we must create our own. An example typings file that exports functions is ansi_up.
          An example with a class is xterm.
      Add a reference to the new library in src/typings.d.ts.

      --- these next steps are deeply complex, without documentation, or examples to steal.
          abandoning for now (2 oct 2016)

       Create a folder in src for the plugin:   jupyterlab/src/leaflet/index.ts, plugin.ts,
         Add index.ts and plugin.ts files.
         If creating CSS, import them in src/default-themes/index.css.
         The index.ts file should have the core logic for the plugin. In this case, it should create a widget and
             widget factory for rendering geojson files (see Documents).
         The plugin.ts file should create the extension and add the content to the application. In this case
             registering the widget factory using the document registry.
      Run npm run build from jupyterlab/jupyterlab
      Run jupyter lab and verify changes.


*-----------------------------------------------------------------------------------------------------------------------
* clone build install phosphorjs (24 sep 2016)

  git clone https://github.com/phosphorjs/phosphor.git
  cd phosphor
  npm install
  npm run build
  npm run build:example
  cd example
  python -m http.server 8001
  Now copy the contents of the example directory on some web server and open index.html in your browser.

*-----------------------------------------------------------------------------------------------------------------------
*  different fimo values at the same spot, for the same motif, in wellington (perhaps hint) (23 sep 2016)

  on whovian
  test.createWellingtonTable()
  browser statement in for loop, sampls are repeated:

  tbl.sub[order(tbl.sub$sample_id),]
                         loc     name length   score1   score2   score3   sample_id
  29 chr19:44903773-44903785 MA0813.1     13 -45.5899  9.09836 9.12e-05 ENCSR000EJB
  43 chr19:44903773-44903785 MA0813.1     13 -45.5899 11.59020 3.71e-05 ENCSR000EJB
  44 chr19:44903773-44903785 MA0813.1     13 -39.4261  9.09836 9.12e-05 ENCSR000EJD
  45 chr19:44903773-44903785 MA0813.1     13 -39.4261 11.59020 3.71e-05 ENCSR000EJD
  27 chr19:44903773-44903785 MA0813.1     13 -44.0255  9.09836 9.12e-05 ENCSR000EJE
  33 chr19:44903773-44903785 MA0813.1     13 -44.0255 11.59020 3.71e-05 ENCSR000EJE
  48 chr19:44903773-44903785 MA0813.1     13 -51.5143 11.59020 3.71e-05 ENCSR000EJF
  61 chr19:44903773-44903785 MA0813.1     13 -51.5143  9.09836 9.12e-05 ENCSR000EJF
  50 chr19:44903773-44903785 MA0813.1     13 -12.9359 11.59020 3.71e-05 ENCSR000EJI
  71 chr19:44903773-44903785 MA0813.1     13 -12.9359  9.09836 9.12e-05 ENCSR000EJI
  38 chr19:44903773-44903785 MA0813.1     13 -36.3668 11.59020 3.71e-05 ENCSR000EJJ
  64 chr19:44903773-44903785 MA0813.1     13 -36.3668  9.09836 9.12e-05 ENCSR000EJJ
  53 chr19:44903773-44903785 MA0813.1     13 -24.8149 11.59020 3.71e-05 ENCSR000EJK
  66 chr19:44903773-44903785 MA0813.1     13 -24.8149  9.09836 9.12e-05 ENCSR000EJK
  55 chr19:44903773-44903785 MA0813.1     13 -35.5984 11.59020 3.71e-05 ENCSR000EJL
  72 chr19:44903773-44903785 MA0813.1     13 -35.5984  9.09836 9.12e-05 ENCSR000EJL

   visible directly in wellington table:
   x <- getHits(db.wellington, "chr19", 44903773, 44903785)
   subset(x, name=="MA0813.1")
                       loc chrom    start   endpos               type     name length strand   sample_id     method             provenance   score1   score2   score3 score4 score5 score6
   17 chr19:44903773-44903785 chr19 44903773 44903785 motif.in.footprint MA0813.1     13      + ENCSR000EJB WELLINGTON corys.wellington.minid -45.5899  9.09836 9.12e-05     NA     NA     NA
   18 chr19:44903773-44903785 chr19 44903773 44903785 motif.in.footprint MA0813.1     13      - ENCSR000EJB WELLINGTON corys.wellington.minid -45.5899 11.59020 3.71e-05     NA     NA     NA
   24 chr19:44903773-44903785 chr19 44903773 44903785 motif.in.footprint MA0813.1     13      + ENCSR000EJD WELLINGTON corys.wellington.minid -39.4261  9.09836 9.12e-05     NA     NA     NA
   25 chr19:44903773-44903785 chr19 44903773 44903785 motif.in.footprint MA0813.1     13      - ENCSR000EJD WELLINGTON corys.wellington.minid -39.4261 11.59020 3.71e-05     NA     NA     NA
   27 chr19:44903773-44903785 chr19 44903773 44903785 motif.in.footprint MA0813.1     13      + ENCSR000EJF WELLINGTON corys.wellington.minid -51.5143  9.09836 9.12e-05     NA     NA     NA
   32 chr19:44903773-44903785 chr19 44903773 44903785 motif.in.footprint MA0813.1     13      + ENCSR000EJE WELLINGTON corys.wellington.minid -44.0255  9.09836 9.12e-05     NA     NA     NA
   33 chr19:44903773-44903785 chr19 44903773 44903785 motif.in.footprint MA0813.1     13      - ENCSR000EJE WELLINGTON corys.wellington.minid -44.0255 11.59020 3.71e-05     NA     NA     NA
   35 chr19:44903773-44903785 chr19 44903773 44903785 motif.in.footprint MA0813.1     13      + ENCSR000EJI WELLINGTON corys.wellington.minid -12.9359  9.09836 9.12e-05     NA     NA     NA
   41 chr19:44903773-44903785 chr19 44903773 44903785 motif.in.footprint MA0813.1     13      - ENCSR000EJF WELLINGTON corys.wellington.minid -51.5143 11.59020 3.71e-05     NA     NA     NA
   43 chr19:44903773-44903785 chr19 44903773 44903785 motif.in.footprint MA0813.1     13      + ENCSR000EJJ WELLINGTON corys.wellington.minid -36.3668  9.09836 9.12e-05     NA     NA     NA
   49 chr19:44903773-44903785 chr19 44903773 44903785 motif.in.footprint MA0813.1     13      - ENCSR000EJI WELLINGTON corys.wellington.minid -12.9359 11.59020 3.71e-05     NA     NA     NA
   51 chr19:44903773-44903785 chr19 44903773 44903785 motif.in.footprint MA0813.1     13      + ENCSR000EJK WELLINGTON corys.wellington.minid -24.8149  9.09836 9.12e-05     NA     NA     NA
   52 chr19:44903773-44903785 chr19 44903773 44903785 motif.in.footprint MA0813.1     13      - ENCSR000EJK WELLINGTON corys.wellington.minid -24.8149 11.59020 3.71e-05     NA     NA     NA
   57 chr19:44903773-44903785 chr19 44903773 44903785 motif.in.footprint MA0813.1     13      - ENCSR000EJJ WELLINGTON corys.wellington.minid -36.3668 11.59020 3.71e-05     NA     NA     NA
   59 chr19:44903773-44903785 chr19 44903773 44903785 motif.in.footprint MA0813.1     13      + ENCSR000EJL WELLINGTON corys.wellington.minid -35.5984  9.09836 9.12e-05     NA     NA     NA
   60 chr19:44903773-44903785 chr19 44903773 44903785 motif.in.footprint MA0813.1     13      - ENCSR000EJL WELLINGTON corys.wellington.minid -35.5984 11.59020 3.71e-05     NA     NA     NA

   are these duplications also in the data from which I filled?

   --- examine the wellington fill
     cd ~/s/data/postgres-fill/wellington/
     wellington.path <- "/local/Cory/for_Paul/wellington_results"

*-----------------------------------------------------------------------------------------------------------------------
* rory asks:

   missing value for score2 h&w should be -100
   just 1 length field (currently length.w and length.h)
   what do zero chipseq scores indicate?

*-----------------------------------------------------------------------------------------------------------------------
* hint + wellington feature table, chr19: why so many identical locs for elf1 (for example) (22 sep 2016)

   cd ~/github/BDDS/trenadb/featureTable/fimoLocVsMethodScores/
   source("extract.R")

   print(load("chr19.42m_47M.RData"))
   tbl.elf1 <- subset(tbl, csTF=="ELF1")
    dim(tbl.elf1) #  71063    21

   tail(as.data.frame(sort(table(tbl.elf1$loc))))
                          Var1 Freq
   739 chr19:45423911-45423920 2548
   740 chr19:45485424-45485433 2548
   741 chr19:45691978-45691987 2548
   742 chr19:45863284-45863293 2548
   743 chr19:45995176-45995185 2548
   744 chr19:46850859-46850868 2548

   tbl.elf1.1.loc <- subset(tbl, loc=="chr19:45423911-45423920")  # 5292   21
   dim(subset(tbl.elf1.1.loc, motif==csmotif))  #  378  21
   tbl.elf1.1.loc.trimmed <- subset(tbl.elf1.1.loc, motif==csmotif)   # 378 21

   unique(tbl.elf1.1.loc.trimmed$loc) # [1] "chr19:45423911-45423920"
   dim(getHits(db.wellington, "chr19", 45423911, 45423920))  #   0 0
   dim(getHits(db.wellington, "chr19", 45423910, 45423921))  #  56 17

   --- reproduce in a test in extract.R, test.ensemble.v1

  # test in one 12 base region, very rich in motifs
   chrom <- "chr19"
   target.loc <- "chr19:45423911-45423920"
   start <- 45423910
   end   <- 45423921
   ft.x  <- ensemble.v1(chrom, start-100, end + 100) # be sure to get a chipseq hit
   ft.xs <- subset(ft.x, loc==small.loc)
   dim(subset(ft.x, loc==target.loc)) # [1] 5292   22



*-----------------------------------------------------------------------------------------------------------------------
* hint + wellington feature table, chr19,

  seth studied cebpe, found hint to be better than wellington.  this is a 1-motif TF.

*-----------------------------------------------------------------------------------------------------------------------
* 5MB hint + wellington feature table for rory's first run (21 sep 2016)

  on riptide

  cd ~/github/BDDS/trenadb/featureTable/fimoLocVsMethodScores/
  extract.R::test.ensemble.v1

   chrom <- "chr19"
   start <- 42000000
   end   <- 47000000
   ft <- ensemble.v1(chrom, start, end)
   save(ft, file="ft.42M.47M.hint.wellington.raw.RData")
   tbl <- cleanFeatureTable(ft)  #   268510     21
   save(tbl, file="chr19.42m_47M.RData")
   tail(sort(table(tbl$loc)), n=1)  #    chr19:45863284-45863293 5488

   print(load("~/github/BDDS/trenadb/featureTable/lymphoblast/chr19.42m_47M.RData"))  #  "tbl"
   dim(tbl) #  268510     21


*-----------------------------------------------------------------------------------------------------------------------
* aggregate data.frame

  data.mtcars
  aggregate(mtcars, by=list(cylinderCount=mtcars$cyl), FUN=mean, na.rm=TRUE)
     cylinderCount      mpg cyl     disp        hp     drat       wt     qsec        vs        am     gear     carb
   1             4 26.66364   4 105.1364  82.63636 4.070909 2.285727 19.13727 0.9090909 0.7272727 4.090909 1.545455
   2             6 19.74286   6 183.3143 122.28571 3.585714 3.117143 17.97714 0.5714286 0.4285714 3.857143 3.428571
   3             8 15.10000   8 353.1000 209.21429 3.229286 3.999214 16.77214 0.0000000 0.1428571 3.285714 3.500000


*-----------------------------------------------------------------------------------------------------------------------
* feature table:  add count column for each method, choose best value, when multiple samples result (20 sep 2016)

  cd ~/github/BDDS/trenadb/featureTable/fimoLocVsMethodScores
  save(tbl.cswhp, file="tbl.cswhp-2500bases.RData")
  dim(tbl.cswhp) # [1] 559  22

  this table reveals

  --- multiple wellington samples at  chr19:44903772-44903790
    extract.R now has createWellingtonTable, which counts samples, calculates median and best scores, collapses
    on loc and motif.

  --- next up: createHintTable in the same style

*-----------------------------------------------------------------------------------------------------------------------
#  piq results need motif location correction (19 sep 2016)

  cd ~/github/BDDS/trenadb/featureTable/fimoLocVsMethodScores/
  extract.R

  status: motivated construction of refimo and test.refimo functions

# we want wellington, hint, chipseq and piq to all use the same fimo regions
# in contrast to the other methods, where i do the fimo intersections, piq does its own
# and apparently does so on an obsolete motif library.  and it may eliminate second-best hits
# case in point:
#   tbl.cswhp
# 13  chr19:44904896-44904914     19  CTCF    69 13.14750 8.31e-06     <NA>       NA       NA       NA                 <NA>    NA        NA       NA     <NA>       NA          NA         NA       NA
# 14  chr19:44904896-44904915     20  <NA>    NA       NA       NA     <NA>       NA       NA       NA                 <NA>    NA        NA       NA MA0139.1  8.12448 -0.19550100   5.687290 0.876744
# 15  chr19:44904899-44904917     19  CTCF    69  9.70492 4.36e-05     <NA>       NA       NA       NA                 <NA>    NA        NA       NA     <NA>       NA          NA         NA       NA
#
# solution:
#  getFimoHits("chr19", 44904895, 44904915)
#   motifname chrom    start   endpos strand motifscore     pval empty            sequence
# 1  MA0139.1    19 44904896 44904914      +    13.1475 8.31e-06       TGGCAGCCAGGGGGAGGTG
# 2  MA0155.1    19 44904900 44904911      +    12.5816 2.35e-05              AGCCAGGGGGAG
# 3  GTF2I.p2    19 44904904 44904912      +    13.5610 1.50e-05                 AGGGGGAGG
# choose motif with minium pval, thus getting the best full-length character match
#
#  tbl.refimo <- getFimoHits("chr19", 44904896-2, 44904915+2)
#  tbl.refimo[which(tbl.refimo$pval == min(tbl.refimo$pval)),]
#   motifname chrom    start   endpos strand motifscore     pval empty            sequence
# 2  MA0139.1    19 44904896 44904914      +    13.1475 8.31e-06       TGGCAGCCAGGGGGAGGTG
# rewirte tbl with this corrected finding


*-----------------------------------------------------------------------------------------------------------------------
* footprint machine learning status new strategy: fimoLocMethodScores (monday 19 sep 2016)

  how many fimo regions on chr19?
  how many hint, wellington, piq regions on chr19

  --- learn about fimo on chr19
     tbl.fimo19 <- dbGetQuery(db.fimo, "select * from hg38 where chr='19'") # 10,639,360
     x <- with(tbl.fimo19, paste(start, endpos, sep="."))
     length(x); # 10639360
     length(unique(x)) # 7925777
     x <- with(tbl.fimo19, paste(motifname, start, endpos, sep="."))
     length(x)         # [1] 10,639,360
     length(unique(x)) # [1] 10,118,357
       # ---> just 5%.  maybe all or mostly explained by  palindromic motifs on opposite strands
     dups <- which(duplicated(x))
     x[dups[1]] # [1] "MA0003.3.60072.60082"
     subset(tbl.fimo19, motifname=="MA0003.3" & start==60072 & endpos==60082)
      #     motifname chr start endpos strand motifscore     pval empty    sequence
      # 24824  MA0003.3  19 60072  60082      +    11.5636 5.79e-05       GCCCTCAGGCA
      # 24825  MA0003.3  19 60072  60082      -    11.0909 7.81e-05       TGCCTGAGGGC

*-----------------------------------------------------------------------------------------------------------------------
* footprint machine learning status: abandon fimoLocMethodMotif for fimoLocMethodScores (monday 19 sep 2016)

  abandon fimoLocs rows vs many hundreds of method*motif in favor of
   mv'd ~/github/BDDS/trenadb/featureTable/extract.R to fimoLocVsMethodMotifs

  fimoLocs rows vs all scores for each method and a chipseq TF (when known)
  if multiple fimoLocs correspond to observed chipseq TFs, then duplicate the rows.



*-----------------------------------------------------------------------------------------------------------------------
* fill piq (16 sep 2016) for chr19 only to start, for apoe feature table (16 sep 2016)

  cd ~/github/BDDS/trenadb/piq/

  cp ~/s/data/postgres-fill/piq/newSchema/fill.R .
  cp ~/s/data/postgres-fill/piq/newSchema/*.sql .
  cp ~/s/data/postgres-fill/piq/newSchema/all_motifs.meme .

  --- chr19 only started at 10am

*-----------------------------------------------------------------------------------------------------------------------
# apoe regulated by

  pparg
  lxr1

  from:   Apolipoprotein E and Alzheimer disease: risk, mechanisms and therapy
           Chia-Chen Liu, Takahisa Kanekiyo, Huaxi Xu & Guojun
   http://www.nature.com/nrneurol/journal/v9/n2/abs/nrneurol.2012.263.html
   nature, february 2013

*-----------------------------------------------------------------------------------------------------------------------
* annotate lymphoblast chipseq hits for actual matching motif, using fimo (13 sep 2016)

  cd ~/github/BDDS/trenadb/featureMatrix/
  extract.R

  ---- some relevant code
print(dim(tbl.apoe))
print(dim(tbl.fimo))
gr.fimo <- with(tbl.fimo, GRanges(seqnames=chrom, IRanges(start=start, end=endpos)))
gr.cs   <- with(tbl.apoe, GRanges(seqnames=chrom, IRanges(start=start, end=endpos)))
tbl.overlaps <- as.data.frame(findOverlaps(gr.fimo, gr.cs, type="any"))
tbl.combined <- cbind(tbl.apoe[tbl.overlaps$subjectHits,],
                      tbl.fimo[tbl.overlaps$queryHits,])[, c("loc", "name", "motifname")]
dim(tbl.combined)

f <- function(gene){
  dbGetQuery(db.trena, sprintf("select motif from tfmotifs where gene = '%s'", gene))[,1]
  }

# find all known motifs for the genes bound to the apoe region as predicted by chipseq
x <- sapply(unique(tbl.combined$name), f)

sharedMotif <- function(gene, motif){
    motifs.for.this.gene <- dbGetQuery(db.trena, sprintf("select motif from tfmotifs where gene='%s'", gene))$motif
    printf("gene: %s   has motifs: %s  includes? %s", gene, paste(motifs.for.this.gene, collapse=","), motif)
    return(motif %in% motifs.for.this.gene)
    }

tbl.combined$bindingSite <- sapply(1:nrow(tbl.combined),
                                   function(i) sharedMotif(tbl.combined$name[i], tbl.combined$motif[i]))

subset(tbl.combined, bindingSite==TRUE)
                         loc  name motifname bindingSite
2    chr19:44904803-44904953 RUNX3  MA0002.2        TRUE
3.4  chr19:44906503-44906653  PBX3  MA0070.1        TRUE
1.6  chr19:44904803-44904953  CTCF  MA0139.1        TRUE
1.7  chr19:44904803-44904953  CTCF  MA0139.1        TRUE
3.17 chr19:44906503-44906653  PBX3  MA0498.2        TRUE
2.12 chr19:44904803-44904953 RUNX3  MA0511.2        TRUE
2.18 chr19:44904803-44904953 RUNX3  MA0684.1        TRUE


*------------------------------------------------------------------------------------------------------------------------
* start whole genome fill of hint (13 sep 2016)

   cd ~/github/BDDS/trenadb/HINT
   cp -p  ~/s/data/postgres-fill/hint/combineWithFimo/*.sql .
   cp -p  ~/s/data/postgres-fill/hint/combineWithFimo/*.R .

   createdb -U pshannon hint
   R -f fill.R &  # about 4pm Tuesday 13 sep, finished about 430 14 sep.

*------------------------------------------------------------------------------------------------------------------------
*  SPR Trees: Chris Rippey, OOC Arboriculturist (206) 386-1688 mailto:christopher.rippey@seattle.gov
*------------------------------------------------------------------------------------------------------------------------
* R code to filter tfs reported by chipseq to bind in a region, using fimo-reported motifs in that region (13 sep 2016)

  [also, see above description of  ~/github/BDDS/trenadb/featureMatrix]
  two essentially idential forms:
     ~/github/notebooks/paul-shannon/trena/chipseq-motifTFmap-fimoDatabase-demo.ipynb
     cd ~/github/BDDS/trenadb/cusanovichChIPseq/test.R

    library(RPostgreSQL)
    chrom <- "chr13"
    loc.start <- 41019200
    loc.end   <- 41019360

    loc.string <- sprintf("%s:d-d", chrom, loc.start, loc.end)

    db.cs <- dbConnect(PostgreSQL(), user="trena", password="trena", dbname="chipseq", host="whovian")
    dbGetQuery(db.cs, "select * from hits limit 3")

    query.regions <- sprintf("select * from regions where chrom='%s' and start > %d and endpos < %d",
                             chrom, loc.start, loc.end)
    system.time(tbl.regions <- dbGetQuery(db.cs, query.regions))  # 0.064 seconds
    dim(tbl.regions)

    query.hits <- sprintf("select * from hits where loc='%s'", tbl[1, "loc"])
    system.time(tbl.hits <- dbGetQuery(db.cs, query.hits))     # 0.35 seconds
    dim(tbl.hits)

    tbl.out <- merge(tbl.regions, tbl.hits, on="loc")
    preferred.column.order <- c("chrom", "start", "endpos", "name", "strand", "score1",
                                "type", "length", "sample_id", "method", "provenance",
                                "score2", "score3", "score4", "score5", "score6")
    tbl.out <- tbl.out[, preferred.column.order]
    head(tbl.out[, 1:10])

       # now find the motif's mapped by fimo in this region
    db.trena <- dbConnect(PostgreSQL(), user="trena", password="trena", dbname="trena", host="whovian")
     # take a look
    dbGetQuery(db.trena, "select * from fimo_hg38 limit 3")
    query.fimo <- sprintf("select * from fimo_hg38 where chrom='%s' and start >= %d and endpos <= %d",
                          "13", loc.start, loc.end)
   system.time(tbl.fimo <- dbGetQuery(db.trena, query.fimo))  # 5.17 seconds; index needed?

     # what genes (tfs) have been mapped into the chr13:41019200-4109360 by cusanovich ChIPseq?
     # which have motifs?
   genes.tfs <- sort(unique(tbl.out$name))                                             # 36
   genes.allMapped <- dbGetQuery(db.trena, "select distinct gene from tfMotifs")[,1]   # 847
   genes.tfs.withMotifs <- intersect(genes.tfs, genes.allMapped)                       # 27/36

     # what motifs are associated with each of these allegedly bound tfs?
   motifs.csGenes <- lapply(genes.tfs.withMotifs, function(gene)
             dbGetQuery(db, sprintf("select motif from tfmotifs where gene = '%s'", gene))[,1])
   names(motifs.csGenes) <- genes.tfs.withMotifs

     # filter this list, keeping only motifs actually mapped by fimo in the target region
  motifs.fimo <- sort(unique(tbl.fimo$motifname))
  for(tf in names(motifs.csGenes)){
     found.by.fimo <- intersect(motifs.csGenes[[tf]], motifs.fimo)
     printf("%8s: %s", tf, paste(found.by.fimo, collapse=","))
     }

[1]     ATF2: MA0490.1,MA0491.1
[1]     BATF: MA0462.1
[1]  BHLHE40:
[1]    CEBPB:
[1]    EP300:
[1]    FOXM1:
[1]     IRF4: MA0050.2,MA0652.1
[1]     JUND: MA0491.1,MA0490.1
[1]      MAX:
[1]      MAZ:
[1]    MEF2A:
[1]    MEF2C:
[1]     MTA3:
[1]     MXI1:
[1]   NFATC1:
[1]     NFIC:
[1]    NFKB1:
[1]     PAX5:
[1]   POU2F2:
[1]    RUNX3:
[1]      SP1:
[1]     SPI1: MA0080.4
[1]    STAT3: MA0517.1
[1]     TAF1:
[1]      TBP:
[1]     TCF3:
[1]      YY1: MA0095.2
>




*-----------------------------------------------------------------------------------------------------------------------
* making sense of cusanovich ChIP-seq data with fimo (12 sep 2016)

  chrom <- "chr13"
  loc.start <- 41019204
  loc.end <-   41019357
  size <- 1 + loc.end - loc.start  # 154 bases
  query <- sprintf("select * from regions where chrom='%s' and start >= %d and endpos <= %d", chrom, loc.start, loc.end)
  locs <- dbGetQuery(db, query)$loc
    # locs[1]: "chr13:41019204-41019354"
  loc.set <- sprintf("('%s')", paste(locs[1], collapse="','"))
  tbl.hits.query <- sprintf("select * from hits where loc in %s", loc.set)
     # 36 151-bp "peaks" exactly aligned
  tbl.hits <- dbGetQuery(db, tbl.hits.query)

   --- fimo from freshly loaded database
   dbGetQuery(db, "select * from fimo_hg38 where chrom='13' and start >= 41019205 and endpos <= 41019357") # 27 hits

*------------------------------------------------------------------------------------------------------------------------
* build new footprints db, postgres on whovian, using chr13 (for seth's ELF1 study) as guinea pig (12 sep 2016)

  cd ~/github/BDDS/trenadb

  createdb -U pshannon trena   # already exists, and empty (no tables)

  fill to these tables: regions + hits; fimo; genesmotifs

  --- fimo first: it is needed by other fillers
    cd /github/BDDS/trenadb/fimo
    create.sql, fill.sql, index.sql
    fill.sql:
       \connect trena;
       \copy fimo_hg38 from '/local/Cory/for_Paul/fimo_out/newGRCh38.fimo.txt' delimiter E'\t' CSV header NULL as 'NULL';

     45M lines, takes < 20 minutes to fill on whovian

  --- fill cusanovich chipseq into regions & hits.  use old fimo db while fimo_hg38 fills
     cd ~/github/BDDS/trenadb/cusanovichChIPseq

   cd ~/s/data/postgres-fill/schema2/cusanovichChIPseq
   cp ~/s/data/postgres-fill/lymphoblast-chipseq/* .

*------------------------------------------------------------------------------------------------------------------------
* footprint database, regions & hits ideas (10 sep 2016)

  1) add length column to hits schema
  2) name column used for:
     binding-sites, use motif id          type="piq" | "hint + fimo" | "wellington + fimo" | "ChIP-seq + fimo"
     chipseq peak: use TF name            type="ChIP-seq peak"
     hint, wellington footprint-no-motif, type="hint footprint" | "wellington footprint"
  3) change "endpos" in the fimo db, hg38 table to "stop".  end is apparently illegal in postgres schema
     make chrom, start, stop the standard throughout.
     change chr to chrom in hg38/fimo also

*------------------------------------------------------------------------------------------------------------------------
* cusanovich tfs: peaks near app tss on chr21 for ctcf, use fimo to find binding sites (10 sep 2016)

  on whovian
     cd ~/s/data/postgres-fill/cusanovich-tfs
     ctcf.R finds two motif hits for MA0139 in the first chip-seq peak, 68 hits overall

    --- full initial script, before moving to laptop to use igvR
      library(RPostgreSQL)
      library(FimoClient)
      library(getDNAClient)

      if(!exists("db.hint"))
         db.hint <- dbConnect(PostgreSQL(), user="pshannon", dbname="hintTest2")

      if(!exists("db.fimo"))
         db.fimo <- dbConnect(PostgreSQL(), user="pshannon", dbname="hg38")

      if(!exists("db.chipSeq"))
         db.chipSeq <- dbConnect(PostgreSQL(), user="pshannon", dbname="chipseqTest")

      if(!exists("dna.service"))
          dna.service <- getDNAClient("hg38")

      if(!exists("fimo.service"))
         fimo.service <-  FimoClient("whovian", 5558)


      getHits <- function(db, chrom, start, stop){
         query.p0 <- "select loc, chrom, start, 'end' from regions"
         query.p1 <- sprintf("where chrom='%s' and start > %d and stop < %d", chrom, start, stop)
         query.regions <- paste(query.p0, query.p1)
         browser()
         tbl.regions <- dbGetQuery(db, query.regions)
         if(nrow(tbl.regions) == 0)
             return(data.frame())
         loc.set <- sprintf("('%s')", paste(tbl.regions$loc, collapse="','"))
         query.hits <- sprintf("select * from hits where loc in %s", loc.set)
         tbl.hits <- dbGetQuery(db, query.hits)
         merge(tbl.regions, tbl.hits, on="loc")
         } # getHits

      getFimoHits <- function(chrom, start, stop){
         chrom <- sub("^chr", "", chrom)
         query <- sprintf("select * from hg38 where chr='%s' and start > %d and endpos < %d", chrom, start, stop)
         dbGetQuery(db.fimo, query)
         }
      chrom <- "chr21"
      loc.start <- 25881625
      loc.end   <- 25882287
      tbl.cs <- getHits(db.chipSeq, chrom, loc.start, loc.end)
      tbl.cs.ctcf <- subset(tbl.cs, name=="CTCF")
      seq <- getSequenceByLoc(dna.service, chrom, loc.start, loc.end)
      tbl.fimo1 <- requestMatch(fimo.service, list(seq))
      tbl.fimo2 <- getFimoHits(chrom, loc.start, loc.end)

*------------------------------------------------------------------------------------------------------------------------
* nb for ChIP-seq with fimo, piq, hint, centered on TF CTCF in the tss of the APP gene on chr21

   http://whovian:9999/notebooks/piqAndHINTandChIPseq-compared-chr21-tf_CTCF.ipynb
   and
   ~/s/data/postgres-fill/cusanovich-tfs/go.R
   ~/s/data/postgres-fill/cusanovich-tfs/byMotif.R

   CTCF -> MA0139.1

  --- goal: compare each method's ability to detect a binding site for CTCF in the tss
     4 tracks:  chipseq, fimo w/in chipseq regions, hint and piq on MA0139



*------------------------------------------------------------------------------------------------------------------------
* microservices on whovian (9 sep 2016)   dna, fimo

  --- start fimoService (dna from ucsc DAS server always running)
    nohup python -i ~/github/fimoService/server/runServer.py 5558 \
         /local/Cory/meme_4.10.2/src/fimo /local/Cory/trn/working/GRCh38/JASPAR_CORE_plus_seth.meme&

  --- test fimoService in R and python
     R CMD INSTALL ~/github/fimoService/client-R/FimoClient
     R -f ~/github/fimoService/client-R/FimoClient/inst/unitTests/test_FimoClient.R
     (cd ~/github/fimoService/client-python; make)

  --- test getDnaService in R and python
     R -f ~/github/getDNAService/client-R/getDNAClient/inst/unitTests/test_getDNAClient.R
     python  ~/github/getDNAService/client-python/testGetDNAClient.py

*------------------------------------------------------------------------------------------------------------------------
* amazon sphere project, nytimes (11 aug 2016)

   Ron Gagliardo, Amazon’s horticulturist, at the company’s one-acre
  greenhouse near Seattle. Mr. Gagliardo is in charge of plants for
  Amazon’s new glass nature complex at its headquarters in downtown
  Seattle.

*------------------------------------------------------------------------------------------------------------------------
*
*------------------------------------------------------------------------------------------------------------------------
* lcl (lymphoblast cell line from Cusanovich et al, 2015) tfs & their motifs

  cd ~/s/data/postgres-fill/cusanovich-tfs/

  http://journals.plos.org/plosgenetics/article?id=10.1371/journal.pgen.1004226

  59 TFs used, listed as column titles in
  http://journals.plos.org/plosgenetics/article/asset?unique&id=info:doi/10.1371/journal.pgen.1004226.s012

  18 or 19 of the lcl tfs have no associated motifs in seth's file
  whovian: ~/s/data/postgres-fill/motifsgenes/motifGenes.tsv
   see go.R for how I learned this

  therefore:
     curl -O http://jaspar.genereg.net/html/DOWNLOAD/JASPAR_CORE/pfm/nonredundant/pfm_vertebrates.txt
     grep ">" pfm_vertebrates.txt > jasparMap.tsv
     emacs edit to 2-column tsv file
     tbl.jaspar <- read.table("jasparMap.tsv", sep="\t", header=FALSE, as.is=TRUE)
     colnames(tbl.jaspar) <- c("motif", "gene")
     length(intersect(tfs, tbl.jaspar$gene)) # 22, alas

     on

ARNTL2
BATF
BCL3
CEBPG
CEBPZ
CLOCK
CREBBP
DIP2B
E2F1
E2F4
E2F6
EP300
ESRRA
EZH2
FOXA3
GTF2B
HCST
HOXB7
IKZF3
IRF3
IRF4
IRF5
IRF7
IRF8
IRF9
JUND
KLF13
LCORL
NFE2L1
NFKB2
NFX1
NFYC
NR1D2
NR2F6
NR3C1
PAX5
POU2F1
POU2F2
RAD21
RDBP
RELA
RELB
RXRA
SKIL
SP1
SP3
SREBF2
STAT2
STAT6
TAF1
TCF12
TFDP1
TFDP2
TFE3
USF1
WHSC1
YY1
ZBTB38
ZHX2


*------------------------------------------------------------------------------------------------------------------------
* lisa neuman describes isb password policy (9 sep 2016)

  Email - never expires
  VPN/Windows/FRS/ISB-Internal = expires every 120 days (this is the password you changed)
  Linux = never (currently at least)
  Laptop = never

*------------------------------------------------------------------------------------------------------------------------
* seth's geneName-motifName map (8 sep 2016)

  cp /local/sament/tfbs/human_brain/motif_to_tf_mappings_with_tfclass_include_multiple.csv ~/s/data/postgres-fill

*------------------------------------------------------------------------------------------------------------------------
* lymphoblast chipseq ChIP-seq, add to chr21 notebook (8 sep 2016)

  whovian
  cd ~/s/data/postgres-fill/lymphoblast-chipseq

  files are here: /proj/price1/sament/lymphoblast_trn/known_tfbs/hg38
  head /proj/price1/sament/lymphoblast_trn/known_tfbs/hg38/ZZZ

  --- cory's email on these data and seth's code

    Here is Seth's code that does the comparisons with the ChIPseq data:
       /proj/price1/sament/lymphoblast_trn/ELF/1merge_footprints_motifs_chip.sh

    ELF1 is on chr13

    That bash script calls the R script by the same name. The
    objective would be to run that script for each of the ChIPseq
    datasets (found here:
    /proj/price1/sament/lymphoblast_trn/known_tfbs/hg38).

    Seth already does a simple mixed linear model with Wellington, HINT and PIQ. We would want to see how that works on
    all the samples and see if there are any obvious ways to improve upon it.

*------------------------------------------------------------------------------------------------------------------------
* postgres piq test database, programmatic merge - much faster than my sql merge (7 sep 2016)

  both about 50 times faster than inner join

  --- R version
    getHits2 <- function(chrom, start, stop){
       query.p0 <- "select loc, chrom, start, stop from regions"
       query.p1 <- sprintf("where chrom='%s' and start > %d and stop < %d", chrom, start, stop)
       query.regions <- paste(query.p0, query.p1)
       tbl.regions <- dbGetQuery(dbpiq, query.regions)
       if(nrow(tbl.regions) == 0)
          return(data.frame())
       loc.set <- sprintf("('%s')", paste(tbl.regions$loc, collapse="','"))
       query.hits <- sprintf("select * from hits where loc in %s", loc.set)
       tbl.hits <- dbGetQuery(dbpiq, query.hits)
       merge(tbl.regions, tbl.hits, on="loc")
       }

   --- python 3 version

      def getHits2(db, chrom, start, stop):
        queryRegions_0 = "select loc, chrom, start, stop from regions"
        queryRegions_1 = "where chrom='%s' and start >= %d and stop <= %d" % (chrom, start, stop)
        queryRegions = "%s %s" % (queryRegions_0, queryRegions_1)
        tbl_regions = pd.read_sql_query(queryRegions, db)
        locs = tbl_regions.loc[:, "loc"].tolist()

       queryHits = "select * from hits where loc in %s" % str(locs)
       queryHits = queryHits.replace("[", "(").replace("]", ")")
       tbl_hits = pd.read_sql_query(queryHits, db)
       return(pd.merge(tbl_regions, tbl_hits, on="loc"))


  --- inner join approach in python

   def getHits(db, chrom, start, end, scoreColumnNameToUse):
      query = """select * from regions r
      inner join hits h on r.loc = h.loc
      where r.chrom = '%s' and r.start > %d and r.stop < %d""" % (chrom, start, end)
      tbl = pd.read_sql_query(query, db)
      tbl['desc']  = tbl.name + "|" + tbl.sample_id  + "|" + tbl[scoreColumnNameToUse].astype(str)
      return(tbl[["chrom", "start", "stop", "desc", scoreColumnNameToUse, "strand"]])

*------------------------------------------------------------------------------------------------------------------------
* pandas tips: dataframes

   --- create tbl in R
    tbl.flux <- as.data.frame(matrix(data=as.integer(1000 * runif(count)), nrow=length(reactions), dimnames=list(reactions, conds)))
   tbl.flux
        cond1 cond2 cond3
     R1   477   246   752
     R2    44   734   633
     R3   799   703   247
     R4   368   736   551
     R5   563   801   234
     write.table(tbl.flux, file="flux.tsv", sep="\t", row.names=TRUE, col.names=TRUE, quote=FALSE)

   --- read and get data in python
    from pandas import *
    tbl_flux = DataFrame.from_csv('flux.tsv', sep='\t', header=0)
    tbl_flux
    reactionNames = tbl_flux.index.tolist()
    conditionNames = tbl_flux.columns.tolist()
    vec = tbl_flux[conditionNames[0]].tolist()
      [477, 44, 799, 368, 563]

*------------------------------------------------------------------------------------------------------------------------
* pandas tips, psycopg2 tips, python database tips

  ---- what tables are in the database?
  import pandas as pd, psycopg2 as psql
  conn = psql.connect("dbname=piqTest user=pshannon")
  query = "select relname from pg_class where relkind='r' and relname !~ '^(pg_|sql_)';"
  pd.read_sql_query(query, conn).loc[:, "relname"].tolist()

  --- pandas tips, rbind, rownames
    tbl_counts = pd.read_sql_query("select count(*) from regions", dbpiq).append(
                 pd.read_sql_query("select count(*) from hits", dbpiq))
    tbl_counts.index = ["regions", "hits"]

  --- pandas tips

  --- pandas tips, subset dataframe by range of row and column indices, by row and column names
     tbl.iloc[0:5, 1:14]
     tbl.loc[0:4, "chrom":"score1"]

    import pandas as pd
    tbl = pd.DataFrame([["chr1", 10,  100,  "fp1", 9.9],
                        ["chr1", 90,  130,  "fp2", 0.5],
                        ["chr1", 45,  80,   "fp3", 0.9],
                        ["chr1", 112, 140,  "fp4", 32],
                       ])
    tbl.columns = ['chrom', 'start', 'end', 'name', 'score']
    tbl.iloc[:, [4,3,4]]
         4    3    4
    0  9.9  fp1  9.9
    1  0.5  fp2  0.5

    tbl.columns = ['chrom', 'start', 'end', 'name', 'score']
    tbl
      chrom start  end name  score
    0  chr1    10  100  fp1    9.9
    1  chr1    90  130  fp2    0.5
    tbl.loc[:, ['chrom', 'name', 'score']]
      chrom name  score
    0  chr1  fp1    9.9
    1  chr1  fp2    0.5

  --- pandas tips, get scalar values, get single rows or columns as heterogeneous lists
    tbl.iat[0,0] # 'chr1'
    tbl.iloc[0,0] # 'chr1'
    type(tbl.iloc[0,0]) <class 'str'>

    tbl.iloc[0,:].tolist() # ['chr1', 10, 100, 'fp1', 9.9000000000000004]
    tbl.iloc[:,0].tolist() # ['chr1', 'chr1']

  --- try to emulate R's paste function on three lists, to create a loc string from chrom:start-end


  --- pandas tips, remove a column

    tbl.drop(tbl.columns[0], axis=1, inplace=True)  # duplicate "loc" columns.  drop the first

*------------------------------------------------------------------------------------------------------------------------
* jupyter tips, port

  jupyter notebook --port=10001

*------------------------------------------------------------------------------------------------------------------------
* piq footprints: piqTest db, regions + hits table, merge in python for speed (7 sep 2016)

  cd ~/github/notebooks/paul-shannon/demos/footprints
  working in ~/github/notebooks/paul-shannon/demos/footprints/merge.py

  import pandas as pd, psycopg2 as psql
   conn = psql.connect("dbname=hint-test user=pshannon")
   def toBed(chrom, start, stop):
       query = """select r.chrom, r.start, r.stop, h.name, h.score1
                   from regions r inner join hits h on r.loc = h.loc                                                                            where r.chrom = '%s' and r.start > %d and r.start < %d""" % (chrom, start, stop)
       tbl = pd.read_sql_query(query, conn)
       return(tbl)



*------------------------------------------------------------------------------------------------------------------------
* piq footprints: piqTest db, regions + hits table, index for speed, merge in R (7 sep 2016)

   [status: did two separate simple queries, merged in R, 30-50x speedup]

  --- data & sql files here:

     cd ~/s/data/postgres-fill/piq/newSchema/

  --- accompanying R notebook
    http://whovian:9999/notebooks/piqFootprintDatabaseTiming.ipynb
    ~/github/notebooks/paul-shannon/demos/footprints/piqFootprintDatabaseTiming.ipynb

  --- before indexing loc in the hits table:
   getHits <- function(chrom, start, stop){
      query.p0 <- "select * from regions r inner join hits h on r.loc = h.loc "
      query.p1 <- sprintf("where r.chrom='%s' and r.start > %d and r.stop < %d", chrom, start, stop)
      query <- paste(query.p0, query.p1)
      dbGetQuery(dbpiq, query)[, -1]  # remove the leading 'loc' column
      }

   getHits2 <- function(chrom, start, stop){
      query.p0 <- "select loc, chrom, start, stop from regions"
      query.p1 <- sprintf("where chrom='%s' and start > %d and stop < %d", chrom, start, stop)
      query.regions <- paste(query.p0, query.p1)
      tbl.regions <- dbGetQuery(dbpiq, query.regions)
      if(nrow(tbl.regions) == 0)
         return data.frame()
      loc.set <- sprintf("('%s')", paste(tbl.regions$locs, collapse="','"))
      query.hits <- "select * from hits where loc in %s"
      tbl.hits <- dbGetQuery(dbpiq, query.hits)
      browser()
      x <- 99
      }

  print(system.time(tbl <- getHits("chr21", 15010000, 15010100)))
  dim(tbl) #   36 16
    user  system elapsed
    0.005   0.000  11.009

  loc.start <- 150100000; loc.stop <- 15010100; loc.chrom = "chr21"
  system.time(getHits2(loc.chrom, loc.start, loc.stop))
     user  system elapsed
    0.010   0.001   0.369


   --- do the indexing
     cat ~/s/data/postgres-fill/piq/newSchemaindexHits.sql
       \connect piqTest;
       create index on hits (loc);

    date; psql -f indexHits.sql; date   # 12 minutes
       Wed Sep  7 10:58:34 PDT 2016
       You are now connected to database "piqTest" as user "pshannon".
       CREATE INDEX
       Wed Sep  7 11:10:45 PDT 2016

    date; psql -f indexRegions.sql; date
      Wed Sep  7 11:50:10 PDT 2016
      You are now connected to database "piqTest" as user "pshannon".
      CREATE INDEX
      Wed Sep  7 11:50:26 PDT 2016

   --- after

*------------------------------------------------------------------------------------------------------------------------
* cdn

  https://code.jquery.com/jquery-3.2.1.slim.min.js


  http://cdnjs.cloudflare.com/ajax/libs/d3/3.4.8/d3.min.js

  https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.2/require.min.js
  https://cdnjs.cloudflare.com/ajax/libs/three.js/r79/three.js
  https://cdnjs.cloudflare.com/ajax/libs/three.js/r80/three.js
  https://cdnjs.cloudflare.com/ajax/libs/three.js/r83/three.js   (19 dec 2016)
  https://cdnjs.cloudflare.com/ajax/libs/d3/4.2.2/d3.min.js
  http://code.jquery.com/jquery-2.2.4.min.js
  https://cdnjs.cloudflare.com/ajax/libs/underscore.js/1.8.3/underscore-min.js

   <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/font-awesome/4.7.0/css/font-awesome.min.css">
                                https://cdnjs.cloudflare.com/ajax/libs/jqueryui/1.12.1/themes/base/jquery-ui.css
                                https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/css/bootstrap.min.css

             'jquery'    :   'http://code.jquery.com/jquery-1.12.4.min',
             'jquery-ui' :   'http://code.jquery.com/ui/1.12.1/jquery-ui.min',
             'bootstrap' :   'http://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/js/bootstrap.min',
             'igv'       :   'http://igv.org/web/release/1.0.6/igv-1.0.6'
             'cytoscape' :  'http://cytoscape.github.io/cytoscape.js/api/cytoscape.js-latest/cytoscape.min',


*------------------------------------------------------------------------------------------------------------------------
* install igv widget on whovian, python 2.7.12, for use with gemini (6 sep 2016)

   cd ~/github/igv.js-jupyter
    # /local/pshannon/anaconda3/envs/py27/bin/pip install -e .
    pip install -e .
    jupyter nbextension install --prefix ~/jupyter.extensions --py igv
    jupyter nbextension enable --py igv    # - Validating: OK

   ---> seems to need a kernel restart

   ---  test it out in a py 2.7 notebook
    cd ../notebooks/paul-shannon/
    jupyter notebook
    from igv import IGV, Reference, Track
    igv = IGV(locus="chr21:25877550-25880550", reference=Reference(id="hg19"),
            tracks=[Track(
               name="Genes",
               url="//s3.amazonaws.com/igv.broadinstitute.org/annotations/hg19/genes/gencode.v18.collapsed.bed",
               index_url="//s3.amazonaws.com/igv.broadinstitute.org/annotations/hg19/genes/gencode.v18.collapsed.bed.idx",
               display_mode="EXPANDED")])
    igv  # to display the track browser

    *-------------------------------------------------
    def createTrack(tblHits, trackName):
      tblHits.to_csv("%s.bed" % trackName, sep="\t", header=False, index=False)
      print("wrote %s.bed" % trackName)
      newTrack = Track(name=trackName,
                       format="bed",
                       indexed=False,
                       url="http://whovian:9999/files/%s.bed" % trackName,
                      display_mode='COLLAPSED')
      return(newTrack)

    igv.load_track(myTrack)

*------------------------------------------------------------------------------------------------------------------------
* pandas DataFrame tips, extract column as list

   tbl_regions
                         loc  chrom     start      stop
   0  chr21:15010014-15010020  chr21  15010014  15010020
   1  chr21:15010064-15010076  chr21  15010064  15010076

   tbl_regions.loc[:, "loc"].tolist()
   ['chr21:15010014-15010020', 'chr21:15010064-15010076']

*------------------------------------------------------------------------------------------------------------------------
* pandas DataFrame tips, merge two tables on shared colum

  tbl = pd.merge(tbl_regions, tbl_hists, on="loc")

*------------------------------------------------------------------------------------------------------------------------
* pandas DataFrame, construct on the fly

  import pandas as pd
  tbl = pd.DataFrame([["chr1", "10", "100", "fp1", 9.9], ["chr1", 90, 130, "fp2", 0.5]])

*------------------------------------------------------------------------------------------------------------------------
* from descartes to kant in two pages (6 sep 2016)

  http://reasonandmeaning.com/2015/01/27/from-descartes-to-kant-in-two-pages/

*------------------------------------------------------------------------------------------------------------------------
* whovian anaconda3 jupyter install: where is py27? (6 sep 2016)

  /local/pshannon/anaconda3/envs/py27/bin/python --version
     Python 2.7.12 :: Continuum Analytics, Inc.

*------------------------------------------------------------------------------------------------------------------------
* whovian jupyter py27 install pandas for test with gemini and igv (6 sep 2016)

   /local/pshannon/anaconda3/envs/py27/bin/pip install pandas
   import pandas as pd

   this notebook is the result:
     ~/github/notebooks/paul-shannon/demos/gemini/gemini-intro1-with-igv.ipynb

*------------------------------------------------------------------------------------------------------------------------
* whovian: learn gemini via notebooks (6 sep 2016)

  use our standard jupyter installation: /local/pshannon/anaconda3, and its 2.7 kernel
  in the notebook, make the gemini installation visible:
     import sys, os
     sys.path.append("/local/pshannon/gemini/anaconda/lib/python2.7/site-packages")

  with this simple test:
     from gemini import GeminiQuery
     db = "../gemini/sampleData/learnSQL.db"
     os.path.isfile(db)
     gq = GeminiQuery(db)
     gq.run("select name from samples")
     for row in gq:
       print row

     import gemini.tests

  http://gemini.readthedocs.io/en/latest/content/installation.html

  the stock gemini install script installed anaconda py 2.7 to
      /local/pshannon/gemini/anaconda/pkgs/gemini-0.19.1-py27_1/
  suggesting two strategies:
    1) sys.path.append("/local/pshannon/gemini/anaconda/lib/python2.7/site-packages")

*------------------------------------------------------------------------------------------------------------------------
* learn gemini (6 sep 2016)

  on whovian
  cd /local/pshannon/gemini/sampleData

     2563155 Jul 28 13:20 chr22.VEP.vcf
        3072 Jul 28 13:20 learnSQL2.db
        2048 Jul 28 13:20 learnSQL.db
         154 Jul 28 13:20 trio.ped

  --- the app
  executable app:  /local/pshannon/bin/gemini
      symlink to:  /local/pshannon/gemini/anaconda/bin/gemini

      cat /local/pshannon/gemini/anaconda/bin/gemini
      #!/local/pshannon/gemini/anaconda/bin/python
      import gemini.scripts
      import gemini.gemini_main
      from gemini.gemini_constants import *
      gemini.gemini_main.main()

   --- limited to python 2.7.x and hg19
     filed issue: https://github.com/arq5x/gemini/issues/781
        http://gemini.readthedocs.io/en/latest/content/installation.html
        specifies that gemini requires python 2.7.x.

   --- the query command
   gemini query -q "select name from samples" learnSQL.db
     John
     Bob
     Mary
     Sue

*------------------------------------------------------------------------------------------------------------------------
* cc consignment store sofa bed (4 sep 2016)

  89 wide, 36 deep, 84 long when opened up,
  mattress 60 wide by 70 long

  suggests "sleepers in seattle"
  queen: 60 x 80
  double or full: 54 x 75
  memory foam from tuft&needle: $600 queen, $500 full
*------------------------------------------------------------------------------------------------------------------------
* attempting pythree.js py3js py3.js example in a notebook: 3d scatter plot (2 sep 2016)

  see below "* three.js 3js 3.js example: 3d scatter plot (2 sep 2016)"

  --- update pythreejs
    cd pythreejs/
    pip install -e .
    jupyter nbextension install --py --symlink --user pythreejs
    jupyter nbextension enable --py --user pythreejs
    cd examples
    jupyter notebook



  jupyter notebook &
  good examples here: http://localhost:8888/notebooks/examples/Examples.ipynb

  --- now try my own

    cd ~/github/notebooks/paul-shannon/demos/pythreejs/
    jupyter notebook &


*------------------------------------------------------------------------------------------------------------------------
* three.js 3js 3.js example: 3d scatter plot (2 sep 2016)

  cd ~/s/examples/js/tharee/scatterPlot/jsfiddleDemo

  10k points, vertices and colors pushed, nicely distributed across a rectangular solid
  my version: index.html


  from: http://jsfiddle.net/joequant/fvSrq/

  --- see also
    http://msbarry.github.io/threejs-tool-page/
    http://bl.ocks.org/phil-pedruco/9852362

*------------------------------------------------------------------------------------------------------------------------
* three.js set up for local no-internet use (29 aug 2016)

   cd ~/github/threejs-cookbook/
   /Users/paul/anaconda/bin/python -m http.server 8003
   load in browser:
     /Users/paul/github/threejs-cookbook/experiments/e01-barn.html

   this also seems to work:

     http://localhost:8003/06-particles-postprocessing/06.01-create-particle-system-from-geometry.html

  --- pythreejs (for jupyter)
   cd ~/github/pythreejs/
   git pull origin

*------------------------------------------------------------------------------------------------------------------------
* backbone set up for no-internet use (29 aug 2016)

  cd ~/s/examples/js/backbone/js/

   -rw-r--r--  1 paul  staff  16464 Aug 29 11:56 backbone-min.js
   -rw-r--r--  1 paul  staff   1567 Aug 29 11:56 backbone.localStorage-min.js
   -rw-r--r--  1 paul  staff  94840 Aug 29 11:55 jquery.min.js
   -rw-r--r--  1 paul  staff  12821 Aug 29 11:56 underscore-min.js

  python -m http.server 8008

    /Users/paul/s/examples/js/backbone/helloWorld/helloWorld.html


*------------------------------------------------------------------------------------------------------------------------
* igv reference tracks, used in jupyter notebooks

   --- discovery: study xml at
     http://s3.amazonaws.com/igv.broadinstitute.org

   --- hg19
   igv = IGV(locus="chr21:25877550-25880550", reference=Reference(id="hg19"),
          tracks=[Track(
                   name="Genes",
                    url="//s3.amazonaws.com/igv.broadinstitute.org/annotations/hg19/genes/gencode.v18.collapsed.bed",
                    index_url="//s3.amazonaws.com/igv.broadinstitute.org/annotations/hg19/genes/gencode.v18.collapsed.bed.idx",
                    display_mode="EXPANDED")])

   --- hg38
   igv = IGV(locus="chr21:25,863,045-25,887,052", reference=Reference(id="hg38"),
          tracks=[Track(
                   name="Genes hg38 v24",
                   format="gtf",
                   url="//s3.amazonaws.com/igv.broadinstitute.org/annotations/hg38/genes/gencode.v24.annotation.sorted.gtf.gz",
                   indexURL="//s3.amazonaws.com/igv.broadinstitute.org/annotations/hg38/genes/gencode.v24.annotation.sorted.gtf.gz.tbi",
                   visibility_window=10000000,
                   display_mode="SQUISHED")])


*------------------------------------------------------------------------------------------------------------------------
* whovian notebook, in github, displays hg38 reference genome, hint and piq tracks around gene APP's tss on chr21

  ~/github/notebooks/paul-shannon/demos/footprints/piqAndHINT-compared-chr21.ipynb

*------------------------------------------------------------------------------------------------------------------------
* pto paychex flex, request time off

  https://myapps.paychex.com: pshannonSeattle, NancyCartwright88@
  Main Page > Menu > Human Resources >Compensation > Attendance/Time-Off

  Why we have to go through Human Resources when we are clearly not HumanResources is ridiculous.

*------------------------------------------------------------------------------------------------------------------------
* next up for footprints:

  see if those segments in which hint intersects with profligate piq have piq scores which would identify them
*------------------------------------------------------------------------------------------------------------------------
* return modem to comcast 2202 westlake (23 aug 2016)

*------------------------------------------------------------------------------------------------------------------------
* igv display of footprints (piq, hint, wellington) 5kb upstream of tpp on chr21 (23 aug)

  see below entries about wildly different footprint counts across the three techniques

  --- on riptide
    cd ~/s/work/priceLab/cory/footprintFinderExperiments/methodDiscrepancies
    go.R
  dir /Volumes/local/Cory/for_Paul/piq_complete/MA00022RUNX1.ENCSR000DBY.bed   21,310,556 Jul 18

*------------------------------------------------------------------------------------------------------------------------
* why are welt, hint and piq producing such different results? (23 aug 2016

  APP.tss <- 25880550
  loc.chrom <- "chr21"
  loc.start <- APP.tss - 1000
  loc.stop  <- APP.tss + 0

  --- welt: no results here
  --- hint: 1 result: chr21:25879839-25879847 chr21 25879839 25879847 MA0738.1      + ENCSR000EJB     13
  --- piq: 1187 resuts, 43 unique locs

*------------------------------------------------------------------------------------------------------------------------
* vastly different numbers of footprints for the 18 lymphoblast samples across methods (23 aug 2016)

   /local/Cory/for_Paul/wellington_results:   18 bed files,       3,162,023 total lines
   /local/Cory/for_Paul/piq_complete:       9342 bed files,   2,185,610,022 total lines
   /local/Cory/for_Paul/hint_sample:          18 bed files       20,736,455 total lines

  Note that, for piq,  9342 files seems to come from 18 samples * 519 motifs

  -- similar scale of footprints found if we look at just one motif, and one sample in piq

  --- next up:  move this EDA to riptide macbook for use with desktop igv

*------------------------------------------------------------------------------------------------------------------------
* piq chr21 into new regions/hits schema (22 aug 2016)

  cd ~/s/data/postgres-fill/piq/newSchema
  started (22 aug, 349pm)
  with 8013/9342 files processed: 26,426,766 hits in 1072128 regions: density of 24.6 hits per region
  with 9342/9342:  30,072,096 hits in 115,8121 regions

*------------------------------------------------------------------------------------------------------------------------
* hint & wellington notebook, tutorial and demo for cory (22 aug 2016)

   ~/github/notebooks/paul-shannon/demos/footprints/chr21-hint-vs-wellington.ipynb
   developed in chr21.R in the same directory, for convenience

   at least temporarily running at

     http://whovian:10000/notebooks/footprints/chr21-hint-vs-wellington.ipynb

   shows 3 motifs-in-footprints in tss of APP, 1 for wellington, not overlapping

*------------------------------------------------------------------------------------------------------------------------
* hint, redo, chr21

  cd ~/s/data/postgres-fill/hint/combineWithFimo/
  createdb -U pshannon hintTest2

  504863 hits in 222660 regions

*------------------------------------------------------------------------------------------------------------------------
* wellington chr21

   --- emulate  ~/s/data/postgres-fill/hint/combineWithFimo/fill.R

   cd ~/s/data/postgres-fill/wellington/
   createdb -U pshannon wellington-test
   cp ../hint/combineWithFimo/*.sql .


   nohup R -f fill.R
   187289 hits in 73685 regions (chr21 only)

*------------------------------------------------------------------------------------------------------------------------
* create minids for footprinting documents

   --- email from ben (17 aug 2016)
    for the minids, we can use /local/local_webservices/bdds/html/ on whovian. It will be accessible at http://bdds.systemsbiology.net/<your_file>
    just to keep things tidy, please make a subdirectory for the footprinting work (perhaps /local/local_webservices/bdds/html/footprinting ?)
    with that, the location for the minids would be http://bdds.systemsbiology.net/footprinting/<your_file>

    mkdir -p /local/local_webservices/bdds/html/trena

      # mistake! echo "cory's howto on the BIND footprint process will appear here" > /local/local_webservices/bdds/html/trena/bind-footprinting.html

    echo "cory's howto on the HINT footprint process will appear here" > /local/local_webservices/bdds/html/trena/hint-footprinting.html
    echo "cory's howto on the piq footprint process will appear here" > /local/local_webservices/bdds/html/trena/piq-footprinting.html
    echo "cory's howto on the wellington footprint process will appear here" > /local/local_webservices/bdds/html/trena/wellington-footprinting.html

    /bin/python ~/github/minid/minid_client/minid.py  /local/local_webservices/bdds/html/trena/hint-footprinting.html --register --name hintFootprintPipeline-aug2016 --locations http://bdds.systemsbiology.net/hint-footprinting.html
    /bin/python ~/github/minid/minid_client/minid.py  /local/local_webservices/bdds/html/trena/piq-footprinting.html --register --name piqFootprintPipeline-aug2016 --locations http://bdds.systemsbiology.net/piq-footprinting.html
    /bin/python ~/github/minid/minid_client/minid.py  /local/local_webservices/bdds/html/trena/wellington-footprinting.html --register --name wellingtonFootprintPipeline-aug2016 --locations http://bdds.systemsbiology.net/wellington-footprinting.html

*------------------------------------------------------------------------------------------------------------------------
* jupyter notebook and igv.js: a simple demo on whovian (19 aug 2016)


   cd ~/github/notebooks/paul-shannon/
   jupyter notebook

   load notebook "hint-footprints-chr21-igv-display"

  ~/github/notebooks/paul-shannon/misc/hint-footprints-chr21-igv-display.ipynb

  status:  cannot get 13 footprints in bed file to load

  ---- query, create table, write it out:


   import pandas as pd, psycopg2 as psql
   conn = psql.connect("dbname=hint-test user=pshannon")
   def toBed(chrom, start, stop):
       query = """select r.chrom, r.start, r.stop, h.name, h.score1
                   from regions r inner join hits h on r.loc = h.loc                                                                            where r.chrom = '%s' and r.start > %d and r.start < %d""" % (chrom, start, stop)
       tbl = pd.read_sql_query(query, conn)
       return(tbl)
   tbl = toBed("chr21", 25860335, 25862720)
   tbl.to_csv("foo.tsv", sep="\t")
   footTrack = Track(name="foo", format="bed", url="http://whovian:9999/edit/misc/foo.bed", display_mode='EXPANDED')
   igv.load_track(footTrack)

  --- now add data from the hint chr21 trial fill, using pands and psycopg2 (psql)
    cribbing from (2 aug 2016) work, on whovian it looks like this:
       ~/github/notebooks-pshannon/psql footprints demo.ipynb

  --- python notebook code
    import pandas as pd, psycopg2 as psql
    conn = psql.connect("dbname=pshannon user=pshannon")
    coi = "chrom, motifstart, motifname, normalizedscore, strand"
    query = "select %s  from footprints where chrom='chr22' and motifstart < 10510285" % coi
    tbl = pd.read_sql_query(query,  conn)

        chrom	motifstart	motifname	normalizedscore	strand
      0	chr22	10510185	MA0151.1	0.811947	+
      1	chr22	10510200	MA0158.1	0.258267	+
      2	chr22	10510282	MA0494.1	0.496226	-
      3	chr22	10510277	MA0740.1	0.349608	-


   --- with hint-test

*------------------------------------------------------------------------------------------------------------------------
* jupyter notebook and igv.js: a simple demo on laptop riptide (19 aug 2016)

   laptop (riptide)
   cd ~/s/examples/igv/jupyter/
   juypter notebok
   http://localhost:8889/notebooks/simple-igv-demo.ipynb

   running in python3

   from igv import IGV, Reference, Track

   IGV(locus="chr1:155,160,475-155,184,282", reference=Reference(id="hg19"), tracks=[Track(
       name="Genes",
       url="//s3.amazonaws.com/igv.broadinstitute.org/annotations/hg19/genes/gencode.v18.collapsed.bed",
       index_url="//s3.amazonaws.com/igv.broadinstitute.org/annotations/hg19/genes/gencode.v18.collapsed.bed.idx",
       display_mode="EXPANDED")])

*------------------------------------------------------------------------------------------------------------------------
* filled whovian database hint-test from all regions & hits in chr21 (19 aug 2016)

   cd ~/s/data/postgres-fill/hint/combineWithFimo
   fill.R

*------------------------------------------------------------------------------------------------------------------------
*

A mixed lay/scientific group - Seattle Parks ecologists, UW
researchers, WSU plant pathologists, and the Friends of Seward Park -
is trying to figure out an unprecedented and alarming sword fern
(Polystichum munitum) die-off in the one hundred acre old-growth
forest in Seattle’s Seward Park.

We had hoped to discover that the die-off, which begin in 2013, would be
self-limiting, a transient episode in the life of this old forest.
But the fern death continues, spreading radially at ~10m/yr, and now
affects > 2% of the forest. Lush understory of three years ago is now
bare ground.

The sword fern is the dominant understory species in Pacific Coast
lowland forests, from northern California to southeast Alaska.
It is famously hardy, resilient to both drought and disease.

Sword fern die-off has not been reported elsewhere in its range
(personal communications from WSU pathologists and authoritative
botanists from the NY Botanical Garden, University of Vermont, and
LSU), nor has it been seen in any related species, anywhere in the
world.

Seward Park's Magnificent Forest is a rare remenant of what was once
more than a million acres of lowland forest. It has been a bellwether
of beauty and hope, an inspiring example of how we humans might live
on this planet, with a wilderness forest flourishing in the midst of a
thriving cosmopolitan city.  The forest is within walking distance of
many heterogeneous communities, a broad ethnic and socioeconomic mix.
The forest is host not only to bald eagles, pileated woodpeckers, owls
and coyotes, and to the oldest trees in Seattle, but to children of all
classes, to nature camps and univeristy researchers, and to countless
visitors who walk the trails beneath towering tress.

Our forest, alas, is no longer flourishing.  It may now have become a
bellwether of another and less happy kind, in which we see up close
how our human lives put forest communities at risk. In the death of
Seward Park's sword ferns, we likely see the effects of climate change
and globalization: newly introduced pests, or new imbalance among
established and previously commensal species.

Perhaps this loss cannot be reversed. It may be that the most we can
hope for is the eventual evolution of a new and likely much dimished
forest community which compatible with our warmer, imbalanced and
polluted world.

But maybe not.  We can make good use of the sword fern die-off.  We
can study it methodically and with scientific imaginatio in
order to learn its causes, and perhaps to devise remedies.

And not least, through careful study and good reporting, we can draw
attention to the harm and loss occuring within this rare, complex and
beautiful urban forest, a local and compelling instance of the harm
and loss taking place broadly (and often remotely) on our plant.  We
can can cultivate informed and detailed attention of the sort which
may, in some measure, bring home to us the need to find new ways to
live on the earth, new ways in which humans and trees, woodpeckers,
children and ferns can all flourish.



Perhaps this forest
can
Or perhaps we can  comprehend the processes in play in the forest,
analyze the sword fern die-off, devise remedies to minimize and
perhaps reverse the process.


The Seward Park die-off began in 2013, is concentrated near the
Hatchery Trail, spreads radially at ~10m/yr and now affects >2% of the
forest. Lush understory of three years ago is now bare ground.


The drought of 2015, pollution and mountain beaver activity may
be contributing factors, but deeper, unknown and probably
pathogenic causes can reasonably be inferred from the die-off’s
concentrated distribution and radial spread.  Several rounds of
traditional laboratory diagnostic techniques have failed to
identify a pathogen.


Seward Park's old growth "Magnificent Forest"

*------------------------------------------------------------------------------------------------------------------------
* two table fill of hint, with fimo intersections (17 aug 2016)

  cd ~/s/data/postgres-fill/hint/combineWithFimo
  source("fill.R")
  runTests()

  --- next step
     create locs.schema, hits.schema
     append tbl.locs and tbl.hits to fptest database.

*------------------------------------------------------------------------------------------------------------------------
* two table fill to fptest, all of seth's tf motifs, all 18 piq samples (17 aug 2016)

  cd ~/s/data/postgres-fill/footprints/

  library(RPostgreSQL)
  library(RUnit)
  db <- dbConnect(PostgreSQL(), user= "trena", password="trena", dbname="fptest", host="whovian")
  checkTrue(dbExistsTable(db, "footprints"))
  checkTrue(dbExistsTable(db, "motifhits"))
  query <- paste("select * from footprints fp",
                 "inner join motifhits mh",
                 "on fp.loc = mh.loc",
                 "where fp.chrom = 'chr21' and fp.motif_start < 5010300")
  tbl <- dbGetQuery(db, query)

  --- with fill completed:
    db <- dbConnect(PostgreSQL(), user= "trena", password="trena", dbname="fptest", host="whovian")
    dbGetQuery(db, "select count(*) from footprints")  #    442802
    dbGetQuery(db, "select count(*) from motifhits")    #  10578654



*------------------------------------------------------------------------------------------------------------------------
* joe lirette, PT, Renew, provides access to exercise videos (17 aug 2016)


   I have created a custom home exercise program for you. The
   frequency and dosage are guides. If you perform 3-4 times per week
   vs 1x/day that should suffice.

  This program provides video demonstrations and detailed instructions
  to help you perform each exercise.  Keep this email so you can
  access your program for any reminders or new exercises we add to
  your routine during therapy.

   To view your exercise program:

     1. Go to http://renew-pt.medbridgego.com
     2. Enter the access code:  6J3GA7NC
     3. Click "Continue to Patient Portal"

*------------------------------------------------------------------------------------------------------------------------
* spatial and climate analysis of BigLeaf Maple decline in western washington (15 aug 2016)

  http://www.cfr.washington.edu/academicprograms/undergrad/esrm/posterDeCordoba.pdf

*------------------------------------------------------------------------------------------------------------------------
* unified hg38 footprints table, and sample table on whovian:  make it much smaller (not > 2B rows!) (15 aug 2016)

  cd ~/s/data/postgres-fill/footprints/
  source("fill.R"); runTests()

     --- test.mapMotifName
     --- test.readPiqTable
     --- test.load.piq.samples.for.motif.and.sampleID

   --- next up
     create fp and sample tables
     fill to each of them, sample by sample, motif by motif
     keep an accumulating list of known locs - the primary key in each table, which must be unique in the fp table

*------------------------------------------------------------------------------------------------------------------------
* unified hg38 footprints table on whovian:  make it much smaller (not > 2B rows!) (15 aug 2016)

  cd ~/s/data/postgres-fill/footprints/
  limit motif-centric table to chr22 and some/all of seth's 77 TFs with ChIP-seq data

   ls /proj/price1/sament/lymphoblast_trn/known_tfbs/hg38/*.bed | wc -l    # 77

  tokens <- strsplit(list.files("/proj/price1/sament/lymphoblast_trn/known_tfbs/hg38", pattern="*.bed"), "_")
  tfs.withChIPSeq <- unlist(lapply(tokens, "[", 1))
  head(tfs.withChIPSeq) # [1] "ATF2"   "ATF3"   "BATF"   "BCL11A" "BCL3"   "BCLAF1"

  library(RPostgreSQL)
  db <- dbConnect(PostgreSQL(), user= "trena", password="trena", dbname="hg38", host="whovian")
  checkTrue(dbExistsTable(db, "motifsgenes"))

  dbGetQuery(db, "select * from motifsgenes limit 5")
       motif     tf
  1 MA0002.2  RUNX1
  2 MA0003.3 TFAP2A
  3 MA0004.1   ARNT
  4 MA0006.1    AHR

  5 MA0006.1   ARNT

   tbl.gm <- dbGetQuery(db, "select * from motifsgenes")
   dim(tbl.gm) # [1] 9289    2


*------------------------------------------------------------------------------------------------------------------------
* how big can a postgres table be?  (15 aug 2016)

   http://stackoverflow.com/questions/21866113/how-big-is-too-big-for-a-postgresql-table

    Another way to speed up your queries significantly on a table with
    > 100 million rows is in the off hours cluster the table on the
    index that is most often used in your queries. We have a table
    with > 218 million rows and have found 30X improvements.


*------------------------------------------------------------------------------------------------------------------------
* postgres, piq, timing a simple query (15 aug 2016)

    query <- "select chrom, motif_start, motif_end, motif_name, sample_id, score1 from \
              footprints where chrom='chr5' and motif_start >88900000 and motif_end < 88904257"

    system.time(tbl <- dbGetQuery(db, query))
     user  system elapsed
    0.011   0.001 363.880
    dim(tbl) # [1] 4284    6

*------------------------------------------------------------------------------------------------------------------------
* big fill

  cd ~/s/data/postgres-fill/footprints/
  select count(*) from footprints;  2,185,610,022   # takes > 8 minutes
   select * from footprints limit 1;
 chrom | motif_start | motif_end | motif_name | normalizedscore | strand | footprint_start | footprint_end | motif_length
       | footprint_ength |  sample_id  | method |    provenance     | score1  |  score2  |   score3   |  score4
       | score5 | score6

 chr1  |       15050 |     15061 | MA0002.2   |                 | -      |                 |               |           12
       |                 | ENCSR000DBY | piq    | ark:/57799/b94s3c | 9.67107 | -1.03703 | -0.0526116 | 0.500737 |
       |



*------------------------------------------------------------------------------------------------------------------------
* kei ono points to latest ipywidgets docs (17 aug 2016)

   https://ipywidgets.readthedocs.io/en/latest/

*------------------------------------------------------------------------------------------------------------------------
* backbone.js tutorial for ipywidgets (22 aug 2016)

  http://adrianmejia.com/blog/2012/09/11/backbone-dot-js-for-absolute-beginners-getting-started/

     example code in ~/s/examples/js/backbone

   as good, maybe better:

      https://www.sitepoint.com/backbone-basics-models-views-collections-templates/

*------------------------------------------------------------------------------------------------------------------------
* alternate zmq client for R (12 aug 2016)

  https://github.com/RBigData/pbdZMQ.git   (7 commits ahead, 10 commits behind snoweye:master)
  https://github.com/snoweye/pbdZMQ.git    (last updated 6 days ago)

*------------------------------------------------------------------------------------------------------------------------
* ipywidget tips


  -- from jason grout, sylvain corlay (emails 27 july 2016)
    Yes, the notebook explain in details how to implement jupyter widgets in an interactive fashion in
       the jupyter notebook.
    The cookiecutter project is meant for people who want to package them in an installable package.

  --- examples, Hello World (a notebook)

     https://github.com/ipython/ipywidgets/blob/master/docs/source/examples/Custom%20Widget%20-%20Hello%20World.ipynb

  --- examples, Date Picker Widget (a notebook)

    https://github.com/ipython/ipywidgets/blob/master/docs/source/examples/Date%20Picker%20Widget.ipynb

     Before reading, make sure to review
     MVC prgramming
     Backbone.js
     The widget IPEP
     The original widget PR discussion

*------------------------------------------------------------------------------------------------------------------------
* R tips ess tips, use other versions (11 aug 2016)

   Also M-x customize-variable and then inferior-R-program-name. Martin Morgan May 6 '11

*------------------------------------------------------------------------------------------------------------------------
* bug: anaconda R version 3.3.1 has system() readline missing symbol problem (11 aug 2016)

   cd ~/s/data/postgres-fill/footprints/

   system("/bin/psql -f fill.sql")
    /bin/psql: symbol lookup error: /local/pshannon/anaconda3/lib/libreadline.so.6: undefined symbol: PC

  ---- remedy 1, poor choice
     but by switching to R3.2.3 the problem seems to go away
     M-x customize-variable and then inferior-R-program-name /usr/bin/R

  --- remedy 2, better conda remove --force readline
    https://github.com/ContinuumIO/anaconda-issues/issues/152


*------------------------------------------------------------------------------------------------------------------------
* psql tips: show indexes

  psql hint
  \d regions
             Table "public.regions"
     Column |       Type        | Modifiers
    --------+-------------------+-----------
     loc    | character varying | not null
     chrom  | character varying |
     start  | integer           |
     endpos | integer           |
    Indexes:
        "regions_pkey" PRIMARY KEY, btree (loc)
        "regions_index" btree (loc, start, endpos)
  \d regions
    ...
    Indexes:
        "hits_index" btree (loc)




*------------------------------------------------------------------------------------------------------------------------
* psql tips: run psql from within R, for fill

  --- original example ~/s/data/postgres-fill/hint/dani/fill.R
   tips: row.names=col.names<-FALSE
         na written out as "NULL"

   for(full.path in full.paths){
      printf("about to read %s [%4d/%4d]", full.path, grep(full.path, full.paths), length(full.paths))
      sampleName <- strsplit(basename(full.path), ".", fixed=TRUE)[[1]][2]
      tbl <- processFile(full.path, sampleName)
      if(all(is.na(tbl))){
          printf("error processing %s", full.path)
          next;
          }
      printf("writing %d lines to current.tsv", nrow(tbl))
      write.table(tbl, file="current.tsv", row.names=FALSE, col.names=FALSE, quote=FALSE, sep="\t", na="NULL")
      system("/bin/psql -f fill.sql")
      printf("after fill");
      } # for full.path


*------------------------------------------------------------------------------------------------------------------------
* chia todo (10 aug 2016)

  regression line error?

   Non.white.minority.population (x) vs. Adults.No.Leisure.Time (y)
   before: beacon hill is removed
         correlation: 0.7439
   after: recalculated correlation: 0.6414
   and slope  seems not to change

   ---- explored in LinearModel.R and test_LinearModel.R, with no resolution yet
     # plotting "Non.white.minority.population" vs  "Adults.No.Leisure.Time" in the cleveland webapp
     # then leaving out Beacon Hill, an outlier at (70, 30), -reduces- the correlation, and
     # does not change the regression line in the way I expect.
     # explore this here, by making the same base R calls found in LinearModel.R
     #
     # status (11 aug 2016): need to hand-check the correlation calculation.  still confused
     #
     test_correlateSomeLeftOut_confusion <- function()




*------------------------------------------------------------------------------------------------------------------------
* create minids for per-source footprint creation (10 aug 2016)

  whovian, cd ~/github
  git clone https://github.com/ini-bdds/minid.git
  cd minid/minid_client

   Your minid registration code is: 8bd72477-3e5c-4410-a8f1-db552d4375ca
   Copy this code and put it in your minid configuration file.

   /bin/python minid.py --register_user --email pshannon@systemsbiology.org --name paul-shannon
     2016-08-10 13:58:21,234 - INFO - No default configuration file found, creating one
     2016-08-10 13:58:21,260 - INFO - Registering new user "paul-shannon" with email "pshannon@systemsbiology.org"
     2016-08-10 13:58:21,275 - INFO - Starting new HTTP connection (1): minid.bd2k.org

   edited ~/.minid/minid-config.cfg on whovian
      [general]
      minid_server: http://minid.bd2k.org/minid
      username: paul-shannon
      email: pshannon@systemsbiology.org
      orcid:
      code: 8bd72477-3e5c-4410-a8f1-db552d4375ca

   --- temporarly fix from @kylechard of the bdds group

    minid test_file.txt --test --register --name "testing" --locations http://example.com/file.txt

   --- my version
    /bin/python minid.py  piqFootprintPipeline-jul2016.txt --register --name piqFootprintPipeline-jul2016 --locations http://systemsbioloyg.net/bdds/piqFootprintPipeline-jul2016.txt
      2016-08-10 15:47:36,953 - INFO - Computing checksum for piqFootprintPipeline-jul2016.txt using <sha256 HASH object @ 0x187d8f0>
      2016-08-10 15:47:36,954 - INFO - Checking if the entity af1f45343af73c22dd26acd61e5c236392d3458a50b549e4d9bf6e40d21cf5c7 already exists on the server: http://minid.bd2k.org/minid
      2016-08-10 15:47:37,009 - INFO - Starting new HTTP connection (1): minid.bd2k.org
      2016-08-10 15:47:37,166 - INFO - Creating new identifier
      2016-08-10 15:47:37,168 - INFO - Starting new HTTP connection (1): minid.bd2k.org
      2016-08-10 15:47:39,154 - INFO - Created/updated minid: ark:/57799/b94s3c


*------------------------------------------------------------------------------------------------------------------------
* the big fill: piq complete (12 aug 2016)

  cd ~/s/data/postgres-fill/footprints/
  finished at 1020 Friday night, about 30 hours
  hg38=> select count(*) from footprints;    2,185,610,022

  nohup psql -f index.sql &

*------------------------------------------------------------------------------------------------------------------------
* the big fill: piq, wellington, hint (9,10 aug 2016)

  whovian: cd ~/s/data/postgres-fill/footprints

  --- next up
    continue with the canonicalization of a (footprint-free) piq sample file, creating these
    as-yet missing columns:
     [1] "normalized.score" "footprint.start"  "footprint.end"    "motif.length"     "footprint.length" "sample.id"
     [7] "method"           "provenance"       "score5"           "score6"


*------------------------------------------------------------------------------------------------------------------------
* fimo + footprints: make sure combination works well with new fimo database, table hg38 (9 aug 2016)

  cd ~/s/data/postgres-fill/hint/combineWithFimo

  hg38 fimo is now in postgres.  create postgres fp/fimo table from postgres fimo

  reproduce experiment below, with fimo hits read from file
   "* cory's hint example, fimo output from chr22, single HINT bed file ENCSR000DBY (4 aug 2016)  fimo + footprints"

   --- reproduce (4 aug work)
     reload(); runTests()
     system.time(run.combineFootprintsAndFimo())  25 seconds elapsed time


  --- compare reading fimo file vs postgres query

    system.time(tbl.fimo22 <- read.table("chr22.fimo.txt", sep="\t", as.is=TRUE, nrow=-1,
                                         comment.char='',row.names=NULL, header=TRUE))  # 55.6 seconds
    system.time(tbl.22 <- dbGetQuery(db, "select * from hg38 where chr='22'"))   # 28.713 seconds

   --- same table structure, but additional "empty" column in

     dim(tbl.22)     # [1] 6649014       9
     dim(tbl.fimo22) # [1] 6649014       8

   --- the successful test
   reload(); runTests()
      [1] --- test.combineFootprintsAndFimo
      [1] --- calculating motif.footprint.overlap
      [1] --- test.combineFootprintsAndDatabasedFimo
      [1] --- calculating motif.footprint.overlap
      [1] TRUE


*------------------------------------------------------------------------------------------------------------------------
* cory estimates 1.1M footprints per sample (all motifs) from hint

  18 samples, thus 20M footprints

  --- footprint files (wellington, hint, piq) (email 5 aug 2016)
     /local/Cory/for_Paul/piq_complete
     /local/Cory/for_Paul/hint_sample
     /local/Cory/for_Paul/wellington_results

  --- hint  (18 samples)
     20030824 Jun 21 16:23 ENCSR000DBY.hint.bed
     66862683 Jun 21 16:23 ENCSR000DBZ.hint.bed
     61907013 Jun 21 16:23 ENCSR000DCA.hint.bed
     64155124 Jun 21 16:23 ENCSR000DCB.hint.bed
     58095251 Jun 21 16:23 ENCSR000DCC.hint.bed
     68249741 Jun 21 16:23 ENCSR000EJB.hint.bed
     76900718 Jun 21 16:23 ENCSR000EJD.hint.bed
     77068367 Jun 21 16:23 ENCSR000EJE.hint.bed
     72379306 Jun 21 16:23 ENCSR000EJF.hint.bed
      9484641 Jun 21 16:23 ENCSR000EJG.hint.bed
     64317246 Jun 21 16:23 ENCSR000EJI.hint.bed
     62346066 Jun 21 16:24 ENCSR000EJJ.hint.bed
     72179773 Jun 21 16:24 ENCSR000EJK.hint.bed
     56008384 Jun 21 16:24 ENCSR000EJL.hint.bed
     81331675 Jun 21 16:24 ENCSR000EMQ.hint.bed
     33689919 Jun 21 16:24 ENCSR000EMR.hint.bed
     86710485 Jun 21 16:24 ENCSR000EMS.hint.bed
     81804245 Jun 21 16:24 ENCSR000EMT.hint.bed


  --- wellington (18 samples)

      1088460 Apr  8 14:06 ENCSR000DBY.sorted.bam.ENCSR000DBY.peaks.400.bed.WellingtonFootprints.-10.bed
      3791608 Apr  8 16:08 ENCSR000DBZ.sorted.bam.ENCSR000DBZ.peaks.400.bed.WellingtonFootprints.-10.bed
      1672833 Apr  8 17:36 ENCSR000DCA.sorted.bam.ENCSR000DCA.peaks.400.bed.WellingtonFootprints.-10.bed
      2122290 Apr  8 19:29 ENCSR000DCB.sorted.bam.ENCSR000DCB.peaks.400.bed.WellingtonFootprints.-10.bed
       677430 Apr  8 20:46 ENCSR000DCC.sorted.bam.ENCSR000DCC.peaks.400.bed.WellingtonFootprints.-10.bed
     14120208 Apr  9 01:48 ENCSR000EJB.sorted.bam.ENCSR000EJB.peaks.400.bed.WellingtonFootprints.-10.bed
     32412272 Apr  9 09:32 ENCSR000EJD.sorted.bam.ENCSR000EJD.peaks.400.bed.WellingtonFootprints.-10.bed
      4609833 Apr  9 13:29 ENCSR000EJE.sorted.bam.ENCSR000EJE.peaks.400.bed.WellingtonFootprints.-10.bed
      5896543 Apr  9 17:41 ENCSR000EJF.sorted.bam.ENCSR000EJF.peaks.400.bed.WellingtonFootprints.-10.bed
      3873998 Apr  9 19:06 ENCSR000EJG.sorted.bam.ENCSR000EJG.peaks.400.bed.WellingtonFootprints.-10.bed
      1580587 Apr  9 20:46 ENCSR000EJI.sorted.bam.ENCSR000EJI.peaks.400.bed.WellingtonFootprints.-10.bed
      6044576 Apr 10 00:09 ENCSR000EJJ.sorted.bam.ENCSR000EJJ.peaks.400.bed.WellingtonFootprints.-10.bed
      4144224 Apr 10 03:28 ENCSR000EJK.sorted.bam.ENCSR000EJK.peaks.400.bed.WellingtonFootprints.-10.bed
      5295564 Apr 10 06:20 ENCSR000EJL.sorted.bam.ENCSR000EJL.peaks.400.bed.WellingtonFootprints.-10.bed
     26687776 Apr 10 11:24 ENCSR000EMQ.sorted.bam.ENCSR000EMQ.peaks.400.bed.WellingtonFootprints.-10.bed
      6362101 Apr 10 12:33 ENCSR000EMR.sorted.bam.ENCSR000EMR.peaks.400.bed.WellingtonFootprints.-10.bed
     33806460 Apr 10 17:07 ENCSR000EMS.sorted.bam.ENCSR000EMS.peaks.400.bed.WellingtonFootprints.-10.bed
      9620200 Apr 10 20:02 ENCSR000EMT.sorted.bam.ENCSR000EMT.peaks.400.bed.WellingtonFootprints.-10.bed


   --- piq (9342 files) (18 samples # 519 motifs)

      21310556 Jul 18 11:29 MA00022RUNX1.ENCSR000DBY.bed
      21291450 Jul 16 11:20 MA00022RUNX1.ENCSR000DBZ.bed
      21292511 Jul 16 22:10 MA00022RUNX1.ENCSR000DCA.bed
      21396568 Jul 17 10:27 MA00022RUNX1.ENCSR000DCB.bed
      21294328 Jul 17 20:06 MA00022RUNX1.ENCSR000DCC.bed






*------------------------------------------------------------------------------------------------------------------------
* getting back to ipywidgets study, jason grout and sylvain corlay suggest notebook widgets to learn on (1 aug 2016)

   hello world + spinner

  [now in ~/github/notebooks/study/ipywidgets-hello-spinner-annotated.ipynb](10 aug 2016)
  riptide | whovian: cd ~/github/notebooks; jupyter notebook
  [used to be in ~/s/examples/jupyter/customWidgetFromIpyWidgetsGithub] (9 aug 2016)

   ~/s/examples/jupyter/customWidgetFromIpyWidgetsGithub/ipywidgets-hello-spinner-annotated.ipynb
   cd ~/s/examples/jupyter/customWidgetFromIpyWidgetsGithub
   jupyter notebook

   --- from pascal bugnion of the ipywidgets repo
        https://github.com/ipython/ipywidgets/issues/695#issuecomment-237461147

     It's fairly common practice to name variables (or object fields) that hold a jQuery element with names starting
     with a $. There is no programmatic meaning to the $ itself in the variable name. It's just convention. See this
     Stack Overflow question, for instance.

     For instance, in a DOMWidgetView, you have access to both this.el, which represents the actual DOM element the
     widget view is attached to, and this.$el, a jQuery element equivalent to $(this.el). Thus, both this:

       this.$el.text('Hi Paul');
       this.el.textContent = 'Hi Paul';

     will have the same behaviour.


    --- annotated spinner widget code

     from traitlets import CInt
     class SpinnerWidget(widgets.DOMWidget):
        _view_name = Unicode('SpinnerView').tag(sync=True)
        _view_module = Unicode('spinner').tag(sync=True)
        value = CInt().tag(sync=True)

     %%javascript
     requirejs.undef('spinner');
     define('spinner', ["jupyter-js-widgets"], function(widgets) {
         var SpinnerView = widgets.DOMWidgetView.extend({
            render: function() {
               var that = this;
               this.$input = $('<input />');
               this.$el.append(this.$input);
               this.$spinner = this.$input.spinner({
                    // in these two anonymous functions, "this" is the event, not the SpinnerView,
                    // to which "that" is a reference
                  change: function(event, ui) {that.handle_spin(that.$spinner.spinner('value'));},
                  spin: function(event, ui)   {that.handle_spin(ui.value);} //ui.value is the new value of the spinner
                  });
               this.value_changed();
               this.model.on('change:value', this.value_changed, this);
               }, // render
            value_changed: function()      {this.$spinner.spinner('value', this.model.get('value'));},
            handle_spin:   function(value) {this.model.set('value', value); this.touch();},
            });
         return {
             SpinnerView: SpinnerView
         };
     });


*------------------------------------------------------------------------------------------------------------------------
* psql tips

   --- create database from bash command line
      createdb -U pshannon footprints

  --- fill from R data.frame
   row.names <- FALSE
   col.names <- FALSE

         na written out as "NULL"

   --- inspection commands
     list databases:  \l    or     select datname from pg_database where datistemplate = false;
     connect to databases: \connect databasename   or \c databasename

     list tables in current database:  \dt
        or  SELECT table_schema,table_name FROM information_schema.tables ORDER BY table_schema,table_name;



   --- connect to database, drop & create table:
       \connect fimo;
       drop table hg38;
       create table hg38(motifname varchar,
                         chr varchar,
                         start int,
                         endpos int,
                         strand varchar,
                         motifscore float,
                         pval float,
                         empty char(1),
                         sequence varchar
                         );


   --- file file with header
   \connect fimo;
   \copy hg38 from 'tiny.txt' delimiter E'\t' CSV header NULL as 'NULL';


*------------------------------------------------------------------------------------------------------------------------
* genome-wide fimo files from Cory (8 aug 2016)

   cd ~/s/data/postgres-fill/fimo

   dir /local/Cory/for_Paul/fimo_out/*.fimo.txt
     28672130668 Aug  6 20:02 /local/Cory/for_Paul/fimo_out/GRCh38.fimo.txt
     26516524484 Aug  6 20:11 /local/Cory/for_Paul/fimo_out/GRm38.fimo.txt

  /local/Cory/for_Paul/fimo_out/GRCh38.fimo.txt

   head -10 /local/Cory/for_Paul/fimo_out/GRCh38.fimo.txt
   #pattern name	sequence name	start	stop	strand	score	p-value	matched sequence
   MA0002.2	10	12880	12890	+	11.4483	6.04e-05		GCTTGTGGCCT
   MA0002.2	10	18991	19001	-	12.4655	2.73e-05		TTCTGTGGTTC
   MA0002.2	10	19478	19488	-	13.3448	1.17e-05		TTCTGTGGTTG

   --- the two-tab problem: don't want to sed two 30G files!
     see if we can fill from
     head -10 /local/Cory/for_Paul/fimo_out/GRCh38.fimo.txt > tiny.txt

   createdb -U pshannon fimo
   psql fimo -f create.sql
     DROP TABLE
     CREATE TABLE
    psql fimo -f fill.sql   # tiny.txt
      COPY 9

  --- next problem: the big file is actually 12 files combined, thus 12 header lines,
     and this bug:

      whovian.fimo> psql -f fill.sql
        You are now connected to database "fimo" as user "pshannon".
        psql:fill.sql:2: ERROR:  invalid input syntax for integer: "start"
        CONTEXT:  COPY hg38, line 20583881, column start: "start"

     remedy: cory will grep -v start on the file, give me a new one.

  --- timing (no indices yet)

    system.time(dbGetQuery(db, "select * from hg38 where chr='10' and start < 19000"))
      user  system elapsed
      0.008   0.001  55.610

  --- built 3 indices
   index.sql:
     \connect fimo;
     create index on hg38 (chr);
     create index on hg38 (start);
     create index on hg38 (endpos);

   system.time(dbGetQuery(db, "select * from hg38 where chr='10' and start < 19000"))
     user  system elapsed
    0.013   0.000  17.456



*------------------------------------------------------------------------------------------------------------------------
* psql tips

  psql -U trena --host whovian skin_hint   # password trean
  psql -U trena --host whovian   # password trena
  psql -U pshannon               # without --host, and with me linux-logged in as pshannon, no password needed
  psql -U pshannon <dbname>      # eg, mm10, hg38, footprints
  list all databases:  \l or \list  [see sample output below]
  choose database: \c hg38
  query current database: SELECT current_database();
  list tables in current database: \dt
     public | gtf         | table | pshannon
     public | motifsgenes | table | pshannon
  create new database
  bash> createdb -U pshannon hg38

   --- 6 aug 2016
     enhancers.hg38    | pshannon
     gtf               | pshannon
     gtf-hsapiens-hg38 | pshannon
     hg38              | pshannon
     lymphoblast       | pshannon
     postgres          | postgres
     pshannon          | pshannon
     template0         | postgres
     template1         | postgres
     trena             | pshannon
     wholeBrain        | pshannon



*------------------------------------------------------------------------------------------------------------------------
* baconian and humboldtian science (6 aug 2016)

  ~/Documents/Alexander_von_Humboldt_Humboldtian_Science_and_the.pdf
   Science in Culture: The Early Victorian Period, susan faye cannon

*------------------------------------------------------------------------------------------------------------------------
* heatmap of cleveland data, bound for a notebook (5 aug 2016)

   ~/github/clevelandHighSchool/misc/exampleCode/heatmap.R


*------------------------------------------------------------------------------------------------------------------------
* jupyter R kernela always dead (5 aug 2016)

   https://github.com/IRkernel/IRkernel/issues/204

   --- fresh install & deploy R kernel for jupyter on whovian (2 aug 2016)

      conda install -c r r-essentials

   --- to update and fix the dead kernel problem, these worked for me

    install.packages(c('repr', 'IRdisplay', 'pbdZMQ', 'devtools'))
    devtools::install_github('IRkernel/IRkernel')
    IRkernel::installspec()  # to register the kernel in the current R installation

*------------------------------------------------------------------------------------------------------------------------
* mm10 gtf into postgres for dani: test (8 aug 2016)

  ~/s/data/postgres-fill/gtf/mm10/quickLook.R

  --- access bug?
   dbGetQuery(db, query)
     Error in postgresqlExecStatement(conn, statement, ...) :
     RS-DBI driver: (could not Retrieve the result : ERROR:  permission denied for relation gtf

   some combination of these, but maybe especially the last line, required for successful query
     GRANT select on all tables in SCHEMA public to trena;
     GRANT connect on database "mm10" to trena;
     GRANT ALL PRIVILEGES ON TABLE "gtf" to trena;   # needed, but did not suffice
      grant all on table gtf to trena;                # this made trena user queries on mm10/gtf work


  --- psql
    psql -U pshannon mm10
    \dt
               List of relations
        Schema | Name | Type  |  Owner
       --------+------+-------+----------
        public | gtf  | table | pshannon


  --- from quickLook.R

    library(RPostgreSQL)
    library(RUnit)
    db <- dbConnect(PostgreSQL(), user= "trena", password="trena", dbname="mm10", host="whovian")
    checkTrue(dbExistsTable(db, "gtf"))
    query <- "select count(*) from gtf"
    tbl <- dbGetQuery(db, query)
    checkTrue(tbl[1,1] > 1600000)


    # a representative query:  find all the protein-coding genes within 1M of mef2c
    # first find Mef2c
    tbl <- dbGetQuery(db, "select * from gtf where gene_name='Mef2c' and moleculetype='gene'")
    checkEquals(dim(tbl), c(1, 30))
    checkEquals(tbl$chr[1], "chr13")
    checkEquals(tbl$gene_id[1], "ENSMUSG00000005583")

    start <- tbl$start[1]
    checkEquals(start, 83504034)

    upstream.start <- start - 10^6
    downstream.start <- start + 10^6
    # now look up and downstream
    clause.1 <- "chr='chr13'"
    clause.2 <- sprintf("start > %d", upstream.start)
    clause.3 <- sprintf("start < %d", downstream.start)
    clause.4 <- sprintf("moleculetype='gene'")
    query <- sprintf("select * from gtf where %s and %s and %s and %s", clause.1, clause.2, clause.3, clause.4)
    tbl <- dbGetQuery(db, query)
    checkTrue(nrow(tbl) > 10)
    checkTrue(all(c("Mir3961", "Mef2c", "C130071C03Rik", "Gm26803") %in% tbl$gene_name))


*------------------------------------------------------------------------------------------------------------------------
* mm10 gtf into postgres for dani: the database fill (6 aug 2016)

  cd ~/s/data/postgres-fill/gtf/mm10/
  bash> createdb -U pshannon mm10
  file exists (from step found just below)  mm10-gtf.tsv
     mm10-gtf.tsv  1613247 lines, no rownames, no colnames

whovian.mm10> head -1 mm10-gtf.tsv | tr "\t" "\n" | nl
     1	chr1
     2	3073253
     3	3074322
     4	.
     5	+
     6	.
     7	gene
     8	ENSMUSG00000102693
     9	1
    10	4933401J01Rik
    11	havana
    12	TEC
    13	OTTMUSG00000049935
    14	1;
    15	NA
    16	NA
    17	NA
    18	NA
    19	NA
    20	NA
    21	NA
    22	NA
    23	NA
    24	NA
    25	NA
    26	NA
    27	NA
    28	NA
    29	NA
    30	havana

  psql -U pshannon mm10
  psql -U pshannon mm10 -f fill.sql

  GRANT select on all tables in SCHEMA public to trena;
  GRANT connect on database "mm10" to trena;
  GRANT ALL PRIVILEGES ON TABLE "gtf" to trena;   # needed, but did not suffice
  grant all on table gtf to trena;                # this made trena user queries on mm10/gtf work



  but still, from quickLook.R:
     library(RPostgreSQL)
     db <- dbConnect(PostgreSQL(), user= "trena", password="trena", dbname="mm10", host="whovian")
     query <- "select count(*) from gtf"
     dbGetQuery(db, query)

     RS-DBI driver: (could not Retrieve the result : ERROR:  permission denied for relation gtf


   --- test from whovian
      library(RPostgreSQL)
      db <- dbConnect(PostgreSQL(), user= "trena", password="trena", dbname="gtf", host="whovian")
      db
      query <- "select count(*) from footprints"
      dbGetQuery(db, query)
      dbListTables(db)  # [1] "hg38human"
      dbGetQuery(db, "select count(*) from hg38human")
      #    count
      # 1 2568100
      colnames(dbGetQuery(db, "select * from hg38human limit 1"))
 [1] "chr"                       "start"
 [3] "endpos"                    "score"
 [5] "strand"                    "frame"
 [7] "moleculetype"              "gene_id"
 [9] "gene_version"              "gene_name"
[11] "gene_source"               "gene_biotype"
[13] "havana_gene"               "havana_gene_version"
[15] "transcript_id"             "transcript_version"
[17] "transcript_name"           "transcript_source"
[19] "transcript_biotype"        "havana_transcript"
[21] "havana_transcript_version" "tag"
[23] "transcript_support_level"  "exon_number"
[25] "exon_id"                   "exon_version"
[27] "ccds_id"                   "protein_id"
[29] "protein_version"           "annotation"

  tbl.mef2c <- dbGetQuery(db, "select * from hg38human where gene_name = 'MEF2C'")
  dim(tbl.mef2c) # [1] 568  30
  head(tbl.mef2c[, c("chr", "start", "endpos", "moleculetype", "gene_biotype")])
      chr    start   endpos moleculetype   gene_biotype
   1 chr5 88717117 88904257         gene protein_coding
   2 chr5 88717117 88883464   transcript protein_coding
   3 chr5 88882955 88883464         exon protein_coding
   4 chr5 88823735 88823930         exon protein_coding
   5 chr5 88823735 88823788          CDS protein_coding
   6 chr5 88823786 88823788  start_codon protein_coding

   as.data.frame(table(tbl.mef2c$moleculetype))
                Var1 Freq
   1             CDS  190
   2            exon  235
   3  five_prime_utr   51
   4            gene    1
   5     start_codon   25
   6      stop_codon   17
   7 three_prime_utr   15
   8      transcript   34



*------------------------------------------------------------------------------------------------------------------------
* mm10 gtf into postgres for dani: create a full 1.6M row, 30 column data.frame (5,6 aug 2016)

  cd ~/s/data/postgres-fill/gtf/mm10
  createStandardTable.R
  mm10.gtf -> /proj/price4/dbergey/postgres_prep/Mus_musculus.GRCm38.85.chr.gtf
     # parsed out all 1,613,247 column nines
  x <- lapply(tbl$col9, function(col9) parseColumnNine(all.keys, col9))
  save(x, file="lapplyParseColumnNine.RData")

  --- this is a list of 1-row data.frames, consolidate, then cbind?
    length(x) # [1] 1613247
    x3 <- x[1:3]
    tbl.x3 <- do.call(rbind, x3)  # seems to work


   tbl.x <- do.call(rbind, x)
   dim(tbl.x) # [1] 1613247      22

   --- from createStandardTable.R
     if(!exists("col9.df.list")){
        load("lapplyParseColumnNine.RData")
        col9.df.list <<- x
        }

     tbl.col9 <<- do.call(rbind, col9.df.list), -9]  # we already have column 9, read & parsed
     tbl <- read.table("mm10.gtf", sep="\t", header=FALSE, nrows=-1, stringsAsFactors=FALSE) [, -9]
     colnames(tbl) <- c("chrom", "annotation",  "moleculeType", "start", "end", "score", "strand", "frame")
     colnames(tbl) <- c("chrom", "annotation",  "moleculeType", "start", "end", "score", "strand", "frame")
     tbl$chrom <- paste("chr", tbl$chrom, sep="")
     stopifnot(nrow(tbl) == nrow(tbl.col9))
      tbl.2 <- cbind(tbl, tbl.col9, stringsAsFactors=FALSE)

     # rectify colnames and column order

     changer <- grep("^end$", colnames(tbl.2))
     if(length(changer) == 1)
        colnames(tbl.2)[changer] <- "endpos"
     tbl.mm10 <<- tbl.2[, standardColnames()]
     save(tbl.mm10, file="tbl.mm10.RData")
     write.table(tbl.mm10, file="mm10-gtf.tsv", sep="\t", quote=FALSE, col.names=FALSE, row.names=FALSE)

*------------------------------------------------------------------------------------------------------------------------
* bullitt foundation grant inquiry questions

  http://www.bullitt.org/wp-content/uploads/2016/04/2.0-Overview-Of-Grant-Inquiry-And-Grant-Proposal-Application.pdf

*------------------------------------------------------------------------------------------------------------------------
* GenomicRanges, granges, findOverlaps (4 aug 2016)

   from ~/github/snpFoot/R/snpFoot.R

   gr.fp <- with(tbl.fpSub, GRanges(seqnames=chr, IRanges(start=mfpStart, end=mfpEnd)))
   gr.snp <- GRanges(seqnames=snp.chromosome, IRanges(start=snp.loc-padding, end=snp.loc+padding))
   tbl.overlaps <- as.data.frame(findOverlaps(gr.fp, gr.snp))
   snp <- rep(-1, length(gr.fp))
   snp[tbl.overlaps$queryHits] <- snp.loc[tbl.overlaps$subjectHits]

   tbl.fpSub$snp <- snp
   result <- subset(tbl.fpSub, snp != -1)
   result[, c("chr", "mfpStart", "mfpEnd", "motifStart", "motifEnd", "sequence", "motifName", "snp", "tfsMatched")]


*------------------------------------------------------------------------------------------------------------------------
* sed tips

  --- replace two tabs with one

    sed -E $'s/\t\t/\t/g' junk   # "ANSI-C" quoting

*------------------------------------------------------------------------------------------------------------------------
* cory's hint example, fimo output from chr22, single HINT bed file ENCSR000DBY (4 aug 2016)  fimo + footprints

  goal: combine fimo output with HINT output, fit it into the evolving ensembl format (developed
        first with piq, see below)

  whovian, cd ~/s/data/postgres-fill/hint/combineWithFimo

  --- email from cory("HINT sample", 4 aug 2016)
   I've put the fimo output from chr22 and a single bed file from hint (ENCSR000DBY) on whovian here:
      /local/Cory/for_Paul/hint_sample/

   The FIMO output is somewhat large but the HINT output is small. Let's discuss what makes the most sense in terms of
   doing the intersect of these file.

   --- first look
      426467056 Aug  4 09:10 22.fimo.txt
       20030824 Jun 21 16:23 ENCSR000DBY.hint.bed

   --- two tabs in the fimo output, due to qScore not being reported
    sed -E $'s/\t\t/\t/g' 22.fimo.txt > chr22.fimo.txt


  ~/s/data/postgres-fill/hint/combineWithFimo/go.R
     runTests <- function()
     explore <- function()   # initial explorations
     combineFootprintsAndFimo <- function(tbl.footprints, tbl.fimoMotifs, chromosome)  # the new workhorse
     test.combineFootprintsAndFimo <- function()  # runs 10 footprints from hint chr22
     run.combineFootprintsAndFimo <- function()   # runs all of hint chr22


*------------------------------------------------------------------------------------------------------------------------
* title ideas for feaven's poster (4 aug 2016)

   Scientific Wellness: do black lives matter?
   Exploratory data analysis, event-driven programming and lasso regression
   applied to health inequities in south Seattle.

  scientific wellness: do black lives matter?
  exploratory data analysis, event-driven programming and lasso regression applied to health inequities in south Seattle


*------------------------------------------------------------------------------------------------------------------------
* fill dani's hint footprints into postgres (3 aug 2016)

  cd ~/s/data/postgres-fill/hint/dani

  gdc <- getDNAClient("mm10")
  tbl <- read.table("sample_ftpts.bed", sep="\t")
  tbl[43,]:  chr1 158464280 158464318  58 MA0597.1 21 29  + 11.44740 7.67e-06   CTGCCCTCA  NA
  getSequenceByLoc(gdc, "chr1", 158464280, 158464318)          "CAACTCCCACCTGCGACTGCCCTCAGACATGGCGATCTG"
                                                                                    |       |
                                                                                    21      29


*------------------------------------------------------------------------------------------------------------------------
* put mm10 gtf into postgres on whovian (3 aug 2016)

  cd ~/s/data/postgres-fill/gtf/mm10
  ln -s /proj/price4/dbergey/postgres_prep/Mus_musculus.GRCm38.85.chr.gtf mm10.gtf
   1,613,252  lines

  tbl <- read.table("mm10.gtf", sep="\t", nrows=5, as.is=TRUE)
  dim(tbl) # [1] 5 9
  --> how to tame column 9?  code included here, not saved in script?

  see below: "* put ensembl gtf file into postgres?  (3 may 2016)"

   cd ~/s/data/public/ensembl/
   tbl <- read.table("Homo_sapiens.GRCh38.84.chr.gtf", sep="\t", nrows=5, as.is=TRUE)  # [1] 5 9
  V1     V2         V3    V4    V5 V6 V7 V8    V9 is a mishmash
1  1 havana       gene 11869 14409  .  +  .
2  1 havana transcript 11869 14409  .  +  .
3  1 havana       exon 11869 12227  .  +  .
4  1 havana       exon 12613 12721  .  +  .
5  1 havana       exon 13221 14409  .  +  .


   --- taming the V9 column
    c9 <- tbl$V9
    length(c9) # [1] 2568100
    c9[1]
    c9.toks <- strsplit(c9, "; ")
    all.toks <- unlist(c9.toks)
    length(all.toks) # [1] 47782409
    head(all.toks)
        [1] "gene_id ENSG00000223972"                         "gene_version 5"
        [3] "gene_name DDX11L1"                               "gene_source havana"
        [5] "gene_biotype transcribed_unprocessed_pseudogene" "havana_gene OTTHUMG00000000961"
    all.tok.toks <- strsplit(all.toks, " ")
    length(all.tok.toks) # [1] 47782409
    c9.titles <- lapply(all.tok.toks, "[", 1)
    length(unique(unlist(c9.titles))) # [1] 22
    unique(unlist(c9.titles))
       [1] "gene_id"                   "gene_version"              "gene_name"                 "gene_source"
       [5] "gene_biotype"              "havana_gene"               "havana_gene_version"       "transcript_id"
       [9] "transcript_version"        "transcript_name"           "transcript_source"         "transcript_biotype"
      [13] "havana_transcript"         "havana_transcript_version" "tag"                       "transcript_support_level"
      [17] "exon_number"               "exon_id"                   "exon_version"              "ccds_id"
      [21] "protein_id"                "protein_version"

    c9.titles.unique <- unique(unlist(c9.titles))
    save(tbl, c9.titles.unique, file="column9.parse.inputs.RData")
    print(load("list.of.parsedColumn9s.RData"))
    print(load("column9.parse.inputs.RData"))
     # [1] "tbl"              "c9.titles.unique"
    dim(tbl); dim(tbl.wide)
      # [1] 2568100       9
      # [1] 2568100      22
   tbl2 <- cbind(tbl, tbl.wide)
   dim(tbl2)  # [1] 2568100      31
   colnames(tbl2)[1:9] <- c ("chr", "annotation", "moleculeType", "start", "end", "score", "strand", "frame", "attribute")
   tbl2$chr <- paste("chr", tbl2$chr, sep="")
   reordered.cols <- c("chr",                      "start",
                       "end",                      "score",                    "strand",                   "frame",
                       "annotation",               "moleculeType",
                       "gene_id",                  "gene_version",             "gene_name",
                       "gene_source",              "gene_biotype",             "havana_gene",               "havana_gene_version",
                       "transcript_id",            "transcript_version",       "transcript_name",           "transcript_source",
                       "transcript_biotype",       "havana_transcript",        "havana_transcript_version", "tag",
                       "transcript_support_level", "exon_number",              "exon_id",                   "exon_version",
                       "ccds_id",                  "protein_id",               "protein_version",           "annotation")

   tbl3 <- tbl2[, reordered.cols]
   dim(tbl3)  # 2568100      31
   save(tbl3, file="tbl.ensembl.gtf.RData")



*------------------------------------------------------------------------------------------------------------------------
* install psycopg on whovian, the most popular python postgres library (2 aug 2016)

   needs to have pg_config to do pip install
   export PATH=/usr/pgsql-9.4/bin:$PATH
   check:
   type pg_config  # pg_config is hashed (/usr/pgsql-9.4/bin/pg_config)
   pip install psycopg2

   --- test, in ipython shell
     from psycopg2 import *
     conn = connect("dbname=pshannon user=pshannon")
     cur = conn.cursor()
     cur.execute("select count(*) from footprints where chrom='chr22'")
     cur.fetchone()  # Out[7]: (1591259,)


  ---- test 2: get the first 4 footprints from chr22, return into pandas DataFrame
     cur.execute("select * from footprints where chrom='chr22' and motifstart < 10510285")
     tbl = DataFrame(cur.fetchall())   # colnames missing

   --- all in one line, colnames preserved
     pd.read_sql_query("select * from footprints where chrom='chr22' and motifstart < 10510285", conn)
     coi = "chrom, motifstart, motifname, normalizedscore, strand"
     query = "select %s  from footprints where chrom='chr22' and motifstart < 10510285" % coi
     tbl = pd.read_sql_query(query,  conn)
         chrom  motifstart motifname  normalizedscore strand
      0  chr22    10510185  MA0151.1         0.811947      +
      1  chr22    10510200  MA0158.1         0.258267      +
      2  chr22    10510282  MA0494.1         0.496226      -
      3  chr22    10510277  MA0740.1         0.349608      -



*------------------------------------------------------------------------------------------------------------------------
* access postgres footprints on whovia from whovian notebook (2 aug 2016)

  version 2.6.2 http://initd.org/psycopg/

*------------------------------------------------------------------------------------------------------------------------
* first footprint notebook on whovian (2 aug 2016)

  cd ~/github/notebooks
  pip install -i https://testpypi.python.org/pypi igv

   --- these failed since i have no access to /usr/local/share
     jupyter nbextension install --py igv
     jupyter nbextension enable --py igv

   --- so tried this
     jupyter nbextension install --prefix ~/jupyter.extensions --py igv
     jupyter nbextension enable --py igv    # - Validating: OK







*------------------------------------------------------------------------------------------------------------------------
* notes on ipywidgets (1 aug 2016)

  https://github.com/ipython/ipywidgets/blob/master/ipywidgets/widgets/widget.py
    Widget class subclasses LoggingConfigurable)
      has these traits:
        _model_module = Unicode('jupyter-js-widgets', help="""A requirejs module name
           in which to find _model_name. If empty, look in the global registry.""").tag(sync=True)
        _model_name = Unicode('WidgetModel', help="""Name of the backbone model
           registered in the front-end to create and sync this widget with.""").tag(sync=True)
        _view_module = Unicode(None, allow_none=True, help="""A requirejs module in which to find _view_name.
           If empty, look in the global registry.""").tag(sync=True)
        _view_name = Unicode(None, allow_none=True, help="""Default view registered in the front-end
           to use to represent the widget.""").tag(sync=True)
        comm = Instance('ipykernel.comm.Comm', allow_none=True)

    has subclass DOMWidget
      https://github.com/ipython/ipywidgets/blob/master/ipywidgets/widgets/domwidget.py
      which has these additional traits:
        _dom_classes
        layout

   import ipywidgets as widgets
   from traitlets import Unicode, CInt
   class HelloWidget(widgets.DOMWidget):
     _view_name = Unicode('HelloView').tag(sync=True)  // widget name
     _view_module = Unicode('hello').tag(sync=True)    // javscript module name, define'd below in a require.js statement

      // define a module called hello, which loads the jupter-js-widgets modules,
      // after which an anonymous function is called with an instance (?) of each required module,
      // as its arg.  this function defines the operation of the new module, returning a few public
      // member functions
      // https://www.sitepoint.com/understanding-requirejs-for-effective-javascript-module-loading/

    define('hello', ["jupyter-js-widgets"], function(widgets) {});

   --- the DOMWidgetView class
     defined  in ./jupyter-js-widgets/src/widget.ts  // a typescript file
     the hello module provides HelloView, a (typescript-mediated?) subclass (extension) of DOMWidgetView

      // The IPython widget framework front end relies heavily on Backbone.js, an MVC
      // (model view controller) framework. Widgets defined in the back end are automatically
      // synchronized with generic Backbone.js models in the front end. The traitlets are added to the
      // front end instance automatically on first state push. The _view_name trait  defined
      // above is used by the widget framework to create the corresponding Backbone.js view and link
      // that view to the model.

      // thus the "HelloView" name in the ctor of HelloWidget allows backbone to
      define('hello', ["jupter-js-widgets"], function(widgets){
        var HelloView = widgets.DOMWidgetView.extend({
            render: function(){
               this.value_changed();
               this.model.on('change:value', this.value_changed, this);
               },
             value_changed: function(){
                   // this.el: the DOM element of this view
                   // DOMWidgetView, frontend, defined in javascript is backbone-associated with
                   // the python HelloWidget (a DOMWidget), which is an MVC model
                this.el.textContent = this.model.get('value');
                },
             });
        return{
           HelloView: HelloView
           };
        })


    --- now the spinner

     note this from pascal bugnion of the ipywidgets repo
        https://github.com/ipython/ipywidgets/issues/695#issuecomment-237461147

     It's fairly common practice to name variables (or object fields) that hold a jQuery element with names starting
     with a $. There is no programmatic meaning to the $ itself in the variable name. It's just convention. See this
     Stack Overflow question, for instance.

     For instance, in a DOMWidgetView, you have access to both this.el, which represents the actual DOM element the
     widget view is attached to, and this.$el, a jQuery element equivalent to $(this.el). Thus, both this:

       this.$el.text('Hi Paul');
       this.el.textContent = 'Hi Paul';

     will have the same behaviour.

     from traitlets import CInt
     class SpinnerWidget(widgets.DOMWidget):
        _view_name = Unicode('SpinnerView').tag(sync=True)
        _view_module = Unicode('spinner').tag(sync=True)
        value = CInt().tag(sync=True)

     %%javascript
     requirejs.undef('spinner');
     define('spinner', ["jupyter-js-widgets"], function(widgets) {
         var SpinnerView = widgets.DOMWidgetView.extend({
            render: function() {
               var that = this;
               this.$input = $('<input />');
               this.$el.append(this.$input);
               this.$spinner = this.$input.spinner({
                    // in these two anonymous functions, "this" is the event, not the SpinnerView, to which "that" is a reference
                  change: function(event, ui) {that.handle_spin(that.$spinner.spinner('value'));},
                  spin: function(event, ui)   {that.handle_spin(ui.value);} //ui.value is the new value of the spinner
                  });
               this.value_changed();
               this.model.on('change:value', this.value_changed, this);
               }, // render
            value_changed: function()      {this.$spinner.spinner('value', this.model.get('value'));},
            handle_spin:   function(value) {this.model.set('value', value); this.touch();},
            });
         return {
             SpinnerView: SpinnerView
         };
     });



*------------------------------------------------------------------------------------------------------------------------
* jason grout and sylvain corlay suggest notebook widgets to learn on (1 aug 2016)

  --- email (27 jul 2016)

   https://github.com/ipython/ipywidgets/blob/master/docs/source/examples/Custom%20Widget%20-%20Hello%20World.ipynb
   https://github.com/ipython/ipywidgets/blob/master/docs/source/examples/Date%20Picker%20Widget.ipynb


  --- made a local copy of the first, to trace, track and debug
    cd ~/s/examples/jupyter/customWidgetFromIpyWidgetsGithub
    cp  ~/github/ipywidgets/docs/source/examples/Custom\ Widget\ -\ Hello\ World.ipynb spinner.ipynb

*------------------------------------------------------------------------------------------------------------------------
* chia, asthma

  http://invw.org/2011/06/13/breathing-uneasy-air-pollution-crisis-in-south-seattle/

*------------------------------------------------------------------------------------------------------------------------
* first piq footprint, by chromosome (1 aug 2016)

> for(chrom in 1:22){
+    query <- sprintf("select * from footprints where chrom='chr%s' order by motifstart limit 2", chrom)
+    print(dbGetQuery(db, query)[, 1:6])
+    }
     chrom motifstart motifend motifname normalizedscore strand
      chr1       9992    10007  MA0074.1        0.195333      -
      chr2      10007    10027  MA0073.1        0.238131      +
      chr3      10163    10177  MA0856.1        0.345638      -
      chr4       9989    10006  MA0112.3        0.183226      -
      chr5       9992    10007  MA0074.1       0.0690715      -
      chr6      60106    60119  MA0135.1        0.384893      +
      chr7      10377    10384  MA0081.1        0.562892      -
      chr8      60001    60009  MA0885.1        0.264427      +
      chr9       9992    10007  MA0074.1        0.199404      -
     chr10      10368    10382  MA0677.1       0.0850056      -
     chr11      60040    60049  MA0122.2       0.0535007      +
     chr12      10185    10205  MA0073.1        0.761399      +
     chr13   15999988 16000005  MA0731.1       0.0277013      -
     chr14   15999988 16000005  MA0731.1       0.0170905      -
     chr15   17000067 17000073  MA0130.1        0.688935      -
     chr16       9992    10007  MA0074.1       0.0992974      -
     chr17      60122    60137  MA0751.1        0.067245      -
     chr18       9992    10005  MA0105.4        0.410439      -
     chr19      60021    60027  MA0056.1        0.642699      -
     chr20      59989    60005  MA0868.1       0.1235490      -
     chr21    5010002  5010008  MA0130.1       0.6677840      +
     chr22   10510185 10510191  MA0151.1        0.811947      +

*------------------------------------------------------------------------------------------------------------------------
* forest seeds (1 aug 2016)

  pacific northwest forest tree seed zones: a template for native plants?
  http://npj.uwpress.org/content/5/2/131.full.pdf+html

*------------------------------------------------------------------------------------------------------------------------
* create index on postgres footprint database on whovian (31 jul 2016)

  cd ~/s/data/postgres-fill/piq/try1
  index.sql:  create index test_index on footprints (chrom, motifStart)
  date; psql -f index.sql; date  #  16:48:43 -> 17:26:33  (38 minutes

   select count(*) from footprints where chrom='chr22' and motifstart <  10586626; # 3475
   before index: 16 seconds
          after: instantly!

  --- something odd about chr22: no footprints in first 10M bases  (cory says this is also true for HINT)

    select count(*) from footprints;   121,422,779
    select count(*) from footprints where chrom='chr22' and motifstart <  1000000;  # 16 seconds, 0 records
    select count(*) from footprints where chrom='chr22' and motifstart <  10 000 000; # 0
    select count(*) from footprints where chrom='chr22' and motifstart <  10586626; # 3475


*------------------------------------------------------------------------------------------------------------------------
* after nearly complete fill of piq data on whovian (29 jul 2016)

  cd ~/s/data/postgres-fill/piq/try1/

    --- 620p Friday (29 jul 2016)
      tail -f ~/s/data/postgres-fill/piq/try1/nohup.out
      look for errors when done, then improve motif.name.map, then rerun those samples


  select count(*) from footprints;  #  118,866,200
  select count(*) from footprints where chrom='chr22';  #  1,566,677

   grep error nohup.out
 [1] error processing /local/Cory/for_Paul/piq_out2/MA00631Nkx25.ENCSR000DBY.bed
 [1] error processing /local/Cory/for_Paul/piq_out2/MA01222NKX32.ENCSR000DBY.bed
 [1] error processing /local/Cory/for_Paul/piq_out2/MA01242Nkx31.ENCSR000DBY.bed
 [1] error processing /local/Cory/for_Paul/piq_out2/MA01491EWSR1FLI1.ENCSR000DBY.bed
 [1] error processing /local/Cory/for_Paul/piq_out2/MA05031Nkx25var2.ENCSR000DBY.bed
 [1] error processing /local/Cory/for_Paul/piq_out2/MA06211mixa.ENCSR000DBY.bed
 [1] error processing /local/Cory/for_Paul/piq_out2/MA06721NKX23.ENCSR000DBY.bed
 [1] error processing /local/Cory/for_Paul/piq_out2/MA06731NKX28.ENCSR000DBY.bed
 [1] error processing /local/Cory/for_Paul/piq_out2/MA06741NKX61.ENCSR000DBY.bed
 [1] error processing /local/Cory/for_Paul/piq_out2/MA06751NKX62.ENCSR000DBY.bed

*------------------------------------------------------------------------------------------------------------------------
* lasso for chia (29 jul 2016)

  cd  ~/github/clevelandHighSchool/datasets/SouthSeattleHealthImpacts/inst/misc/lasso   go.R

*------------------------------------------------------------------------------------------------------------------------
* Medieval Engineering and the Sociology of Knowledge
   mentioned in solomon's "objectivity in the making"

   Lynn White, Jr.
   Pacific Historical Review
   Vol. 44, No. 1 (Feb., 1975), pp. 1-21

*------------------------------------------------------------------------------------------------------------------------
* load piq footprints into psql (29 jul 2016)

   cd ~/s/data/postgres-fill/piq/try1/


   write.table(tbl, file="current.tsv", row.names=FALSE, col.names=FALSE, quote=FALSE, sep="\t", na="NULL")
   \copy footprints from 'current.tsv' delimiter E'\t' CSV NULL as 'NULL';

    bash> psql
    pshannon> select * from footprints limit 3;
              select chrom, motifstart, motifend, footprintstart from footprints limit 3;
              chrom | motifstart | motifend | footprintstart
             -------+------------+----------+----------------
              chr1  |      15050 |    15061 |
              chr1  |      44200 |    44211 |

   --- 620p Friday (29 jul 2016)

     tail -f ~/s/data/postgres-fill/piq/try1/nohup.out
     look for errors when done, then improve motif.name.map, then rerun those samples

*------------------------------------------------------------------------------------------------------------------------
* standardize footprint schema, seccond lookat cory's piq output  (28 jul 2016)

   cd ~/s/data/postgres-fill/piq/try1

   go.R

   --- files from cory
   directory <- "/local/Cory/for_Paul/piq_out2"
   files <- dir(directory, pattern=".*.bed")

   MA00022RUNX1-style names to be replaced by MA00022.01, using
       whovian: /local/Cory/for_Paul/all_motifs.meme

   mapping:

   put all 519 files for ENCSR000DBY from PIQ on whovian here:

  --- proposal

     Cory and I came up with this, for your review.  It is presented here
     in transposed form, since 19 columns are easier to assess when
     transposed into 19 rows.  Some notes on the columns are found below.

     - Paul
                           row 1       row 2       row 3       row 4      row 5
                           =====       =====       =====       =====      =====

     chrom                  chr1        chr1        chr1        chr1        chr1
     motifStart            15050       44200      109353      113212      170671
     motifEnd              15061       44211      109364      113223      170682
     motifName          MA0002.2    MA0002.2    MA0002.2    MA0002.2    MA0002.2
     normalizedScore   0.0000000   0.4233021   0.6320342   1.0000000   0.1071845
     strand                    -           -           -           +           -
     footprintStart         <NA>        <NA>        <NA>        <NA>        <NA>
     footprintEnd           <NA>        <NA>        <NA>        <NA>        <NA>
     motifLength              12          12          12          12          12
     footprintLength        <NA>        <NA>        <NA>        <NA>        <NA>
     sampleID        ENCSR000DBY ENCSR000DBY ENCSR000DBY ENCSR000DBY ENCSR000DBY
     method                  piq         piq         piq         piq         piq
     provenance       minid.XXXX  minid.XXXX  minid.XXXX  minid.XXXX  minid.XXXX
     score1             9.671067   10.098560   10.049386   10.323649    9.437782
     score2           -1.0370301  -0.9215501  -0.8156147  -0.9875232  -0.9419930
     score3          -0.05261156  1.45767722  2.40180208  4.11611185  0.60521606
     score4            0.5007372   0.5125384   0.5299446   0.5083878   0.5040531
     score5                 <NA>        <NA>        <NA>        <NA>        <NA>
     score6                 <NA>        <NA>        <NA>        <NA>        <NA>

     motifStart, motifEnd, footprintStart, footprintEnd: some methods report all 4.  piq reports only the motif

     normalizedScore: a sensible algorithm will be figured out.  In
     this example, I add piq’s four independent scores, then
     normalized the sum.  Silly, but adequate as a placeholder.

     provenance: a BDDS minid, perhaps pointing at an archived docker
     image, with input data and run-time parameters

     score1-6: enough slots to hold any number of scores, each with a
     method-specific meaning.  piq has four scores, the most we have
     yet seen.  A description of what these per-method scores mean
     will need to be maintained separately.

     not present here: mapping of transcription factor gene symbol,
     possibly dimers or …, will be kept in another table.

     The first six columns recapitulate the BED format.

     My next step will be to fill a test database table with
     chromosome 22 data from all three of our current methods.  I hope
     to put them, and an igv.js genome track viewer into a jupyter
     notebook for everyone to examine.



*------------------------------------------------------------------------------------------------------------------------
* jupyter tips: config file customizations (23 sep 2016)

  c.NotebookApp.ip = '*'
  c.NotebookApp.open_browser = True
  c.NotebookApp.port = 9998
  c.NotebookApp.allow_origin = '*'     # allow any origin to access the notebook server

*------------------------------------------------------------------------------------------------------------------------
* recap:  run gemini jupyter notebook on whovian, display on laptop (28 jul 2016)

   cd ~/local/src/    # /local/pshannon/src
   latest anaconda supports "jupyter notebook" command

   type -a jupyter # jupyter is /local/pshannon/anaconda3/bin/jupyter

   3 customizations made in my ~/.jupyter/jupyter_notebook_config.py

   gemini for python 2.7 installed via big script into

    /local/phsannon/src/gemini basics.ipynb

     import sys, os
     sys.path.append("/local/pshannon/gemini/anaconda/lib/python2.7/site-packages")
     from gemini import GeminiQuery
     db = "../gemini/sampleData/learnSQL.db"
     os.path.isfile(db)
     gq = GeminiQuery(db)
     gq.run("select name from samples")
     for row in gq:
       print row

      John
      Bob
      Mary
      Sue

*------------------------------------------------------------------------------------------------------------------------
* install anaconda on whovian (28 jul 2016)

   downloaded to macbook from https://www.continuum.io/downloads
     425991075 Jul 28 12:17 Anaconda3-4.1.1-Linux-x86_64.sh

   scp  Anaconda3-4.1.1-Linux-x86_64.sh pshannon@whovian:/local/pshannon/src
   whovian, cd /local/pshannon/src
   bash Anaconda3-4.1.1-Linux-x86_64.sh

   PATH="/local/pshannon/anaconda3/bin:$PATH"

   --- configure so that it may be reached from macbook
     on whovian:
       jupyter notebook --generate-config
       Writing default config to: /users/pshannon/.jupyter/jupyter_notebook_config.py

   --- relaxed configuration on whovian
     c.NotebookApp.ip = '*'
     c.NotebookApp.open_browser = False
     c.NotebookApp.port = 9999

*------------------------------------------------------------------------------------------------------------------------
* test & learn gemini on whovian (28 jul 2016)

   cd /local/pshannon/gemini-examples/intro/
   on whovian (28 jul 2016): cd /local/pshannon/gemini-examples/intro
   reading:
     https://gist.githubusercontent.com/arq5x/9e1928638397ba45da2e/raw/5dd52cc3b49a80ce7c6daf4ba1d8f82565b0fb97/gemini-intro.sh

   --- get data
     curl https://s3.amazonaws.com/gemini-tutorials/learnSQL.db > learnSQL.db
     curl https://s3.amazonaws.com/gemini-tutorials/learnSQL2.db > learnSQL2.db
     curl https://s3.amazonaws.com/gemini-tutorials/chr22.VEP.vcf > chr22.VEP.vcf
     curl https://s3.amazonaws.com/gemini-tutorials/trio.ped > trio.ped

   --- the result
  2563155 Jul 24 12:29 chr22.VEP.vcf
     2048 Jul 24 12:28 learnSQL.db
     3072 Jul 24 12:29 learnSQL2.db
      154 Jul 24 12:29 trio.ped

   ---- try out command line access
      PATH=/Users/paul/source/gemini/tools/bin:$PATH
      gemini query -q "SELECT name FROM samples" learnSQL.db
        John
        Bob
        Mary
        Sue



*------------------------------------------------------------------------------------------------------------------------
* install gemini on whovian (27 jul 2016)

  ---- now try manual installation, so that separately installed python27 for jupyter can see it

    system default /usr/bin/python is 2.7.5
    cd ~/github/gemini
    /usr/bin/pip install --install-option="--prefix=/users/pshannon/pylibs" SQLAlchemy
    /usr/bin/python setup.py build_ext --inplace

    export PYTHONPATH="/users/pshannon/pylibs/lib64/python2.7/site-packages"
    export PYTHONPATH="/local/pshannon/gemini/anaconda/lib/python2.7/site-packages"


  --- install using
  cd /local/pshannon/gemini
  wget https://raw.github.com/arq5x/gemini/master/gemini/scripts/gemini_install.py
  nohup python gemini_install.py /local/pshannon /local/pshannon/gemini

   ...
   Finished: gemini, tools and data installed
    Tools installed in:
     /local/pshannon
      NOTE: be sure to add /local/pshannon/bin to your PATH.
   Data installed in:
       /local/pshannon/gemini
    NOTE: Install data files for GERP_bp & CADD_scores (not installed by default).

   /local/pshannon/bin:
     lrwxrwxrwx. 1 pshannon pricelab   29 Jul 27 17:02 gemini -> ../gemini/anaconda/bin/gemini
     lrwxrwxrwx. 1 pshannon pricelab   28 Jul 27 17:02 gemini_conda -> ../gemini/anaconda/bin/conda
     lrwxrwxrwx. 1 pshannon pricelab   26 Jul 27 17:02 gemini_pip -> ../gemini/anaconda/bin/pip
     lrwxrwxrwx. 1 pshannon pricelab   29 Jul 27 17:02 gemini_python -> ../gemini/anaconda/bin/python
     lrwxrwxrwx. 1 pshannon pricelab   29 Jul 27 17:02 grabix -> ../gemini/anaconda/bin/grabix


*------------------------------------------------------------------------------------------------------------------------
* ipythoin tips

  ~/anaconda/bin/ipython  (29 jul 2016) version 4.1.2, runs on top of pythoin 3.5.1

*------------------------------------------------------------------------------------------------------------------------
* igv.js for jupyter (27 jul 2016)

  pip install -i https://testpypi.python.org/pypi igv    # failed likely due to confused 2.7/3.5 pythons & pips

   so thorin proposes this:
      conda install -c igv igv

  jupyter nbextension install --py igv
  jupyter nbextension enable --py igv

  also: git clone https://github.com/igvteam/igv.js-jupyter

  pip install igv
  jupyter nbextension install --py --user igv     # in user directory, not /usr/local/...
  jupyter nbextension enable igv   --user --py


*------------------------------------------------------------------------------------------------------------------------
* python tips execfile

   python 2: execfile("./filename")
   python 3: exec(open("./filename").read())

*------------------------------------------------------------------------------------------------------------------------
* python tips: traitlets

  https://traitlets.readthedocs.io/en/stable/

  attach attributes to python classes, with
     type checking
     dynamically calculated default values
     "on change" callbacks

   https://github.com/ipython/ipywidgets/blob/master/ipywidgets/widgets/widget.py#L118

   shows

      class Widget(LoggingConfigurable)


   --- used in threejs notebook examples
     ball = Mesh(geometry=SphereGeometry(radius=1), material=LambertMaterial(color='red'), position=[2,1,0])


  in pythreejs.py

    class Mesh(Object3d):

      _view_name = Unicode('MeshView').tag(sync=True)
      _model_name = Unicode('MeshModel').tag(sync=True)
      geometry = Instance(Geometry).tag(sync=True, **widget_serialization)
      material = Instance(Material).tag(sync=True, **widget_serialization)

    Extra metadata can be associated with the traitlet using the .tag() convenience method
    or by using the traitlet instance's .metadata dictionary.


*------------------------------------------------------------------------------------------------------------------------
* pythreejs, install, study, extend? (26 jul 2016)

  git clone https://github.com/jovyan/pythreejs.git
  cd pythreejs/
  pip install -e .
  jupyter nbextension install --py --symlink --user pythreejs
  jupyter nbextension enable --py --user pythreejs
  cd examples
  jupyter notebook

*------------------------------------------------------------------------------------------------------------------------
* R tips: tryCatch, to display error without stopping

   for (i in 1:5) tryCatch(read.table("xasdf"), error=function(e) print(e))

*------------------------------------------------------------------------------------------------------------------------
* install R 3.3.1 on whovian (25 jul 2016)

  cd ~/src
  curl -O https://cran.r-project.org/src/base/R-3/R-3.3.1.tar.gz
  tar zxf R-3.3.1.tar.gz
  cd R-3.3.1

   ./configure --prefix=/users/pshannon/localInstall/ --with-readline=no --with-x=no
  failed with incorrect JAVA_HOME


*------------------------------------------------------------------------------------------------------------------------
* build emacs from source on whovian (25 jul 2016)

  cd ~/src
  curl -O ftp://ftp.gnu.org/pub/gnu/emacs/emacs-24.5.tar.gz   # 59,216,034

   cd /users/pshannon/src/emacs-24.5
   mkdir ~/localInstall
   ./configure --prefix=/users/pshannon/localInstall/ --with-x-toolkit=no --with-xpm=no --with-jpeg=no --with-gif=no --with-tiff=no
   make
   make install


*------------------------------------------------------------------------------------------------------------------------
* start looking at cory's piq output, in preparation for a big single-schema footprint postgres database (25 jul 2016)

   cd ~/s/data/postgres-fill/piq/

   put all 519 files for ENCSR000DBY from PIQ on whovian here:

   whotivan:/local/Cory/for_Paul/piq_out

   They are still downloading, so give them at least 10 minutes.  I
   need to get you samples for HINT and Wellington, but they should
   actually be the same that you have, just an individual file name
   (i.e. ENCSR000DBY.bam) for each one.

   cd /~s/data/postgres-fill/piq
   ls -1 /local/Cory/for_Paul/piq_out/ | wc -l  # 162

   cd ~/s/data/postgres-fill/piq/try0
   cp /local/Cory/for_Paul/piq_out/MA04961MAFK.ENCSR000DBY.bed .
   wc -l MA04961MAFK.ENCSR000DBY.bed  # 86205

   gibberish starting at line 38340


*------------------------------------------------------------------------------------------------------------------------
* python tip: list imported modules

  import sys;
  sys.modules.keys()

*------------------------------------------------------------------------------------------------------------------------
* python tip, jupyter tip, notebook tip: are jupyter widgets installed? (24 jul 2016)

   import ipywidgets as widgets
   widgets.Widget.widget_types.values()

*------------------------------------------------------------------------------------------------------------------------




* python tip: list imported modules

  import sys;
  sys.modules.keys()

*------------------------------------------------------------------------------------------------------------------------
* python tip, jupyter tip, notebook tip: which jupyter widgets are installed? (24 jul 2016)

   import ipywidgets as widgets
   widgets.Widget.widget_types.values()

*------------------------------------------------------------------------------------------------------------------------
* python tip, setup.py, packaging, wheels & etc

   https://hynek.me/articles/sharing-your-labor-of-love-pypi-quick-and-dirty/

   "every project that you want to package needs a setup.py file that is executed whenever you build a distribution
    and – unless you install a wheel – on each installation."

*------------------------------------------------------------------------------------------------------------------------
* futher anatomy of ipywidgetexample: distributed files and directories, nothing built or setup (26 jul 2016)

  cd ~/s/examples/jupyter/jupyter-widget-example-asDownloaded;  ls -lR

      53 MANIFEST.in  (specifies dynamically-created MANIFEST)
     617 README.md
     475 RELEASE.md
      26 setup.cfg    ([bdist_wheel]; universal=1   # a universal wheel, good for py 2 and 3
    5543 setup.py     # includes boilerplate, setup_args (name, version, data_files, ipywidgets version required

       D ipywidgetexampleUnbuilt/
           280  __init__.py
            79  _version.py
           438  example.py         # defines class HelloWorld(widgets.DOMWidget)
       D js/
           168  README.md           # explains node is prereq, and npm install --save jupyter-widget-example
           650  package.json        # node modules to install, "main" is src/index.js
          2295  webpack.config.js   # module.exports, and array, each with entry field: src/extension.js, index.js, embed.js
             D  src/
                 453  embed.js      # entry point for the npmcdn bundle
                1139  example.js    # 39 lines: HelloModel, HelloView, each a derived class
                 627  extension.js
                 589  index.js      # few lines, Entry point for the notebook bundle containing custom model definitions.
                                    # points to example.js



*------------------------------------------------------------------------------------------------------------------------
* python tips, setup and install

  ---  MANIFEST.in
     creates a MANIFEST, the exact list of files to include in your distribution.
     the sdist command processes this template, generates a manifest based on
     its instructions and what it finds in the filesystem. sdist -> "source distribution"

  from ~/~/s/examples/jupyter/jupyter-widget-example-asDownloaded/MANIFEST.in
     recursive-include ipywidgetexample/static *.*
     somehow js/src/extenions.js and index.js end up in ipywidgetexample/static/
     some separate step must do that
     then from ipywidgetexample/static/ they end up in the egg? installed?


  from ~/github/bqplot/MANIFEST.in
        recursive-include bqplot/static *.*
        include bqplot/map_data/*.json

*------------------------------------------------------------------------------------------------------------------------
* futher anatomy of ipywidgetexample (26 jul 2016)

  cd ~/s/examples/jupyter/jupyter-widget-example/
  bumped minor version number in ipy7widgetexaple/_version.py
  pip -v install -e .

*------------------------------------------------------------------------------------------------------------------------
* bqplot: another example of ipywidgets, allegedly with the same structure as hello world (25 jul 2016)

  git clone https://github.com/bloomberg/bqplot.git
  cd bqplot
  pip install -e .
  jupyter nbextension install --py --symlink --user bqplot
  jupyter nbextension enable --py --user bqplot

   find . -name "*.ipynb"
     ./examples/Advanced Plotting/Advanced Plotting.ipynb
     ./examples/Advanced Plotting/Animations.ipynb
     ./examples/Advanced Plotting/Axis Properties.ipynb
     ./examples/Advanced Plotting/Plotting Dates.ipynb
     ./examples/Applications/Wealth of Nations.ipynb
     ./examples/Basic Plotting/Basic Plotting.ipynb
     ./examples/Basic Plotting/Pyplot.ipynb
     ./examples/Index.ipynb
     ./examples/Interactions/Interaction Layer.ipynb
     ./examples/Interactions/Mark Interactions.ipynb
     ./examples/Marks/Bars.ipynb
     ./examples/Marks/Boxplot.ipynb
     ./examples/Marks/Candles.ipynb
     ./examples/Marks/FlexLine.ipynb
     ./examples/Marks/GridHeatMap.ipynb
     ./examples/Marks/Hist.ipynb
     ./examples/Marks/Label.ipynb
     ./examples/Marks/Lines.ipynb
     ./examples/Marks/Map.ipynb
     ./examples/Marks/Market Map.ipynb
     ./examples/Marks/Pie.ipynb
     ./examples/Marks/Scatter.ipynb

   cd ~/github/bqplot/examples
   jupyter notebook

    --- which files change with build & install?
      cd ~/github/bqplot/
      touch timestamp
      pip install -e .
      find . -newer timestamp
          ./bqplot/static/extension.js
          ./bqplot/static/index.js
          ./bqplot/static/index.js.map
          ./bqplot.egg-info/dependency_links.txt
          ./bqplot.egg-info/PKG-INFO
          ./bqplot.egg-info/requires.txt
          ./bqplot.egg-info/SOURCES.txt
          ./bqplot.egg-info/top_level.txt
          ./js/dist/index.js
          ./js/dist/index.js.map
          ./js/node_modules

*------------------------------------------------------------------------------------------------------------------------
* jupyter-widget, ipywidgets:  directory structure

   ---- bgplot ~/s/github/bgplot

      bgplot/  [some interesting files and subdirectories]
         __init__.py: defines the bgplot module
         __pycache__/: directory of compiled (.pyc) files
         _version.py:  defines __version__ as '0.7.1'
         axes.py" defines module bgplot.axes
         interacts.py: module bqplot.interacts, class Interaction(Widget): a mouse interaction layer
         map_data/: EuropeMapData.json, USMapData.json, WorldMapData.json
         static/:   built up by webpack?
            extension.js: seems to be instructions for require to load nbextensions
            index.js:  lots of functions for style, d3, __webpack_require__(i) function calls
            index.js.map: not sure
         toolbar.py: panzoom, save, reset, ...

       js/   [node related only?]
         package.json:
            devDependencies
            dependencies (bootstrap, d3, jquery, jupyter-js-widgets, topojson, underscore)
         dist/ index.js, index.js.map
         src/  > 70 javascript file
         webpack.config.js: how to build bqplot bundle for notetook and for an embeddable (?) bqplot

       setup.py: run by pip?


  ---- ipywidgetexample  ~/s/examples/jupyter/jupyter-widget-example

     ipywidgetexample/
        __init__.py
        __pycahce__:
        _versio.py
        example.py: imports modules it needs (ipywidgets, traitles), registers('hello.Hello'),
                      defines class HelloWorld(widgets.DOMWidget)
        static/: built up by webpack?
            extension.js: seems to be instructions for require to load nbextensions
            index.js:  lots of functions for style, d3, __webpack_require__(i) function calls
            index.js.map: not sure

     build/lib/ipywidgetexample:
          __init__.py
          _version.py
          example.py
          static
            extension.js
            index.js
            index.js.map


*------------------------------------------------------------------------------------------------------------------------
* jupyter-widget-example (24 jul 2016)

   --- code and README's

   http://ipywidgets.readthedocs.io/en/latest/examples/Widget%20Low%20Level.html
   http://ipywidgets.readthedocs.io/en/latest/examples/Custom%20Widget%20-%20Hello%20World.html
   https://github.com/ipython/ipywidgets
   https://github.com/jupyter/widget-cookiecutter

   pip install cookiecutter
   cd ~/s/examples/jupyter
   cookiecutter https://github.com/jupyter/widget-cookiecutter.git
   cd ~/s/examples/jupyter/jupyter-widget-example/
   pip install -e .
   jupyter nbextension install --py --symlink --user ipywidgetexample
   jupyter nbextension enable --py --user ipywidgetexample
   jupyter notebook

   within notebook:
      from ipywidgetexample import *
      HelloWorld()   # displays simple text "Hello World!" in the "widget space" below the input cell

   --- now change the message, the simplest possible modification
     ~/s/examples/jupyter/jupyter-widget-example/ipywidgetexample/example.py
      now reads

@widgets.register('hello.Hello')
class HelloWorld(widgets.DOMWidget):
    """"""
    _view_name = Unicode('HelloView').tag(sync=True)
    _model_name = Unicode('HelloModel').tag(sync=True)
    _view_module = Unicode('jupyter-widget-example').tag(sync=True)
    _model_module = Unicode('jupyter-widget-example').tag(sync=True)
    value = Unicode('Hello Universe!').tag(sync=True)

   --- rebuild

    pip install -e .
    jupyter nbextension install --py --symlink --user ipywidgetexample
    jupyter nbextension enable --py --user ipywidgetexample
    jupyter notebook


   --- run
     cd ~/s/examples/jupyter/jupyter-widget-example/
     jupyter notebook
     load and run helloWorld.ipynb

*------------------------------------------------------------------------------------------------------------------------
* macos wget

    brew install wget --with-libressl
*------------------------------------------------------------------------------------------------------------------------
* gemini tutorial (24 jul 2016)

   cd ~/s/examples/gemini/intro/
   on whovian (28 jul 2016): cd /local/pshannon/gemini-examples/intro
   reading:
     https://gist.githubusercontent.com/arq5x/9e1928638397ba45da2e/raw/5dd52cc3b49a80ce7c6daf4ba1d8f82565b0fb97/gemini-intro.sh

   --- get data
     curl https://s3.amazonaws.com/gemini-tutorials/learnSQL.db > learnSQL.db
     curl https://s3.amazonaws.com/gemini-tutorials/learnSQL2.db > learnSQL2.db
     curl https://s3.amazonaws.com/gemini-tutorials/chr22.VEP.vcf > chr22.VEP.vcf
     curl https://s3.amazonaws.com/gemini-tutorials/trio.ped > trio.ped

   --- the result
  2563155 Jul 24 12:29 chr22.VEP.vcf
     2048 Jul 24 12:28 learnSQL.db
     3072 Jul 24 12:29 learnSQL2.db
      154 Jul 24 12:29 trio.ped

   ---- try out command line access
      PATH=/Users/paul/source/gemini/tools/bin:$PATH
      gemini query -q "SELECT name FROM samples" learnSQL.db
      KeyError: 'variants'

   --- debug using RSQLite
    library(RSQLite)
     db <- dbConnect(dbDriver("SQLite"), "learnSQL.db")
     dbListTables(db) # [1] "samples"
     dbGetQuery(db, "select * from samples limit 1")
       sample_id name family_id paternal_id maternal_id sex phenotype ethnicity
     1         1 John         1         Bob         Sue   1         2       CEU


*------------------------------------------------------------------------------------------------------------------------
* install gemini (23 jul 2016)

  cd ~/source/gemini
  curl -O https://raw.githubusercontent.com/arq5x/gemini/master/gemini/scripts/gemini_install.py
  needs python 2.7
  needs wget (see above)

  /usr/bin/python gemini_install.py tools data/

  --- Gemini data files updated
     Finished: gemini, tools and data installed
     Tools installed in:
      /Users/paul/source/gemini/tools
     NOTE: be sure to add /Users/paul/source/gemini/tools/bin to your PATH.
     Data installed in:
      /Users/paul/source/gemini/data
     NOTE: Install data files for GERP_bp & CADD_scores (not installed by default).

     Run tests with:
      cd /Users/paul/source/gemini/data/github_gemini && bash master-test.sh

   error:  github_gemini directory does not exist

   --- solution
      git clone https://github.com/arq5x/gemini.git
         /Users/paul/github/gemini/master-test.sh       2320 Jul 24 12:06

    PATH=/Users/paul/source/gemini/tools/bin:$PATH
    PATH=/Users/paul/source/gemini/data/anaconda/bin:$PATH

  --- a few more data files
    CADD scores are not being loaded because the annotation file could not be found.
       gemini update --dataonly --extra cadd_score    # 13 hours predicted!
    GERP per bp is not being loaded because the annotation file could not be found.
       gemini update --dataonly --extra gerp_bp      #  3 hours predicted

   --- run master tests
      cd ~/github/geminia
      bash master-test.sh


  --- gemini gists
     https://gist.github.com/arq5x

  --- gemini-intro.sh, a gist

   https://gist.githubusercontent.com/arq5x/9e1928638397ba45da2e/raw/5dd52cc3b49a80ce7c6daf4ba1d8f82565b0fb97/gemini-intro.sh

*------------------------------------------------------------------------------------------------------------------------
* cyjs in a notebook (22 jul 2016)



  --- reproduce
   cd  ~/http/js/
   python -m http.server 9999    # serves up local copy of cytoscape-2.7.6.js

   cd ~/s/examples/jupyter/cyjs/firstTry
   jupyter notebook              # serves up cyjs.ipynb



  -- email to max franz

have narrowed down the problem a bit.  I’ll be grateful for any insight you can offer.

It seems to be some sort of an interaction between the libraries loaded by the default & empty notebook, and (I am guessing) some feature of the cytoscape.js file.

urlA = “http://localhost:9999/dummy.js"
urlB = "http://localhost:9999/cytoscape-2.7.6.js"
var script = document.createElement( 'script' );
script.src = urlA or urlB
document.head.appendChild( script );

1) if Jupyter has NOT been loaded, then I can execute the above 5 lines (urlA or urlB) and cytoscape() is defined
2) if Jupyter has been loaded, and I execute the lines in the js console, urlA results in a defined “dummy()” function, but urlB leads to “cytoscape()” producing a ReferenceError, cytoscape is not defined.
3) with Jupyter loaded, igv.js evaluates fine.  It is quite straightforward in javascript style.  Maybe it lacks some features you have used for cytoscape.js, which clash with standard included libraries for Jupyter?

That's my best guess: that somehow even the empty jupyter notebook loads libraries which somehow clash with cytoscape.js


My jupyter version:

jupyter notebook --version    # 4.2.1


*------------------------------------------------------------------------------------------------------------------------
* igv.js in a notebook

   cd ~/s/examples/jupyter/igv/preview/

*------------------------------------------------------------------------------------------------------------------------
* prepare for jupyterlab

  [status: not ready yet for real exploration]
  jupyter --version # 4.1.0
  jupyter notebook --version 4.1.0
  conda update notebook
     notebook: 4.1.0-py35_2 --> 4.2.1-py35_0
  jupyter notebook --version # 4.2.1

  pip install jupyterlab   # Successfully installed jupyterlab-0.1.1
  book.notebook> jupyter serverextension enable --py jupyterlab
Enabling: jupyterlab
- Writing config: /Users/paul/.jupyter
    - Validating...
      jupyterlab  OK

  cd ~/github/jupyterlab/
  jupyter lab
  note ready...


* draft #2 email to jerry large (21 jul 2016)
*------------------------------------------------------------------------------------------------------------------------
* draft #3 email to jerry large (2 jul 2016), with hsiao-ching's suggestions
Dear Mr. Large,

I was moved by  your column yesterday in the Seattle Times, "Police conflicts are a symptom of a
larger, often unacknowledged disease" and by this statement in particular: "Racism kills, poverty
kills, and the two together are especially deadly."

You may be interested in a collaboration to address aspects of this problem, between Cleveland High
School and the Institute for Systems Biology. (ISB is a nonprofit biomedical research institute
located around the corner from the Seattle Times on Terry Avenue.)

In this collaboration Cleveland students will analyze environmental, health and socioeconomic data
for ten Seattle zip codes using visualization and analytical software developed at the ISB.  The
data are from a 2013 EPA-funded study by Linn Gould et al. Linn provides ongoing guidance to the
project.  Cleveland teachers suggested this project, and shaped its design.

The software is an interactive data exploration webapp, available here:

 http://clevelandehc.systemsbiology.net

Two especially damning examples are easily seen:

 Poverty strongly predicts child hospitalization rates for asthma.
 Race correlates loosely with life expectancy, producing life spans 10 years shorter for some.

Another aspect of our community involvement is the participation (as a software developer) by an ISB
summer intern, a young Eirtrean woman, a Rainier Scholar, who now attends SMU, and who grew up in
one of the most affected neighborhoods covered in the study.

At the ISB we often use statistics and computer visualzation to discover patterns in complex
systems.  We are excited to apply these techniques outside of molecular biomedicine -
our usual concern - in order to address historically intractable inequities and injustices in our community.

We predict that Cleveland students this year will benefit not only by learning these new analytical
techniques, but also by becoming informed citizens who, with a newly enriched grasp of the
sometimes inequitable circumstances in which we live, may find the means to improve them.

I come to this work inspired by several experiences from my own (white, and fairly privileged) life:

  - I dropped out of college in order to feel more useful, taking up carpentry, learning
    the trade from a distinguished elder, a man whose grandparents had been slaves

  - Over the past two summers, while working in computational biology at the Fred Hutch,
    I mentored two summer students, both of them Caucuasian sons of UW brain surgeions.
    Good, smart kids, but their prospects in life were quite good with or without our
    work together.

  - I have lived in South Seattle, and daily observe the structural inequalities that
    reach back into our national history, and hope that we can together ameliorate
    them, and soon!

*------------------------------------------------------------------------------------------------------------------------
* linn's 2013 seattle times story.

  http://www.seattletimes.com/seattle-news/study-finds-life-is-shorter-for-some-in-the-98108-zip-code/  mapes, gould

*------------------------------------------------------------------------------------------------------------------------
* draft #2 email to jerry large (21 jul 2016)

Dear Mr. Large,

I was moved when I read your column today in the Seattle Times, "Police conflicts are a symptom of a
larger, often unacknowledged disease" and by this statement in particular: "Racism kills, poverty
kills, and the two together are especially deadly."

You may be interested in a collaboration to address aspects of this problem, between Cleveland High
School and the Institute for Systems Biology.

In this collaboration Cleveland students will analyze environmental, health and socioeconomic data for
ten Seattle zip codes using visualization and analytical software developed at the ISB.  The data
are from a 2013 EPA-funded study by Linn Gould et al. Linn provides ongoing guidance to the project.
Cleveland teachers suggested this project, and shaped its design.

The software is an interactive data exploration webapp, available here:

 http://clevelandehc.systemsbiology.net

Two especially damning examples are easily seen:

 Poverty strongly predicts child hospitalization rates for asthma.
 Race correlates loosely with life expectancy, producing life spans 10 years shorter for some.

Another aspect of our community involvement is the participation (as a software developer) by an ISB
summer intern, a young woman, a Rainier Scholar, who now attends SMU, and who grew up in one of
the most affected neighborhoods covered in the study.

At the ISB we often use statistics and computer visualzation to discover patterns in complex
systems.  We are excited to apply these techniques outside of molecular biomedicine -
our usual concern - in order to address historically intractable inequities and injustices in our community.

We predict that Cleveland students this year will benefit not only by learning these new analytical
techniques, but also by becoming informed citizens who, with a newly enriched grasp of the
sometimes inequitable circumstances in which we live, may find the means to improve them.

*------------------------------------------------------------------------------------------------------------------------
* draft email to jerry large (21 jul 2016)

Dear Mr. Large,

I was moved when I read your column today in the Seattle Times, "Police conflicts are a symptom of a
larger, often unacknowledged disease" and by this statement in particular: "Racism kills, poverty
kills, and the two together are especially deadly."

You may be interested in a collaboration to address aspects of this problem, between Cleveland High
School and the Institute for Systems Biology.

In this collaboration Cleveland students will analyze environmental, health and socioeconomic data for
ten Seattle zip codes using visualization and analytical software developed at the ISB.  The data
are from a 2013 EPA-funded study by Linn Gould et al. Linn provides ongoing guidance to the project.

The software, an interactive data exploration webapp,  is available here:

  http://clevelandehc.systemsbiology.net

Two especially damning examples are easily seen:

  Poverty predicts child hospitalization rates for asthma.
  Race correlates loosely with life expectancy, producing life spans 10 years shorter for some.

Another aspect of our community involvement is the participation (as a software developer) by an ISB
summer intern, a young woman, a Rainier Scholar now attending SMU who grew up in one of
the most affected neighborhoods found in the study.

At the ISB we often use computation and computer visualzation to discover patterns in complex
systems.  We are excited to apply these sophisticated techniques outside of molecular biomedicine,
our usual concern, to address historically intractable inequities and injustice in our community.
We predict that Cleveland students this year will benefit not only by learning these new analytical
techniques, but also by becoming informed citizens -- citizens with a newly enriched grasp of the
sometimes inequitable, and sometimes improvable circumstances in which we live.


*------------------------------------------------------------------------------------------------------------------------
* simple 3-node, no edge graph, json (21 jul 2016)

   g = [{"data": {"id":"A"}}, {"data":{"id":"B"}}, {"data":{"id":"C"}}];
     // surrounding quotes must be single, internal must be double
   gString = '[{"data": {"id": "x"}}, {"data":{"id": "y"}}, {"data":{"id": "z"}}]';
   cy.load(JSON.parse(gString))
   cy.load(g)
   cy.layout({"name": "grid"})
   g2 =  [{"data": {"id": "x"}}, {"data":{"id": "y"}}, {"data":{"id": "z"}}]
   style2 = [{selector: 'node', style: {content: 'data(id)', 'text-halign': 'center', 'text-valign': 'center', 'background-color': 'white', 'border-color':'red', 'border-width': "1px"}}]
   cy.style(style2)

*------------------------------------------------------------------------------------------------------------------------
* create readable json from RCy graph (20 jul 2016)

this can then be used in cyjs jupyter widget

library(RCyjs)
library(RUnit)

g <- simpleDemoGraph()
rcy <- RCyjs(9000:9010, graph=g)
s <- getJSON(rcy)
s2 <- gsub("\\\"", "'",  s)
s3 <- gsub("},", "},\n", s2)
s4 <- gsub("'", "\"", s3)
s5 <- paste("network = ", s4, sep="")
write(s5, file="s5.json")

# test it out
s6 <- fromJSON("s5.json")
checkTrue(is.list(s5))
checkTrue(length(s5) >= 12)


   --- now start a py3 kernel
from py2cytoscape import cytoscapejs as cyjs
import json
file = "s4.json"
file = "maripaludis.json"
g = json.load(open(file))
g
cyjs.render(g)

*------------------------------------------------------------------------------------------------------------------------
* explore cy/jupyter (20 jul 2016)

  cd ~/github/py2cytoscape/examples/
  jupyter-notebook

*------------------------------------------------------------------------------------------------------------------------
* chrome cors, open from command line without security (20 jul 2016)

  chrom version 51

   open /Applications/Google\ Chrome.app --args --disable-web-security --user-data-dir -–allow-file-access-from-files
*------------------------------------------------------------------------------------------------------------------------
* figure out igv.js/chinook difficulty, with igv minimal (20 jul 2016)

  cd ~/s/examples/igv/igv.js/minimal
  drawing from slightly more complex ~/s/work/priceLab/lizBlue/try1/index.html and bed files


*------------------------------------------------------------------------------------------------------------------------
* adx chinook app (19 jul 2016)

  got working igv.js code from cd ~/s/work/priceLab/lizBlue/try1/index.html
  cd ~/github/adx/chinook/webapplets/igv

   for now, serve bed files from lizBlue
   cd  ~/s/work/priceLab/lizBlue/try1/
   python -m http.server 8005

*------------------------------------------------------------------------------------------------------------------------
* chinook demoTab, demo tab, template (18 jul 2016)

   a good place to start in crafting a new tab

   cd ~/github/Chinook/ChinookServer/inst/scripts/demoTab

   just two messages registered, first calls second, dataset item names displayed in the demo tab:

        hub.addMessageHandler("datasetSpecified", datasetSpecified);
        hub.addMessageHandler("demoDisplayDatasetItemNames", displayDatasetItemNames);



*------------------------------------------------------------------------------------------------------------------------
* d3 heatmap: clustergrammer (15 jul 2016)

  https://github.com/MaayanLab/clustergrammer
  looks promising.

 --- using python 2.7.10
sudo /usr/bin/python -m pip install pandas
/usr/bin/python
from clustergrammer import Network
net = Network()
net.load_file('txt/rc_two_cats.txt')
net.make_clust(dist_type='cos',views=['N_row_sum', 'N_row_var'])
net.write_json_to_file('viz', 'json/rc_two_cats.json', 'no-indent')


--- load webapp

cd ~/github/clustergrammer/
add this line to load_clustergram.js:

   make_clust('rc_two_cats.json')

python -m http.server 10001


   --- now try this with allFactors.tsv

     /Users/paul/github/clevelandHighSchool/datasets/SouthSeattleHealthImpacts/inst/extdata/allFactors.tsv

/usr/bin/python
from clustergrammer import Network
net = Network()
filename = '/Users/paul/github/clevelandHighSchool/datasets/SouthSeattleHealthImpacts/inst/extdata/allFactorsNormalized.tsv'
net.load_file(filename)
net.make_clust(dist_type='cos',views=['N_row_sum', 'N_row_var'])
net.write_json_to_file('viz', 'json/allFactorsNormalized.json', 'no-indent')



   --- matrix upload: try it out here
     http://amp.pharm.mssm.edu/clustergrammer/

   --- build json from matrix using python  3.5.1 [abandoned]
     cd ~/github/clustergrammer/    # has python package in clustergrammer/clustergrammer
     changed all import statements, except numpy, to (eg), from
           import initialize_net
       to
           from . import initialize_net

      in load_data.py, changed "import StringIO" to "from io import StringIO"

     python 3.5.1
from clustergrammer import *
net = Network()
net.load_file('txt/rc_two_cats.txt')
net.make_clust(dist_type='cos',views=['N_row_sum', 'N_row_var'])
net.write_json_to_file('viz', 'json/mult_view.json', 'no-indent')

*------------------------------------------------------------------------------------------------------------------------
* heatmap demo for feaven, mtcars and cleveland data (14 jul 2016)

  ~/github/clevelandHighSchool/misc/exampleCode/heatmap.R

*------------------------------------------------------------------------------------------------------------------------
* eduardo viverios de castro, who is afraid of the ontological wolf? (15 jul 2016)

  https://sisu.ut.ee/sites/default/files/biosemio/files/cusas_strathern_lecture_2014.pdf
  saved into ~/Documents

*------------------------------------------------------------------------------------------------------------------------
* snp and pedigree viz for liz blue, igv.js, rcyjs, demo (14 jul 2016)

  added library(SNPlocs.Hsapiens.dbSNP144.GRCh37) in order to get better names for bed file and igv


*------------------------------------------------------------------------------------------------------------------------
* snploc tips, rsid, dbSNP from R (14 jul 2016)

  library(SNPlocs.Hsapiens.dbSNP144.GRCh37)
  snps <- SNPlocs.Hsapiens.dbSNP144.GRCh37

   # have this snploc form liz blue: "22:37771985_A/G"
  snpsByOverlaps(snps, "ch22:37771980-37771990")

  as.data.frame(snpsByOverlaps(snps, "ch22:37771980-37771990"))
     seqnames      pos strand RefSNP_id alleles_as_ambig   # IUPAC nucleotide ambiguity code
   1     ch22 37771985      + rs4821653                R


*------------------------------------------------------------------------------------------------------------------------
* javascript heatmap, looks very promising (14 jul 2016)

  http://openscreen.cz/software/inchlib/home/

  --- get code
    cd ~/github
    git clone https://github.com/skutac/InCHlib.js.git

  --- first look: reproduce example from http://openscreen.cz/software/inchlib/examples/18
    cd ~/s/examples/js/heatmaps/inchlib/webDemo

  --- install the clustering software,     instructions and docs: http://openscreen.cz/software/inchlib/inchlib_clust
    cd ~/s/examples/js/heatmaps/inchlib/webDemo/cluster
    unzip /Users/paul/Downloads/inchlib_clust-0.1.4.zip
    cd inchlib_clust-0.1.4
    python inchlib_clust.py # to debug with python3
      edited 3 exception handling statements:
           #except Exception, e:
           except Exception:
      replaced urllib2 with urllib
      pip install fastcluster

   python setup.py install

   cd ~/s/examples/js/heatmaps/inchlib/webDemo
   run make:
       python ./cluster/inchlib_clust-0.1.4/build/lib/inchlib_clust.py \
          example_data.csv -m example_metadata.csv -cm example_column_metadata.csv -dh -mh -cmh -o example.json



*------------------------------------------------------------------------------------------------------------------------
* igv.js tips

   --- good overview of api
     https://github.com/igvteam/igv.js/wiki/Browser

*------------------------------------------------------------------------------------------------------------------------
* parallel, mclapply, Rscript, passing command line args (12 jul 2016)

   --- see full workup, starting with Hadley's work, at ~/s/examples/R/parallel/go.R

library(parallel)
cores <- detectCores()

coryDemo3 <- function(bamfileName, motifNumber) {
   function(bamfileName, motifNumber) {
       cmd <- sprintf("/usr/local/bin/Rscript demo2.R %s %d", bamfileName, motifNumber)
       print(cmd)
       system(cmd)
       }
   }

# this works
f <- coryDemo3(bamfileName, motifNumber)
f("a", 7)

bamfileNames <- LETTERS[1:10]
motifNumbers <- 1:10

system.time(lapply(1:10, function(i) f(bamfileNames[i], motifNumbers[i])))
system.time(mclapply(1:10, function(i) f(bamfileNames[i], motifNumbers[i]), mc.cores = cores))


# demo2.R
printf <- function(...) print(noquote(sprintf(...)))
printf("executing demo2.R")
args <- commandArgs(trailingOnly=TRUE)
stopifnot(length(args) == 2)

bamfileName <- args[1]
motifNumber <- as.integer(args[2])
printf("demo.R recieved these args: bamfileName '%s' and motifNumber %d", bamfileName, motifNumber)
printf("sleeping %d seconds", motifNumber)
Sys.sleep(motifNumber)
printf("sleep complete)
*------------------------------------------------------------------------------------------------------------------------
* get grunt install, grokked and working (12 jul 2016)

  ~/s/examples/grunt/try0/

  --- install latest node (4.4.7)
    https://nodejs.org/en/download/     # a pkg installer, quick and easy
    node -v  # v4.4.7
    npm -v   # 2.15.8

  sudo /usr/local/bin/npm install -g grunt-cli

  cd ~/github/
  npm install   // reads package.json, installs everything mentioned there
  grunt

  File "dist/igv.js" created.

    Running "uglify:igv" (uglify) task
    File dist/igv.min.map created (source map).
    File dist/igv.min.js created: 826.43 kB → 387.48 kB


   --- try this out with liz blue's app
     cd ~/s/work/priceLab/lizBlue/try1/

*------------------------------------------------------------------------------------------------------------------------
* build locally modified igv.js (12 jul 2016)


  npm update -g npm
*------------------------------------------------------------------------------------------------------------------------
* igv.js mouseDown events (11 jul 2016)

./browser.js
            isMouseDown = false,
            mouseDownX = undefined;
        $(trackContainerDiv).mousedown(function (e) {
            isMouseDown = true;
            mouseDownX = lastMouseX;
            if (isMouseDown) { // Possibly dragging
                if (mouseDownX && Math.abs(coords.x - mouseDownX) > igv.browser.constants.dragThreshold) {
            mouseDownX = undefined;
            isMouseDown = false;

./igv-create.js
        $(document).mousedown(function (e) {
            //console.log("browser.isMouseDown = true");
            browser.isMouseDown = true;
            //console.log("browser.isMouseDown = undefined");
            browser.isMouseDown = undefined;

./trackView.js
            $(self.igvTrackManipulationHandle).mousedown(function (e) {
                self.isMouseDown = true;
                self.isMouseDown = undefined;
        var isMouseDown = undefined,
            mouseDownXY = undefined,
        $(document).mousedown(function (e) {
            mouseDownXY = igv.translateMouseCoordinates(e, trackView.contentDiv);
            left = mouseDownXY.x;
        $(trackView.contentDiv).mousedown(function (e) {
            isMouseDown = true;
            if (isMouseDown && isMouseIn) {
                dx = mouseMoveXY.x - mouseDownXY.x;
                        left = mouseDownXY.x + dx;
            if (isMouseDown) {
                isMouseDown = false;
        var isMouseDown = false,
            mouseDownX = undefined,
        $(trackView.canvas).mousedown(function (e) {
            isMouseDown = true;
            mouseDownX = lastMouseX;
                } else if (Math.abs(canvasCoords.x - mouseDownX) <= igv.browser.constants.dragThreshold && trackView.track.popupData) {
                            mouseDownX = undefined;
            mouseDownX = undefined;
            isMouseDown = false;
        $(this.innerScrollDiv).mousedown(function (event) {

./ui/colorpicker.js
            $userColorInput.mousedown(function () {

*------------------------------------------------------------------------------------------------------------------------
* load HINT (and refurbished wellington) footprints into prosgres (11 jul 2016): fimo columns identified

   cd /users/pshannon/s/data/postgres-fill/lymphoblast-HINT
   wc -l /local/Cory/trn/working/for_seth/lympho_hint_fp.bed #    58255589

   seth is most interested in HINT

   --- new data table
   head -3 /local/Cory/trn/working/for_seth/lympho_hint_fp.bed
   1	10158	10169	108	MA0073.1	1	20	+	4.16514	5.89e-05	CCCTAACCCTAACCCTAACC
   1	10175	10186	108	MA0073.1	1	20	+	4.53211	5.26e-05	ACCCTAACCTAACCCTAACC
   1	10276	10298	65	MA0073.1	10	29	+	3.09174	8.17e-05	ACCCTAACCCCAACCCCAAC

   bash> psql
   psql> \c lymphoblast
   psql> \dt
 Schema |    Name     | Type  |  Owner
--------+-------------+-------+----------
 public | footprints  | table | pshannon
 public | motifsgenes | table | pshannon


    drop table HINT_footprints;
    create table HINT_footprints(chr varchar,  mfpStart int, mfpEnd int,
                            motifScore real,  motifName varchar,
                            motifStart int, motifEnd int, motifStrand char(1),
                            motifPval real, motifQval real,  motifSequence varchar);

   \copy HINT_footprints from '/local/Cory/trn/working/for_seth/lympho_hint_fp.bed' delimiter E'\t' CSV;

   some bad lines, find and eliminate them
   cat /local/Cory/trn/working/for_seth/lympho_hint_fp.bed | sed -f badLines310.sed > /tmp/lympho_hint_fp.bed
   \copy HINT_footprints from '/tmp/lympho_hint_fp.bed' delimiter E'\t' CSV;
    COPY 58255279

   --- test on macbook
library(RPostgreSQL)
Loading required package: DBI
> db <- dbConnect(PostgreSQL(), user= "trena", password="trena", dbname="lymphoblast", host="whovian")
> dbGetQuery(db, "select * from hint_footprints limit 4")
  chr mfpstart mfpend motifscore motifname motifstart motifend motifstrand motifpval motifqval        motifsequence
1   1    10158  10169        108  MA0073.1          1       20           +   4.16514  5.89e-05 CCCTAACCCTAACCCTAACC
2   1    10175  10186        108  MA0073.1          1       20           +   4.53211  5.26e-05 ACCCTAACCTAACCCTAACC
3   1    10276  10298         65  MA0073.1         10       29           +   3.09174  8.17e-05 ACCCTAACCCCAACCCCAAC
4   1    10276  10298         65  MA0155.1         20       31           -   8.86735  9.32e-05         GGGTTGGGGTTG
>


   still bad lines:
     ERROR:  invalid input syntax for type real: "Klf12_DBD"
     CONTEXT:  COPY hint_footprints, line 593, column motifscore: "Klf12_DBD"

   --- sed/grep fix
  grep -c "10$" tabCount.txt  # 58255279
   wc -l tabCount.txt         # 58255589   310 bad lines

   --- our traditional columns
        create table footprints(chr varchar,  mfpStart int, mfpEnd int, strand char(1),
                                motifName varchar,  motifLength int, footprintLength int,
                                score real, pval real, qval real,  sequence varchar);



   here are the fimo columns:

        X.pattern.name sequence.name start stop strand   score  p.value  q.value matched.sequence
    1             MA0076.2      tert_mut     1   11      + 13.1818 2.22e-05 0.000133      CCCCTTCCGGG
    2 ELK1,4_GABP{A,B1}.p3      tert_mut     2   11      - 11.7000 4.50e-05 0.000539       CCCGGAAGGG
    3          ETV6_full_2      tert_mut     2   11      - 10.7245 9.30e-05 0.001120       CCCGGAAGGG
    4             MA0645.1      tert_mut     2   11      - 10.7308 9.54e-05 0.001150       CCCGGAAGGG

   head -3 /local/Cory/trn/working/for_seth/lympho_hint_fp.bed
   1	10158	10169	108	MA0073.1	1	20	+	4.16514	5.89e-05	CCCTAACCCTAACCCTAACC
   1	10175	10186	108	MA0073.1	1	20	+	4.53211	5.26e-05	ACCCTAACCTAACCCTAACC
   1	10276	10298	65	MA0073.1	10	29	+	3.09174	8.17e-05	ACCCTAACCCCAACCCCAAC



*------------------------------------------------------------------------------------------------------------------------
* load HINT (and refurbished wellington) footprints into prosgres (11 jul 2016)

   --- email from cory (8 jul 2016)

     The two files are here on whovian:
       /local/Cory/trn/working/for_seth/lympho_wellington_fp.bed
       /local/Cory/trn/working/for_seth/lympho_hint_fp.bed

    The columns are mostly the same, with one additional column that is now the 4th column for the
    score (see attached). There's one value for which I can't remember the name, but it should be
    the same as in the old files.

   ---- attached

chr     fp_start   fp_end  fp_scor  motif     motif_start   motif_end  strand  cant_remember   FIMO_pvalue     motif_sequence
1       10158       10169      108  MA0073.1        1       20           +       4.16514       5.89e-05        CCCTAACCCTAACCCTAACC
1       10175       10186      108  MA0073.1        1       20           +       4.53211       5.26e-05        ACCCTAACCTAACCCTAACC
1       10276       10298       65  MA0073.1        10      29           +       3.09174       8.17e-05        ACCCTAACCCCAACCCCAAC

    --- my questions for cory

lymph_hint_fp.bed is definitely new. You reran wellington also?  Do we discard the May 3rd wellington/lymphoblast?

The extra column in the new lymph_wellington_fp.bed is not found in the old, nor in the HINT table.  Shall I just discard it?

How about a quick phone call?

Thanks!

- Paul
v

     head ../lymphoblast/lymphoblast_fp.bed   # from May 3rd
     1       10799   10834   KLF16_DBD       23      33      -       14.9082 5.09e-06        0       GCCACGCCTCC
     1       10799   10834   MA0039.2        24      33      +       9.93878 9.81e-05        0       GAGGCGTGGC
     1       10799   10834   MA0079.3        17      27      -       11.0192 6.47e-05        0       CCTCCACCCCG
     1       10799   10834   MA0162.2        20      33      -       13.7692 1.04e-05        0       GCCACGCCTCCACC

     head /local/Cory/trn/working/for_seth/lympho_wellington_fp.bed    # new wellington, different input? different parameters?
     1       10804   10829           40.4247398376   KLF16_DBD       23      33      -       14.9082 5.09e-06        GCCACGCCTCC
     1       10804   10829           40.4247398376   MA0039.2        24      33      +       9.93878 9.81e-05        GAGGCGTGGC
     1       10804   10829           40.4247398376   MA0079.3        17      27      -       11.0192 6.47e-05        CCTCCACCCCG
     1       10804   10829           40.4247398376   MA0162.2        20      33      -       13.7692 1.04e-05        GCCACGCCTCCACC
     1       10804   10829           40.4247398376   MA0599.1        18      27      -       11.5918 5.64e-05        CCTCCACCCC
     1       10804   10829           40.4247398376   MA0697.1        11      25      -       8.5     5.87e-05        TCCACCCCGACGCGC

     head /local/Cory/trn/working/for_seth/lympho_hint_fp.bed      # new hint
     1       10158   10169   108     MA0073.1        1       20      +       4.16514 5.89e-05        CCCTAACCCTAACCCTAACC
     1       10175   10186   108     MA0073.1        1       20      +       4.53211 5.26e-05        ACCCTAACCTAACCCTAACC
     1       10276   10298   65      MA0073.1        10      29      +       3.09174 8.17e-05        ACCCTAACCCCAACCCCAAC
     1       10276   10298   65      MA0155.1        20      31      -       8.86735 9.32e-05        GGGTTGGGGTTG
     1       10313   10325   72      MA0073.1        2       21      +       4.75229 4.92e-05        AACCCCAACCCCAACCCTAA
     1       10313   10325   72      MA0155.1        1       12      -       8.86735 9.32e-05        GGGTTGGGGTTG

    --- cory sets me straight
     11 columns in both lympho_wellington and lympho_hint

    --- old footprint schema
psql
\c lymphoblast;
\dt
select * from footprints limit 3;
  chr  | mfpstart | mfpend | strand | motifname | motiflength | footprintlength |  score  |   pval   | qval |     sequence
-------+----------+--------+--------+-----------+-------------+-----------------+---------+----------+------+------------------
 chr11 |   747400 | 747435 | -      | MA0088.2  |          11 |              26 | 14.8621 | 1.28e-06 |    0 | GGCCCACAATGCCCCG
 chr11 |   747400 | 747435 | +      | MA0131.2  |          23 |              34 | 12.8636 | 2.17e-05 |    0 | GGCCGTCCGCGC
 chr11 |   747400 | 747435 | +      | MA0696.1  |           2 |              15 | 7.89362 | 4.04e-05 |    0 | AGCCGCCCGCGGGG

     --- prep on whovian
          see "* add seth's enhancer tables to postgres (5 jul 2016)" below
           ~/s/data/postgres-fill/lymphoblastHINT/
      ~/s/data/postgres-fill/lymphoblastWellington/

      cd /users/pshannon/s/data/postgres-fill/HINT



*------------------------------------------------------------------------------------------------------------------------
* R subset operator, drop=FALSE
*------------------------------------------------------------------------------------------------------------------------
* human genome assembly names and versions (8 jul 2016)

   http://www.ncbi.nlm.nih.gov/projects/genome/assembly/grc/human/

   grc: Genome Reference Consortium

   from biostars:

    GRCh37/hg19 and GRCh38 are genome builds rather than annotations, which describe where features
    are in a given genome build. The actual sequences you'll get from NCBI/UCSC/Ensembl will be
    identical, but their annotations will be different and (importantly) updated at different
    frequencies. NCBI's annotation is the "refseq" dataset (the "refGene" track in UCSC), which is
    essentially a subset of the UCSC and Ensembl annotations. UCSC's annotations are kind of a
    mess. You'll find genes with the same ID on multiple strand and multiple chromosomes, which
    makes them a bit useless. Ensembl's annotations typically contain more features than UCSC (so a
    bit more noise), but they're otherwise much better put together (e.g., you'll never find a gene
    ID on different strand or different chromosomes) and their IDs are typically easier to map to
    other things (e.g., gene names, GO and pathway memberships). Ensembl also updates its annotation
    fairly often and versions everything nicely, so it's quite convenient to report what version you
    used in a paper (reproducibility is always a good thing). Given the choice, use the Ensembl
    annotation.

    BTW, don't forget that the various sources can use different names for chromosomes (e.g., chr1
    in UCSC is just 1 in Ensembl), so don't mix and match them.

    get hg19 from, eg

       http://hgdownload.cse.ucsc.edu/goldenPath/hg19/chromosomes/chr22.fa.gz

*------------------------------------------------------------------------------------------------------------------------
* install samtools for faidx (index fasta for igv.js) (8 jul 2016)

  /Users/paul/source/samtools/samtools-1.3.1
  executable:
    /Users/paul/source/samtools/samtools-1.3.1/samtools

  --- sample use, with liz blue's chr22 data
    cd   ~/s/work/priceLab/lizBlue/try1/
    curl -O http://ftp.ensembl.org/pub/release-77/fasta/homo_sapiens/dna/Homo_sapiens.GRCh38.dna.chromosome.22.fa.gz
    gunzip Homo_sapiens.GRCh38.dna.chromosome.22.fa.gz
    /Users/paul/source/samtools/samtools-1.3.1/samtools faidx Homo_sapiens.GRCh38.dna.chromosome.22.fa
    gzip Homo_sapiens.GRCh38.dna.chromosome.22.fa
    mv Homo_sapiens.GRCh38.dna.chromosome.22.fa.fai Homo_sapiens.GRCh38.dna.chromosome.22.fa.gz.fai

*------------------------------------------------------------------------------------------------------------------------
* vcf to matrix, to table (8 jul 2016)

  mentioned in https://www.bioconductor.org/packages/devel/bioc/vignettes/VariantAnnotation/inst/doc/VariantAnnotation.pdf

   res <- genotypeToSnpMatrix(vcf)


*------------------------------------------------------------------------------------------------------------------------
* liz blue, try1 (8 jul 2016) first look, use igv.js

  cd ~/s/work/priceLab/lizBlue/try1/

  cp  ~/s/examples/igv/igv-web/snpFootBed/index.html

   curl -O http://ftp.ensembl.org/pub/release-77/fasta/homo_sapiens/dna/Homo_sapiens.GRCh38.dna.chromosome.22.fa.gz
*------------------------------------------------------------------------------------------------------------------------
* liz blue, try1 (8 jul 2016) first look, grok the vcf file

  cd ~/s/work/priceLab/lizBlue/try1
  install_github("PriceLab/getDNA", subdir="client-R/getDNAClient")

  tbl.ped <- read.table("trio.ped", sep="\t", as.is=TRUE, comment.char="", header=TRUE, fill=TRUE)

  family_id sample_id paternal_id maternal_id sex phenotype ethnicity
    family1      1805          -9          -9   2         1       CEU
    family1      1847          -9          -9   1         1       CEU
    family1      4805        1847        1805   1         2       CEU

  tbl.geno[, 1:6]
       22:35797333_T/C 22:35799542_C/T 22:35808708_C/T 22:35817553_C/T 22:35817597_C/A 22:35947585_C/A
  1805              03              03              01              02              02              02
  1847              02              02              02              02              03              02
  4805              03              03              01              03              03              03


   --- these geno values are coded:  (this from ?genotypeToSnpMatrix)

     Genotypes are stored in the SnpMatrix as 0, 1, 2 or 3 where
         0 = missing
         1 = "0/0"
         2 = "0/1" or "1/0"
         3 = "1/1".

     In SnpMatrix terminology, "A" is the reference allele and "B" is the risk allele.
     Equivalent statements to those made with 0 and 1 allele values would be
       0 = missing
       1 = "A/A"
       2 = "A/B" or "B/A"
       3 = "B/B"


  --- what's the reference genome?
   library(getDNAClient)
   dnaClient<- getDNAClient("hg38")


   --- interpret the first variant

    chrom: 22
      pos: 35797333
       id: .
      ref: T
      alt: C
    qual: 12352.2
   filter: PASS
     info: .
   format: GT:AD:DP:GQ:PL
       GT: genotype
       AD: Allelic depths for the ref and alt alleles in the order listed
       DP: Approximate read depth; some reads may have been filtered
       GQ: Genotype Quality
       PL: Normalized, Phred-scaled likelihoods for genotypes as defined in the VCF specification

            GT      AD      DP   GQ       PL
    1805:  1/1    0,  83    83   99   3187, 250,    0
    1847:  0/1   96,  73   169   99   2315,   0, 3248
    4805:  1/1    0, 213   216   99   6849, 554,    0



*------------------------------------------------------------------------------------------------------------------------
* liz blue, try1 (8 jul 2016) from email

   --- GOAL

   Creating a web-based visualization tools to investigate the potential regulatory effects of
   sequence variants. We are thinking of the ADSP/AMP-AD pilot regions to start, but would be
   generalizable to other regions. The user would upload a multisample VCF with the variants that
   they care about, as well as a pedigree and phenotype file (like a PLINK .fam file).

   --- THOUGHTS

   (1) It would be limited to a region of interest, defined by linkage signals, shared haplotypes,
       LD blocks surrounding association hits, etc. It needs to be limited to a region, rather than a
       genome, in order for the user to wrap their brain around all the info coming at them.

   (2) Display static annotations, like the variants uploaded by the user, footprints, gene locations, FIMO
       predicted consequences, histone modifications, DHS, known eQTLs, etc. The trick will be to avoid
       getting too complicated, but the UCSC genome browser for example can show lots of info to illustrate
       patterns without being overwhelming. It would be helpful to have brief definitions for what these
       things are, and their general interpretation in a friendly readme.

   (3) A button to run TReNA in real time. This identifies, via their cognate motifs and TFs,
       footprints that might be regulatory.  This requires picking a model, and keeping the focus on AD is
       helpful for this (influenced Cory's choices when building the model). The details of the model
       influence interpretation, so we'd need a similar friendly readme to explain what data went into the
       model... so people don't go back to those data sets and think they have independent supporting
       evidence.

   (4) Evidence for cosegregation within a pedigree We talked about this idea during the
       meeting. Would require integrating info from a pedigree file, phenotype file, and possibly a
       covariate file. For large pedigrees, a traditional pedigree drawing might be too hard to see on
       screen, but Paul was interested in trying a network-like drawing that might be more
       legible. Highlighting who carries a variant would be helpful. It would also be helpful to see if the
       variant genotypes aren't Mendelian consistent, and either indicate problems with the pedigree or the
       genotypes.

    (5) Multiple windows Cory brought up using an EMACS-like interface, so that one could see the
        big picture in one window while zooming in on a single feature in another. This would be pretty
        novel and useful.

   GROWTH

    I think we want to restrict the scope of things initially, but there are lots of ways this could
    grow. For example:

    (1) We can help the user filter variants by how they segregate in the pedigree(s)
        We also talked about the user uploading a VCF and using the browser to pick out variants that fit a
        dominant/recessive/etc. model. Generalizing the logic for these can be tricky, especially when there
        is missing data. You might look at GEMINI to see if we could use their algorithms, and integrate it
        with the fast VCF query developed at ISB.

    (2) Or filter by additional annotations, like allele frequency or conservation or ...  If you
        have reference allele frequencies (ie, KAVIAR, UK10K, 1000genomes, ESP, ExAC, etc), I am sure people
        would want to filter by frequency. They then will also want to filter by annotation, and you might
        want to have things like CADD/GERP/PolyPhen2/SIFT/etc available. --> Note, these are all things
        GEMINI does. If you collaborated with them, GEMINI could do the heavy lifting on this and we just
        need to figure out how to get the user's GEMINI database to talk to the web tool.

    RESOURCES

     (1) NIAGADS has a large database with loads of annotation for variants/genes related to AD,
       see: https://www.niagads.org/genomics/ They also have this info implemented as a genome browser,
       see: https://www.niagads.org/genomics/jbrowse.jsp

     (2) GEMINI basically turns an annotated VCF into a database and has premade queries for modes of inheritance, see: http://gemini.readthedocs.io/en/latest/
         It might be useful to use their logic for the queries without implementing their databasing/annotation. Talk to them about a collaboration. (3) In the meeting, we talked about the idea of including a pedigree check/builder. There are a lot of caveats I don't know we want to get into. Estimating kinship coeffients accurately requires appropriate reference allele frequencies which aren't always available, or using a method like KING-robust which is not always as accurate as you would like. This is a level of QC someone analyzing a pedigree should have done on their own before investigating variants. That said, an indicator that a variant is not Mendelian consistent in the data set would be helpful. If you are interested in how to reconstruct pedigrees from kinship estimates, see PRIMUS/PADRE here, http://www.ncbi.nlm.nih.gov/pubmed/27374771.

     HOMEWORK

    I needed to get a multisample VCF and pedigree file to Paul so he can start playing with the
    data. I can't email ADSP data to people who aren't on the project, so I've modified a CEU data
    set from GEMINI. I chose the region of interest after poking at GWAS signals in the NIAGADS
    browser. There are some weak signals in this area for AD, and a few stronger signals from the
    GWAS catalog and I am not sure what studies those p-values belong to.

       --> curl https://s3.amazonaws.com/gemini-tutorials/chr22.VEP.vcf > chr22.VEP.vcf

       --> curl https://s3.amazonaws.com/gemini-tutorials/trio.ped > trio.ped
       --> vcftools --vcf chr22.VEP.vcf --chr 22 --from-bp 35785001 --to-bp 37897000 --remove-filtered-all --recode --out chr22ROI


*------------------------------------------------------------------------------------------------------------------------
* learn jupyter widgets

  from https://github.com/ipython/ipywidgets went to
     https://github.com/ipython/ipywidgets/blob/master/docs/source/examples/Index.ipynb

    many examples under ~/github/ipywidgets/docs/source/examples

    my exploration and examples
    cd ~/s/examples/jupyter/widgets; jupyter-notebook


   --- custom widget, hello world (21 jul 2016)
     confusing.  turning to ~/github/ipywidgets/docs/source/examples

*------------------------------------------------------------------------------------------------------------------------
* fresh install of anaconda (7 jul 2016)
* fresh install of anaconda (7 jul 2016)

    2016-06-28 4.1.0:       Anaconda3-4.1.0-MacOSX-x86_64.pkg
    ~/anaconda/bin/conda update anaconda

       python is /Users/paul/anaconda/bin/python    # 3.5.1, apple build 07dec2015
       pip is /Users/paul/anaconda/bin/pip
       jupyter-notebook also ~/anaconda/bin

*------------------------------------------------------------------------------------------------------------------------
* pwm motif options

  --- jaspar format

   ~/github/piq-single/pwms/jaspar.txt: 457
   ~/github/piq-single/pwms/jasparfix.txt: 1316
   ~/github/TReNA/inst/extdata/jasparVertebrateCore2016-519-matrices.txt: 519

  --- meme format
     ~/github/TReNA/inst/extdata/all_motifs.meme    586

*------------------------------------------------------------------------------------------------------------------------
* R tips write test file (7 jul 2016)

  --- by example, writing pwms

     count <- 3
     output <- vector("character", count * 5)
     base <- 1
     for(motif.name in moi.present[1:count]){
         start.line <- title.line.locs[motif.name] + 1
         end.line <- start.line + 3
         printf("%s: %d", motif.name, start.line)
         output[base] <- sprintf(">%s", motif.name)
         browser()
         output[(base+1):(base+4)] <- lines[start.line:end.line]
         base <- base + 5
         }

     writeLines(output, "test.pwm")

*------------------------------------------------------------------------------------------------------------------------
* cory piq run: create jaspar-format motif file (pcm) for each motif in seth's all_motifs.meme

   cd ~/s/work/priceLab/cory/piq/
   make

*------------------------------------------------------------------------------------------------------------------------
* test dnaSequence & fimoServer fimo server on whovian from riptide (5 jul 2016)

   /usr/local/bin/R -f /Users/paul/github/getDNAService/client-R/getDNAClient/inst/unitTests/test_getDNAClient.R
   /usr/local/bin/R -f /Users/paul/github/fimoService/client-R/FimoClient/inst/unitTests/test_FimoClient.R

   cd ~/s/work/priceLab/cory/piq/motifWrangling/
   grep -c MOTIF all_motifs.meme  # 586   -- used in TReNA
   grep MOTIF all_motifs.meme > meme.motif.ids
   R> motifs <- scan("meme.motif.ids", what=character(0), sep="\n")
      tokens <- strsplit(motifs, " ")
      motifs <- unlist(lapply(tokens, "[", 2)) # 586
      tokens <- strsplit(motifs, ".", fixed=TRUE)
      motifs <- unlist(lapply(tokens, "[", 1)) #  "MA0002" "MA0003" "MA0004" "MA0006" "MA0007" "MA0009"
      write(motifs, sep="\n", file="motifs.586.meme.txt")


  --- next up
    stem motif names in motifs.586.meme.txt
    for each, dig out pcm matrix, with 4 predictable lines (A,C,G,T) after header line
    find the line number of the matrix name match, then get next 4 lines also


   --- ~/s/work/priceLab/cory/piq/motifWrangling/go.R creates 3 motif sample, for testing.  use it in make

*------------------------------------------------------------------------------------------------------------------------
* start fimoService (22 jun 2016)


  --- is it already running?
    ps x | grep run

     1:01 /users/pshannon/R324/lib64/R/bin/exec/R -f runMetNets.R
     0:00 python -i runServer.py 5558 /local/Cory/meme_4.10.2/src/fimo /local/Cory/trn/working/GRCh38/JASPAR_CORE_plus_seth.meme

  --- if not
    cd ~/github/fimoService/server
    nohup python -i runServer.py 5558 /local/Cory/meme_4.10.2/src/fimo /local/Cory/trn/working/GRCh38/JASPAR_CORE_plus_seth.meme&


  --- single test on riptide, my laptop
    /usr/local/bin/R -f /Users/paul/github/fimoService/client-R/FimoClient/inst/unitTests/test_FimoClient.R

  --- crontab test on riptide
    cd ~/crontabs
    whovianFimoServer.cron
    crontab -l
    */5 * * * * /usr/local/bin/R -f /Users/paul/github/fimoService/client-R/FimoClient/inst/unitTests/test_FimoClient.R  > /Users/paul/crontabs/logs/ms.log 2>&1


*------------------------------------------------------------------------------------------------------------------------
* add seth's enhancer tables to postgres (5 jul 2016)

   cd /users/pshannon/s/data/postgres-fill
   for background, see entries in ~/s/log/notes on riptide
   mkdir enhancers; cd enhancers
   file: toStandardTable.R
   --- toStandardTable.R
     library(plyr)
     hiC.file <- "/proj/price1/sament/resources/enhancerTargets/rao2014/tss.loops.rao2014.txt"
     dnase.file <- "/proj/price1/sament/resources/enhancerTargets/thurman2012/tss.loops.thurman2012.txt"
     tbl.hic <- read.table(hiC.file, sep="\t" , header=TRUE, as.is=TRUE)        #  106266     12
     tbl.hic$method <- "Hi-C"
     tbl.dnase <- read.table(dnase.file, sep="\t" , header=TRUE, as.is=TRUE)    # 3328776     12
     tbl.dnase$method <- "DNase-DNase"
     #tbl.test <- rbind.fill(head(tbl.hic), head(tbl.dnase))
     tbl <- rbind.fill(tbl.hic, tbl.dnase)
     x <- order(tbl$chr, tbl$start, tbl$end)
     tbl.out <- tbl[x,]
     dim(tbl.out) # [1] 3435042      13

     # validation: sum(nrow(tbl.hic), nrow(tbl.dnase))  # [1] 3435042
     write.table(tbl.out, file="enhancer.tsv", row.names=FALSE, quote=FALSE, sep="\t")
     # 434936373 Jul  5 16:41 enhancer.tsv

  bash> createdb -U pshannon enhancers.hg38
  psql -U pshannon enhancers.hg38
  pshannon> \dt    # no relations found.
  pshannon> create table enhancers(chr1 varchar,
                                   start1 integer,
                                   end1 integer,
                                   geneName varchar,
                                   transcriptName varchar,
                                   transcriptID varchar,
                                   geneID varchar,
                                   chr2 varchar,
                                   start2 integer,
                                   end2 integer,
                                   distance numeric,
                                   cellType varchar,
                                   method varchar,
                                   cor numeric);
   \copy enhancers from 'enhancer.tsv' delimiter E'\t' CSV;

  GRANT select on all tables in SCHEMA public to trena;
  GRANT connect on database "enhancers.hg38" to trena;


   --- test from psql
    select * from enhancers limit 4;
     chr1 | start1 |  end1  | genename | transcriptname |  transcriptid   |     geneid      | chr2 | start2  |  end2   | distance | celltype |   method    |   cor
    ------+--------+--------+----------+----------------+-----------------+-----------------+------+---------+---------+----------+----------+-------------+----------
     chr1 | 924880 | 924880 | SAMD11   | SAMD11-011     | ENST00000420190 | ENSG00000187634 | chr1 | 1041140 | 1041290 |   116259 | NULL     | DNase-DNase | 0.737101
     chr1 | 924880 | 924880 | SAMD11   | SAMD11-011     | ENST00000420190 | ENSG00000187634 | chr1 | 1191760 | 1191910 |   266879 | NULL     | DNase-DNase | 0.731211
     chr1 | 924880 | 924880 | SAMD11   | SAMD11-011     | ENST00000420190 | ENSG00000187634 | chr1 | 1305020 | 1305170 |   380139 | NULL     | DNase-DNase |  0.70828
     chr1 | 924880 | 924880 | SAMD11   | SAMD11-011     | ENST00000420190 | ENSG00000187634 | chr1 | 1080200 | 1080350 |   155319 | NULL     | DNase-DNase | 0.704411

   select count(*) from enhancers;   3435042

   --- in R
   library(RPostgreSQL)
   db <- dbConnect(PostgreSQL(), user= "trena", password="trena", dbname="enhancers.hg38", host="whovian")
   as.data.frame(t(dbGetQuery(db, "select * from enhancers where distance > 2000000000")
                                  1
     chr1                      chr1
     start1                15341761
     end1                  15341761
     genename                 FHAD1
     transcriptname       FHAD1-004
     transcriptid   ENST00000444385
     geneid         ENSG00000142621
     chr2                      chr1
     start2               234774253
     end2                 234784253
     distance             219432491
     celltype               GM12878
     method                    Hi-C
     cor                          0

*------------------------------------------------------------------------------------------------------------------------
* all the tables for postgres fill (20 jun 2016)

   cd /users/pshannon/s/data/postgres-fill
   dir */*.tsv
     593,861,194 May  3 22:03 gtf/ensembl-gtf.tsv
     734,745,528 May  3 11:10 lymphoblast/lymphoblast_fp.tsv
         279,011 May 19 15:57 motifsgenes/motifGenes.tsv
         142,237 May  3 09:52 motifsgenes/motifToMultipleGenes.tsv
      353790k431 Apr 27 12:12 wholeBrain/fpAnnotated.tsv
   3,156,774,744 May 10 12:09 wholeBrain/wholeBrain.tsv

*------------------------------------------------------------------------------------------------------------------------
* add slightly revised motif/genes table to wholeBrain database

    cd ~/s/data/postgres-fill/motifsgenes
    psql
    \c wholeBrain
    \dt
                  List of relations
      Schema |    Name     | Type  |  Owner
     --------+-------------+-------+----------
      public | footprints  | table | pshannon
      public | motifsgenes | table | pshannon

    select * from motifsgenes limit 3;
      motif   |   tf
    ----------+--------
     MA0002.2 | RUNX1
     MA0003.3 | TFAP2A
     MA0004.1 | ARNT

   wholeBrain=> drop table motifsgenes;
    mv ~/tmp/motifGenes.tsv .
    (delete colnames in 1st line)

    create table motifsgenes(motif varchar, tf_name varchar, tf_ensg varchar);
    \copy motifsgenes from 'motifGenes.tsv' delimiter E'\t' CSV;
    \copy motifsgenes from 'motifToMultipleGenes.tsv' delimiter E'\t' CSV;
    COPY 9017

  GRANT select on all tables in SCHEMA public to trena;

    select * from motifsgenes limit 4;
      motif   | tf_name |     tf_ensg
    ----------+---------+-----------------
     MA0002.2 | RUNX1   | ENSG00000159216
     MA0003.3 | TFAP2A  | ENSG00000137203
     MA0004.1 | ARNT    | ENSG00000143437
     MA0006.1 | AHR     | ENSG00000106546


*------------------------------------------------------------------------------------------------------------------------
* add latest footprints (wholeBrain and lymphoblast) from cory (10 may 2016)

  --- email (9 may 2016)

   I've put the footprint files on whovian here:  /local/Cory/trn/final_fp_files
   Both brain and lymphoblast are there. They were both made using the same scripts.

  --- cory's files, in place
    dir /local/Cory/trn/final_fp_files/
       2 926 976 570 May  6 14:13 brain_fp_uniq.bed
         853 181 432 May  9 17:01 lympho_fp_uniq.bed

  --- fill wholeBrain
   cd ~/s/data/postgres-fill/wholeBrain
   head -3 /local/Cory/trn/final_fp_files/brain_fp_uniq.bed
       1	10021	10042	MA0073.1	1	20	+	4.16514	5.89e-05	CCCTAACCCTAACCCTAACC
       1	10044	10083	MA0073.1	2	21	+	4.16514	5.89e-05	CCCTAACCCTAACCCTAACC
       1	10085	10121	MA0073.1	14	33	+	4.55046	5.23e-05	ACCCTAACCCAACCCTAACC

   psql -U pshannon wholeBrain
   select count(*) from footprints;      4 692 138
 select * from footprints limit 3;
 chr  | mfpstart | mfpend  | strand | motifname | motiflength | footprintlength | score |   pval   | qval  |   sequence
------+----------+---------+--------+-----------+-------------+-----------------+-------+----------+-------+---------------
 chr1 |  1000050 | 1000077 | -      | MA0813.1  |          13 |              26 |  50.4 | 9.15e-06 | 0.492 | CGCCCTAGGGGCT
 chr1 |  1000050 | 1000077 | -      | MA0815.1  |          13 |              26 |  53.2 | 4.82e-06 | 0.462 | CGCCCTAGGGGCT
 chr1 |  1000050 | 1000077 | -      | MA0872.1  |          13 |              26 |  51.7 | 6.72e-06 | 0.483 | CGCCCTAGGGGCT


   --- despite size, will try to add "chr" prefix to all chromosome names, and rearrange columns
     tbl <- read.table("/local/Cory/trn/final_fp_files/brain_fp_uniq.bed", header=FALSE, as.is=TRUE, sep="\t")
     head(tbl$V1) # [1] "1" "1" "1" "1" "1" "1"
     tbl$V1 <- paste("chr", tbl$V1, sep="")
     colnames(tbl) <- c("chr","mfpstart","mfpend","motifname","motifStartOffset","motifEndOffset","strand","score","pval","sequence")
     tbl$motiflength <- 1 + tbl$motifEndOffset - tbl$motifStartOffset
     tbl$footprintlength <- 1 + tbl$mfpend - tbl$mfpstart
     tbl$qval <- rep(0.0, nrow(tbl))

     some qc:
      fivenum(tbl$motiflength)     #   7 10 11 14 29
      fivenum(tbl$footprintlength) #   22  30  34  36 180

     tbl.2 <- tbl[, c("chr","mfpstart","mfpend","strand","motifname","motiflength","footprintlength","score","pval","qval","sequence")]
     dim(tbl.2) # 43 301 380       11
     write.table(tbl.2, file="wholeBrain.tsv", quote=FALSE, row.names=FALSE, col.names=FALSE, sep="\t")

   ---- empty and fill
     truncate footprints;
     wholeBrain=> select count(*) from footprints; # 0
     \copy footprints from 'wholeBrain.tsv' delimiter E'\t' CSV;

*------------------------------------------------------------------------------------------------------------------------
* create database for each genome assembly, for each tissue/s-specific project (9 may 2016)

  --- the hg38 genome.db
    cd ~/s/data/postgres-fill/motifsgenes
    psql
    \c hg38
    create table motifsgenes(motif varchar, tf varchar);
    \copy motifsgenes from 'motifToMultipleGenes.tsv' delimiter E'\t' CSV;
    COPY 9289

*------------------------------------------------------------------------------------------------------------------------
* add ensembl gtf to postgres (3 may 2016)

  cd ~/s/data/postgres-fill/gtf
  print(load("tbl.ensembl.gtf.RData")) # [1] "tbl3"
  write.table(tbl3, sep="\t", quote=FALSE, row.names=FALSE, col.names=FALSE, file="ensembl-gtf.tsv")

  bash> createdb -U pshannon hg38
  psql
  pshannon> \c gtf
  pshannon> create table gtf(chr varchar, start int, endpos int, score varchar, strand varchar,
                             frame varchar, moleculeType varchar, gene_id varchar,
                             gene_version varchar,
                             gene_name  varchar,
                             gene_source  varchar,
                             gene_biotype  varchar,
                             havana_gene  varchar,
                             havana_gene_version  varchar,
                             transcript_id  varchar,
                             transcript_version  varchar,
                             transcript_name  varchar,
                             transcript_source  varchar,
                             transcript_biotype  varchar,
                             havana_transcript  varchar,
                             havana_transcript_version  varchar,
                             tag  varchar,
                             transcript_support_level  varchar,
                             exon_number  varchar,
                             exon_id  varchar,
                             exon_version  varchar,
                             ccds_id  varchar,
                             protein_id varchar,
                             protein_version  varchar,
                             annotation varchar);

\c hg38
\copy gtf from 'ensembl-gtf.tsv' delimiter E'\t' CSV;
COPY 2568100
hg38=>
  GRANT connect on database "hg38" to trena;
  GRANT select on all tables in SCHEMA public to trena;

   --- test from whovian
      library(RPostgreSQL)
      db <- dbConnect(PostgreSQL(), user= "trena", password="trena", dbname="gtf", host="whovian")
      db
      query <- "select count(*) from footprints"
      dbGetQuery(db, query)
      dbListTables(db)  # [1] "hg38human"
      dbGetQuery(db, "select count(*) from hg38human")
      #    count
      # 1 2568100
      colnames(dbGetQuery(db, "select * from hg38human limit 1"))
 [1] "chr"                       "start"
 [3] "endpos"                    "score"
 [5] "strand"                    "frame"
 [7] "moleculetype"              "gene_id"
 [9] "gene_version"              "gene_name"
[11] "gene_source"               "gene_biotype"
[13] "havana_gene"               "havana_gene_version"
[15] "transcript_id"             "transcript_version"
[17] "transcript_name"           "transcript_source"
[19] "transcript_biotype"        "havana_transcript"
[21] "havana_transcript_version" "tag"
[23] "transcript_support_level"  "exon_number"
[25] "exon_id"                   "exon_version"
[27] "ccds_id"                   "protein_id"
[29] "protein_version"           "annotation"

  tbl.mef2c <- dbGetQuery(db, "select * from hg38human where gene_name = 'MEF2C'")
  dim(tbl.mef2c) # [1] 568  30
  head(tbl.mef2c[, c("chr", "start", "endpos", "moleculetype", "gene_biotype")])
      chr    start   endpos moleculetype   gene_biotype
   1 chr5 88717117 88904257         gene protein_coding
   2 chr5 88717117 88883464   transcript protein_coding
   3 chr5 88882955 88883464         exon protein_coding
   4 chr5 88823735 88823930         exon protein_coding
   5 chr5 88823735 88823788          CDS protein_coding
   6 chr5 88823786 88823788  start_codon protein_coding

   as.data.frame(table(tbl.mef2c$moleculetype))
                Var1 Freq
   1             CDS  190
   2            exon  235
   3  five_prime_utr   51
   4            gene    1
   5     start_codon   25
   6      stop_codon   17
   7 three_prime_utr   15
   8      transcript   34


*------------------------------------------------------------------------------------------------------------------------
* add lymphoblast footprints to postgres (3 may 2016)

  cd ~/s/data/postgres-fill/lymphoblast/
  cp /local/Cory/trn/lympho/lymphoblast_fp.bed .

   --- wholeBrain tsv input file format
     whovian.lymphoblast> head ../wholeBrain/fpAnnotated.tsv
     chr1	1000050	1000077	-	MA0813.1	13	26	50.4	9.15e-06	0.492	CGCCCTAGGGGCT
     chr1	1000050	1000077	-	MA0815.1	13	26	53.2	4.82e-06	0.462	CGCCCTAGGGGCT
     chr1	1000050	1000077	-	MA0872.1	13	26	51.7	6.72e-06	0.483	CGCCCTAGGGGCT
     chr1	1000095	1000120	+	MA0632.1	10	26	54	4e-06	0.332	CGCGCGCGCC

   --- incoming lymphoblast tsv input file format: change this in R to match wholeBrain

     whovian.lymphoblast> head lymphoblast_fp.bed
     1	10799	10834	KLF16_DBD	23	33	-	14.9082	5.09e-06	0	GCCACGCCTCC
     1	10799	10834	MA0039.2	24	33	+	9.93878	9.81e-05	0	GAGGCGTGGC
     1	10799	10834	MA0079.3	17	27	-	11.0192	6.47e-05	0	CCTCCACCCCG
     1	10799	10834	MA0162.2	20	33	-	13.7692	1.04e-05	0	GCCACGCCTCCACC

    --- slight reformat
     tbl <- read.table("lymphoblast_fp.bed", sep="\t", as.is=TRUE, header=FALSE)
     colnames(tbl) <- c("chr", "start", "end", "motif", "offset.1", "offset.2", "strand", "q", "p", "score", "sequence")
     tbl$chr <- paste("chr", tbl$chr, sep="")
     new.column.order <- c("chr", "start", "end", "strand", "motif", "offset.1", "offset.2", "q", "p", "score", "sequence")
     tbl <- tbl[, new.column.order]

    --- result
      head(tbl)
         chr start   end strand     motif offset.1 offset.2        q        p score        sequence
      1 chr1 10799 10834      - KLF16_DBD       23       33 14.90820 5.09e-06     0     GCCACGCCTCC
      2 chr1 10799 10834      +  MA0039.2       24       33  9.93878 9.81e-05     0      GAGGCGTGGC
      3 chr1 10799 10834      -  MA0079.3       17       27 11.01920 6.47e-05     0     CCTCCACCCCG
      4 chr1 10799 10834      -  MA0162.2       20       33 13.76920 1.04e-05     0  GCCACGCCTCCACC
      5 chr1 10799 10834      -  MA0599.1       18       27 11.59180 5.64e-05     0      CCTCCACCCC
      6 chr1 10799 10834      -  MA0697.1       11       25  8.50000 5.87e-05     0 TCCACCCCGACGCGC

     write.table(tbl, file="lymphoblast_fp.tsv", sep="\t", quote=FALSE, row.names=FALSE, col.names=FALSE)
        -rw-r--r--. 1 pshannon pricelab 704475018 May  3 10:45 lymphoblast_fp.bed
        -rw-r--r--. 1 pshannon pricelab 734745528 May  3 11:10 lymphoblast_fp.tsv


    --- now do the fill
      previously:    createdb -U pshannon lymphoblast
      psql>
        \c lymphoblast
        create table footprints(chr varchar,  mfpStart int, mfpEnd int, strand char(1),
                                motifName varchar,  motifLength int, footprintLength int,
                                score real, pval real, qval real,  sequence varchar);

        \dt
        \copy footprints from 'lymphoblast_fp.tsv' delimiter E'\t' CSV;
        COPY 10091138
          lymphoblast=> select count(*) from footprints;   #  10091138

     lymphoblast> GRANT select on all tables in SCHEMA public to trena;
     lymphoblast=> create table motifsgenes(motif varchar, tf varchar);
      CREATE TABLE
   lymphoblast=> \dt
               List of relations
     Schema |    Name     | Type  |  Owner
    --------+-------------+-------+----------
     public | footprints  | table | pshannon
     public | motifsgenes | table | pshannon

   lymphoblast=> \copy motifsgenes from '../wholeBrain/motifToMultipleGenes.tsv' delimiter E'\t' CSV;
   COPY 9289

    lymphoblast> GRANT select on all tables in SCHEMA public to trena;



*------------------------------------------------------------------------------------------------------------------------
* add trena user

  cd ~/s/data/postgres-fill/wholeBrain/
  sudo -i -u postgres psql

  create role trena with password 'trena' login;
  bash> createdb trena
  GRANT connect on database "wholeBrain" to trena;
  GRANT select on all tables in SCHEMA public to trena;

*----------------------------------------------------------------------------------------------------
* test fill wholeBrain footprints (3 may 2016)

   cd ~/s/data/postgres-fill/wholeBrain/
   R -f test.R

  stolen from ~/s/data/postgres-fill/wholeBrain/test_FootprintFinder.R

    test_privateFootprintDatabaseOnWhovian()

*----------------------------------------------------------------------------------------------------
* fill wholeBrain motif-to-protein table (3 may 2016)

  laptop> scp /Users/paul/github/Private_Cory_Data/data/tbl.motifToMultipleGenes.RData pshannon@whovian:tmp/
  whovian> cd  ~/s/data/postgres-fill/wholeBrain/
  print(load("~/tmp/tbl.motifToMultipleGenes.RData"))
  write.table(tbl.motifToMultipleGenes, sep="\t", quote=FALSE, row.names=FALSE, col.names=FALSE, file="motifToMultipleGenes.tsv")

  psql
   \c wholeBrain
    wholeBrain=> create table motifsgenes(motif varchar, tf varchar);
     CREATE TABLE
   wholeBrain=> \dt
               List of relations
     Schema |    Name     | Type  |  Owner
    --------+-------------+-------+----------
     public | footprints  | table | pshannon
     public | motifsgenes | table | pshannon

   wholeBrain=> \copy motifsgenes from 'motifToMultipleGenes.tsv' delimiter E'\t' CSV;
   COPY 9289

  wholeBrain> GRANT select on all tables in SCHEMA public to trena;

   ---- now run some simple tests from laptop

*----------------------------------------------------------------------------------------------------
* fill wholeBrain footprints (27 apr 2016)

  cd ~/s/data/postgres-fill/wholeBrain
  from riptide:
    cd ~/github/Private_Cory_Data/data
    scp tbl.fpAnnotated.RData pshannon@whovian:tmp/     # 136MB
  mv ~/tmp/tbl.fpAnnotated.Rdata .
  print(load("tbl.fpAnnotated.RData"))
  dim(tbl.fpAnnotated) #  4,692,138      17

     # add two columns
  tbl.fpAnnotated$footprintLength = with(tbl.fpAnnotated,1 + fpEnd-fpStart)
  tbl.fpAnnotated$motifLength = with(tbl.fpAnnotated,1 + motifEnd-motifStart)

  colnames(tbl.fpAnnotated)[grep("motifStrand", colnames(tbl.fpAnnotated))] <- "strand"
  colnames(tbl.fpAnnotated)[grep("pvalue", colnames(tbl.fpAnnotated))] <- "pval"
  colnames(tbl.fpAnnotated)[grep("qvalue", colnames(tbl.fpAnnotated))] <- "qval"
  colnames(tbl.fpAnnotated)[grep("motifScore", colnames(tbl.fpAnnotated))] <- "score"

  coi <- c("chr","mfpStart","mfpEnd","strand","motifName","motifLength","footprintLength","score","pval","qval","sequence")
  write.table(tbl.fpAnnotated[,coi], quote=FALSE, row.names=FALSE, col.names=FALSE, sep="\t", file="fpAnnotated.tsv")

   psql
   \c wholeBrain
   create table footprints(chr varchar,  mfpStart int, mfpEnd int, strand char(1),
                           motifName varchar,  motifLength int, footprintLength int,
                           score real, pval real, qval real,  sequence varchar);
   \dt
   \copy footprints from 'fpAnnotated.tsv' delimiter E'\t' CSV;
    COPY 4692138

  wholeBrain> GRANT select on all tables in SCHEMA public to trena;

*----------------------------------------------------------------------------------------------------
* add trena user (27 apr 2016)

   cd ~/s/data/postgres-fill/wholeBrain/

   sudo -i -u postgres psql
   create role trena with password 'trena' login createdb;

*----------------------------------------------------------------------------------------------------
* remove password on pshannon user (27 apr 2016)

   alter role pshannon password null; # ALTER ROLE
   postgres=# select * from pg_shadow;
   usename  | usesysid | usecreatedb | usesuper | usecatupd | userepl | passwd | valuntil | useconfig
  ----------+----------+-------------+----------+-----------+---------+--------+----------+-----------
   postgres |       10 | t           | t        | t         | t       |        |          |
   pshannon |    16384 | t           | f        | f         | f       |        |          |
   (2 rows)


*----------------------------------------------------------------------------------------------------
* first use (27 apr 2016)

   whovian> sudo -i -u postgres psql
   psql (9.4.7)
   postgres=# create role pshannon with password 'pshannon' login createdb;

   createdb pshannon
   psql  # default user in my login, pshannon.  this now works
   createdb -U pshannon wholeBrain
   createdb -U pshannon lymphoblast

*----------------------------------------------------------------------------------------------------
* email from russ after installation on whovian (25 apr 2016)


   Paul, postgresql 9.4 is installed on whovian. I've granted you sudo permissions to the postgres user
   which should allow you to do any of the administrative tasks involved in managing your databases. You
   should, for instance, be able to do the following to create a pshannon user, if you so desire:

$ sudo -i -u postgres psql
psql (9.4.7)
Type "help" for help.

postgres=# create role pshannon with password 'pshannon' login createdb;
postgres=# \q
$

Let me know if anyone else should also have this privilege.




*----------------------------------------------------------------------------------------------------
* postgres tips (24 apr 2016)

  found version 9.3 ships with osx.  installed it.  root user: posgres, pw=postgres, on port 5432
  installed as /Applications/PostgreSQL 9.3
  utilities here:

     /Library/PostgreSQL/9.3/bin

    clusterdb createdb createlang createuser dropdb droplang dropuser
    ecpg initdb oid2name pg_archivecleanup pg_basebackup pg_config
    pg_controldata pg_ctl pg_dump pg_dumpall pg_isready pg_receivexlog
    pg_resetxlog pg_restore pg_standby pg_test_fsync pg_test_timing
    pg_upgrade pg_xlogdump pgbench pltcl_delmod pltcl_listmod
    pltcl_loadmod postgres postmaster psql reindexdb vacuumdb vacuumlo

  --- added to PATH, in ~/.bashrc
     PATH=$PATH:/Library/PostgreSQL/9.3/bin

  --- create new user:  add me (pshannon) with db creation privileges
     login as postgres root:
        psql -U postgres
     create role pshannon with password 'pshannon' login createdb;
      \du
                                   List of roles
       Role name |                   Attributes                   | Member of
      -----------+------------------------------------------------+-----------
       postgres  | Superuser, Create role, Create DB, Replication | {}
       pshannon  | Create DB                                      | {}

  --- every user apparently needs a database of their own, with their name:

   /Library/PostgreSQL/9.3/bin/createdb -U postgres pshannon

  --- test this out by creating tcx (temporal cortex) database, fill with tbl.fp
    /Library/PostgreSQL/9.3/bin/createdb -U pshannon tcx

  --- list databases
    psql -U postgres
    \l
                                   List of databases
         Name    |  Owner   | Encoding | Collate | Ctype |   Access privileges
      -----------+----------+----------+---------+-------+-----------------------
       postgres  | postgres | UTF8     | C       | C     |
       pshannon  | postgres | UTF8     | C       | C     |
       tcx       | pshannon | UTF8     | C       | C     |
       template0 | postgres | UTF8     | C       | C     | =c/postgres  postgres=CTc/postgres
       template1 | postgres | UTF8     | C       | C     | =c/postgres  postgres=CTc/postgres


   --- create footprints table withing tcx (temporal cortext) database
     psql -U pshannon
     \l
     \c tcx
     tcx=> create table footprints(chr char(40),  mfpStart int, mfpEnd int, motifName char(24),  motifLength int,
                             footprintLength int, strand char(1),  score real, pvalue real, mystery int,   sequence char(36))
     \dt
                 List of relations
       Schema |    Name    | Type  |  Owner
      --------+------------+-------+----------
       public | footprints | table | pshannon
      (1 row)

    tcx=> \copy footprints from '/Users/paul/github/TReNA.lymphoblast/inst/extdata/lymphoblast_fp.bed' delimiter E'\t' CSV;
    tcx-> select count(*) from footprints;  #  10091138

    --- abandoned RPostgreSQL since it failed to connect:
      db <- dbConnect(PostgreSQL(), user= "pshannon", password="pshannon", dbname="tcx")
      Error in postgresqlNewConnection(drv, ...) :
       RS-DBI driver: (could not connect pshannon@local on dbname "tcx"

    --- finally figured out how to connect: make host explicit, default 'local' does not exist
     db <- dbConnect(PostgreSQL(), user="pshannon", password="pshannon", port=5432, dbname="tcx", host="localhost")
     query <- "select count(*) from footprints"
     dbGetQuery(db, query)
          count
     1 10091138
     # or
     rs <- dbSendQuery(db, query)
     length(rs)  #
     fetch(rs, 1)
        count
     1 10 091 138
     #  get data.frame
     query <- "select * from footprints limit(4)"
     dim(dbGetQuery(db, query)) # 4, 11
     colnames(dbGetQuery(db, query))
       [1] "chr"             "mfpstart"        "mfpend"          "motifname"
       [5] "motiflength"     "footprintlength" "strand"          "score"
       [9] "pvalue"          "mystery"         "sequence"

*------------------------------------------------------------------------------------------------------------------------
* test fimoServer fimo server on whovian from riptide (5 jul 2016)

   /usr/local/bin/R -f /Users/paul/github/fimoService/client-R/FimoClient/inst/unitTests/test_FimoClient.R

*------------------------------------------------------------------------------------------------------------------------
* load seth's enhancer targets into a new postgres database (5 jul 2016)

  --- email to seth (1 jul 2016)

     Here are a couple of questions.

     With the stamlab DNase-DNase correlations, the first three rows (transposed for easier reading):

     as.data.frame(t(read.table("/proj/price1/sament/resources/enhancerTargets/thurman2012/tss.loops.thurman2012.txt", sep="\t", header=TRUE, as.is=TRUE, nrows=3)))
                                  1               2               3
     chr                        chr2            chr2            chr2
     start                  15940564        15940564        15940564
     end                    15940564        15940564        15940564
     gene_name                  MYCN            MYCN            MYCN
     transcript_name        MYCN-001        MYCN-001        MYCN-001
     transcript_id   ENST00000281043 ENST00000281043 ENST00000281043
     gene_id         ENSG00000134323 ENSG00000134323 ENSG00000134323
     chr.1                      chr2            chr2            chr2
     start.1                15939998        16281932        16322392
     end.1                  15940148        16282082        16322542
     cor                    0.999997        0.999997        0.999995
     dist                        415          341367          381827

     Am I right to infer

        chr:start-end are the promoters, each represented as a 1-base region
        chr.1:start.1-end.1 are the distal enhancers, each 150 bases long
        cor is the correlation of open chromatin across tissues (a pvalue on
        that correlation would be nice to know…)

     The Hi-C data seems to be much the same: 1-base promoter, much longer
     distal enhancer (end.1-start.1, mean is 15kb), the “cor" column replaced by
     “celltype”.

     Maybe these can go into the same table, with one extra column “experimentType”,
     “cor” being empty for the Rao data, “celltype” empty for the Thurman data?

     I think postgres on whovian is the best place for these data.

  --- seth's reply

     The loops are not really directed, although the DNase-DNase
     correlations only include pairs where one end intersects a promoter.
     In processing the data, I look for overlaps of promoters with either
     region on a line and consider the other region its distal enhancer.

     I'm glad you agree that the Postgres db is a good way to access the table.

   --- seth's original email, with pointers to files (28 jun 2016)

    I have created tables with enhancer-promoter loops predicted from Hi-C
    experiments reported in Rao et al. 2015 (Nature) and from DNase-DNase
    correlations reported in Thurman et al. 2012 (Nature). I think it would be
    super useful to include these in the Postgres db so that we can incorporate
    them into our analyses. Here's a description of the files that are
    available:

      ---- Hi-C

      I downloaded Hi-C loop lists reported by Rao et al. (2015) from GEO
      (supplementary files of GSE63525) and lifted over the coordinates to hg38. By
      definition, these are undirected loops. Each row describes two genomic regions
      and a cell type in which they have been shown to contact each other. This file
      is here:

    /proj/price1/sament/resources/enhancerTargets/rao2014/rao2014_loops_hg38.bed

    I then wrote a script that uses functions in TReNA and GenomicRanges to find
    loops between transcription start sites and distal genomic regions. The script
    is here:

       /proj/price1/sament/resources/enhancerTargets/rao2014/enhancersPerEnsg.R And the

   resulting file is here:

     /proj/price1/sament/resources/enhancerTargets/rao2014/tss.loops.rao2014.txt

     ---- DNase-DNase correlations:

       A second method to predict the targets of distal enhancers is to find
       pairs of enhancers and promoters whose accessibility to DNase is correlated
       across tissues. The ENCODE consortium generated a list of these
       enhancer-promoter pairs in one of their 2012 Nature papers (Thurman et
       al. 2012). I downloaded their table and lifted the regions over to hg38 to
       create a loop list file:

         /proj/price1/sament/resources/enhancerTargets/thurman2012/thurman2012_genomewideCorrs_hg38.bed

      Again, I used functions from TReNA and GenomicRanges to create a file mapping
     enhancers to promoters in the same format as for the Hi-C data: script:

        /proj/price1/sament/resources/enhancerTargets/thurman2012/enhancersPerEnsg.R
     file:

       /proj/price1/sament/resources/enhancerTargets/thurman2012/tss.loops.thurman2012.txt

    I'll defer to your judgment about where in the TReNA package each of these
    files and scripts could be placed. The major use case is to intersect these
    regions with footprints that could then be inputted to runTReNA.

*------------------------------------------------------------------------------------------------------------------------
* cyjs in jupyter,  try 1a (3 jul 2016)

  --- jupyter installed for ~/anaconda, so use it's pip to install py2cytoscape
     ~/anaconda/bin/pip install py2cytoscape
     Successfully installed py2cytoscape-0.5.0 python-igraph-0.7.1.post6

  --- background  (see "try 1" below)
    cloned py2cytoscape, hope to find a cyjs-only example
    cd ~/github/py2cytoscape/examples
    curl -O   http://nbviewer.jupyter.org/github/idekerlab/py2cytoscape/blob/develop/examples/New_wrapper_api_sample.ipynb
     ~/anaconda/bin/jupyter-notebook

   --- a few dead simple notebook statements
     from py2cytoscape import cytoscapejs as cyjs
     import json
     g = json.load(open("../tests/data/galFiltered.json"))
     cyjs.render(g)

   --- saved this as minimalCyjsDisplay.ipynb (503395 Jul  3 09:48)
*------------------------------------------------------------------------------------------------------------------------
* cyjs in jupyter, try 1 (2 jul 2016)

  --- encountered this july 2015 note from kei

   I'm a core developer of Cytoscape and working on both desktop version and
   tools using Cytocape.js.  These days, I use Jupyter Notebook as my primary
   tool to run my workflows.  To use it with Cytoscape.js, I wrote a small tool
   called py2cytoscape, to embed Cytoscape.js in the notebooks:

   http://nbviewer.ipython.org/github/idekerlab/cy-rest-python/blob/develop/basic/CytoscapeJS_visualization.ipynb
   http://nbviewer.ipython.org/github/idekerlab/cy-rest-python/blob/develop/cytoscape-js/CytoscapeJs_and_igraph.ipynb

   BioJS components are also very useful if we can use it from Jupyter Notebook,
   and my question is, do you have any plan to have a repository or something
   for similar widget for notebooks?  If I'm not alone, it would be better to
   have some sort of standard or repository.

  --- advice from the first notebook above
    which is now here: http://nbviewer.jupyter.org/github/idekerlab/cy-rest-python/blob/develop/basic/CytoscapeJS_visualization.ipynb


  --- install on riptide from instructions given here:   https://github.com/idekerlab/py2cytoscape
    using ~/miniconda/bin/python,pip, ...
     ~/miniconda2/bin/conda install scipy pandas networkx jupyter
     ~/miniconda2/bin/pip install py2cytoscape
    had some problems with igraph dependency install, eventually worked out
    pip install IPython

    cd ~/github
    git clone https://github.com/idekerlab/py2cytoscape.git

  some sample graph and styles here:
    tests/data/galFiltered.json
    https://github.com/idekerlab/cy-rest-python/tree/develop/basic/sample_data

   --- try it out, hoping to find guidance from
    http://nbviewer.jupyter.org/github/idekerlab/py2cytoscape/blob/develop/examples/New_wrapper_api_sample.ipynb

     python  #
     Python 3.5.1 |Continuum Analytics, Inc.| (default, Dec  7 2015, 11:24:55)
       # obsolote? import py2cytoscape.util.cytoscapejs as cyjs
       # obsolete? import py2cytoscape.cytoscapejs as renderer
   >>> from py2cytoscape import cytoscapejs as cyjs
        <IPython.core.display.Javascript object>
    In : import json
         g = json.load(open("tests/data/galFiltered.json"))
    In : cyjs.render(g)
          ImportError: No module named 'jinja2'



*------------------------------------------------------------------------------------------------------------------------
* ein

  cd ~/github
  git clone git://github.com/millejoh/emacs-ipython-notebook.git

    # cd emacs-ipython-notebook/
    # bash lisp/zeroein.el  # starts new emacs but too much I don't yet understand

  --- Manual install
    Put Emacs lisp ein*.el files and Python file ein.py in a directory defined in your load-path.
    ---> change one liene of source, uncommenting this line (line 84 on 2 jul 2016)
          ~/github/emacs-ipython-notebook/lisp/ein.el
      ;; For backward compatibility + providing easy way to load EIN for
      ;; users who prefer manual installation.
     (require 'ein-loaddefs)

   M-x ein:notebooklist-open  reports
    cannot open load file: no such file or directory, websocket

  --- cd ~/s/work/jupyter
    jupyter-notebook

*------------------------------------------------------------------------------------------------------------------------
* matt's maripaludis prep uses new rcyjs approach, with httpAddGraph used in ctor (1 jul 2016)

   reproduce, recreate matt's metabolic network here:
   uses "2016_04_11_model.xml"

   ~/github/metnetViz/datasets/Maripaludis/inst/prep/v0/newBuild.R

    tbls <- xmlToTables()
    g <- toGraphNEL(tbls$interactions,
                    tbls$reactions,
                    tbls$genes,
                    tbls$metabolites,
                    tbls$flux)
    rcy <- RCyjs(PORT_RANGE, graph=g)
    readAndApplyLayout(rcy, "organicLayout.tsv");
    fit(rcy)
    httpSetStyle(rcy, "style.js")


*------------------------------------------------------------------------------------------------------------------------
*  Thinking etho-ecology with Stengers and Whitehead (1 jul 2016)

   https://footnotes2plato.com/2011/06/13/thinking-etho-ecology-with-stengers-and-whitehead/

  I’ve been reading Stengers’ recently translated book Thinking with
  Whitehead (2011) with an eye to developing an eco-ontology, or
  ecological realism. Adam and I are still in the process of searching
  for an adequate characterization for this project, but in nuce, we
  want to untangle the ethical, epistemological, cosmological, and
  ontological knot that is the ecological crisis. The hope is that a
  coherent and adequate philosophical grasp of the complex relations
  between each of these threads will enable us to bring forth more
  resilient modes of living and dying as human beings on planet
  earth. We are just the latest participants in a tradition of
  cosmopolitical thought, and with the help of philosophers like
  Stengers and Whitehead, perhaps we can play some small role in
  transforming the danger of ecological crisis into an opportunity
  opening up an entirely novel civilizational adventure.

*------------------------------------------------------------------------------------------------------------------------
* footprints for vineet (30 jun 2016)

   Human gene symbol - EFHC1
   Rat gene symbol - efhc1

   biocLite(c("glmnet", "randomForest", "vbsr", "RPostgreSQL"))

*------------------------------------------------------------------------------------------------------------------------
* run piq for cory on whovian (30 jun 2016)

   cd ~/s/work/priceLab/cory/piq
   makefile checked into github TReNA repo:

    ~/github/TReNA/inst/misc/footprintFinding/piq/makefile

   one outstanding question:  single chromosome bam file somehow produces hits on all chromosomes

     https://bitbucket.org/thashim/piq-single/issues/27/bam-file-for-chr20-only-footprints

*------------------------------------------------------------------------------------------------------------------------
* run piq for cory (30 jun 2016)

  [see "grok piq for cory" below]

  cd ~/s/work/priceLab/cory/piq/
  scp pshannon@whovian:/local/Cory/for_Paul/ENCSR000DBY.chr20.bam .    # 62M

  make targets: pwmHits, bamConvert, call

*------------------------------------------------------------------------------------------------------------------------
* grok piq for cory (30 jun 2016)

  paper: http://www.nature.com/nbt/journal/v32/n2/full/nbt.2798.html

  --- setup
     https://bitbucket.org/thashim/piq-single/src
     cd ~/github

  git clone https://bitbucket.org/thashim/piq-single.git

  biocLite("BSgenome.Hsapiens.UCSC.hg38")
  R -f common.r

   --- trial run.  jasparfix.txt has 1316 entries
     Rscript pwmmatch.exact.r common.r pwms/jasparfix.txt 139 ~/tmp/piq.out

    pwm 139 seems to be  >MA0139.1;CTCF
      A  [ 87 167 281  56   8 744  40 107 851   5 333  54  12  56 104 372  82 117 402 ]
      C  [291 145  49 800 903  13 528 433  11   0   3  12   0   8 733  13 482 322 181 ]
      G  [ 76 414 449  21   0  65 334  48  32 903 566 504 890 775   5 507 307  73 266 ]
      T  [459 187 134  36   2  91  11 324  18   3   9 341   8  71  67  17  37 396  59 ]

   --- results   ~/tmp/piq.out/

    1822688 Jun 30 11:48 139.pwmout.RData
    1823146 Jun 30 11:50 139.pwmout.rc.RData

    print(sort(noquote(load("~/tmp/piq.out/139.pwmout.RData"))))
      [1] chrstr:    the 93 chromomome names in the genome file
      [2] clengths:   93 integers, counts of pwm matches per chromosome, fivenum:   0    2    6  787 8341
                      chr1 has 8341 hits
      [3] coords: :   a list of IRanges, each as long as the pmw is wide, locations of hits?
      [4] coords.pwm:  fivenum(coords.pwm[[1]]): [1]  7.445832  7.905765  8.585242  9.802982 17.574774
                       scores?
      [5] coords.short: 81 IRanges - not sure what makes this subset.  each is 19 bsaes long
      [6] coords2:   81 IRanges, each 600 bases long
      [7] ipr:       4 * 19 matrix  fivenum(ipr) # -51.4821434  -2.5659056  -0.9420577   0.5246537   1.3774740
      [8] ncoords:   chromosome names.  names(coords.short) == ncoords
      [9] pwmin:     pwm IN
     [10] pwmname: "MA0139.1;CTCF"

   --- now run again, but this time with hg38
    modify common.r:

      # load genome file
      suppressMessages(bis("BSgenome.Hsapiens.UCSC.hg38"))
      genome = BSgenome.Hsapiens.UCSC.hg38

    mkdir ~/tmp/piq.out.hg38
    Rscript pwmmatch.exact.r common.r pwms/jasparfix.txt 139 ~/tmp/piq.out.hg38


*------------------------------------------------------------------------------------------------------------------------
* jocelyn has 3 long sequences for the fimo server (29 jun 2016)

   cd ~/github/fimoService/client-R/FimoClient/inst/extdata/
   print(load("jp_sequence_fasta.RData"))  # [1] "seqs"

*------------------------------------------------------------------------------------------------------------------------
* elpy, an ess-like python environment for emacs (29 jun 2016)

   git clone https://github.com/jorgenschaefer/elpy.git
   pip install rope
   pip install jedi
   pip install flake8
   pip install importmagic
   pip install autopep8
   pip install yapf

   Evaluate this in your *scratch* buffer:

    (require 'package)
    (add-to-list 'package-archives
             '("elpy" . "https://jorgenschaefer.github.io/packages/"))

  Then run to load the contents of the new repository, and to install elpy.
     M-x package-refresh-contents
     M-x package-install RET elpy RET

Finally, add the following to your .emacs:

(package-initialize)
(elpy-enable)



*------------------------------------------------------------------------------------------------------------------------
* tulip-python 4.8.1

  app installed via dmg in /Applications/Tulip-4.8.1.app

  got wheel from https://pypi.python.org/pypi/tulip-python#downloads
     # now cp35 - c python 3.5
  pip install ~/Downloads/tulip_python-4.8.1-cp35-cp35m-macosx_10_6_intel.macosx_10_9_intel.macosx_10_9_x86_64.macosx_10_10_intel.macosx_10_10_x86_64.whl
    Installing collected packages: tulip-python
    Successfully installed tulip-python-4.8.1

   to here? /Users/paul/anaconda/lib/python3.5/site-packages/tulip_python-4.8.1.dist-info/
   test:  from tulip import *   # works!

  cd ~/s/examples/tulip/v0


*------------------------------------------------------------------------------------------------------------------------
* matt richards maripaludis demo (29 jun 2016)

  --- webapp
    cd ~/github/metnetViz/webapps/v0/
    R -f build.R   # creates, lays out, applies style which highlights flux

*------------------------------------------------------------------------------------------------------------------------
* rsid, snp, reported by liz blue, useful for demonstrating getdna and fimo microservices (28 jun 2016)

    rs146894928

   http://www.ncbi.nlm.nih.gov/projects/SNP/snp_ref.cgi?rs=146894928

   chr1:172883225  C/T on forward strand

*------------------------------------------------------------------------------------------------------------------------
* python tips: parse xml, read document on web, reverseComplement (27 jun 2016)

   --- see also ~/github/getDNA/client-python/
    which employes a DAS server provided by ucsc

from lxml import etree

def getSequence(chromosome, start, end, reverseComplement=False):
    base = 'http://genome.ucsc.edu/cgi-bin/das/hg19/dna?segment='
    url = base + chromosome + ':' + str(start) + ',' + str(end)
    doc = etree.parse(url)
    if doc == '':
       return('THE SEQUENCE DOES NOT EXIST FOR GIVEN COORDINATES')
    sequence = doc.xpath('SEQUENCE/DNA/text()')[0].replace('\n','').upper()
    if(reverseComplement):
       sequence = revComp(sequence)
    return(sequence)

def revComp(sequence):
   complement = {'A': 'T', 'C': 'G', 'G': 'C', 'T': 'A'}
   result = "".join(complement.get(base, base) for base in reversed(sequence))
   return(result)

*------------------------------------------------------------------------------------------------------------------------
* getDNAClient, next up (24 jun 2016)

  cd ~/github/getDNA/client-R/getDNAClient/inst/unitTests

  getSequenceByLocString   # as test_getSequenceByLocString shows, this may be all we need
                           # with lapply doing iteration when needed

*------------------------------------------------------------------------------------------------------------------------
* memory leak and rogue pointer with rzmq (I think): try out pdbZMQ (23 jun 2016)

   https://github.com/RBigData/pbdZMQ

   cd  ~/github/fimoService/server
   make -f makefile.pshannon

   cd ~/github/fimoService/explore/pdbZMQ/
   R -f client.R

   --- next up:
     try this in ~/github/fimoService/client-R/FimoClient/R/FimoClient.R

*------------------------------------------------------------------------------------------------------------------------
* matt richards maripaludis demo (23 jun 2016)

  --- webapp
    cd ~/github/metnetViz/datasets/Maripaludis/inst/prep/v0/
    R -f build.R   # creates, lays out, applies style which highlights flux

  --- using Chinook dataset
    ~/github/metnetViz/datasets/Maripaludis

  --- current network creation with RCyjs
    cd /Users/paul/github/metnetViz/datasets/Maripaludis/inst/prep/v0
    R -f build.R

  --- old network creation with RCyjs
      (from below)
    * reproduce matt richards maripaludis metabolic network (20 may 2016)
       cd  ~/s/work/priceLab/mattRichards/try0
       R> source("toTables.R"); rcy <- run(TRUE)
       readAndApplyLayout(rcy, "organicLayout.tsv"); fit(rcy)
       readAndApplyLayout(rcy, "orthogonalLayout.tsv"); fit(rcy)
       readAndApplyLayout(rcy, "radialLayout.tsv"); fit(rcy)


*------------------------------------------------------------------------------------------------------------------------
* ess emacs R configuration

   --- install the latest R

   --- M-x customize-variable   inferior-R-program-name
     leads to a buffer with interactive input and buttons
     look for bright blue "Inferior R Program Name"  and add in /usr/local/bin/R
     click "Apply and Save" button just above
     see that this is added to the bottom of .emacs:
        (custom-set-variables
         ;; custom-set-variables was added by Custom.
         ;; If you edit it by hand, you could mess it up, so be careful.
         ;; Your init file should contain only one such instance.
         ;; If there is more than one, they won't work right.
         '(display-time-mode t)
         '(gud-gdb-command-name "gdb --annotate=1")
         '(inferior-R-program-name "/usr/local/bin/R")
         '(large-file-warning-threshold nil)
         '(tool-bar-mode nil))

    --- get and use latest ess
      git clone https://github.com/emacs-ess/ESS.git  or cd <there> and git pull .

    --- within .emacs
      (add-to-list 'load-path "~/github/ESS/lisp")
      (load "ess-site")   // finds ~/github/ESS/lisp/ess-site.el
      (ess-toggle-underscore nil)


*------------------------------------------------------------------------------------------------------------------------
* trouble building meme 4.11.2 on whovian - fixed! (29 jun 2016)

   ./configure --prefix=/local/tools/meme --with-url=http://meme-suite.org --enable-build-libxml2 --enable-build-libxslt$
   make clean
   make
   make check
   make install

   2427790 Jun 29 12:48 /local/tools/meme/bin/fimo


*------------------------------------------------------------------------------------------------------------------------
* trouble building  meme 4.11.2 on whovian (16,20 jun 2016)

  whovian, cd /local/pshannon/meme_4.11.2/
   following advice found here:   http://meme-suite.org/doc/general-faq.html#Q007

    Q. MEME Suite won't compile! I get error messages about libxml2 or libxslt. What should I do?

     pA. libxml2 is a library for parsing XML files. libxslt is a library for processsing XML files. using
     XSLT stylesheets. MEME Suite will try to use the versions of these libraries already installed on your
     system. If the libraries can't be found on your system, MEME Suite will build its own copies from source
     included in the MEME Suite distribution. If MEME Suite detects a local copy of libxml2, but no local
     copy of libxslt, it will try to build its own copy of libxslt, but it may run into conflicts between
     the installed versions of libxml2 and included version of libxslt that will keep MEME suite from compiling.
     If you run into this problem you can force MEME Suite to build both libraries from the included source.
     Just add the options --enable-build-libxml2 and --enable-build-libxslt to your configure command line.
     For further information about configure options see the installation guide.



  ./configure --prefix=/local/tools/meme --with-url=http://meme-suite.org --enable-build-libxml2 --enable-build-libxslt
  make
   ...
  libtool: link: gcc -I../src/libxml2/include -std=gnu89 -Wall -Wno-unused -DUNIX -D__USE_FIXED_PROTOTYPES__ -O3 -o ama ama-ama.o  ./.libs/libcommon.a ../src/libxml2/.libs/libxml2.a -lz -lm
  ./.libs/libcommon.a(lt65-libxslt_la-documents.o): In function `xsltLoadDocument':
  documents.c:(.text+0x5ec): undefined reference to `xmlXIncludeProcessFlags'
  ./.libs/libcommon.a(lt68-libxslt_la-functions.o): In function `xsltDocumentFunction':
  functions.c:(.text+0x9b3): undefined reference to `xmlXPtrNewContext'
  functions.c:(.text+0x9cf): undefined reference to `xmlXPtrEval'


   --- email to developers at uw:

ear meme suite developers,

Thank you for this fine collection of tools.

I encountered link errors when building version 4.11.2 on linux, with several xml related references unresolved.

Perhaps you can help?

Thank you!

- Paul

uname -a
Linux whovian.systemsbiology.net 3.8.13-68.1.3.el7uek.x86_64 #2 SMP Wed Apr 22 11:51:54 PDT 2015 x86_64 x86_64 x86_64 GNU/Linux

./configure --prefix=/local/tools/meme --with-url=http://meme-suite.org --enable-build-libxml2 --enable-build-libxslt

make
...
libtool: link: gcc -I../src/libxml2/include -std=gnu89 -Wall -Wno-unused -DUNIX -D__USE_FIXED_PROTOTYPES__ -O3 -o ama ama-ama.o  ./.libs/libcommon.a ../src/libxml2/.libs/libxml2.a -lz -lm
./.libs/libcommon.a(lt65-libxslt_la-documents.o): In function `xsltLoadDocument':
documents.c:(.text+0x5ec): undefined reference to `xmlXIncludeProcessFlags'
./.libs/libcommon.a(lt68-libxslt_la-functions.o): In function `xsltDocumentFunction':
functions.c:(.text+0x9b3): undefined reference to `xmlXPtrNewContext'
functions.c:(.text+0x9cf): undefined reference to `xmlXPtrEval'
collect2: error: ld returned 1 exit status

*------------------------------------------------------------------------------------------------------------------------
* more detail on liz blues chr1/18 twoFamiliesCoSegregatedSNPs.raw file into a hg38 liftover bed (20 jun 2016)

       X.pattern.name sequence.name start stop strand   score  p.value  q.value matched.sequence chrom  snpStart            name
1            MA0160.1           alt     2    9      + 12.3131 2.67e-05 0.000428         GAGGTCAC  chr1 172883225 rs146894928:C-T
2 sci09.v2_Nr2f2_2192           alt     1   10      - 11.4771 6.22e-05 0.000497       TGTGACCTCA  chr1 172883225 rs146894928:C-T
3            MA0018.2           alt     1    8      + 11.3964 7.40e-05 0.001180         TGAGGTCA  chr1 172883225 rs146894928:C-T
4 sci09.v1_Nr2f2_2192           alt     1   10      + 11.2857 8.67e-05 0.000694       TGAGGTCACA  chr1 172883225 rs146894928:C-T

*------------------------------------------------------------------------------------------------------------------------
* parse liz blue's chr1 chr18 twoFamiliesCoSegregatedSNPs.raw file into a hg38 liftover bed (20 jun 2016)

   cd ~/s/work/priceLab/cory/elizabethBlue/
   source("emailtoBedFile.R")

   source("runFimo.R")
   source("~/s/work/priceLab/cory/motifLossGainTest/go.R")
   getDNA("hg38", "chr1", 171998915, 171998915)  # gets same G listed as ref in row 1


[1] 7  rs146894928:C-T  ref: TGAGGCCACAG  alt: TGAGGTCACAG
       X.pattern.name sequence.name start stop strand   score  p.value  q.value matched.sequence
1            MA0160.1           alt     2    9      + 12.3131 2.67e-05 0.000428         GAGGTCAC
2 sci09.v2_Nr2f2_2192           alt     1   10      - 11.4771 6.22e-05 0.000497       TGTGACCTCA
3            MA0018.2           alt     1    8      + 11.3964 7.40e-05 0.001180         TGAGGTCA
4 sci09.v1_Nr2f2_2192           alt     1   10      + 11.2857 8.67e-05 0.000694       TGAGGTCACA
[1] 8  rs142949221:G-A  ref: ATAGGGTTAGC  alt: ATAGGATTAGC
  X.pattern.name sequence.name start stop strand   score  p.value  q.value matched.sequence
1       MA0648.1           alt     2   11      - 11.2830 6.05e-05 0.000484       GCTAATCCTA
2       MA0891.1           alt     2   11      - 10.6271 7.43e-05 0.000594       GCTAATCCTA
3       MA0714.1           alt     3   11      - 11.0577 7.48e-05 0.000897        GCTAATCCT
4       MA0712.1           alt     3   10      - 11.2766 9.01e-05 0.001440         CTAATCCT
[1] 19  rs4797436:C-T  ref: GGAAGCCAATC  alt: GGAAGTCAATC
  X.pattern.name sequence.name start stop strand   score  p.value  q.value matched.sequence
1       MA0676.1           alt     1    9      + 11.3065 7.72e-05 0.000926        GGAAGTCAA
[1] 28  rs77127090:T-G  ref: CACTTTGCAGC  alt: CACTTGGCAGC
  X.pattern.name sequence.name start stop strand   score  p.value  q.value matched.sequence
1       MA0670.1           alt     2   11      - 12.5778 4.14e-05 0.000331       GCTGCCAAGT
2       MA0671.1           alt     3   11      - 10.4894 7.20e-05 0.000864        GCTGCCAAG


*------------------------------------------------------------------------------------------------------------------------
* fimoService setup

   --- on whovian (20 jun 2016)
     wc -l /Users/paul/s/work/priceLab/cory/footprintWorkflow/JASPAR_CORE_plus_seth.meme #  1059
     FIMO="/local/Cory/meme_4.10.2/src/fimo"

*------------------------------------------------------------------------------------------------------------------------
* 56 terabytes of disk space for priceLab (20 jun 2016)

  /proj/bdds
  nfs monted, so alos visible on whovian and buffy (along with price[1-3]


   on mac or pc:   smb://farfisa.systemsbiology.net/bdds

*------------------------------------------------------------------------------------------------------------------------
* test out fimo service on a bunch of variants from elizabeth blue (17 jun 2016)


*------------------------------------------------------------------------------------------------------------------------
* python module, class and unittest examples (20 jun 2016)

   ~/s/examples/python/moduleExample/
   ~/s/examples/python/classExample/

*------------------------------------------------------------------------------------------------------------------------
* build fimo on whovian

  --- old (usable) version available

     /local/Cory/meme_4.10.2/src/fimo --version   # 4.10.2

*------------------------------------------------------------------------------------------------------------------------
* python runFimo (16 jun 2016)

  cd ~/s/examples/zmq/py/runFimo/
  exec(open("runFimo.py").read()); runTests()

*------------------------------------------------------------------------------------------------------------------------
* python zmq: exchange pandas dataframes (14 jun 2016)

   cd ~/s/examples/zmq/py/reqrep-json-readTable/
   client.py
   server.py

*------------------------------------------------------------------------------------------------------------------------
* python pandas dataframe (14 jun 2016)

   import pandas
   tbl = pandas.read_csv("fimo.txt", delimiter="\t")
   tbl.shape  # (4, 9)
   pandas.DataFrame.to_json(tbl)
      '{"#pattern name":{"0":"MA0076.2","1":"ELK1,4_GABP{A,B1}.p3","2":"ETV6_full_2","3":"MA0645.1"},"sequence name":{"0":"te

   pandas.read_json(pandas.DataFrame.to_json(tbl))   # sorts columns alphabetically by column title

*------------------------------------------------------------------------------------------------------------------------
* python zmq req/rep json demo, minimal example (14 jun 2016)

   cd ~/s/examples/zmq/py/reqrep-json/
     server.py
     client.py

   --- on client
     socket.send_json({'clientCounter': request})
     message = socket.recv_json()


   --- on server:
     request = socket.recv_json()
     clientCounter = request['clientCounter']

     obj = {'a': clientCounter, 'b': clientCounter * clientCounter}
     socket.send_json(obj)



*------------------------------------------------------------------------------------------------------------------------
* python zmq req/rep demo, minimal example (14 jun 2016)

  ~/s/examples/zmq/py/reqrep/server.py
  create two shells
  python -i server.py
  python -i client.py

*------------------------------------------------------------------------------------------------------------------------
* try out fimo on TERT 10 base pair wt sequence, and mutant motif gain sequence (14 jun 2016)

   cd /s/work/priceLab/cory/footprintWorkflow

   ~/meme/bin/fimo  ./JASPAR_CORE_plus_seth.meme  tertWT.fa

*------------------------------------------------------------------------------------------------------------------------
* TERT promoter motif gain mutation (14 jun 2016)

   cd ~/s/work/priceLab/cory/motifLossGainTest    file go.R

     # test with TERT promoter gained motif
     # chr5, 1,295,228 C>T and 1,295,250 C>T; hereafter termed C228T and C250T,
     #   Both C228T and C250T generated an identical 11-bp nucleotide stretch (5′-CCCCTTCCGGG-3′)
     #   the originals of these two must be
     #      (5′-CCCCCTCCGGG-3′)   yes   wt1      forward: CCCGGAGGGGG
     #      (5′-CCCCTCCCGGG-3′)   yes   wt2      forward: CCCGGGAGGGG

       chr5   -    1295116   1295232    117     chr5:1295116,1295126
       CCCCCTCCGGG  (wt1)     # on + strand: CCCGGAGGGGG
  CCCAGCCCCCTCCGGGCCCTCCCAGCCCCTCCCCTTCCTTTCCGCGGCCCCGCCCTCTCCTCGCGGCGCGAGTTTCAGGCAGCGCTGCGTCCTGCTGCGCACGTGGGAAGCCCTGGCCCCGGCCACCCCCGCGATGCCGCGCGC

    tss <- 1295262

    ---- wt 1
      getDNA("hg19", "chr5", tss-40, tss-30, reverseComplement=FALSE) #  "CCCGGAGGGGG"
      getDNA("hg19", "chr5", tss-40, tss-30, reverseComplement=TRUE)  #  "CCCCCTCCGGG"

    ---- wt 2
      getDNA("hg19", "chr5", tss-17, tss-7, reverseComplement=FALSE)  #  "CCCGGGAGGGG"
      getDNA("hg19", "chr5", tss-17, tss-7, reverseComplement=TRUE)   #  "CCCCTCCCGGG"
      getDNA("hg19", "chr5", 1295245, 1295255, reverseComplement=TRUE)   #  "CCCCTCCCGGG"

       getDNA("hg19", "chr5", 1295116, 1295126, rev=TRUE)

     getDNA("hg19", "chr5", 1295116, 1295126) # [1] "CCGGGGCCAGG"

     wt1, reverse strand:  CCCCCTCCGGG      revComp(CCCGGAGGGGG)

*------------------------------------------------------------------------------------------------------------------------
* getSeq, get sequence from bsgenome object

  biocLite("BSgenome.Hsapiens.NCBI.GRCh38")
  library(BSgenome.Hsapiens.NCBI.GRCh38)
  hg38 <- BSgenome.Hsapiens.NCBI.GRCh38
  getSeq(hg38, "5", 1295228, 1295250)

    23-letter "DNAString" instance
    seq: CGTGGGAAGCGCGGTCCTGGGCG


   getSeq(hg39, "5", 1295220, 1295236)  #   17-letter "DNAString" instance

    20 2 4 6 8
     CTCCGCCACGTGGGAAG

     C228T
     CTCCGCCATGTGGGAAG

   biocLite("BSgenome.Hsapiens.UCSC.hg18")
   library(BSgenome.Hsapiens.UCSC.hg18)
   hg18 <- BSgenome.Hsapiens.UCSC.hg18

  getSeq(hg18, "chr5", 1295220, 1295236) #   17-letter "DNAString" instance
  20 2 4 6 8
   GCAAACCTTCAGAAGCC

   C228T?


*------------------------------------------------------------------------------------------------------------------------
* getDNA(genome, chrom, start, end)  from ucsc DAS (14 jun 2016)

  cd ~/s/work/priceLab/cory/motifLossGainTest/go.R
  R -f /Users/paul/s/work/priceLab/cory/motifLossGainTest/go.R

*------------------------------------------------------------------------------------------------------------------------
* get fimo by installing meme suite, version 4.11.2  may 5 2016 (13 jun 2016)

   cd ~/source/meme/meme_4.11.2/
   ./configure --prefix=$HOME/meme --with-url="http://meme-suite.org"
   make
   make test
   make install

   --- tert gain of motif test

   light-induced damage (chr5, 1,295,228 C>T and 1,295,250 C>T; hereafter termed C228T and C250T,
    can't get these to  quite fit (pshannon, 18 may 2017)
   rs2853669:   chr5:1,295,234   C/T
   rs796832466: chr5:1,295,349

   chr5:1,295,228-1,295,250
   looking for (both C228T and C250T generated an identica)l 11-bp nucleotide stretch (5′-CCCCTTCCGGG-3′)
   containing a consensus binding site for E-twenty-six (ETS) transcription factors (GGAA, reverse
   complement) within the TERT promoter region.

     GGAA -> CCTT  (the ETS binding motif)

     ucsc genome browser, hg38, tert chr5:1,253,167-1,295,047 41,881 bp
                          hg37       chr5:1,253,287-1,295,162 41,876 bp.

   http://genome.ucsc.edu/cgi-bin/das/hg19/dna?segment=chr5:1295220,1295260
  <SEQUENCE id="chr5" start="1295220" stop="1295260" version="1.00">
     <DNA length="41">ggcccggagggggctgggccggggacccgggaggggtcggg</DNA>
  </SEQUENCE>



*------------------------------------------------------------------------------------------------------------------------
* cory, fimo, and ALL the footprints (even those unmapped to a motif) (13 jun 2016)

   gain of motif, loss of motif

  cd ~/s/work/priceLab/cory/footprintWorkflow

  --- email 10 jun 2016

    Here's the small bit of code I run for FIMO in connecting the footprints with the motifs:
    # intersect with fimo
    #/bin/bash/
    files=`ls -1 /scratch/all_bed/fasta/*.fa`
    for i in $files
       do
	name=`echo "$i" | cut -f 5 -d "/" | cut -f 1 -d "."`
	mkdir -p /scratch/fimo_out/$name
	fimo --oc --text /scratch/fimo_out/$name/ --no-qvalue /scratch/resources/all_motifs.meme /scratch/all_bed/fasta/$name.fa & > /scratch/fimo_out/$name.fimo.txt
      done
   Here's the FIMO website for installing the program:  http://meme-suite.org/doc/download.html?man_type=web
   Here's the collection of meme PWM from Seth:

   --- looking for well-attested & interesting

     http://www.nature.com/nrg/journal/v17/n2/full/nrg.2015.17.html?WT.feed_name=subjects_genomic-instability

     As more whole genomes are analysed, we are likely to see new types of mutational effects; for
     example, most known point mutations related to oncogenesis lead to gain of TF motifs, and we
     expect to see examples of mutations leading to loss of motifs. Below, we discuss some case
     studies in which non-coding variants disrupt regulatory elements or create new ones (Fig. 4).

    --- TERT, gain of motif

      http://www.ncbi.nlm.nih.gov/pmc/articles/PMC4423787/
       "Highly recurrent TERT promoter mutations in human melanoma"

    Gain of TF-binding sites. TERT (telomerase reverse transcriptase) encodes the catalytic subunit
    of the enzyme telomerase. Telomerase lengthens telomeres, allowing cells to escape apoptosis and
    become cancerous. TERT expression is generally repressed in normal somatic cells, but can be
    overexpressed in cancer67. In the past few years, numerous studies have reported recurrent
    mutations in the promoter of TERT in many different cancer types15, 67, 68, 69. These mutations
    create binding motifs for the ETS family of TFs, including TCFs (ternary complex factors),
    leading to their binding to the TERT promoter and subsequent upregulation of gene expression
    (Fig. 4B). Tumours in tissues with relatively low rates of self-renewal (including melanomas,
    urothelial carcinomas and medulloblastomas) tend to exhibit higher frequencies of TERT promoter
    mutations69. The high occurrence of these mutations points to their role as driver as opposed to
    passenger mutations.

    Both C228T and C250T generated an identical 11-bp nucleotide stretch (5′-CCCCTTCCGGG-3′)
    containing a consensus binding site for E-twenty-six (ETS) transcription factors (GGAA, reverse
    complement) within the TERT promoter region.

    Analysis of whole-genome sequencing data from malignant melanomas (1, 2) revealed two somatic
    telomerase reverse transcriptase (TERT) gene promoter mutations in 17 of 19 (89%) cases
    examined. The average sequence coverage at the TERT promoter locus was 30-fold in normal samples
    and 60-fold in tumor samples (fig. S1A). Each of these promoter mutations resulted in a
    cytidine-to-thymidine transition at a dipyrimidine motif indicative of ultraviolet (UV)
    light–induced damage (chr5, 1,295,228 C>T and 1,295,250 C>T; hereafter termed C228T and C250T,
    respectively), and both mutations localized within 100 base pairs (bp) of the TERT
    transcriptional start site (TSS) (mean allelic fraction, 0.32; range, 0.07 to 0.55) (table
    S1). We validated these mutations by means of polymerase chain reaction and Sanger sequencing
    tumor/normal sample pairs from both the discovery set (Fig. 1A and fig. S1, B and C) and an
    extension set of 51 additional melanoma tumor/normal sample pairs. Within this extension set, 33
    tumors (65%) harbored one of the mutations. Moreover, the mutations were mutually exclusive in
    both the discovery and extension sets (P = 5.4 × 10−7, Fisher’s one-sided exact test). Two
    tumors with a C228T transition also contained an adjacent C>T transition (at position chr5,
    1,295,229), which is indicative of a dinucleotide CC>TT transition. Together, these TERT
    promoter mutations were observed in 50 of 70 (71%; 95% confidence interval: 59 to 82%,
    Clopper-Pearson method) melanomas examined (Fig. 1B and table S1).

*------------------------------------------------------------------------------------------------------------------------
* jquery datatable simple javascript array table demo (13 jun 2016)

   ~/github/gists/jQueryDataTableLoadFromArray

*------------------------------------------------------------------------------------------------------------------------
* rcyjs error seen: ERROR: [on_request_read] parse error (13 jun 2016)

  ERROR: [on_request_read] parse error
  packageVersion("httpuv") # [1] '1.3.3'


*------------------------------------------------------------------------------------------------------------------------
* rcyjs demo for christopher clarkson, posted to bioc support list (13 jun 2016)

  cd ~/s/work/rcy/bioc-support-question-jun2016/
  demo.R

*------------------------------------------------------------------------------------------------------------------------
* officer tuttle (sp?) from south precinct, concerning painting on trees for ghs beer bash (?) 10 jun 2016

  206.379.1494

*------------------------------------------------------------------------------------------------------------------------
* tooltip for metnet chinook network viewer, matt richards (10 jun 2016)

  --- get simple example working, follow example on cyjs homepage

    view-source:  http://js.cytoscape.org/demos/546dd8ca4872cc87106a/

<html>
<head>
<link href="style.css" rel="stylesheet" />
<meta charset=utf-8 />
<meta name="viewport" content="user-scalable=no, initial-scale=1.0, minimum-scale=1.0, maximum-scale=1.0, minimal-ui">
<title>qTip extension</title>
<script src="http://ajax.googleapis.com/ajax/libs/jquery/1/jquery.min.js"></script>
<script src="../../js/cytoscape.min.js"></script>
<script src="http://cdnjs.cloudflare.com/ajax/libs/qtip2/2.2.0/jquery.qtip.min.js"></script>
<script src="http://cdnjs.cloudflare.com/ajax/libs/qtip2/2.2.0/jquery.qtip.min.js"></script>
<link href="http://cdnjs.cloudflare.com/ajax/libs/qtip2/2.2.0/jquery.qtip.min.css" rel="stylesheet" type="text/css" />
<script src="https://cdn.rawgit.com/cytoscape/cytoscape.js-qtip/2.2.5/cytoscape-qtip.js"></script>
<script src="code.js"></script>
<link href="style.css" rel="stylesheet" type="text/css" />
</head>
<body>
<div id="cy"></div>
</body>
</html>


   --- here is code.js
$(function(){ // on dom ready

var cy = cytoscape({

  container: document.getElementById('cy'),

  boxSelectionEnabled: false,
  autounselectify: true,

  elements: {
    nodes: [
      { data: { id: 'n', label: 'Tap me' } }
    ]
  },

  layout: {
    name: 'grid',
    padding: 100
  },

  ready: function(){
    window.cy = this;
  },

  style: 'node { content: data(label); }'
});

// you can use qtip's regular options
// see http://qtip2.com/
cy.$('#n').qtip({
  content: 'Hello!',
  position: {
    my: 'top center',
    at: 'bottom center'
  },
  style: {
    classes: 'qtip-bootstrap',
    tip: {
      width: 16,
      height: 8
    }
  }
});

}); // on dom ready



*------------------------------------------------------------------------------------------------------------------------
* netlogo purple_membrane model:  can we make it browser-ready? (9 jun 2016)

   --- 13 mar 2017
     language spec changed?
     error message: (Breed declarations must have plural and singular. BREED [NODES] has only one name.)

     language spec: In NetLogo 6.0, you must specify both plural and singular breed names. In prior
     versions, declarations like breed [mice] were legal, but this support has been removed in
     6.0. If you have models which use only plural breed names, it is recommended that you convert
     them to specify both names before opening in 6.0 since doing so will permit the NetLogo
     converter to work most effectively on any other code in your model which needs conversion.

     fix:
       breed [nodes nodeSingle]   # initially [nodes node] but   let selectables turtles with [ breed = nodes ]
       breed [edges edge]
       breed [edge-heads edge-head]
       breed [edge-bodies edge-body]

    --- seems to work
      committed to github



   http://www.netlogoweb.org/launch#https://raw.githubusercontent.com/baliga-lab/purple_membrane/master/purple_membrane_browserVersion.nlogo
   cd ~/github/purple_membrane

   ---- this version works in the 5.3.1 desktop app: fromWebsite.nlogo
     /Applications/NetLogo\ 5.3.1/NetLogo\ 5.3.1.app/Contents/MacOS/NetLogo &
     click start/reset button
     click go   ;; nothing happens however
     move sliders, see node sizes change

   ---- will this work in the browser? no!
     cp fromWebsite.nlogo pmBrowser.nlogo
     http://www.netlogoweb.org/      ;; click, random model is launched, do file upload
     loading pmBrowser.nlogo leads to error reports

   ---- retrieve browser-compatible version, which runs on desktop & web, albeit with stubby links
      cp purple_membrane.nlogo stubbyLinks.nlogo
      problem? line and arrow turtles (maybe all turtles) are positioned by the centers, rather than
         by an end.

     ---  turtle 27 is the green edge bop -> bacterioRhodopsin
        heading 135
        xcor  -6.5
        ycor -7
        size 17

        show [size] of turtle 27  ;; observer: 17
        ask turtle 27 [set size 17]
        ask turtle 27 [set heading 135]
        ask turtle 27 [set ycor -7]
        ask turtle 27 [set xcor -6.5]

     --- turtle 28, green target arrow, bop -> bacterioRhodopsin
        heading 135, xcor -1.5, ycor -12, size 1.5


     --- purple_membrane_browserVersion.nlogo
       has all the edge and arrow geometries

    after starting a simple python 3 web server in ~/github/purple_membrane/
    this worked:

       python -m http.server 9009
       http://www.netlogoweb.org/launch#http://localhost:9009/purple_membrane_browserVersion.nlogo

*------------------------------------------------------------------------------------------------------------------------
* igvR tips: display scored bed table for jocelyn, rearrange columns, compose name(9 jun 2016)

  cd ~/s/work/priceLab/jocelyn/chipseq/
   tbl <- read.table("DB_Mm_pQ_LXRa_0401.bed", sep="\t", as.is=TRUE, nrows=10)
        V1      V2      V3  V4 V5  V6
     1  chr1 3000217 3000397 179 44  99
     2  chr1 3000224 3000341 116 44  99

   colnames(tbl) <- c("chr", "start", "end", "score", "five", "six")
         chr   start     end score five six
     1  chr1 3000217 3000397   179   44  99
     2  chr1 3000224 3000341   116   44  99

   sprintf("%s:%d-%d", tbl$chr, tbl$start, tbl$end)
      [1] "chr1:3000217-3000397" "chr1:3000224-3000341" "chr1:3000329-3000531" "chr1:3000329-3000531" "chr1:3000512-3000577"
      [6] "chr1:3000687-3000762" "chr1:3000687-3000772" "chr1:3000687-3000800" "chr1:3000687-3000800" "chr1:3000688-3000773"
   tbl$name <- sprintf("%s:%d-%d", tbl$chr, tbl$start, tbl$end)

         chr   start     end score five six                 name
     1  chr1 3000217 3000397   179   44  99 chr1:3000217-3000397
     2  chr1 3000224 3000341   116   44  99 chr1:3000224-3000341

   tbl.ready <-  tbl[, c("chr", "start", "end", "name", "score")]
         chr   start     end                 name score
     1  chr1 3000217 3000397 chr1:3000217-3000397   179
     2  chr1 3000224 3000341 chr1:3000224-3000341   116
       10 chr1 3000688 3000773 chr1:3000688-3000773    84

  displayScoredFeatures(igv, tbl.ready, quiet=FALSE)



*------------------------------------------------------------------------------------------------------------------------
* Genome sequences of six Phytophthora species associated with forests in New Zealand

   ~/Documents/StudholmePhytophthora-2016.pdf
   ~/Documents/Duncan_PCR.pdf  Detection of Phytophthora in plants by the Polymerase Chain Reaction

*------------------------------------------------------------------------------------------------------------------------
* old version of cytoscape.js (8 jun 2016)

  macbook riptide: ~/http/js/cytoscape-2.6.1.min.js

  see also https://github.com/cytoscape/cytoscape.js/releases where zip & tarballs are archived

*------------------------------------------------------------------------------------------------------------------------
* install R 3.3.0 on buffy (7 jun 2016)

   zlib and bzip2 no longer included.  awful!
   see instructions to install these two here:

      http://pj.freefaculty.org/blog/?p=315

  ./configure --prefix=/local/R/R330 --enable-R-shlib --with-readline=no --with-x=no

   --- need zlib
      wget http://zlib.net/zlib-1.2.8.tar.gz                                                                                 |
      tar zxf zlib-1.2.8.tar.gz                                                                                              |
      cd zlib-1.2.8                                                                                                          |
      ./configure --prefix=$HOME/libs                                                                                        |
      mkdir ~/libs                                                                                                           |
      make                                                                                                                   |
      make install                                                                                                           |

   --- set up for R configure & make, suggested

    export PATH=$HOME/packages/bin:$PATH
    export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:$LD_LIBRARY_PATH
    export CFLAGS="-I$HOME/packages/include"
    export LDFLAGS="-L$HOME/packages/lib"

   --- set up for R configure & make, my adaptation

    export PATH=$HOME/libs/bin:$PATH
    export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:$LD_LIBRARY_PATH
    export CFLAGS="-I$HOME/libs/include"
    export LDFLAGS="-L$HOME/libs/lib"


   --- install bzip2
     make -f Makefile-libbz2_so
     make clean
     make
     make -n install PREFIX=$HOME/libs
     make install PREFIX=$HOME/libs


*------------------------------------------------------------------------------------------------------------------------
* install R 3.3.0 on whovian

  cd /users/pshannon/src/install/R-3.3.0

  ./configure --prefix=/local/tools/R/R330 --enable-R-shlib --with-readline=no --with-x=no
   make
   make install
   /local/tools/R/R330/bin/R


*------------------------------------------------------------------------------------------------------------------------
* cysjs tips: control node color via mapData: do NOT quote color names!

    "background-color":"mapData(flux, 0, 1000, white, red)",

*------------------------------------------------------------------------------------------------------------------------
* cyjs bug: node[>flux] is invalid selector

   [sidestepped by adding new node attribute: fluxType [negative, positive, missing]

   cd ~/github/metnetViz/datasets/Maripaludis/inst/prep/v0/
   source("build.R"); reproduce()

   {"selector": "node[flux>0]", "css" :{"background-color": "mapData(flux, 0.5, 200, white, red)"}},
   {"selector": "node[flux<0]", "css":{"background-color": "mapData(flux, -200, 0.5, green, white)"}},

   js.cytoscape.org/api/cytoscape.js-latest/cytoscape.min.js:62 The selector `node[>flux]`is invalid

   --- in javascript console

*------------------------------------------------------------------------------------------------------------------------
* maripaludis network construction move to ~/github/metnetViz/datasets/Maripaludis (7 jun 2016)

   previously: ~/github/vizMiscellany/metabolicNetworks/try0/* .
   now: want this in the package, for better containment
        cd /Users/paul/github/metnetViz/datasets/Maripaludis/inst/prep/v0

*------------------------------------------------------------------------------------------------------------------------
* netlogo tips: create random network, apply circular layout (6 jun 2016)

to setup
  clear-all
  create-turtles 5
  ;; turtle 1 creates links with all other turtles
  ;; the link between the turtle and itself is ignored
  ask turtle 0 [ create-links-with other turtles ]
  show count links ;; shows 4
  ;; this does nothing since the link already exists
  ask turtle 0 [ create-link-with turtle 1 ]
  show count links ;; shows 4 since the previous link already existed
  ask turtle 2 [ create-link-with turtle 1 ]
  show count links ;; shows 5
  ask turtles [set size 5]
  layout-circle turtles 8
end


*------------------------------------------------------------------------------------------------------------------------
* debugging broken purple membrane model, netlogo (6 jun 2016)

  loaded from ~/github/purple_membrane/purble_membrane.nlogo

  --- problem: nodes are not connected.  edges superimposed on single nodes

   bop: who=5, in-edges [(turtle 24)], out-edges [(turtle 27)], node-type "protein", breed "nodes", shape "square"
        inspect turtle 24
          shape "line" from (turtle 2), into (turtle 5), edge_type 0, breed edges
        inspect turtle 2, label "bat", breed nodes, shape "square"
          out-edges: [(turtle 18) (turtle 21) (turtle 24)]
          in-edges:  [(turtle 12) (turtle 15)]

    most visible problem: line (edge 24) from bop (node 5) to bat (node 2) has bad coordinates
       or more damningly, it is not a link but instead a turtle, but SHOULD be a turtle


    --- strategy
       create two node, one-edge network, sneak up on recreating the model



*------------------------------------------------------------------------------------------------------------------------
* von neumann machine simulator

  http://vnsimulator.altervista.org/en/

  variables:
    x: 12
    y: 80

   instructions:
     lod x
     add y
     stor z
*------------------------------------------------------------------------------------------------------------------------
* cory writes from montana (4 jun 2016)

  I'm trying out a different list of variants from Mariet and I either broke something or we have a
  new test case. The ZCWPW1 gene is on the negative strand, with the variants of interest being
  downstream from the promoter (the opposite direction we usually think of having the promoter).

  I tried putting a negative number as the "upstream" variable and it didn't like it. I've attached
  my code and variant list. I'm hoping you can troubleshoot. I think I'm also better understanding
  what a gist is good for!

   cd ~/s/work/priceLab/cory/mariet-zcwpw1-snps/

*------------------------------------------------------------------------------------------------------------------------
* 3js browserViz (4 jun 2016)

  ~/github/threejs-cookbook/experiments/
  # cd ~/github/browserViz/3js  (not sure about this)

  use ~/s/examples/js/three/particles/index.html for minimalist exploration

*------------------------------------------------------------------------------------------------------------------------
* inspired by 3js cookbook and the TrackballControls, try maripaludis radial layout (3 jun 2016)

   cd ~/github/threejs-cookbook/pshannon/study/spiral
   cp ~/github/vizMiscellany/metabolicNetworks/try0/radialLayout.tsv .

   --- R
     s <- toJSON(head(tbl), pretty=TRUE)
    write(paste("g <- ", s), file="radial.json")


*------------------------------------------------------------------------------------------------------------------------
* 3js cookbook: create particle system from scratch, lovely green spiral, adapt (3 jun 2016)

   cd ~/github/threejs-cookbook/pshannon/study/spiral

*------------------------------------------------------------------------------------------------------------------------
* 3js cookbook, cow pointcloud examples uses orbitControls, try in greengenes? (3 jun 2016)

   see working example:
      cd ~/github/threejs-cookbook
      /Users/paul/anaconda/bin/python -m http.server 8003
      browse to
         http://localhost:8003/06-particles-postprocessing/06.01-create-particle-system-from-geometry.html
      picks up these libraries:
          <script src="../libs/OrbitControls.js"></script>

    orbit controls not quite what i want

*------------------------------------------------------------------------------------------------------------------------
* greengenes in 3js, figure out camera angle etc (3 jun 2016)

   cd ~/github/three.js/examples/pshannon/pointsBillboards/
   add newlines per node to make emacs and other editing easier:
      sed -e s/\},\{/\},X\{/g greenGenesFullLayout.json | tr X '\n'> greenGenesFullLayoutLines.json
   198k lines loads very quickly into emacs

   -- read into R to learn full xy scale
   s <- scan("greenGenesFullLayoutLines.json", sep="\n", what=character(0), skip=1)
   x <- fromJSON(s)
   class(x) # [1] "data.frame"
   dim(x)   # [1] 198643      3
   head(x)
            id        x       y
      1 n99324 34087.94 5474.07
      2 n99325 34087.94 5544.07
      3 n99326 32965.44 5594.07
   range(x$x) # [1]       9.5 2806567.1
   range(x$y) # [1]   25.00 8044.07

  --- 100 nodes: can we see them all?
    head -100 greenGenesFullLayoutLines.json > g100.json  # hand edit last line to close array
    <script src="g100.json"></script>
    f <- "g100.json"
    tbl <- fromJSON(scan(f, sep="\n", what=character(0), skip=1)); range(tbl$x); range(tbl$y)
     fivenum(tbl$x);   # 9.500   383.875   927.000  1429.500 34087.938
     fivenum(tbl$y)    # 5474.07 5994.07 6094.07 6144.07 6294.07

    camera.position.set(927, 6094, -1000)
    camera.lookAt(new THREE.Vector3(927, 6094, 0))
    renderer.render(scene, camera)


     f <- "greenGenesFullLayoutLines.json"
     tbl <- fromJSON(scan(f, sep="\n", what=character(0), skip=1)); range(tbl$x); range(tbl$y)
     fivenum(tbl$x); # 9.5  643793.1 1376808.7 2089493.1 2806567.1
     fivenum(tbl$y)  # 25.00 2045.00 2545.00 2995.00 8044.07
     centerX = 1376808
     centerY = 2545
     camera.position.set(centerX, centerY, -1000)
     camera.lookAt(new THREE.Vector3(centerX, centerY, 0))
     renderer.render(scene, camera)

*------------------------------------------------------------------------------------------------------------------------
* 3js tips

  Object.keys(camera)

  --- change camera position
   camera.position.set(-60, 40, 30)
   camera.lookAt(new THREE.Vector3(0,0,0));  // cannot omit Vector3 constructor call
   renderer.render(scene, camera)

  --- change position of object in scene
    cube.position  // T…E.Vector3 {x: -4, y: 3, z: 0}
    cube.position.set(-6, 3, 0)
    renderer.render(scene, camera)

  --- change camera position in a loop (happens very fast)
    x=0; y=0; z=0;
    for(var i=1; i <100; i++){x =+ (i * 0.01); camera.lookAt(new THREE.Vector3(x, y, z)); renderer.render(scene, camera)}


   --- add axis to a scene
       // X axis is red, Y is green, Z is blue.
     var axes = new THREE.AxisHelper(20);  // 20 is the axis length
     scene.add(axes);


   --- get camera lookAt vector:

     The camera is looking down it's internal negative z-axis, so create a vector pointing down the negative z-axis:
     Apply the same rotation to the vector that is applied to the camera:
     The resulting vector will be pointing in the direction that the camera is looking.

        var vector = new THREE.Vector3( 0, 0, - 1 );
        vector.applyQuaternion(camera.quaternion).add(camera.position)

     ***  put camera at origin, slide out the z axis, should see sphere and cube straight on
        camera.position.set(0,0,-30)
        camera.lookAt(new THREE.Vector3(0,0,0))
        renderer.render(scene, camera)
        var vector = new THREE.Vector3(0, 0, -1); // camera-local direction
        vector.applyQuaternion(camera.quaternion).add(camera.position)
           // T…E.Vector3 {x: 0, y: 0, z: -29}

     ***  move camera up on y axis 30 units
        camera.position.set(0,-30,-30)
        camera.lookAt(new THREE.Vector3(0,0,0))
        renderer.render(scene, camera)
        var vector = new THREE.Vector3(0, 0, -1); // camera-local direction
        vector.applyQuaternion(camera.quaternion).add(camera.position)
           // {x: 0, y: -29.29289323091507, z: -29.292893220889763}

    *** look at 1,1,-11
        camera.position.set(0,-30,-30)
        camera.lookAt(new THREE.Vector3(1,1,-1))
        renderer.render(scene, camera)
        var vector = new THREE.Vector3(0, 0, -1); // camera-local direction
        vector.applyQuaternion(camera.quaternion).add(camera.position)
           //  a bit to the right in x, a bit up in y, a bit up in z
           // {x: 0.023550609708449445, y: -29.26993114856995, z: -29.317032344159195}

      new THREE.Vector3(camera.matrix[8], camera.matrix[9], camera.matrix[10]);
       // T…E.Vector3 {x: 0, y: 0, z: 0}

   --- reset both camera position and camera lookAt

    camera.position.set(-30, 40, 30); renderer.render(scene, camera)
    camera.lookAt(new THREE.Vector3(0,0,0));
    renderer.render(scene, camera)

*------------------------------------------------------------------------------------------------------------------------
* R tips: canonical sort order, encoding, utf-8, utf8, good thing to put in all unit tests (1 jun 2016)

  dan says to use the C locale always!
  Sys.setlocale("LC_ALL", "C")


*------------------------------------------------------------------------------------------------------------------------
* data transformations, asinh, arcsinh, sqrt of count data, log of size data (1 jun 2016)

   http://www.biostathandbook.com/transformation.html

*------------------------------------------------------------------------------------------------------------------------
* sword fern monitoring data, from kramer and tristan, mixed with nelson's map from sep 2015 (30 apr 2016)

   cd ~/s/work/fatnose/swordFerns/

*------------------------------------------------------------------------------------------------------------------------
* for cory, igvR display of foxp4 & etc from mariet's snps  (31 may 2016)

   cd ~/s/work/priceLab/cory/marietsSnps/

        chr  mfpstart    mfpend     motifname     pval         motif tf_name         tf_ensg       snp        beta   gene.cor
210473 chr7 100080777 100080812      MA0030.1 8.32e-05      MA0030.1   FOXP4 ENSG00000137166 100080774 -0.06232602 -0.0758814
210522 chr7 100080777 100080812      MA0032.2 7.08e-05      MA0032.2   FOXP4 ENSG00000137166 100080774 -0.06232602 -0.0758814
210571 chr7 100080777 100080812      MA0041.1 7.01e-05      MA0041.1   FOXP4 ENSG00000137166 100080774 -0.06232602 -0.0758814
210620 chr7 100080777 100080812      MA0481.1 4.37e-05      MA0481.1   FOXP4 ENSG00000137166 100080774 -0.06232602 -0.0758814
210680 chr7 100080777 100080812      MA0846.1 2.20e-05      MA0846.1   FOXP4 ENSG00000137166 100080774 -0.06232602 -0.0758814
210728 chr7 100080777 100080812      MA0851.1 2.38e-05      MA0851.1   FOXP4 ENSG00000137166 100080774 -0.06232602 -0.0758814
210777 chr7 100080777 100080812      MA0852.1 3.88e-05      MA0852.1   FOXP4 ENSG00000137166 100080774 -0.06232602 -0.0758814
210829 chr7 100080795 100080824      MA0041.1 7.01e-05      MA0041.1   FOXP4 ENSG00000137166 100080774 -0.06232602 -0.0758814
385929 chr7 100271843 100271874 EWSR1-FLI1.p2 8.91e-06 EWSR1-FLI1.p2   EWSR1 ENSG00000182944 100271925  0.22309425  0.3437514
385938 chr7 100271892 100271923      MA0509.1 8.83e-06      MA0509.1    RFX1 ENSG00000132005 100271925  0.01397556  0.5427026


    --- from this:
      best foxp4 with shared snp.  collapse foxp4 which the same snp.loc, disregard variable motif, choose best pval,

210680 chr7 100080777 100080812      MA0846.1 2.20e-05      MA0846.1   FOXP4 ENSG00000137166 100080774 -0.06232602 -0.0758814
385929 chr7 100271843 100271874 EWSR1-FLI1.p2 8.91e-06 EWSR1-FLI1.p2   EWSR1 ENSG00000182944 100271925  0.22309425  0.3437514
385938 chr7 100271892 100271923      MA0509.1 8.83e-06      MA0509.1    RFX1 ENSG00000132005 100271925  0.01397556  0.5427026


*------------------------------------------------------------------------------------------------------------------------
* install chinook metnets webapp on buffy (31 may 2016)

  mkdir github, cd github

  git clone https://github.com/paul-shannon/chinook.git
  git clone https://github.com/paul-shannon/chinook.git


*------------------------------------------------------------------------------------------------------------------------
* onlies folklife 2016

  https://soundcloud.com/northwestfolklifefestival/the-onlies-live-2016

*------------------------------------------------------------------------------------------------------------------------
* install maripaludis network viewer on eager (31 may 2016)

   ssh pshannon@eager [use latest isb password: Dappled42!]
   xemacs, create shell
   cd ~/github
   git clone https://github.com/paul-shannon/chinook
   cd chinook
   R CMD INSTALL ChinookDataset/
   R CMD INSTALL ChinookServer/
   cd ..
   git clone https://github.com/PriceLab/metnetsViz


*------------------------------------------------------------------------------------------------------------------------
* rzmq pubsub, pub/sub (30 may 2016)

  cd ~/s/examples/zmq/R/pubsub/

  library(devtools)
  install_github("armstrtw/rzmq")

   version 0.8.0  (0.7.7 offered by cran)

  ---- zmq-pub.R
    library(rzmq)
    library(jsonlite)
    context = init.context()
    socket = init.socket(context,"ZMQ_PUB")
    bind.socket(socket,"tcp://*:5556")
    while(TRUE) {
      topic = as.integer(round(runif(1, 9999, 10005) + 0.5))
      messagedata = as.integer(round(runif(1, 1, 215) + 0.5) + 80)
      message <- sprintf("%d %d", topic, messagedata)
      printf("outgoing message: %s", message)
      message.raw <- charToRaw(message)
      printf("class of message.raw: %s", class(message.raw))
      send.socket(socket, message.raw, serialize=FALSE)
      Sys.sleep(1)
      }

  ---- zmq-sub.R
    library(rzmq)
    library(jsonlite)
    context = init.context()
    socket = init.socket(context,"ZMQ_SUB")
    connect.socket(socket,"tcp://localhost:5556")
    subscribe(socket, "")   # empty string means "subscribe to all channels"
    i <- 0
    while (i < 5) {
       res <- receive.socket(socket, unserialize=FALSE)
       x <- rawToChar(res)
       print(x)
       i <- i + 1
       }


*------------------------------------------------------------------------------------------------------------------------
* R color tips
   library(grDevices)
   colorRampPalette(c("green", "white", "black"))(10)
 [1] "#00FF00" "#38FF38" "#71FF71" "#AAFFAA" "#E2FFE2" "#E2E2E2" "#AAAAAA" "#717171" "#383838" "#000000"
   colorRampPalette(c("black", "white", "green"))(10)
 [1] "#000000" "#383838" "#717171" "#AAAAAA" "#E2E2E2" "#E2FFE2" "#AAFFAA" "#71FF71" "#38FF38" "#00FF00"

*------------------------------------------------------------------------------------------------------------------------
* zmq node request-reply (29 may 2016)

  cd ~/s/examples/zmq/node/request-reply/
  npm install zmq   # seems to have some python 2.7.x involvement
  date >tmp
  node reply.js tmp &   # Listening for zmq requesters...
  node request.js tmp
     Sending request for tmp
     Received request to get: tmp
     Sending response content
     Received response: { content: 'Sun May 29 21:05:36 PDT 2016\n', timestamp: 1464581147704, pid: 58700 }

  --- next up: try pubsub.  try websocket.  try bridging.  try putting zmq server into chinook server.

*------------------------------------------------------------------------------------------------------------------------
* zmq python pubsub (29 may 2016)

  cd ~/s/examples/zmq/py/pubsub

*------------------------------------------------------------------------------------------------------------------------
* simple zmq pub/sub in node, sub client in R (23 jan 2016)
   updated (29 may 2016)

   cd ~/s/examples/node/zmq/

   npm install zmq  # did fresh install related to python version: needs < 3.0, /usr/bin/python
   date > tmp

   ---- node server
    node zmq-filer-rep.js
      Listening for zmq requesters...
      Received request to get: tmp
      Sending response content

   ---- node client
   node zmq-filer-req.js tmp
      Sending request for tmp
     Received response: { content: 'Sun May 29 15:49:31 PDT 2016\n',
                        timestamp: 1464563201739,
                         pid: 57918 }

*------------------------------------------------------------------------------------------------------------------------
* pip tips: install with python 2.7, for python 2.7 (29 may 2016)

  curl -O  https://bootstrap.pypa.io/get-pip.py
  python get-pip.py --user --verbose
  sudo /Users/paul/Library/Python/2.7/bin/pip install  zmq

*------------------------------------------------------------------------------------------------------------------------
* install apache thrift (29 may 2016)

   working from instructions at https://thrift.apache.org/docs/install/os_x

   --- Install Boost: Download the boost library from boost.org untar compile with

       Boost is a set of libraries for the C++ programming language
       that provide support for tasks and structures such as linear
       algebra, pseudorandom number generation, multithreading, image
       processing, regular expressions, and unit testing. It contains
       over eighty individual libraries.

      cd ~/source/
      got boost_1_61_0.tar.gz from sourceforge
      ./bootstrap.sh
      sudo ./b2 threading=multi address-model=64 variant=release stage install
         fatal error, pyconfig.h not found, abandonded, using brew instead
      brew install boost  # Warning: boost-1.60.0_1 already installed

   --- Install libevent: Download libevent, untar and compile with
    https://github.com/libevent/libevent/releases/download/release-2.0.22-stable/libevent-2.0.22-stable.tar.gz
    cd ~/source/libevent-2.0.22-stable
    ./configure --prefix=/usr/local   # failed not finding openssl/bio.h, found in anaconda installation
    export CPPFLAGS='-I/Users/paul/anaconda/include/'; ./configure --prefix=/usr/local
     make
     sudo make install



*------------------------------------------------------------------------------------------------------------------------
* trying out nginx microservices with apache thrift, a first R thrift client hrbase (28 may 2016)

   cd ~/github
   git clone https://github.com/RevolutionAnalytics/rhbase.git

   cd ~/s/examples/thrift/rhbase/pkg
   fails, apparently needeing apache thrift installed

   --- install apache thrift
     brew install boost
     mv ~/Downloads/thrift-0.9.3.tar.gz .
   gunzip thrift-0.9.3.tar.gz
   tar xvf thrift-0.9.3.tar
   brew install bison
   brew link bison --force
   ./configure --prefix=/usr/local/ --with-boost=/usr/local --with-libevent=/usr/local
   make
   sudo make install

   --- needs openssl

*------------------------------------------------------------------------------------------------------------------------
* learn 3js (25 may 2016)

  cd ~/s/study/3js
  downloaded all of the book's (2nd edition) code to ~/s/study/3js/book/
  then mv'd book/libs to ~/s/study/3js for easy finding by webserver
  in a shell called sh-http-learn3:  python -m http.server 8001

*------------------------------------------------------------------------------------------------------------------------
* interactive heat maps for R (25 may 2016)

   http://www.r-bloggers.com/interactive-heat-maps-for-r/

*------------------------------------------------------------------------------------------------------------------------
* put matt's maripaludis metabolic network in github, whovian, and make visible (25 may 2016)

   cd ~/github/vizMiscellany/metabolicNetworks/try0
   https://github.com/PriceLab/vizMiscellany/tree/master/metabolicNetworks/try0


   --- next up:
     ~/github/metnets/datasets/Maripaludis/inst/unitTests/test_Maripaludis.R fails to load
     ../extdata/metabolicNetwork.json.RData
     should it be saved as a json object?
     print(load("../extdata/metabolicNetwork.json.RData"))  #  [1] "g.json"
     nchar(g.json) # [1] 706815

*------------------------------------------------------------------------------------------------------------------------
* reproduce:  198644 edge greengenes phylogenetic tree in three.js using pointclouds (25 may 2016)

   cd ~/s/work/priceLab/daniel/greengenesViz

      8188588 May 20 16:27 treeLayout.json   # only this is needed for the pointcloud
      5220773 May 20 12:17 treeLayout.tsv

   wc -l            1 treeLayout.json
               198644 treeLayout.tsv

   ---- start simple web server
     cd   ~/github/three.js/
     python -m http.server 8001

   ---- browser to
     http://localhost:8001/examples/pshannon/pointsBillboards/

   ---- viewing in a browser
      cd ~/github/three.js/examples/pshannon/pointsBillboards
      index.html has these relevant lines.
        <script src="../../../build/three.min.js"></script>
        <script src="../../js/Detector.js"></script>
        <script src="../../js/libs/stats.min.js"></script>
        <!-- script src="graph.json"></script -->
        <script src="greenGenesFullLayout.json"></script>


   ---- graph.json written in R from tree layed out by java
      g = [{"id":"N42","x":434.25,"y":25}, ...
      ...
         for(i = 0; i < g.length * 1; i ++){
            var vertex = new THREE.Vector3();
            vertex.x = g[i].x;
            vertex.y = g[i].y;
            vertex.z = 0;
            geometry.vertices.push(vertex);
            } // for i


    cp ~/s/work/priceLab/daniel/greengenesViz/treeLayout.json greenGenesFullLayout.json  # add "g = " at start
      of this one-line huge file

    change index.html to load this file

    198643 vertices in about 2 seconds.

*------------------------------------------------------------------------------------------------------------------------
* netlogo tips

  reserved keywords:
     globals
     breed
     turtles-own
     patches-own
     to
     to-report
     extensions
     __includes (experimental)


  agents:  patches, turtles links, the observer

  inspect turtle:
    right click on it

  "ask turtle N [a b]"                    ;; send messages a and b to turtle N

  change an attribute:
    ask turtle 19 [set color green]    ;; 19 is the "who number"

  builtin turtle properties:
    who
    color
    heading
    xcor
    ycor
    shape
    label
    label-color
    breed
    hidden?
    size
    pen-size
    pen-mode

  add new turtle property (must be declared before any function definitions].
  the general form:

      turtles-own [newAttribute]

  create a new turtle subtype, or breed, called "cats"; give a name to a single instance: "cat"

    breed [cats cat]              ;; "cats" defines the name of the agentset;  "cat" defines the name of a single member of the breed.
    cats-own [fur kittens]
    create-cats 10
    ask cats [set color grey]
    show cat 1


   turtle state: its own default and custom properties AND "a turtle has direct access to
     the variables of the patch it is standing on"

  how many turtles?

    count turtles

   --- full code from tutorial 3

turtles-own [energy] ;; for keeping track of when the turtle is ready
                     ;; to reproduce and when it will die

to setup
  clear-all
  setup-patches
  setup-turtles
  reset-ticks
end

to setup-patches
  ask patches [ set pcolor green ]
end

to setup-turtles
  create-turtles number    ;; uses the value of the number slider to create turtles
  ask turtles [ setxy random-xcor random-ycor ]
end

to go
  if ticks >= 500 [ stop ]  ;; stop after 500 ticks
  move-turtles
  eat-grass
  check-death
  reproduce
  regrow-grass
  tick                    ;; increase the tick counter by 1 each time through
end

to move-turtles
  ask turtles [
    right random 360
    forward 1
    set energy energy - 1  ;; when the turtle moves it looses one unit of energy
  ]
end

to eat-grass
  ask turtles [
    if pcolor = green [
      set pcolor black
           ;; the value of energy-from-grass slider is added to energy
      set energy energy + energy-from-grass
    ]
  ifelse show-energy?
    [ set label energy ] ;; the label is set to be the value of the energy
    [ set label "" ]     ;; the label is set to an empty text value
  ]
end

to reproduce
  ask turtles [
    if energy > birth-energy [
      set energy energy - birth-energy  ;; take away birth-energy to give birth
      hatch 1 [ set energy birth-energy ] ;; give this birth-energy to the offspring
    ]
  ]
end

to check-death
  ask turtles [
    if energy <= 0 [ die ] ;; removes the turtle if it has no energy left
  ]
end

to regrow-grass
  ask patches [ ;; 3 out of 100 times, the patch color is set to green
    if random 100 < 3 [ set pcolor green ]
  ]
end



*------------------------------------------------------------------------------------------------------------------------
* learn netlogo

   cd ~/s/work/edu/netlogo/learn/tut0/
   /Applications/NetLogo\ 5.3.1/NetLogo\ 5.3.1.app/Contents/MacOS/NetLogo

   --- following https://ccl.northwestern.edu/netlogo/docs/tutorial1.html

*------------------------------------------------------------------------------------------------------------------------
* susequehanna shale hills point cloud three.js demo (23 may 2016)

  http://potree.org/demo/potree_1.3/showcase/SHCZO_Dec10.html

*------------------------------------------------------------------------------------------------------------------------
* laws in nature, stephen mumford, 2004

  dir ~/Documents/LawsInNature-StephenMumbord.pdf
  247 pages
  see also http://plato.stanford.edu/entries/laws-of-nature/
*------------------------------------------------------------------------------------------------------------------------
* reproduce matt richards maripaludis metabolic network (20 may 2016)

    cd  ~/s/work/priceLab/mattRichards/
    R> source("toTables.R"); rcy <- run(TRUE)
    readAndApplyLayout(rcy, "organicLayout.tsv"); fit(rcy)
    readAndApplyLayout(rcy, "orthogonalLayout.tsv"); fit(rcy)
    readAndApplyLayout(rcy, "radialLayout.tsv"); fit(rcy)

*------------------------------------------------------------------------------------------------------------------------
* prep to load greengenes, apply yfiles tree layout, three.js with daniel's filtered greengenes tree (23 may 2016)

   cd ~/github/three.js/examples/pshannon/pointsBillboards/

   --- create small tree, use yfiles for layout
     library(phytools)
     set.seed(3); x=3;  tt<-log(x)-log(2); t <- pbtree(n=x,t=tt); plotTree(t)

   --- grok phylo tree representation: map edge adj mtx numbers to tip.labels
     tbl.edges   a b
               1 4 1
               2 4 5
               3 5 2
               4 5 3
      t1, t2, t3 correpond to nodes of that number
      4 and 5 are internal nodes

    ?phylo says this
    edge: a two-column matrix of mode numeric where each row represents
          an edge of the tree; the nodes and the tips are symbolized
          with numbers; the tips are numbered 1, 2, ..., and the nodes
          are numbered after the tips. For each row, the first column
          gives the ancestor.

    --- for example
     set.seed(17); x=4; tt<-log(x)-log(2); t <- pbtree(n=x,t=tt); plotTree(t)
     tbl.edges <- as.data.frame(t$edge); colnames(tbl.edges) <- c("a", "b")
     nodes <- as.character(sort(unique(c(tbl.edges$a, tbl.edges$b))))
     tbl.edges  # a b
                # 5 1
                # 5 6
                # 6 7
                # 7 2
                # 7 3
                # 6 4

     t$tip.label #  "t1" "t3" "t4" "t2"
     node:          1    2     3    4
     parent of t3 and t4: n7
     parent of t2 and n7: n6
     parent of n6 and t1: n5

     looks like:
        4 tip to node assignment can be read off of tip.label
        node [5] is root
        node [6:7] are interior nodes

                _____________________ t2
                |
                |
     ___________| n6
    |           |
    |           |                    __ t4
    |           |                   |
    |           |________________n7_|
    |                               |
    |                               |__ t3
    |
    | n5
    |
    |
    |
    |
    |_____________________________ t1


  --- run simple very imperfect tree display
    http server running here:
        ~/github/three.js/
        python -m http.server 8001

   ~/github/three.js/examples/pshannon/pointsBillboards/index.html
   browse to http://localhost:8001/examples/pshannon/pointsBillboards/
   go.R:
     library(phytools)
     library(jsonlite)
     set.seed(17);
     x=40
     tt<-log(x)-log(2);
     t <- pbtree(n=x,t=tt); plotTree(t)
     tbl <- as.data.frame(t$edge)
     colnames(tbl) <- c("a", "b")
     nodes <- as.character(sort(unique(c(tbl$a, tbl$b))))
     # apply tip.labels to initial nodes, internal node labels to the remainder
     first.internal.node <- length(t$tip.label) + 1
     last.internal.node <- length(nodes)
     labels <- c(t$tip.label, paste("N", first.internal.node:last.internal.node, sep=""))
     tbl$a <- labels[tbl$a]
     tbl$b <- labels[tbl$b]
     write.table(tbl, file="edges.tsv", sep="\t", quote=FALSE, row.names=FALSE, col.names=FALSE)
     system("make")
     tbl.pos <- read.table("treeLayout.tsv", header=TRUE, as.is=TRUE, sep="\t")
     json <- toJSON(tbl.pos)
     javascript <- sprintf ("g = %s", json)
     write(javascript, file="graph.json")

   which index.html reads in via <script src="graph.json"></script>

   --- now try all of greengenes as layed out by yfiles
    yfiles layout in ~/s/work/priceLab/daniel/greengenesViz/treeLayout.tsv
     tbl.pos <- read.table("~/s/work/priceLab/daniel/greengenesViz/treeLayout.tsv", sep="\t", header=TRUE) # , nrows=5)
     json <- toJSON(tbl.pos)
     javascript <- sprintf ("g = %s", json)
     write(javascript, file="graph.json")


*------------------------------------------------------------------------------------------------------------------------
* create three.js with daniel's filtered greengenes tree (20 may 2016)

   cd ~/s/work/priceLab/daniel/greengenesViz/go.R
   tbl.layout <- read.table("treeLayout.tsv", sep="\t", as.is=TRUE, header=TRUE)
   toJSON(head(tbl.layout))
    [{"id":"n99324","x":34087.9375,"y":5474.07},{"id":"n99325","x":34087.9375,"y":5544.07},{"id":"n99326","x":32965.4375,"y":5594.07},{"id":"n99327","x":1509.5,"y":5644.07},{"id":"n99328","x":1378.25,"y":5694.07},{"id":"n99329","x":1378.25,"y":5744.07}]
    s <- toJSON(head(tbl.layout))
    write(s, file="treeLayout-small.json")
    s <- toJSON(tbl.layout)
    write(s, file="treeLayout.json")

  -rw-r--r--   1 paul  staff  8188588 May 20 16:27 treeLayout.json
  -rw-r--r--   1 paul  staff      250 May 20 16:27 treeLayout-small.json

    --- next up:
       add this json to the three.js app at ~/github/three.js/examples/pshannon/pointsBillboards/index.html
       start webserver:
          cd ~/github/three.js/python -m http.server 8001
       browse to
         http://localhost:8001/examples/pshannon/pointsBillboards/

*------------------------------------------------------------------------------------------------------------------------
* create rcyjs sample tree, perparing for daniel's greengenes display (20 may 2016)

   cd ~/s/work/priceLab/daniel/greengenesViz/go.R
   reload(); rcy <- run()
   system("make")
   java -cp /Users/paul/jars/yfiles-for-java.jar:.:/Users/paul/s/work/yfiles/v3.0/yFiles-for-Java-Complete-3.0-Evaluation/tutorials:/Users/paul/jars/opencsv-3.7.jar PerformLayout interactions.tsv  treeLayout.tsv
    arg count: 2
    readAndApplyLayout(rcy, "treeLayout.tsv")

*------------------------------------------------------------------------------------------------------------------------
* task for cory & eblue (19 may 2016)

  [result is ~/github/myGists/trenaDemoGeneToSnpsInScoredFootprints/findPiez02RegulatorySnps.R]

  cd ~/s/work/priceLab/cory/eblue19May2016
  R -f go.R
   print(subset(tbl.fpoi, snp != -1))
        chr mfpstart   mfpend motifname     pval    motif tf_name         tf_ensg         snp
  576 chr18 11148289 11148318  MA0692.1 9.64e-05 MA0692.1    MITF ENSG00000187098 18:11148314
  580 chr18 11148289 11148318  MA0692.1 9.64e-05 MA0692.1    USF1 ENSG00000158773 18:11148314
 582 chr18 11148289 11148318  MA0692.1 9.64e-05 MA0692.1     MLX ENSG00000108788 18:11148314


  book.eblue19May2016> cp go.R ~/Desktop/stage/findPiez02RegulatorySnps.R

  PrivateCoryData/inst/extdata/
     chr18_CU0070F.shared.bed
     chr18_LD0949F.shared.bed

   runLiftOver on these, add to package
   build trena model, find footprints for predictive tfs around PIEZO2
   intersect above snps with those footprints,
   display in igv


> print(subset(tbl.fpoi, snp != -1))
      chr mfpstart   mfpend motifname     pval    motif tf_name         tf_ensg         snp
576 chr18 11148289 11148318  MA0692.1 9.64e-05 MA0692.1    MITF ENSG00000187098 18:11148314
580 chr18 11148289 11148318  MA0692.1 9.64e-05 MA0692.1    USF1 ENSG00000158773 18:11148314
582 chr18 11148289 11148318  MA0692.1 9.64e-05 MA0692.1     MLX ENSG00000108788 18:11148314
>
book.eblue19May2016> cp go.R ~/Desktop/stage/findPiez02RegulatorySnps.R

*------------------------------------------------------------------------------------------------------------------------
* wholeBrain database on whovian now has 3-column motifsgenes table (19 may 2016)

   book.unitTests> psql -U trena --host whovian
   Password for user trena:
   psql (9.3.4, server 9.4.7)
   WARNING: psql major version 9.3, server major version 9.4.
            Some psql features might not work.
   Type "help" for help.

   trena=> \c wholeBrain
   \c wholeBrain
   psql (9.3.4, server 9.4.7)
   WARNING: psql major version 9.3, server major version 9.4.
            Some psql features might not work.
   You are now connected to database "wholeBrain" as user "trena".
   wholeBrain=> \dt
   \dt
               List of relations
    Schema |    Name     | Type  |  Owner
   --------+-------------+-------+----------
    public | footprints  | table | pshannon
    public | motifsgenes | table | pshannon
   (2 rows)

   wholeBrain=> select * from motifsgenes limit 4;
   select * from motifsgenes limit 4;
     motif   | tf_name |     tf_ensg
   ----------+---------+-----------------
    MA0002.2 | RUNX1   | ENSG00000159216
    MA0003.3 | TFAP2A  | ENSG00000137203
    MA0004.1 | ARNT    | ENSG00000143437
    MA0006.1 | AHR     | ENSG00000106546
   (4 rows)

   ---- from whovian:s/notes/postgres-notes
      * add slightly revised motif/genes table to wholeBrain database

    cd ~/s/data/postgres-fill/motifsgenes
    psql
    \c wholeBrain
    \dt
                  List of relations
      Schema |    Name     | Type  |  Owner
     --------+-------------+-------+----------
      public | footprints  | table | pshannon
      public | motifsgenes | table | pshannon

    select * from motifsgenes limit 3;
      motif   |   tf
    ----------+--------
     MA0002.2 | RUNX1
     MA0003.3 | TFAP2A
     MA0004.1 | ARNT

   wholeBrain=> drop table motifsgenes;
    mv ~/tmp/motifGenes.tsv .
    (delete colnames in 1st line)

    create table motifsgenes(motif varchar, tf_name varchar, tf_ensg varchar);
    \copy motifsgenes from 'motifGenes.tsv' delimiter E'\t' CSV;
    \copy motifsgenes from 'motifToMultipleGenes.tsv' delimiter E'\t' CSV;
    COPY 9017

  GRANT select on all tables in SCHEMA public to trena;

    select * from motifsgenes limit 4;
      motif   | tf_name |     tf_ensg
    ----------+---------+-----------------
     MA0002.2 | RUNX1   | ENSG00000159216
     MA0003.3 | TFAP2A  | ENSG00000137203
     MA0004.1 | ARNT    | ENSG00000143437
     MA0006.1 | AHR     | ENSG00000106546



*------------------------------------------------------------------------------------------------------------------------
* add ensg colum to postgres genome database on whovian,

    print(load("/Users/paul/github/Private_Cory_Data/data/tbl.motifToMultipleGenes.RData")) # [1] "tbl.motifToMultipleGenes"
    dim(tbl.motifToMultipleGenes) # [1] 9289    2
    head(tbl.motifToMultipleGenes)
         motif    tfs
    1 MA0002.2  RUNX1
    2 MA0003.3 TFAP2A
    3 MA0004.1   ARNT
    4 MA0006.1    AHR
    5 MA0006.1   ARNT
    6 MA0007.3     AR

   ---- get all gene_name -> gene_id mappings
     tbl.ids <- dbGetQuery(db, "select distinct gene_id, gene_name from gtf")  # 60504     2
     indices <- match(tbl.motifToMultipleGenes$tfs, tbl.ids$gene_name)         # 9289
     ensg <- tbl.ids$gene_id[indices]   # 9289
     length(unique(ensg))  # [1] 845
     length(unique(tbl.motifToMultipleGenes$tfs)) # [1] 847
     tbl.motifToMultipleGenes$ensg <- ensg
     colnames(tbl.motifToMultipleGenes) <- c("motif", "tf.gene", "tf.ensg")
     tbl.motifToMultipleGenes <- unique(tbl.motifToMultipleGenes)
     na.rows <- which(is.na(tbl.motifToMultipleGenes$tf.ensg))
     unique(tbl.motifToMultipleGenes[na.rows,]$tf.gene)
        "TFAP2G": TFAP2C
        "NR3C3" : PGR
        "NR3C4" : AR

    ---- now redo these steps after fixing the obsolete genes
      print(load("/Users/paul/github/Private_Cory_Data/data/tbl.motifToMultipleGenes.RData")) # [1] "tbl.motifToMultipleGenes"
      old <- "TFAP2G"; new <- "TFAP2C"; tbl.motifToMultipleGenes[grep(old, tbl.motifToMultipleGenes$tfs), "tfs"] <- new
      old <- "NR3C3"; new <- "PGR"; tbl.motifToMultipleGenes[grep(old, tbl.motifToMultipleGenes$tfs), "tfs"] <- new
      old <- "NR3C4"; new <- "AR";  tbl.motifToMultipleGenes[grep(old, tbl.motifToMultipleGenes$tfs), "tfs"] <- new
      tbl.motifToMultipleGenes <- unique(tbl.motifToMultipleGenes)
      indices <- match(tbl.motifToMultipleGenes$tfs, tbl.ids$gene_name)         # 9289
      ensg <- tbl.ids$gene_id[indices]   # 9289
      length(unique(ensg))  # [1] 845
      length(unique(tbl.motifToMultipleGenes$tfs)) # [1] 845
      tbl.motifToMultipleGenes$ensg <- ensg
      colnames(tbl.motifToMultipleGenes) <- c("motif", "tf.gene", "tf.ensg")
      tbl.motifToMultipleGenes <- unique(tbl.motifToMultipleGenes)
      dim(tbl.motifToMultipleGenes) # [1] 9017    3

     write.table(tbl.motifToMultipleGenes, sep="\t", quote=FALSE, row.names=FALSE, col.names=TRUE, file="motifGenes.tsv")
     scp motifGenes.tsv pshannon@whovian:tmp/

        motif tf.gene         tf.ensg
1 MA0002.2   RUNX1 ENSG00000159216
2 MA0003.3  TFAP2A ENSG00000137203
3 MA0004.1    ARNT ENSG00000143437
4 MA0006.1     AHR ENSG00000106546
5 MA0006.1    ARNT ENSG00000143437
6 MA0007.3      AR ENSG00000169083
> colnames(tbl.motifToMultipleGenes) <- c("motif", "tf.gene", "tf.ensg")
head(tbl.motifToMultipleGenes)
     motif tf.gene         tf.ensg
1 MA0002.2   RUNX1 ENSG00000159216
2 MA0003.3  TFAP2A ENSG00000137203
3 MA0004.1    ARNT ENSG00000143437
4 MA0006.1     AHR ENSG00000106546
5 MA0006.1    ARNT ENSG00000143437
6 MA0007.3      AR ENSG00000169083

     motif    tfs            ensg
1 MA0002.2  RUNX1 ENSG00000159216
2 MA0003.3 TFAP2A ENSG00000137203
3 MA0004.1   ARNT ENSG00000143437
4 MA0006.1    AHR ENSG00000106546
5 MA0006.1   ARNT ENSG00000143437
6 MA0007.3     AR ENSG00000169083


  scp /Users/paul/github/Private_Cory_Data/data/tbl.motifToMultipleGenes.RData pshannon@whovian:tmp/
  see whovian ~/s/notes/postgres-notes for actual fill commands
  whovian> cd  ~/s/data/postgres-fill/wholeBrain/
  write.table(tbl.motifToMultipleGenes, sep="\t", quote=FALSE, row.names=FALSE, col.names=FALSE, file="motifToMultipleGenes.tsv")


*------------------------------------------------------------------------------------------------------------------------
* add ampADMayo expression data to Private_Cory_Data (18 may 2016)

  cd ~/github/Private_Cory_Data/inst/extdata
  cp ~/s/data/priceLab/AD/ampADMayo.64253genes.278samples.RData .

*------------------------------------------------------------------------------------------------------------------------
* truck: on rebuilding a worn-out pickup and other post-technological adventures (for leo's birthday)

  http://www.thirdplacebooks.com/book/9780874517552

*------------------------------------------------------------------------------------------------------------------------
* phylogenetic tree layout info (18 may 2016)

  some good stuff from d3: https://github.com/d3/d3/issues/213
  circular dendrogram, with edge lengths honored:  https://www.jasondavies.com/tree-of-life/

*------------------------------------------------------------------------------------------------------------------------
* preliminary RCyjs & etc plots of newick trees (18 may 2016)

   library(phyloseq)
   trefile = system.file("extdata", "GP_tree_rand_short.newick.gz", package = "phyloseq")
   x <- read_tree(trefile)
   plotTree(x)

  primate.tree <- "((Human:1,Chimp:0.7),Gorilla:12),Monkey);"
  x2 <- read.newick(text=primate.tree)
   plotTree(x2)   # fails, unrooted

  this works: plotTree(read.newick(text="(B,(A,D),C);"))
  plotTree(read.newick(text="((A, B), C), D);"))
  plotTree(read.newick(text="((Human,Chimp), Gorilla), Monkey);"))
  plotTree(read.newick(text="((Human:1,Chimp:2), Gorilla:3), Monkey:4);"))
  plotTree(read.newick(text="((Human:1,Chimp:2), Gorilla:3), Monkey:4)Mouse;"))

   ---- good reproducible trees
     library(phytools)
     set.seed(3); x=3;  tt<-log(x)-log(2); t <- pbtree(n=x,t=tt); plotTree(t)
        Phylogenetic tree with 3 tips and 2 internal nodes.
        Tip labels: [1] "t2" "t3" "t1"
        Rooted; includes branch lengths.
     str(t)
     List of 4
      $ edge       : int [1:4, 1:2] 4 5 5 4 5 1 2 3
      $ Nnode      : int 2
      $ tip.label  : chr [1:3] "t2" "t3" "t1"
      $ edge.length: num [1:4] 0.194 0.211 0.211 0.405
      - attr(*, "class")= chr "phylo"
      - attr(*, "order")= chr "cladewise"
     # 5 nodes, 3 tips, infer that 5 is the internal node connecting 1 (t2) and 2 (t3)
                                   4 is the internal node connecting to 3 (t1) and internal node 5
     t$edge
          [,1] [,2]
     [1,]    4    5
     [2,]    5    1
     [3,]    5    2
     [4,]    4    3


   --- use daniel's data
     library(phyloseq)
     s <- scan("/Users/paul/s/work/priceLab/daniel/notebook-zero/greengenes_97.tree", what=character(0))  # Read 431 items
     s2 <- paste(s, collapse="")
     nchar(s2) # [1] 2542308
     write(s2, file="greenGenesCompacted.tree")
     tg <- read_tree_greengenes("greenGenesCompacted.tree")

         Phylogenetic tree with 99322 tips and 99321 internal nodes.
         Tip labels:
         	4479984, 698544, 564724, 4465919, 3618043, 823988, ...
         Node labels:
         	, , 'k__Archaea', , '0.961, '0.972, ...
         Rooted; includes branch lengths.
      dim(tg$edge) # [1] 198642      2

*------------------------------------------------------------------------------------------------------------------------
* newick info, rooted and unrooted (18 may 2016)

   http://www.ncbi.nlm.nih.gov/Class/NAWBIS/Modules/Phylogenetics/phylo9.html

*------------------------------------------------------------------------------------------------------------------------
* simple newick tree, with lengths, phytools package (18 may 2016)

  library(phytools)
  packageVersion("phytools") # [1] '0.5.20'
  primate.tree <- "((Human:1,Chimp:0.7),Gorilla:12),Monkey);"
  read.newick(text=primate.tree)
    or
  read.newick(text="((Human:1,Chimp:0.7),Gorilla:12),Monkey);")

*------------------------------------------------------------------------------------------------------------------------
* read daniel's python notebok tree file, using phytools package read.newick function (18 may 2016)

  s <- scan("/Users/paul/s/work/priceLab/daniel/notebook-zero/greengenes_97-100-sample.tree", what=character(0))
  s2 <- paste(s, collapse="")
  nchar(s2) #  [1] 19830
  x2 <- read.newick(text=s2)
     Phylogenetic tree with 71 tips and 75 internal nodes.
     Tip labels:
	4330849, 4393962, 4303423, 2743763, 4471279, 4420570, ...
     Node labels:
	, , , , 'p__Cyanobacteria', 0.081, ...
      Rooted; includes branch lengths.
     names(x2) # [1] "edge"        "Nnode"       "tip.label"   "edge.length" "node.label"
     dim(x2$edge) # [1] 145   2
      head(x2$edge)
           [,1] [,2]
      [1,]   72   73
      [2,]   73    1
      [3,]   73   74
      [4,]   74    2
      [5,]   74   75
      [6,]   75   76
    x2$edge.length
  [1] 0.00000 0.40927 0.00000 0.33865 0.00000 0.02540 0.28667 0.27911 0.06223 0.08296 0.01196 0.00867 0.00000 0.00431 0.32866 0.00962
 [17] 0.01836 0.03255 0.07291 0.02971 0.10187 0.03988 0.03734 0.00291 0.03522 0.01871 0.02540 0.10648 0.12724 0.00429 0.00646 0.00085
 [33] 0.00237 0.00185 0.00098 0.01923 0.00901 0.00959 0.02293 0.02534 0.03184 0.01836 0.00588 0.03683 0.05052 0.05275 0.07102 0.01215
 [49] 0.01473 0.03500 0.00229 0.00384 0.01683 0.00828 0.00981 0.03698 0.03629 0.16066 0.06343 0.03212 0.01810 0.01870 0.03759 0.02251
 [65] 0.00040 0.00199 0.00014 0.00324 0.00721 0.01148 0.03015 0.00027 0.02707 0.02127 0.01392 0.00086 0.00027 0.01674 0.01332 0.02224

*------------------------------------------------------------------------------------------------------------------------
* read newick tree, grok data structure (18 may 2016)

  library(phytools)
  packageVersion("phytools") # [1] '0.5.20'
  primate.tree <- "((Human,Chimp),Gorilla),Monkey);"
  read.newick(text=primate.tree)
     Phylogenetic tree with 4 tips and 2 internal nodes.
     Tip labels:
        [1] "Human"   "Chimp"   "Gorilla" "Monkey"
     Unrooted; no branch lengths.

   x <- read.newick(text=tree)
   class(x) # [1] "phylo"
   str(x)
     # List of 5
     #  $ edge       : num [1:5, 1:2] 5 6 6 5 5 6 1 2 3 4
     #  $ Nnode      : int 2
     #  $ tip.label  : chr [1:4] "Human" "Chimp" "Gorilla" "Monkey"
     #  $ edge.length: NULL
     #  $ node.label : NULL
     #  - attr(*, "class")= chr "phylo"
     #  - attr(*, "order")= chr "cladewise"
     # > x$edge
     #      [,1] [,2]
     # [1,]    5    6
     # [2,]    6    1
     # [3,]    6    2
     # [4,]    5    3
     # [5,]    5    4
     # >

*------------------------------------------------------------------------------------------------------------------------
* very small greengenes tree for visualization experimenhts (18 may 2016), from daniel's notebook

   created 749 node tree, with 750 tips, removed "[" and "]" characters by hand
   f <- "~/s/work/priceLab/daniel/notebook-zero/greengenes_97-100-sample.tree"

*------------------------------------------------------------------------------------------------------------------------
* smallish phylogenetic tree for visualization experimenhts (18 may 2016)

   --- from http://greengenes.lbl.gov/cgi-bin/JD_Tutorial/nph-Trees.cgi

     Greengenes does not have a tree making option contained within it,
     but does support tree making with the files it generates.  A
     program called Mega is a recommended program for the beginner to
     use in making phylogenetic trees from their sequences.


   --- cd ~/s/work/priceLab/daniel/notebook-zero-small
     these steps depend upon prior execution of daniel's notebook-zero notebook, and results are written
     back to that directory

   --- now have these tree files
        141929 May 18 11:28 greengenes_97-100-sample.tree
       2542738 Apr 28 10:24 greengenes_97.tree
       2642060 Apr 28 12:54 test.tree

  s <- scan("/Users/paul/s/work/priceLab/daniel/notebook-zero/greengenes_97-100-sample.tree", what=character(0))
  s2 <- paste(s, collapse="")
  nchar(s2) # [1] 141881


   --- how to read a (newick) tree file, using phyloseq capabilities, and phyloseq demo files
     library(phyloseq)
     trefile = system.file("extdata", "GP_tree_rand_short.newick.gz", package = "phyloseq")
     x <- read_tree(trefile)
     Phylogenetic tree with 500 tips and 499 internal nodes.
       Tip labels: 153762, 175045, 71074, 525569, 557121, 560734, ...
       Node labels: , 0.858.4, 0.943.7, 0.985.6, 0.695, 0.692.78, ...
       Rooted; includes branch lengths.


   --- try it with daniel's small greengenes tree
     library(phyloseq)
     s <- scan("/Users/paul/s/work/priceLab/daniel/notebook-zero/greengenes_97-100-sample.tree", what=character(0))
     s2 <- paste(s, collapse="")
     nchar(s2) # [1] 141881
     write(s2, file="greenGenesSmall.tree")



*------------------------------------------------------------------------------------------------------------------------
* biom_format:  explore biom - the Biological Observeration Matrix format

  http://biom-format.org/
  cd ~/s/examples/R/phyloseq/smallDemo/

 go.R
library(biomformat)
library(phyloseq)

min_dense_file <- system.file("extdata", "min_dense_otu_table.biom", package = "biomformat")
in_sparse_file <- system.file("extdata", "min_sparse_otu_table.biom", package = "biom")
rich_dense_file <- system.file("extdata", "rich_dense_otu_table.biom", package = "biom")
rich_sparse_file <- system.file("extdata", "rich_sparse_otu_table.biom", package = "biom")
min_dense_file <- system.file("extdata", "min_dense_otu_table.biom", package = "biom")
rich_dense_char <- system.file("extdata", "rich_dense_char.biom", package = "biom")
rich_sparse_char <- system.file("extdata", "rich_sparse_char.biom", package = "biom")

x1 <- read_biom(min_dense_file)
x2 <- read_biom(min_sparse_file)
x3 <- read_biom(rich_dense_file)
x4 <- read_biom(rich_sparse_file)
x5 <- read_biom(rich_dense_char)
x6 <- read_biom(rich_sparse_char)


mtx.x4 <- as.matrix(biom_data(x4))
mtx.x4
#          Sample1 Sample2 Sample3 Sample4 Sample5 Sample6
# GG_OTU_1       0       0       1       0       0       0
# GG_OTU_2       5       1       0       2       3       1
# GG_OTU_3       0       0       1       4       0       2
# GG_OTU_4       2       1       1       0       0       1
# GG_OTU_5       0       1       1       0       0       0
prod(dim(mtx.x4))  # [1] 30


observation_metadata(x4)[1,]  # the linnaen classification, gross-to-fine
#            taxonomy1         taxonomy2              taxonomy3            taxonomy4             taxonomy5      taxonomy6 taxonomy7
# GG_OTU_1 k__Bacteria p__Proteobacteria c__Gammaproteobacteria o__Enterobacteriales f__Enterobacteriaceae g__Escherichia       s__


sample_metadata(x4)
#         BarcodeSequence  LinkerPrimerSequence BODY_SITE Description
# Sample1    CGCTTATCGAGA CATGCTGCCTCCCGTAGGAGT       gut   human gut
# Sample2    CATACCAGTAGC CATGCTGCCTCCCGTAGGAGT       gut   human gut
# Sample3    CTCTCTACCTGT CATGCTGCCTCCCGTAGGAGT       gut   human gut
# Sample4    CTCTCGGCCTGT CATGCTGCCTCCCGTAGGAGT      skin  human skin
# Sample5    CTCTCTACCAAT CATGCTGCCTCCCGTAGGAGT      skin  human skin
# Sample6    CTAACTACCAAT CATGCTGCCTCCCGTAGGAGT      skin  human skin


*------------------------------------------------------------------------------------------------------------------------
* phyloseq network example, hoping to display in graphosaurus (15 may 2016)

  cd ~/s/examples/R/phyloseq/plotNetwork/
  http://joey711.github.io/phyloseq/plot_network-examples.html

  library(phyloseq)
  packageVersion("phyloseq") # [1] '1.9.11' me: 1.15.14
  packageVersion("ggplot2")   # 2.1.0
  data(enterotype)
  set.seed(711L)
  enterotype = subset_samples(enterotype, !is.na(Enterotype))
  plot_net(enterotype, maxdist = 0.4, point_label = "Sample_ID")
  ig <- make_network(enterotype, max.dist=0.3)
  length(V(ig))  # [1] 167
  dim(get.edgelist(ig)) # [1] 1272    2
  head(layout.fruchterman.reingold(ig))
                [,1]     [,2]
     [1,] -0.9672516 4.676497
     [2,]  5.5957440 4.523299
     [3,]  4.0705271 7.589071
     [4,]  3.1467135 6.770226
     [5,] -3.7616097 4.419199
     [6,] -6.5618033 6.448084

   -- an explicit tree
    t <- make_tree(10, 2)
    tbl.nodes <- as.data.frame(layout_as_tree(t))
    colnames(tbl.nodes) <- c("x", "y")
    tbl.nodes$name <- paste("N", as.character(1:nrow(tbl.nodes)), sep="")
    tbl.nodes <- tbl.nodes[, c("name", "x", "y")]

*------------------------------------------------------------------------------------------------------------------------
* three.js, webgl, graphosaurus demo (15 may 2016)

  --- start web server
   cd  ~/github/graphosaurus/dist/
   python -m http.server 8005

   open ~/s/examples/js/three/graphosaurus/millionNodes/index.html

*------------------------------------------------------------------------------------------------------------------------
* build minimal opengl program on macbook (13 may 2016)

  https://developer.apple.com/opengl/
  abandoned.  back to three.js

*------------------------------------------------------------------------------------------------------------------------
* features for matt

   full node info popup, include genes on reaction nodes, color reaction nodes.
   display flux
   select subnetwork by reaction names, shortest path.

    R_rxn05197_LSQBKT_c0_RSQBKT_   matt is surprised by the "LSQBKT_c0_RSQBKT_"

*------------------------------------------------------------------------------------------------------------------------
* postgres tips, rpostgresql tips, hg38 tips

   library(RPostgreSQL)
   db <- dbConnect(PostgreSQL(), user= "trena", password="trena", dbname="hg38", host="whovian")
 or
   db <- dbConnect(PostgreSQL(), user= "trena", password="trena", dbname="wholeBrain", host="whovian")
   dbListTables(db)   # footprints, motifsgenes
   tbl.tfs <- dbGetQuery(db, "select * from motifsgenes")
   dim(tbl.tfs)  # [1] 9017    3
   tbl.tfs <- unique(tbl.tfs[, 2:3])
   dim(tbl.tfs) # [1] 845   2
   head(tbl.tfs[order(tbl.tfs$tf_name),])
          tf_name         tf_ensg
     1587    ADNP ENSG00000101126
     1599   ADNP2 ENSG00000101544
     4        AHR ENSG00000106546
     666     AHRR ENSG00000063438
     538     AIRE ENSG00000160224
     476     ALX1 ENSG00000180318
  write.table(tbl.tfs, file="~/Desktop/stage/tfs.tsv", sep="\t", quote=FALSE, row.names=FALSE, col.names=TRUE)

  --- get location of gene

   name <- "PIEZ02"
   biotype <- "protein_coding"
   moleculetype <- "gene"
   query <- paste("select gene_name, chr, start, endpos, strand from gtf where ",
                    sprintf("gene_name='%s' ", name),
                    sprintf("and gene_biotype='%s' and moleculetype='%s'", biotype, moleculetype),
                    collapse=" ")

     dbGetQuery(obj@genome.db, query)


*------------------------------------------------------------------------------------------------------------------------
* use TReNA with elizabeth blue's bed file, PIEZ02 on chr18

  cd ~/s/work/priceLab/cory/eblueMay2016/

  --- cory's email The zip file attached has the bed file. Use one
   from chr18 (near PIEZ02).  The objective I have is building a local
   TReNA model for all the genes +/- 1 MB from these bed file
   coordinates. Based on our SQL query yesterday, I think this will
   end up being around 11 genes (protein coding and lncRNAs). The +/-1
   MB distance is just to define the genes of interest. Once that list
   is defined, for each of those genes, I would want to build a model
   (or models) that consider +/-1 MB from the TSS for each of those
   genes. I may also want to do it for +/-10 kb from the TSS, or
   define promoter regions as I see fit.

   Once I've built a gene model, I want to be able to see all the
   footprints utilized in the model. I would then do an intersect of
   these footprints with the SNPs in the bed file from Liz.


   ---- chose just one small bed file
      chr18.CU0070F.lrt.bed    677 lines

*------------------------------------------------------------------------------------------------------------------------
* cyjs tips, rcy tips, style.js

  also see ~/s/work/priceLab/mattRichards/style.js

vizmap =  [
    {selector:"node", css: {
        "text-valign":"center",
        "text-halign":"center",
        "background-color":"rgb(250, 250, 250)",
        "border-color": "black",
        "border-with": "1px",
        "shape": "ellipse",
        "width": 100,
        "height": 100,
        content: "data(id)",
        "width":"mapData(degree,  0.0, 150.0, 30.0, 160.0)",
        "height":"mapData(degree, 0.0, 150.0, 30.0, 160.0)"
        }},

    {selector:"node:selected", css: {
        "text-valign":"center",
        "text-halign":"center",
        "background-color":"rgb(250, 250, 250)",
        "border-width": "5px",
         content: "data(id)"

        }},

    {selector: 'node[nodeType="patient"]', css:{
        "content":"data(label)",
        "border-color": "black",
        "border-width": "3px",
        "font-size" : 8,
        "background-color": "rgb(250, 250, 250)",
        "shape" : "ellipse",
        content: "data(id)"

        }},

    {selector: 'node[nodeType="gene"]', css:{
        "shape"  : "ellipse",
        "font-size": 8,
        content: "data(id)",
        "border-color": "blue",
        "border-width": "1px"}},


   {"selector":"node[nodeType='centromere']", style:
      {"shape": "roundrectangle",
       "width": "180px",
       "height": "80px",
       "content": "data(id)",
       "border-color": "green",
       "border-width": 1,
       "font-size": "56px"
       }},

   {"selector":"node[nodeType='telomere']", style:
      {"shape":"octagon",
       "border-color": "black",
       "background-color": "lightgray",
       "border-width": 1,
       content: "",
       "width": 10,
       "height": 10
       }},


    {selector: 'node[nodeType="gene fusion"]', css:{
        "content":"data(label)",
        "shape"  : "roundrectangle",
        "width"   : "mapData(degree, 0.0, 20.0, 20.0, 100.0)",
        "height"  : "mapData(degree, 0.0, 20.0, 20.0, 100.0)",
        "font-size": 18,
        "border-color": "red",
        "border-width": "3px"}},

    {selector:"node[nodeType='gene fusion']:selected",css: {
       "border-width": "8px"}},

    {selector: 'node[nodeType="drug"]', css:{
        "content":"data(label)",
        "shape"  : "rectangle",
        "width"   : "mapData(degree, 0.0, 20.0, 40.0, 200.0)",
        "height"  : "mapData(degree, 0.0, 20.0, 40.0, 200.0)",
        "font-size": 30,
        "border-color": "red",
        "border-width": "1px"}},

    {selector:"node[nodeType='gene']:selected",css: {
       "border-width": "8px"}},

    {selector:"node[nodeType='patient']:selected",css: {
       "border-width": "8px"}},

    {"selector":"edge[edgeType='chromosome']",
       "style":{"line-color":"rgb(0,0,128)",
       "line-style":"solid",
       "width":"1px",
       "curve-style": "bezier"}},

    {selector: "edge[edgeType='mutation']", css: {
        "line-color": "black",
        "width": "6px",
        "line-style": "dashed",
        "curve-style":"haystack",   // bezier, haystack
        "source-arrow-shape":"none",
        "target-arrow-color":"red",
        "target-arrow-shape":"none"
         }},

    {selector: 'edge[edgeType="cnGain.1"]', css:{
        "line-color": "rgb(255,128,128)",
        "width": "1px"}},

    {selector: 'edge[edgeType="cnGain.2"]', css:{
        "line-color": "red",
        "width": "8px"}},

    {selector: 'edge[edgeType="cnLoss.1"]', css:{
        "line-color": "rgb(128,255,123)",
        "width": "1px"}},

    {selector: 'edge[edgeType="cnLoss.2"]', css:{
        "line-color": "green",
        "width": "8px"}}

   ];



*------------------------------------------------------------------------------------------------------------------------
* yfiles tips

   --- organic layout options
     import com.yworks.yfiles.layout.organic.OrganicLayout;
     OrganicLayout layouter = new OrganicLayout();
     layouter.setMinimumNodeDistance(80);

*------------------------------------------------------------------------------------------------------------------------
* github tips: refresh from master

  scenario:
     local changes not working, rename file to file-date-time
  git fetch --all
  git reset --hard origin/master

*------------------------------------------------------------------------------------------------------------------------
* git tips: create a local repo

  cd <directory of interest>
  git init
  git add <file>
  git commit -m "msg"
*------------------------------------------------------------------------------------------------------------------------
* readTable for java (10 may 2016)

   http://opencsv.sourceforge.net/
   download:
      https://sourceforge.net/projects/opencsv/
   cp ~/Downloads/opencsv-3.7.jar ~/jars


  cd  ~/s/examples/java/readTable/
  make: builds and runs AddressExample.java
  https://sourceforge.net/p/opencsv/source/ci/master/tree/examples/addresses.csv

*------------------------------------------------------------------------------------------------------------------------
* too few footprints around mef2c in whovian/postgres/wholeBrain
*------------------------------------------------------------------------------------------------------------------------
* small daniel-related demo in phyloseq (5 may 2016)

  library(biomformat)
  library(phyloseq)
  sapply(c("phyloseq", "biomformat"), packageVersion) # $phyloseq [1]  1 15 14   $biomformat  [1]  0 99  4
  min_dense_file   = system.file("extdata", "min_dense_otu_table.biom", package = "biomformat")
  x1 <- read_biom(min_dense_file)



*------------------------------------------------------------------------------------------------------------------------
* daniel notebook-zero-small (05 may 2016)

  cd ~/s/work/priceLab/daniel/notebook-zero-small
  mv ~/Downloads/for_paul_subsample.ipynb .

  --- start notebook server, with proper 2.7 version of python
    source activate example
    daniel's subsampling did not produce static files I could ponder.


*------------------------------------------------------------------------------------------------------------------------
* put ensembl gtf file into postgres?  (3 may 2016)

   cd ~/s/data/public/ensembl/
   tbl <- read.table("Homo_sapiens.GRCh38.84.chr.gtf", sep="\t", nrows=5, as.is=TRUE)  # [1] 5 9
  V1     V2         V3    V4    V5 V6 V7 V8    V9 is a mishmash
1  1 havana       gene 11869 14409  .  +  .
2  1 havana transcript 11869 14409  .  +  .
3  1 havana       exon 11869 12227  .  +  .
4  1 havana       exon 12613 12721  .  +  .
5  1 havana       exon 13221 14409  .  +  .


   --- taming the V9 column
    c9 <- tbl$V9
    length(c9) # [1] 2568100
    c9[1]
    c9.toks <- strsplit(c9, "; ")
    all.toks <- unlist(c9.toks)
    length(all.toks) # [1] 47782409
    head(all.toks)
        [1] "gene_id ENSG00000223972"                         "gene_version 5"
        [3] "gene_name DDX11L1"                               "gene_source havana"
        [5] "gene_biotype transcribed_unprocessed_pseudogene" "havana_gene OTTHUMG00000000961"
    all.tok.toks <- strsplit(all.toks, " ")
    length(all.tok.toks) # [1] 47782409
    c9.titles <- lapply(all.tok.toks, "[", 1)
    length(unique(unlist(c9.titles))) # [1] 22
    unique(unlist(c9.titles))
       [1] "gene_id"                   "gene_version"              "gene_name"                 "gene_source"
       [5] "gene_biotype"              "havana_gene"               "havana_gene_version"       "transcript_id"
       [9] "transcript_version"        "transcript_name"           "transcript_source"         "transcript_biotype"
      [13] "havana_transcript"         "havana_transcript_version" "tag"                       "transcript_support_level"
      [17] "exon_number"               "exon_id"                   "exon_version"              "ccds_id"
      [21] "protein_id"                "protein_version"

    c9.titles.unique <- unique(unlist(c9.titles))
    save(tbl, c9.titles.unique, file="column9.parse.inputs.RData")
    print(load("list.of.parsedColumn9s.RData"))
    print(load("column9.parse.inputs.RData"))
     # [1] "tbl"              "c9.titles.unique"
    dim(tbl); dim(tbl.wide)
      # [1] 2568100       9
      # [1] 2568100      22
   tbl2 <- cbind(tbl, tbl.wide)
   dim(tbl2)  # [1] 2568100      31
   colnames(tbl2)[1:9] <- c ("chr", "annotation", "moleculeType", "start", "end", "score", "strand", "frame", "attribute")
   tbl2$chr <- paste("chr", tbl2$chr, sep="")
   reordered.cols <- c("chr",                      "start",
                       "end",                      "score",                    "strand",                   "frame",
                       "annotation",               "moleculeType",
                       "gene_id",                  "gene_version",             "gene_name",
                       "gene_source",              "gene_biotype",             "havana_gene",               "havana_gene_version",
                       "transcript_id",            "transcript_version",       "transcript_name",           "transcript_source",
                       "transcript_biotype",       "havana_transcript",        "havana_transcript_version", "tag",
                       "transcript_support_level", "exon_number",              "exon_id",                   "exon_version",
                       "ccds_id",                  "protein_id",               "protein_version",           "annotation")

   tbl3 <- tbl2[, reordered.cols]
   dim(tbl3)  # 2568100      31
   save(tbl3, file="tbl.ensembl.gtf.RData")





*------------------------------------------------------------------------------------------------------------------------
* load tbl.motifToMultipleGenes into Postgres on whovian, in both databases wholeBrain & lymphoblast (3 may 2016)

  --- grok it on riptide
    print(load("/Users/paul/github/Private_Cory_Data/data/tbl.motifToMultipleGenes.RData")) # [1] "tbl.motifToMultipleGenes"
    dim(tbl.motifToMultipleGenes) # [1] 9289    2
    head(tbl.motifToMultipleGenes)
         motif    tfs
    1 MA0002.2  RUNX1
    2 MA0003.3 TFAP2A
    3 MA0004.1   ARNT
    4 MA0006.1    AHR
    5 MA0006.1   ARNT
    6 MA0007.3     AR

  scp /Users/paul/github/Private_Cory_Data/data/tbl.motifToMultipleGenes.RData pshannon@whovian:tmp/
  see whovian ~/s/notes/postgres-notes for actual fill commands
  whovian> cd  ~/s/data/postgres-fill/wholeBrain/
  write.table(tbl.motifToMultipleGenes, sep="\t", quote=FALSE, row.names=FALSE, col.names=FALSE, file="motifToMultipleGenes.tsv")


*------------------------------------------------------------------------------------------------------------------------
* test whovian postgress wholeBrain footprint database & query (3 may 2016)


*------------------------------------------------------------------------------------------------------------------------
* yfiles progress, some simple organic layouts of matt richard's maripaludis model (6 may 2016)

  cd  ~/s/work/priceLab/mattRichards/

  R> rcy <- run(TRUE)   # random layout graph display, interactions.tsv file written
  bash> make            # reads interactions.tsv into java, does layout, writes tsv file to stdout
  R> readAndApplyLayout(rcy, "organicLayout-3.tsv")

  --- next up
     learn how to respect node size in layouter
     try hierarchical layouter with hubs removed
     use more nuanced scheme to avoid being trapped by hub nodes

*------------------------------------------------------------------------------------------------------------------------
* yfiles progress, but don't know how to iterate over the nodes in the graph in order to get layed-out position (3 may 2016)

  cd ~/s/work/priceLab/mattRichards/
  PerformLayout.java
  has tsv file reader
  interactions3.tsv

      import com.yworks.yfiles.graph.LayoutUtilities;
      import com.yworks.yfiles.layout.hierarchic.HierarchicLayout;
      import com.yworks.yfiles.graph.*;
      import com.yworks.yfiles.geometry.*;

      import java.io.BufferedReader;
      import java.io.*;
      import java.util.ArrayList;
      import java.util.List;
      import java.util.StringTokenizer;

      //------------------------------------------------------------------------------------------------------------------------
      public class PerformLayout {
      //------------------------------------------------------------------------------------------------------------------------
      public static void main(String[] args) throws Exception
      {

        String line;
        InputStream fis = new FileInputStream("interactions3.tsv");
        InputStreamReader isr = new InputStreamReader(fis);
        BufferedReader br = new BufferedReader(isr);

        IGraph graph = new DefaultGraph();
        RectD nodeBounds = new RectD(0, 0, 50, 50);

        while ((line = br.readLine()) != null) {
           String[] tokens = line.split("\t");
           System.out.println(tokens[0] + " -> " + tokens[1]);
           INode a = graph.createNode(nodeBounds);
           INode b = graph.createNode(nodeBounds);
           graph.addLabel(a, tokens[0]);
           graph.addLabel(b, tokens[1]);
           IEdge e = graph.createEdge(a, b);
           }

        System.out.println(graph);
        LayoutUtilities.applyLayout(graph, new HierarchicLayout());

        //System.out.println (graph.nodes());

        //graph.nodes.forEach(
        //   System.out.println(node[i].getLayout().getCenter());
        //   }));

        //DefaultCollectionModel<INode> nodes = graph.getNodes();
        //INode[] nodes = graph.getNodeArray();
      } // main
      //------------------------------------------------------------------------------------------------------------------------
      } // class PerformLayout



*------------------------------------------------------------------------------------------------------------------------
* headless layout example from yfiles support (2 may 2016)

  Thank you for your email and your interest in yFiles for Java
  3.0. My name is Julius Gonser. I am a member of the Java developer
  team and would like to answer your question.

  With yFiles for Java you need only a few lines of code to implement your requirements:

 // create a graph in which the nodes and edges live
 IGraph graph = new DefaultGraph();

 // create three nodes at the point of origin with a size of 50 x 50
 RectD nodeBounds = new RectD(0, 0, 50, 50);
 INode n1 = graph.createNode(nodeBounds);
 INode n2 = graph.createNode(nodeBounds);
 INode n3 = graph.createNode(nodeBounds);

 // connect them with two edges
 IEdge e1 = graph.createEdge(n1, n2);
 IEdge e2 = graph.createEdge(n2, n3);

 // perform a layout e.g. a hierarchic layout
 LayoutUtilities.applyLayout(graph, new HierarchicLayout());

 // and get the coordinates of their centers
 System.out.println("n1: " + n1.getLayout().getCenter());
 System.out.println("n2: " + n2.getLayout().getCenter());
 System.out.println("n3: " + n3.getLayout().getCenter());

*------------------------------------------------------------------------------------------------------------------------
* try out yFiles 3.0 layout (2 may 2016)

  cd ~/s/work/yfiles/v3.0/yFiles-for-Java-Complete-3.0-Evaluation/tutorials/tutorial01_GettingStarted/step14_AutomaticGraphLayout/
  javac SampleApplication.java
  java -cp ../../../lib/yfiles-for-java.jar:../.. tutorial01_GettingStarted.step14_AutomaticGraphLayout.SampleApplication


   --- make it work in groovy?
    brew install groovy
    type -a groovysh
        # groovysh is /usr/local/opt/groovy/bin/groovysh
    CLASSPATH=$CLASSPATH:$HOME/s/work/yfiles/v3.0/yFiles-for-Java-Complete-3.0-Evaluation/lib/yfiles-for-java.jar
    export GROOVY_HOME=/usr/local/opt/groovy/libexec
    source ~/.bashrc
    cd ~/s/work/yfiles/v3.0/
    groovysh
       import com.yworks.yfiles.graph.LayoutUtilities;
       import com.yworks.yfiles.layout.hierarchic.HierarchicLayout;
       import com.yworks.yfiles.graph.ILookup;


   --- need to know more yfiles basics.
      cd ~/s/work/yfiles/v3.0/yFiles-for-Java-Complete-3.0-Evaluation/tutorials/tutorial01_GettingStarted/step01_CreatingTheView/
      javac SampleApplication.java
      java -cp ../../../lib/yfiles-for-java.jar:../.. tutorial01_GettingStarted/step01_CreatingTheView.SampleApplication


    --- finally figured out
      cd ~/s/work/yfiles/v3.0/yFiles-for-Java-Complete-3.0-Evaluation/tutorials/tutorial01_GettingStarted/me
      make
     ----- before
       135.0, 35.0
       360.0, 380.0
       35.0
     ----- after
       35.0, 0.0
       35.0, 50.0
       10.0, 100.0

    --- next up: fix ~/s/examples/java/readTSV/TSVreader.java so that it reads the triples written
       by ~/s/work/priceLab/mattRichards/toTables.R, run()




*------------------------------------------------------------------------------------------------------------------------
* rcyjs tips

   --- create graph
    g <- new("graphNEL", edgemode = "directed")

    nodeDataDefaults(g, attr = "type") <- "undefined"
    nodeDataDefaults(g, attr = "label") <- ""
    edgeDataDefaults(g, attr = "edgeType") <- "undefined"

    g <- graph::addNode(unique(c(tbl.interactions$a, tbl.interactions$b)), g)
    g <- graph::addEdge(tbl.interactions$a, tbl.interactions$b, g)
    edgeData(g, tbl.interactions$a, tbl.interactions$b) <- tbl.interactions$type

    g

  --- display graph
     PORTS <- 9047:9097
     rcy <- RCyjs(portRange=portRange, quiet=TRUE, graph=g, hideEdges=FALSE);


*------------------------------------------------------------------------------------------------------------------------
* netlogo tips

   run desktop java NetLogo 5.3.1
      /Applications/NetLogo\ 5.3.1/NetLogo\ 5.3.1.app/Contents/MacOS/NetLogo

   --- for debugging create a global variable, then assign it and operate upon it in the command center

    ~/s/work/edu/netlogo/PurpleMembrane.nlogo
    in code, at top:
       globals [ ... x]
    in command center:
       set x nodes with [ name = "bop"]
       show x   ;; observer: (agentset, 1 turtle)

  --- interogate an agent's variables (think: the attributes of an object)
     with prior definition, at top of file:
       nodes-own
          [ name amount in-edges out-edges knockedout? nodetype ]
     in command center:
        set x nodes with [ name = "bop"]
        set nodeTmp1 nodes with [ name = "bat"]
        show [name] of x    ;; also amount, knockedout? nodetype, but in-edges and out-edges come up empty

  --- create some more temporary convenience globals:

   globals
    [ edges-data network-data catalytic-amount1 catalytic-amount2 change
      bat-ko-status crtb1-ko-status brp-ko-status bop-ko-status selectable nodeTmp1 nodeTmp2 edgeTmp1 ]

   --- found this via google
   So instead of:
      [set [xcor] of myself pxcor
   you can use:
       ask myself [set xcor [pxcor] of myself ]

   our bug:
      set [out-edges] of from tmp
   could become
      ask from [set out-edges [tmp] of from]

    ---- this seems to work
      ;; add edge to edge lists of both nodes
      let tmp lput self out-edges-of from
      ask from [set out-edges [tmp] of myself]

    ---- does it work?
      set nodeTmp1 nodes with [ name = "bat"]
      show [out-edges] of nodeTmp1
         observer: [[(turtle 18) (turtle 21) (turtle 24)]]
      show [in-edges] of nodeTmp1
         observer: [[(turtle 24)]]

    ---- official statement on deprecation of "-of", and the new "of" syntax:

      We have replaced three different language constructs, -of (with
      hyphen), value-from, and values-from with a single of construct
      (no hyphen).

                     old			new
       color-of turtle 0			[color] of turtle 0
     value-from turtle 0 [size * size]		[size * size] of turtle 0
     mean values-from turtles [size]		mean [size] of turtles

   When of is used with a single agent, it reports a single
   value. When used with an agentset, it reports a list of values (in
   random order, since agentsets are always in random order).  Note that
   when opening old models in the new version, -of, value-from, and
   values-from will automatically be converted to use "of" instead, but
   some nested uses of these constructs are too complex for the converter
   and must be converted by hand.




*------------------------------------------------------------------------------------------------------------------------
* sword fern monitoring data, from kramer and tristan (30 apr 2016)

   cd ~/s/work/fatnose/swordFerns/

   downloaded from here

      https://docs.google.com/spreadsheets/d/1WldC-Np3hJRwLzVop9EpgssBSpMZZJssLNc64qqu0X4

   saved to
       ~/s/work/fatnose/swordFerns/SewardParkFernDataSheet1.tsv   #     7996 Apr 30 13:11


   There is the link to the data. The only map work that I have seen
   thus far, is the map that Tristan had with the gps locations of
   each plot. But I do not have any way to access that. Hop all is
   well for you Paul and I look forward to getting back out to collect
   another round of data this spring.

  ---- read into R, format for use in javascript



*------------------------------------------------------------------------------------------------------------------------
* google maps, fatnose, api

  cd ~/s/examples/js/googlemaps/markersWithInfoWindows/twoMarkersMutexPopupsOnPeninsula/

  cd ~/s/work
*------------------------------------------------------------------------------------------------------------------------
* for matt, parse sbml, maripalusis?  (29 apr 2016)

   cd ~/s/work/priceLab/mattRichards/
   source("toTables.R"); runTests()
   parses metabolites, reactions, genes

   --- next up: combine into an rcyjs network, a neo4j graph database

*------------------------------------------------------------------------------------------------------------------------
* neo4j tips: clear the database
  in R:

  ~/s/data/priceLab/functionalConnectionMaps/ad-igap-demo/clear.R
library(RNeo4j)
gdb <- startGraph("http://localhost:7474/db/data/", username="neo4j", password="isb");
node.count <- getNodes(gdb, "match(n) return count(n)")[[1]]
edge.count <- getRels(gdb, "match(n)-[r]->(t) return count(r)")[[1]]
printf("%5d nodes, %6d edges", node.count, edge.count)
clear(gdb)

*------------------------------------------------------------------------------------------------------------------------
* biomformat, read ag_r1-25.biom in R, phyloseq (29 apr 2016)

  cd ~/s/bioc/trunk/Rpacks/phyloseq/

library(bioformat)
Error in library(bioformat) : there is no package called ‘bioformat’
> library(biomformat)
> min_dense_file   = system.file("extdata", "min_dense_otu_table.biom", package = "biomformat")
> x1 <- read_biom(min_dense_file)
> read_biom("~/s/work/priceLab/daniel/notebook-zero/ag_r1-25.biom")
  C-c C-c
Warning message:
In strsplit(msg, "\n") : input string 1 is invalid in this locale
> x <- read_biom("~/s/work/priceLab/daniel/notebook-zero/ag_r1-25.biom")
Warning message:
In strsplit(msg, "\n") : input string 1 is invalid in this locale
> class(x)
[1] "biom"
attr(,"package")
[1] "biomformat"
> x
biom object.
type: OTU table
matrix_type: dense
25998 rows and 7898 columns
>
*------------------------------------------------------------------------------------------------------------------------
* having trouble reading greengenes_97.tree, turning to another example using phyloseq R package (28 apr 2016)

  cd ~/s/examples/R/phyloseq/
   temp_otutax = "
   otu_url = "http://downloads.hmpdacc.org/data/HMQCP/otu_table_psn_v35.txt.gz"
   download.file(otu_url, temp_otutax)

   temp_map = tempfile()
   map_url = "http://downloads.hmpdacc.org/data/HMQCP/v35_map_uniquebyPSN.txt.bz2"
   download.file(map_url, temp_map)
   temp_map = bzfile(temp_map)


   temp_tree = tempfile()
   tree_url = "http://downloads.hmpdacc.org/data/HMQCP/rep_set_v35.tre.gz"
   download.file(tree_url, temp_tree)

*------------------------------------------------------------------------------------------------------------------------
* read daniel's greengenes_97.tree file into ggtree

  cd ~/s/work/priceLab/daniel/notebook-zero/

  2,542,738 Apr 28 10:24 greengenes_97.tree    all in one line

     # convert all "," to ",\n"

   cat greengenes_97.tree | sed 's/,/,\'$'\n''/g' > test.tree

   wc test.tree
       99322   99752 2642060 test.tree

  phyfile <- system.file("extdata", "sample.phy", package="ggtree")

   --- some simple newick format files from https://en.wikipedia.org/wiki/Newick_format
    (,,(,));                               no nodes are named
    (A,B,(C,D));                           leaf nodes are named
    (A,B,(C,D)E)F;                         all nodes are named
    (:0.1,:0.2,(:0.3,:0.4):0.5);           all but root node have a distance to parent
    (:0.1,:0.2,(:0.3,:0.4):0.5):0.0;       all have a distance to parent
    (A:0.1,B:0.2,(C:0.3,D:0.4):0.5);       distances and leaf names (popular)
    (A:0.1,B:0.2,(C:0.3,D:0.4)E:0.5)F;     distances and all names
    ((B:0.2,(C:0.3,D:0.4)E:0.5)F:0.1)A;    a tree rooted on a leaf node (rare)


   --- another sample, from https://www.bioconductor.org/packages/3.3/bioc/vignettes/ggtree/inst/doc/treeVisualization.html

     nwk <- system.file("extdata", "sample.nwk", package="ggtree")

     scan(nwk, what=character(0))
     (((((((A:4,B:4):6,C:5):8,D:6):3,E:21):10,((F:4,G:12):14,H:8):13):13,((I:5,J:2):30,(K:11,L:11):2):17):4,M:56);
     tree <- read.tree(nwk)
     ggtree(tree)+geom_point(aes(shape=isTip, color=isTip), size=3)

*------------------------------------------------------------------------------------------------------------------------
* daniel notebook-zero (28 apr 2016)

  cd ~/s/work/priceLab/daniel/notebook-zero/

I'm providing the example code in a Jupyter Notebook as I've found them to be
rather useful for this purpose. However, I realize that you may not have
Jupyter setup. What I recommend, because it's super awesome, is to leverage
conda. Conda is a Python-oriented environment and package mananger, which is
not limited to Python (e.g., https://bioconda.github.io/). The following is
a crash course:

# get conda
curl -o miniconda.sh http://repo.continuum.io/miniconda/Miniconda3-latest-MacOSX-x86_64.sh

# install conda (note, this will install locally, -b is "silent")
chmod +x miniconda.sh
./miniconda.sh -b

# update conda
conda update --yes conda

# create a Python environment that will support the example notebook, and
# install three packages necessary for the example. We're using Python 2.7
# unfortunately as the Python 3.x build for one of the dependencies is missing.
# 1) jupyter provides the ecosystem for the notebook, and is the cornerstone
#    of the scientific python community. It is the successor to IPython by
#    the IPython development team.
# 2) pandas implements the R DataFrame, and is at this time a core project in
#    the scientific python ecosystem. This provides support for manipulating
#    the covariate data for the example.
# 3) scikit-bio is a bioinformatics toolkit that is still in alpha. This
#    provides support for manipulating phylogenetic trees for the example.
# 4) biom-format is implements an in-memory representation of the observation
#    counts table (the OTU table), and provides support for manipulating these
#    tables within the example. We're installing this from the "bioconda"
#    channel as we haven't migrated biom-format to the main conda repository.

conda create --yes --name example jupyter pandas scikit-bio python=2
conda install --yes --name example -c bioconda biom-format

# activate the new environment, and start a notebook server
source activate example

# if you type `which python` now you'll notice that it is within an environment
# specific prefix, same with libraries. Conda is _awesome_ because it is
# general, so for instance, you can even install bioconductor from the
# bioconda channel. The beauty is that you can have as many independent
# environments as you want, and just switch as necessary for dependencies or
# analyses, etc, which is invaluable as software inevitably has version
# conflicts.

# Anyway, to start the notebook server, run the following. This will bring up
# a webpage which will let you open "notebook" files, and you should be able
# to open the .ipynb file that is attached.
jupyter-notebook

*------------------------------------------------------------------------------------------------------------------------
* smbl & metabolic networks for matt (27 apr 2016)

  cd ~/s/work/priceLab/mattRichards/
  source("toTables.R"); runTests()

*----------------------------------------------------------------------------------------------------
* rececol paper:  An application of recreation resource assessment techniques to inform management action in
   an urban-proximate natural area

  Ashley D'Antonio a,n, Christopher Monz a, Nell Larson b, Amy Rohman a

*----------------------------------------------------------------------------------------------------
* a variety of trena-usable matrices from ampADMayo.64253genes.278samples.RData (28 sep 2016)

  added to ~/github/Private_Cory_Data/inst/extdata

  print(load("~/github/Private_Cory_Data/inst/extdata/prepped.tcx.matrices.RData"))

*----------------------------------------------------------------------------------------------------
* create variety of trena-usable matrices from ampADMayo.64253genes.278samples.RData (26 apr 2016)

  cd ~/s/data/priceLab/AD/expression.matrix.prep/
  R -f prepareMatrices.R

     saving mtx.tcx: 18281 278
     saving mtx.tcx.ctl: 18281 80
     saving mtx.tcx.ad: 18281 84

  to load:
     print(load("~/s/data/priceLab/AD/expression.matrix.prep/prepped.tcx.matrices.RData"))
     "mtx.tcx"     "mtx.tcx.ctl" "mtx.tcx.ad"

*----------------------------------------------------------------------------------------------------
* first rcyjs/trena map (14 apr 2016)

   cd ~/github/TReNA/inst/misc/batchRuns/
   go.R
   has functions displayModel, genome.layout

*----------------------------------------------------------------------------------------------------
* abca7 deep dive (26 apr 2016)

   --- trena run, bayes.spike only 500 bp shoulders only

   http://content.iospress.com/articles/journal-of-alzheimers-disease/jad121546
   "selected SNPs in MZF-1 gene exert a minor effect on AD risk."

     subset(tbl, target=="ABCA7")
            tf        beta         pval         z      post     score    gene.cor target  dzClass geneClass
     1    MZF1  1.19349693 7.325848e-22  9.608998 1.0000000 21.135142  0.64655268  ABCA7  control      risk
     2   SPDEF  0.20152760 2.564777e-07  5.152908 0.8266366  6.590950  0.32082072  ABCA7  control      risk
     3     SP7 -0.16905896 3.467300e-05 -4.140381 0.9697852  4.460009 -0.32756550  ABCA7  control      risk
     4     SP6  0.03475578 1.501636e-02  2.431984 0.2775770  1.823435  0.26183568  ABCA7  control      risk
     5  GTF2A2  0.04184775 4.974331e-02  1.962165 0.1383122  1.303265  0.07749733  ABCA7  control      risk

     6    MZF1  1.21177126 6.510265e-24 10.083881 1.0000000 23.186401  0.75423767  ABCA7 affected      risk
     7    EGR1 -0.21351222 3.321610e-07 -5.104220 0.8245462  6.478651 -0.30037798  ABCA7 affected      risk
     8     SP6 -0.15005182 1.213041e-05 -4.375231 0.8906846  4.916125 -0.51086913  ABCA7 affected      risk
     9   PATZ1 -0.38343290 1.761221e-04 -3.751012 0.4858097  3.754186 -0.36354965  ABCA7 affected      risk
     10   ETV6  0.30463968 2.382905e-04  3.674527 0.6944336  3.622893  0.11509969  ABCA7 affected      risk
     11   ETV4  0.04115155 3.284550e-03  2.939771 0.2749467  2.483524  0.58222281  ABCA7 affected      risk
     12    SP4 -0.19402088 9.304522e-03 -2.600658 0.3677726  2.031306 -0.33578541  ABCA7 affected      risk
     13    ERF -0.14258098 9.936753e-03 -2.578022 0.3345832  2.002755 -0.11678146  ABCA7 affected      risk
     14  KLF12  0.08841581 2.242574e-02  2.283079 0.2170341  1.649253  0.09460772  ABCA7 affected      risk


*----------------------------------------------------------------------------------------------------
* cory's hypothesis:  are there any tf's enriched in the AD gwas genes? (26 apr 2016)


   --- preamble: display gwas manhattan plot, and all "nearby" snps in footprints

    cd ~/s/data/priceLab/AD
    go.R

       library(igvR)
       igv <- igvR()
       # make sure genome is hg38
       print(load("tbl.gwas.level_1.RData"))
       displayGWASTable(igv, tbl.gwas, "gwas level 1")
       print(load("tbl.gwasADsnpsInFp.05pval.igap2013.RData"))
       displayBedTable(igv, tbl.gwasADsnpsInFp[, c("chr", "mfpStart", "mfpEnd", "name")], "gwas snp in fp")


    --- run latest trena on these gwas-implicated genes
     cory directs me to 20 genes in supplemental table 6 in the igap paper
     http://www.nature.com/ng/journal/v45/n12/abs/ng.2802.html
     http://www.nature.com/ng/journal/v45/n12/extref/ng.2802-S1.pdf, scroll to page 28

     gad <- c("ABCA7", "APOE", "BIN1", "CASS4", "CD2AP", "CELF1", "CLU", "CR1", "EPHA1", "FERMT2",
              "HLA-DRB1", "INPP5D", "MEF2C", "MS4A6A", "NME8", "PICALM", "PTK2B", "SLC24A4", "RIN3",
              "SORL1", "ZCWPW1")

   --- validate these names
     library(biomaRt)
     ensembl.hg38 <- useMart("ensembl", dataset="hsapiens_gene_ensembl")
     coi <- c("entrezgene", "chromosome_name", "start_position", "hgnc_symbol")
     key <- "hgnc_symbol"
     tbl <- getBM(attributes=coi, filters=key, values=gad, mart=ensembl.hg38)

   --- the script: ~/s/data/priceLab/AD/enrichedTfsForIgap21genes.4
     library(TReNA)
     library(biomaRt)
     library(RUnit)
     gad <- c("ABCA7", "APOE", "BIN1", "CASS4", "CD2AP", "CELF1", "CLU", "CR1", "EPHA1", "FERMT2",
              "INPP5D", "MEF2C", "MS4A6A", "NME8", "PICALM", "PTK2B", "SLC24A4", "RIN3",
              "SORL1", "ZCWPW1")
     gad.risk <- c("ABCA7", "APOE", "BIN1", "CD2AP", "CELF1", "CR1", "FERMT2", "PTK2B", "INPP5D")
     gad.preventive <- c("CASS4", "CLU", "EPHA1", "MEF2C", "MS4A6A", "NME8", "PICALM",
                         "SLC24A4", "RIN3", "SORL1", "ZCWPW1")

     # make sure these gene symbols are all legit
     if(!exists("ensembl.hg38"))
     ensembl.hg38 <- useMart("ensembl", dataset="hsapiens_gene_ensembl")
     coi <- c("entrezgene", "chromosome_name", "start_position", "hgnc_symbol")
     key <- "hgnc_symbol"
     tbl <- getBM(attributes=coi, filters=key, values=gad, mart=ensembl.hg38)
     checkTrue(all(gad %in% tbl$hgnc_symbol))
     source("~/github/TReNA/inst/misc/batchRuns/runForSpecifiedGenes.R")
     run(gad)


   --- results written to ~/s/data/priceLab/AD/tfEnrichmentIgapGenes/
    status:  set aside in favor of abca7 deep dive

   --- REPRODUCE this note

     cd ~/s/data/priceLab/AD/
     source("enrichedTfsForIgap21genes.R")

     this specifies genes of interest ("gad" 20 igap ad genes) then

       source("~/github/TReNA/inst/misc/batchRuns/runForSpecifiedGenes.R")

     which currently (badly) hard-codes size.upstream and down and the output.directory

     cd ~/s/data/priceLab/AD/tfEnrichmentIgapGenes

     where results are written, and where go.R will create a single data.frame
     note: choosing shoulders of promoter search leads to very different betas and tfs.


     subset(tbl, target=="ABCA7")
            tf        beta         pval         z      post     score    gene.cor target  dzClass geneClass
     1    MZF1  1.19349693 7.325848e-22  9.608998 1.0000000 21.135142  0.64655268  ABCA7  control      risk
     2   SPDEF  0.20152760 2.564777e-07  5.152908 0.8266366  6.590950  0.32082072  ABCA7  control      risk
     3     SP7 -0.16905896 3.467300e-05 -4.140381 0.9697852  4.460009 -0.32756550  ABCA7  control      risk
     4     SP6  0.03475578 1.501636e-02  2.431984 0.2775770  1.823435  0.26183568  ABCA7  control      risk
     5  GTF2A2  0.04184775 4.974331e-02  1.962165 0.1383122  1.303265  0.07749733  ABCA7  control      risk

     6    MZF1  1.21177126 6.510265e-24 10.083881 1.0000000 23.186401  0.75423767  ABCA7 affected      risk
     7    EGR1 -0.21351222 3.321610e-07 -5.104220 0.8245462  6.478651 -0.30037798  ABCA7 affected      risk
     8     SP6 -0.15005182 1.213041e-05 -4.375231 0.8906846  4.916125 -0.51086913  ABCA7 affected      risk
     9   PATZ1 -0.38343290 1.761221e-04 -3.751012 0.4858097  3.754186 -0.36354965  ABCA7 affected      risk
     10   ETV6  0.30463968 2.382905e-04  3.674527 0.6944336  3.622893  0.11509969  ABCA7 affected      risk
     11   ETV4  0.04115155 3.284550e-03  2.939771 0.2749467  2.483524  0.58222281  ABCA7 affected      risk
     12    SP4 -0.19402088 9.304522e-03 -2.600658 0.3677726  2.031306 -0.33578541  ABCA7 affected      risk
     13    ERF -0.14258098 9.936753e-03 -2.578022 0.3345832  2.002755 -0.11678146  ABCA7 affected      risk
     14  KLF12  0.08841581 2.242574e-02  2.283079 0.2170341  1.649253  0.09460772  ABCA7 affected      risk





*----------------------------------------------------------------------------------------------------
* run TReNA on ampADMayo.64253genes.278samples.RData, preserve ENSG ids (25 apr 2016)

  cory suggests looking first at the neighborhood of PIEZ02: chr18:10,668,247-11,150,762

    the ensembl annotation landing page: http://uswest.ensembl.org/info/data/ftp/index.html
    here's the specific on for all transcripts (RNAseq): ftp://ftp.ensembl.org/pub/release-84/gtf/homo_sapiens
    This one is on the landing page under Homo_sapaiens, "GTF"

    ftp://ftp.ensembl.org/pub/release-84/gtf/homo_sapiens/Homo_sapiens.GRCh38.84.chr.gtf.gz
    ~/s/data/public/ensembl/Homo_sapiens.GRCh38.84.chr.gtf.gz  45671176 Mar  8 15:53

   grep -i -n ENSG00000154864 Homo_sapiens.GRCh38.84.chr.gtf | wc -l  #      642
    temporarily set aside: many hundreds of lines in the

   --- also try biomaRt
     library(biomaRt)
     ensembl.hg38 <- useMart("ensembl", dataset="hsapiens_gene_ensembl")
     tbl <- getBM(attributes=c("entrezgene", "chromosome_name", "hgnc_symbol"), filters="chromosome_name", values="5", mart=ensembl.hg38)
      head(getBM(attributes=c("hgnc_symbol"), filters="chromosome_name", values="5", mart=ensembl.hg38))

   line number start/end for: ENSG 2219062-2219703   2209062-2229703
   head -2229703 Homo_sapiens.GRCh38.84.chr.gtf  | tail -21000 > piez02-neighborhood.tsv
     # too many genes, get fewer
   head -12000 piez02-neighborhood.tsv | tail -2000 > piez02-2k.tsv
   tbl <- read.table("~/s/data/public/ensembl/piez02-2k.tsv", sep="\t", as.is=TRUE, header=FALSE)
   table(tbl[, "V3"])
            CDS            exon  five_prime_utr            gene     start_codon      stop_codon three_prime_utr      transcript
            531             933             111              63              53              47              99             163
   col9 <- tbl[,9]
   tokens <- strsplit(col9, split=";")
   biotype <- unlist(lapply(tokens, function(x) grep("gene_biotype", x, v=TRUE)))
   biotype <- sub(" gene_biotype ", "", biotype)
   geneID <- unlist(lapply(tokens, function(x) grep("gene_id", x, v=TRUE)))
   geneID <- sub("gene_id ", "", geneID)
   length(geneID) # [1] 2000
   length(unique(geneID)) # [1] 64

   as.data.frame(table(biotype))
                            biotype Freq
                                TEC    3
                          antisense   39
                            lincRNA  109
                              miRNA    6
               processed_pseudogene   51
                     protein_coding 1735
                               rRNA    3
                              snRNA    3
   transcribed_processed_pseudogene   25
 transcribed_unprocessed_pseudogene   18
             unprocessed_pseudogene    8

   colnames(tbl) <- c("chrom", "style", "type", "start", "end", "col6", "strand", "col8", "col9", "biotype")
   tbl <- tbl[, c("chrom", "style", "type", "start", "end",  "strand", "biotype", "col6", "col8", "col9")]
   tbl$geneID <- geneID
   tbl <- tbl[, c("chrom", "geneID", "style", "type", "start", "end",  "strand", "biotype", "col6", "col8", "col9")]

   save(tbl, file="tbl.piez02-neighorhood-1k.RData")
   print(load("~/s/data/priceLab/AD/tbl.piez02-neighorhood-1k.RData"))


   --- FootprintFinder updated to handle ensemble_gene_ids as well as gene symbols
     TReNA package version 0.99.22

   --- now add new test to test_TReNA.R using only non-coding genes
     choose non-coding genes, add tfs (after mapping to ensembl_gene_ids), create a test matrix
       to save in TReNA/inst/extdata

     print(load("~/s/data/priceLab/AD/tbl.piez02-neighorhood-1k.RData"))
     genes.noncoding.near.piez02 <- unique(subset(tbl, biotype != "protein_coding" & type != "exon")$geneID) # 54
     [1] "ENSG00000272799" "ENSG00000223138" "ENSG00000263630" "ENSG00000265554" "ENSG00000264876" "ENSG00000266102"
     [7] "ENSG00000260913" "ENSG00000265728" "ENSG00000266604" "ENSG00000264503" "ENSG00000264311" "ENSG00000264072"
    [13] "ENSG00000266470" "ENSG00000265038" "ENSG00000260779" "ENSG00000264843" "ENSG00000264714" "ENSG00000274838"
    [19] "ENSG00000263952" "ENSG00000263682" "ENSG00000267051" "ENSG00000273119" "ENSG00000267564" "ENSG00000267425"
    [25] "ENSG00000267252" "ENSG00000267371" "ENSG00000236396" "ENSG00000267794" "ENSG00000257513" "ENSG00000267143"
    [31] "ENSG00000267773" "ENSG00000260759" "ENSG00000267333" "ENSG00000267455" "ENSG00000267165" "ENSG00000272703"
    [37] "ENSG00000273141" "ENSG00000267079" "ENSG00000267661" "ENSG00000266955" "ENSG00000267480" "ENSG00000266995"
    [43] "ENSG00000267292" "ENSG00000212712" "ENSG00000267533" "ENSG00000256616" "ENSG00000267722" "ENSG00000267478"
    [49] "ENSG00000200827" "ENSG00000267162" "ENSG00000267116" "ENSG00000279285" "ENSG00000267643" "ENSG00000267733"

     --- got tfs out this way, based upon test_FootprintFinder, test_getFootprintsForEnsemblGenes
    goi <- "ENSG00000273141"
    db.uri <- sprintf("sqlite:%s", system.file(package="TReNA.brain", "extdata", "fpTf.sqlite"))
    fp <- FootprintFinder(ensembl.hg38, db.uri, goi)

    tbl <- getFootprints(fp, goi, 7000, 7000)
    tfs <- unique(tbl$tfs)

    ensembl.hg38 <- useMart("ensembl", dataset="hsapiens_gene_ensembl")
    tbl.bm <- getBM(attributes=c("ensembl_gene_id", "hgnc_symbol"), filters="hgnc_symbol", values=tfs, mart=ensembl.hg38)
    tfs.ens <- unique(tbl.bm$ensembl_gene_id)   # 242
    genes.ens <- c(genes.noncoding.near.piez02, tfs.ens)
    length(genes.ens)  # 296

    --- now build the minimum expression matrix to run with trena
      print(load("~/s/data/priceLab/AD/ampADMayo.64253genes.278samples.RData"))
      dim(mtx) # [1] 64253   278
      inactive.rows <- which(rowSums(mtx) < 10)   # 36254 rows
      mtx <- mtx[-inactive.rows,]
      tfs.ens <- intersect(tfs.ens, rownames(mtx)) # 189
      noncoding.genes.active <- intersect(genes.noncoding.near.piez02, rownames(mtx))
      rowSums(mtx[noncoding.genes.active,])
      ENSG00000272799: 12.82413
      ENSG00000265728: 16.67319
      ENSG00000264843: 57.52538
      ENSG00000264714: 121.75346
      ENSG00000267165: 1677.00154
      ENSG00000273141: 23.54717
      ENSG00000267079: 17.12701
      ENSG00000267480: 32.90891
      ENSG00000212712: 16.93189
      ENSG00000267533: 14.80689
      ENSG00000256616: 280.77997
      ENSG00000267478: 12.26161
      ENSG00000267733: 104.83652
      sapply(fivenum(rowSums(mtx)), as.integer)
        ENSG00000207181 ENSG00000261546 ENSG00000185291 ENSG00000162714 ENSG00000210082
                     10              68             926            7035        16797664
      genes.ens <- unique(c(tfs.ens, noncoding.genes.active)) # 202
      mtx.nonCoding <- mtx[genes.ens,]
      genes.noncoding.near.piez02.active <- noncoding.genes.active
      save(mtx.nonCoding, genes.noncoding.near.piez02.active, file="../extdata/mtx.AD.noncodingNearPiez02.RData") # 340k

*----------------------------------------------------------------------------------------------------
* postgres tips (24 apr 2016)

  found version 9.3 ships with osx.  installed it.  root user: posgres, pw=postgres, on port 5432
  installed as /Applications/PostgreSQL 9.3
  utilities here:

     /Library/PostgreSQL/9.3/bin

    clusterdb createdb createlang createuser dropdb droplang dropuser
    ecpg initdb oid2name pg_archivecleanup pg_basebackup pg_config
    pg_controldata pg_ctl pg_dump pg_dumpall pg_isready pg_receivexlog
    pg_resetxlog pg_restore pg_standby pg_test_fsync pg_test_timing
    pg_upgrade pg_xlogdump pgbench pltcl_delmod pltcl_listmod
    pltcl_loadmod postgres postmaster psql reindexdb vacuumdb vacuumlo

  --- added to PATH, in ~/.bashrc
     PATH=$PATH:/Library/PostgreSQL/9.3/bin

  --- create new user:  add me (pshannon) with db creation privileges
     login as postgres root:
        psql -U postgres
     create role pshannon with password 'pshannon' login createdb;
      \du
                                   List of roles
       Role name |                   Attributes                   | Member of
      -----------+------------------------------------------------+-----------
       postgres  | Superuser, Create role, Create DB, Replication | {}
       pshannon  | Create DB                                      | {}

  --- every user apparently needs a database of their own, with their name:

   /Library/PostgreSQL/9.3/bin/createdb -U postgres pshannon

  --- test this out by creating tcx (temporal cortex) database, fill with tbl.fp
    /Library/PostgreSQL/9.3/bin/createdb -U pshannon tcx

  --- list databases
    psql -U postgres
    \l
                                   List of databases
         Name    |  Owner   | Encoding | Collate | Ctype |   Access privileges
      -----------+----------+----------+---------+-------+-----------------------
       postgres  | postgres | UTF8     | C       | C     |
       pshannon  | postgres | UTF8     | C       | C     |
       tcx       | pshannon | UTF8     | C       | C     |
       template0 | postgres | UTF8     | C       | C     | =c/postgres  postgres=CTc/postgres
       template1 | postgres | UTF8     | C       | C     | =c/postgres  postgres=CTc/postgres


   --- create footprints table withing tcx (temporal cortext) database
     psql -U pshannon
     \l
     \c tcx
     tcx=> create table footprints(chr char(40),  mfpStart int, mfpEnd int, motifName char(24),  motifLength int,
                             footprintLength int, strand char(1),  score real, pvalue real, mystery int,   sequence char(36))
     \dt
                 List of relations
       Schema |    Name    | Type  |  Owner
      --------+------------+-------+----------
       public | footprints | table | pshannon
      (1 row)

    tcx=> \copy footprints from '/Users/paul/github/TReNA.lymphoblast/inst/extdata/lymphoblast_fp.bed' delimiter E'\t' CSV;
    tcx-> select count(*) from footprints;  #  10091138

    --- abandoned RPostgreSQL since it failed to connect:
      db <- dbConnect(PostgreSQL(), user= "pshannon", password="pshannon", dbname="tcx")
      Error in postgresqlNewConnection(drv, ...) :
       RS-DBI driver: (could not connect pshannon@local on dbname "tcx"

    --- finally figured out how to connect: make host explicit, default 'local' does not exist
     db <- dbConnect(PostgreSQL(), user="pshannon", password="pshannon", port=5432, dbname="tcx", host="localhost")
     query <- "select count(*) from footprints"
     dbGetQuery(db, query)
          count
     1 10091138
     # or
     rs <- dbSendQuery(db, query)
     length(rs)  #
     fetch(rs, 1)
        count
     1 10 091 138
     #  get data.frame
     query <- "select * from footprints limit(4)"
     dim(dbGetQuery(db, query)) # 4, 11
     colnames(dbGetQuery(db, query))
       [1] "chr"             "mfpstart"        "mfpend"          "motifname"
       [5] "motiflength"     "footprintlength" "strand"          "score"
       [9] "pvalue"          "mystery"         "sequence"



*----------------------------------------------------------------------------------------------------
* next up (sunday, 24 apr 2016)

  new package created: ~/github/TReNA.lymphoblast/
  make sure it works with test_FootpringFinder.R
  then try it with ~/github/TReNA/inst/misc/batchRuns/runFromPkg.R

*----------------------------------------------------------------------------------------------------
* make sqlite database and simple R data package out of lymphoblast TReNA.lymphoblast data (23 apr 2016)

  cd ~/github/TReNA.lymphoblast/inst/extdata/
  file from cory: lympoblast_fp.bed
  added these columns
      chr	mfpStart	mfpEnd	motifName	motifLength	footprintLength	strand	score	pvalue	mystery	sequence
	1	10799	10834	KLF16_DBD	23	33	-	14.9082	5.09e-06	0	GCCACGCCTCC
	1	10799	10834	MA0039.2	24	33	+	9.93878	9.81e-05	0	GAGGCGTGGC
	1	10799	10834	MA0079.3	17	27	-	11.0192	6.47e-05	0	CCTCCACCCCG

  --- also need motif-to-gene mapping
   library(PrivateCoryData)
   print(data(tbl.motifToMultipleGenes))
   write.table(tbl.motifToMultipleGenes, sep="\t", col.names=TRUE, row.names=FALSE, quote=FALSE, file="motifToMultipleGenes.tsv")


  --- now add them to sqlite database:
     library(RSQLite)
     db <- dbConnect(dbDriver("SQLite"), "lymphoblast-fp.sqlite")
     tbl.fp <- read.table("lymphoblast_fp.bed", header=TRUE, as.is=TRUE, sep="\t")
     dbWriteTable(db, "footprints", tbl.fpAnnotated, append=TRUE)      # < 15 seconds, 10,091,138 rows
     tbl.motifToMultipleGenes <- read.table("motifToMultipleGenes.tsv", sep="\t", header=TRUE, as.is=TRUE) # 9289 x 2
     dbWriteTable(db, "motifsGenes", tbl.motifToMultipleGenes, append=TRUE)  # 9289 x 2
     #dbWriteTable(db, "humangenes", humangenes,  append=TRUE)  # 64216 x 5
     dbGetQuery(db, "select count(*) from footprints, motifsGenes, where motifName='MA0813.1'")
     dbGetQuery(db, "select * from footprints where motifName='MA0813.1' limit 4")
        chr mfpStart mfpEnd motifName motifLength footprintLength strand    score   pvalue mystery      sequence
      1   1   779172 779199  MA0813.1          15              27      + 11.52460 3.83e-05       0 GCCCCCTGAGGCT
      2   1   827115 827150  MA0813.1          23              35      + 15.13110 5.48e-06       0 TGCCCTGAGGGGC
      3   1   869912 869947  MA0813.1           7              19      -  9.31148 8.54e-05       0 CCCCCTGGTGGCA
      4   1   869913 869948  MA0813.1           6              18      -  9.31148 8.54e-05       0 CCCCCTGGTGGCA

     dbDisconnect(db)
*----------------------------------------------------------------------------------------------------
* ractive + cellphone network (22 apr 2016)

  cd ~/s/examples/cyjs/cellphone-simple/
  copied index.html, network.json, vizmap.json from ~/github/cellphone/explorations/plainHTML

*----------------------------------------------------------------------------------------------------
* post-doc candidate max, from bill noble's lab:

  says inverse hyperbolic sine transform, well-behaved around zero, is the standard way to
  transform count data.  so that, for instance, the differene between 5 & 10 is much
  different between 105 & 110
  log(c(5,10))      #  1.609438 2.302585    diff: 0.69
  log(c(105,110))   #  4.65396  4.70048     diff: 0.046
  asinh(c(5,10))    #  2.312438 2.998223    diff: 0.68
  asinh(c(105,110)) #  5.347130 5.393648    diff 0.046

  — near zero

   log  (c(0.00000001, 0.000000012))  # [1] -18.42068 -18.23836   diff: 0.18
   asinh(c(0.00000001, 0.000000012))  # [1] 1.0e-08 1.2e-08       diff: -2e-09


encode nature portal, one paper focused transcription prediction, histone modification
deep-sea: predict

  predict sequence to a) histone modification & tf binding, causually linked given cell type
  both of which are causally linked to gene expression.

*----------------------------------------------------------------------------------------------------
* new trena, explore results, look for bugs (19 apr 2016)

  cd ~/github/TReNA/inst/misc/batchRuns/u5kd5k/

  --- plan: create an interactions table, load into neo4j, look for a hotspot
   see below for previous work filling interactions into neo4j: "* neo4j tips: fill from makefile"

  --- first test: take liz blue's 44 genes
     ~/github/Private_Cory_Data/inst/extdata/trn10.genes44/genes.44.RData
     create data.frame of all interactions from trena for 41/44 liz blue genes.
     these three missing, maybe just naming error:  HLA, ZCWWPW1, FASLG

    reload(); run();   creates
      ~/github/TReNA/inst/misc/batchRuns/u5kd5k/neo4j:
          5912 Apr 19 12:34 go.R
         80356 Apr 19 12:35 interactions.tsv
          1316 Apr 19 12:34 molecules.tsv

   --- working version
     cd ~/github/TReNA/inst/misc/batchRuns/u5kd5k/neo4j/
     R> reload(); run()   # currently filtered at abs(beta) > 0.4
     bash>
       make clear
       make fill.m
       make fill.i
       make report   # 140 nodes,    178 edges

*----------------------------------------------------------------------------------------------------
* running new trena on full genome: about 10 hours with two solvers, lasso & bayesSpike (19 apr 2016)

  cd ~/github/TReNA/inst/misc/batchRuns/
  source("chr5.R")
  for(chrom in 1:22) run(as.character(chrom))
  in ~/github/TReNA/inst/misc/batchRuns/u5kd5k/
     2410 Apr 18 15:39 MIIP.trena.RData
     2620 Apr 19 01:52 DNAL4.trena.RData

*----------------------------------------------------------------------------------------------------
* another aspect of scientific wellness: environmental and economic correlates of health in south seattle

  a case study in scientific wellness: environmental and economic correlates of health in south seattle

Public School Explorations of Environmental and Economic Correlates of
Health in South Seattle: a Case Study in Scientific Wellness

Poor children in Seattle are hospitalized for asthma at twice the rate
as children from higher income families.

Life expectancy in Seattle is corrleated with income: those from
prosperous neighborhoods live up to ten years longer than residents of
poor neighborhoods.

These two examples - one from early life, one from late - are among
the most vivid phemonema to emerge from a 2013 EPA study (add
reference to Linn Gould's research).  Though causality is complex, the
data show compelling correlations across many measures of poverty,
neighborhood, race and wellness.

Though these measures and these phenomena may not yet be included among
the standard assays of the emerging discipline of scientific wellness,
it may be appropriate to give them some attention.

To that end, and in league with staff and faculty at Cleveland High
School, we have developed an interactive web application to explore
these data.  The webapp offers side-by-side Seattle zip code maps for
comparisons of twenty categories of the 2013 data. Correlation plots
can be made for any pair of factors.

  http://clevelandehc.systemsbiology.net/

We request modest ongoing support for this project.  It combines the
ISB's commitment to scientific wellness and to public school
education.   We predict these  concrete results:

  1) Environmental science, biology and statistcs students at
     Cleveland will learn and apply scientific methods to matters
     directly related to their lives and their community.

  2) With skillful use of press and media, we citizens of Seattle
     will become better informed about the actual circumstances
     in which we live.

  3) The ISB's reputation will be modestly enhanced as we foster the
     application of the tools of scientific wellness - and P4 medicine
     - to sectors of our community who are otherwise not likely to
     benefit.


*----------------------------------------------------------------------------------------------------
* obliteride signs along the lake (14 apr 2016)

  spoke with leslie, who reluctantly promised to contact me with resolution.

*----------------------------------------------------------------------------------------------------
* hadley ggplot2 heatmap (14 apr 2016)

  cd ~/s/work/robMoritz/cholesterolRegulation/
  this worked, after lots of fuss:.  the limits parameter keeps the

   heatmap <- function(tbl.melt, title) {
      colors <- c("-2" = "blue", "0" = "white", "2" = "red")
      (p <- ggplot(tbl.melt, aes(time, celline))
             + ggtitle(title)
             + geom_tile(aes(fill = value), colour = "white")
             #+ scale_fill_gradient2(low="dodgerblue", mid = "white", high = "red", midpoint=0, limits=c(-2, 2))
             + scale_fill_gradientn(values=rescale(c(-2, 0, 2)), colours=c("dodgerblue", "white", "red"), limits=c(-2.0, 2.0))
             + ylim(rev(levels(tbl.melt$celline))))
      } # heatmap

    gene <- "MKI67"
     reload(); tbl.melt <- createTableMelt(tbl.raw, gene);  heatmap(tbl.melt, gene)

*----------------------------------------------------------------------------------------------------
* hadley heatmap (13 apr 2016)

   https://learnr.wordpress.com/2010/01/26/ggplot2-quick-heatmap-plotting/
   ~/s/examples/bioc/ggplot/nba.R

     library(ggplot)
     library(reshape)
     library(plyr)
     library(dplyr)
     library(scales)

     nba <- read.csv("http://datasets.flowingdata.com/ppg2008.csv")  # 50 x 21

     # The players are ordered by points scored, and the Name variable
     #converted to a factor that ensures proper sorting of the plot.

     nba$Name <- with(nba, reorder(Name, PTS))

     # Whilst FlowingData uses heatmap function in the stats-package that
     # requires the plotted values to be in matrix format, ggplot2 operates
     # with dataframes. For ease of processing, the dataframe is converted
     # from wide format to a long format.

     # The game statistics have very different ranges, so to make them comparable
     # all the individual statistics are rescaled.

     nba.m <- melt(nba)
     nba.m <- ddply(nba.m, .(variable), transform, rescale = rescale(value))

     (p <- ggplot(nba.m, aes(variable, Name))
                  + geom_tile(aes(fill = rescale), colour = "white")
                  + scale_fill_gradient(low = "white", high = "steelblue"))


*----------------------------------------------------------------------------------------------------
* daniel's 3d graphics viewer: three.js (12 apr 2016)

   cd   ~/s/examples/js/three/particles

   --- create a scene, a green spinning cube
      http://threejs.org/docs/#Manual/Introduction/Creating_a_scene
      ~/s/examples/js/three/tutorial-createScene/index.html

  --- display many points
     1,000,000 in about 8 seconds
     ~/s/examples/js/three/particles/index.html
     appears to need no local webserver support.  uses cdn and no locally loaded textures

        <script src="https://cdnjs.cloudflare.com/ajax/libs/three.js/r77/three.min.js"></script>
        <script src="https://cdnjs.cloudflare.com/ajax/libs/three.js/r75/three.min.js"></script>

*----------------------------------------------------------------------------------------------------
* rcyjs setNodeAttributes parse/eval mystery (11 apr 2016)

  construct this string from:
    var name = "YY1"
    var attributeName = "score"
    var value = 13

  cy.nodes().filter("[name='YY1']").data({"score": 13})

   --- this does not work
     var filterString     = "[name='" + name + "']"
     var assignmentString = "{'" + attributeName + "': " + value + "}"

   --- this does
      var name = nodeIDs[i];
      var newValue = msg.payload.values[i];
      var filterString = "[name='" + name + "']";
      console.log("filterString: " + filterString);
      console.log("nodeID: " + name + "   value: " + newValue);
      var dataObj = cy.nodes().filter(filterString).data();
      Object.defineProperty(dataObj, attributeName, {value: newValue});


*----------------------------------------------------------------------------------------------------
* first large-scale batch operation of the refactored TReNA (9 apr 2016)

  cory proposes:  construct trns for all genes for two sample sets,
    for TCX (temporal cortex) data.
    80 ctl samples, 84 AD, 18281 genes after mapping to hugo symbol, eliminating low variance genes.
    saved two matrices:
    save(mtx.tcx.ctl, mtx.tcx.ad, file="~/github/TReNA/inst/misc/batchRuns/mtx.tcx.ctl80.ad84.genes18281.RData")

  --- next up: run trena, per gene, for all genes on chr5, separately for each of AD and CTL

*----------------------------------------------------------------------------------------------------
* update clevelandehc (8 apr 2016) ie compatibility

  --- on macbook
    changed jquery library to ie compatible version in
      ~/github/Oncoscape/Oncoscape/inst/scripts/index.common
      old: <!-- script src="http://oncoscape-static.s3-website-us-west-2.amazonaws.com/js/jquery-2.1.3.min.js"></script-->
      new: <script src="https://code.jquery.com/jquery-1.12.3.min.js"></script>

    git add, commit, push

  --- on eager
    cd ~/github/clevelandHighSchool
    git pull    # get latest version of index.common
    cd webapps/current

   --- find old process, kill it, start new
    ps x | grep run
    8824 ?        S      1:53 /usr/lib64/R/bin/exec/R -f runCleveland.R


*----------------------------------------------------------------------------------------------------
* ben logsdon's vbsr: variational bayes spike regression (7 aug 2016)

  cd ~/s/examples/R/vbsr/
  library(vbsr)
  set.seed(2)
  n <- 100
  m <- 95
  ntrue <- 10
  e <- rnorm(n)
  X <- matrix(rnorm(n*m),n,m)
  tbeta <- sample(1:m,ntrue)
  beta <- rep(0,m)
  beta[tbeta]<- rnorm(ntrue,0,2)
  y <- X%*%beta+e
  res<- vbsr(y,X,family='normal')
  plot(res$beta,beta)

*----------------------------------------------------------------------------------------------------
* test for normality (needed for lasso expression data) (7 apr 2016) suggested by hongdong

  https://cran.r-project.org/web/packages/nortest/index.html

  nortest: Tests for Normality, Five omnibus tests for testing the composite hypothesis of normality.

*----------------------------------------------------------------------------------------------------
* make matrix and test submatrix from AMP-AD_MayoBB_UFL-Mayo-ISB_IlluminaHiSeq2000_TCX_GeneCounts_Normalized_JulyRerun.txt

  print(load("~/s/data/priceLab/AD/ampADMayo.64253genes.278samples.RData"))   "mtx"
  cd  ~/github/TReNA/inst/unitTests
  f <- "~/s/work/cory/snpfp/mef2c-tf/AMP-AD_MayoBB_UFL-Mayo-ISB_IlluminaHiSeq2000_TCX_GeneCounts_Normalized_JulyRerun.txt"
  df <- read.table(f, , sep="\t", as.is=TRUE)   # 64253 278
  x <- sub("^X", "S", colnames(mtx))
  colnames(mtx) <- x
  save(mtx, file="ampADMayo.64253genes.278samples.

  mv ampADMayo.64253genes.278samples.RData ~/s/data/priceLab/AD/

  print(load("~/s/data/priceLab/AD/ampADMayo.64253genes.278samples.RData"))   "mtx"
  31.8M Apr  6 10:41 ampADMayo.64253genes.278samples.RData

*----------------------------------------------------------------------------------------------------
* haploreg downloads (7 apr 2016)

  http://www.broadinstitute.org/mammals/haploreg/data/

  whovian:/users/pshannon/s/data/haploreg/haploreg_v4.0_20151021.vcf.gz
     13,109,301,629 Apr  7 18:07

   --- email from luke ward

   It's great that Haploreg might be useful for your Alzheimer's
   pipeline! Since I left MIT two years ago I have only been
   able/allowed to develop Haploreg in my spare time, and that's
   mostly just been one data update. I agree that a REST framework
   would be more useful than the POST framework for plugging into
   tools like yours, but I don't have the technical skills or time to
   make that switch at this point.

   Since the whole thing is downloadable as a flat .vcf table, would
   you be able to accomplish the same thing by simply putting that
   table into a local sql or other database that could be queried?
   Especially since if you're just searching by variants or locations,
   those are available in their own columns.

Luke

On Wed, Mar 30, 2016 at 2:08 PM, Paul Shannon <pshannon@systemsbiology.org> wrote:
Hi Luke,

We have a rather ad hoc collection of tools and data for exploring variants and expression in Alzheimer’s Disease.  It’s am mix of R, python, desktop IGV and some browser-based visualizations.

It would be very handy if, from an R session, after having identified a region of interest, we could do something like this:

  haploreg <- "http://www.broadinstitute.org/mammals/haploreg/haploreg.php”;
  mef2c.args <- “loc=chr5:88047814-88237678”
  url <- sprintf(“%s?%s”, haploreg, mef2c.args)
  browseURL(url)

This ignores option setting and, not incidentally :} does not work in its current form.

Is there a way to do something like this?  If it were possible, we could weave haploreg into our exploratory work flow in quite a nice way.


*----------------------------------------------------------------------------------------------------
* trena refactor, next up (6 apr 2016)

  cd ~/github/TReNA/inst/unitTests/
  test_predict.mef2c.regulators
  parse out 58 tfs from + MEF2c from.  make this a test data matrix.  run the lasso model
  also with penalties calculated somehow
       # book.mef2c-tf> head -2 ~/s/work/cory/snpfp/mef2c-tf/AMP-AD_MayoBB_UFL-Mayo-ISB_IlluminaHiSeq2000_TCX_GeneCounts_Normalized_JulyRerun.txt | tail -1 |tr "\t" "\n" | nl
     # 1	ENSG00000000003
     # 2	    10.690786
     # 3	    15.237268
     # 4	    13.177868
     # 5	    11.059819


*----------------------------------------------------------------------------------------------------
* cory, minerva describe rs9357347 possibly affecting TREM2 regulation  (5 apr 2016)
  what footprints do we see?  good test for new LassoSolver?

  ---- email (5 apr 2016) frm minerva carrasquillo, nilufer taner also mentioned

   Yes, it would be great if you could evaluate how this regulatory
   SNP alters TF binding based on TReNA. The SNP is rs9357347, located
   within a DNase hypersensitive site, and it is predicted to alter
   both SP1 and PPAR binding. It is located within sequence reported
   to be subject to enhancer-associated histone marks in the
   hippocampus.


  ---- find footprints

    source("~/github/snpFoot/inst/misc/constrainTFs/lasso/go.R")
    x <- getFootprints("TREM2")

  ---- the snp?  rs9357347
    biocLite("SNPlocs.Hsapiens.dbSNP144.GRCh38")
    library("SNPlocs.Hsapiens.dbSNP144.GRCh38")
    snps <- SNPlocs.Hsapiens.dbSNP144.GRCh38
    s <- snpsById(snps, "rs9357347")  # a GRanges object
    [1]      ch6 [41182853, 41182853]      + |   rs9357347                M

    x <- getFootprints("TREM2")
      [1] --- biomart coordinates for TREM2
       entrezgene chromosome_name start_position end_position strand
     1      54209               6       41158506     41163186     -1
   [1] promoter region chr6:41157506-41158506

   --- distance from minus strand start to snp
     41182853 - 41163186: [1] 19667

   ---- args(getFootprints): (geneSymbol, size.upstream = 1000, size.downstream = 0)


   --- that snp, at chr6: 41182853
      source("~/github/snpFoot/inst/misc/constrainTFs/lasso/go.R")
      tbl.trem2fp <- getFootprints("TREM2", 20000, 0)
      range(c(tbl.trem2fp$mfpStart, tbl.trem2fp$mfpEnd))  # [1] 41163197 41182990
        # found just one motif, in the closest footprint
      unique(subset(tbl.trem2fp, mfpStart >= (loc-65) & mfpEnd <= loc)$motif)   # [1] "MA0479.1"


*----------------------------------------------------------------------------------------------------
* trena lasso scoring for predictor penalties (5 apr 2016)

  cd ~/github/TReNA/inst/unitTests/
  source("test_TReNA.R"); runTests()


*----------------------------------------------------------------------------------------------------
* cyjs demos, cy.js demos, cytoscape.js demos (5 apr 2016)

  cd ~/s/examples/cyjs

    Feb 18  2014 angiogenesis/
    Feb 20  2014 contributedDemos/
    Apr  5 10:07 contributedDemos2/     # copied from ~pshannon-isb/s/git/cytoscape.js-demos/*
    Feb  4  2013 cytoscape.js/
    Jan 20  2014 cytoscape.js-edgehandles-master/
    Feb  8  2014 demo0/
    Apr 27  2015 fileDriven/
    Feb 17  2014 hamidGBM/
    Feb 11  2014 js/
    Mar 13  2014 mouseMotionDisappearingNetworkChromeBug/
    Mar 31  2014 panzoomDemo/
    Aug  3  2015 qtip/
    Feb 17  2014 seinfeld/
    Mar 31  2014 simpleLoad/
    Feb 18  2014 single/
    Feb 18  2014 websiteDemo0/


*----------------------------------------------------------------------------------------------------
* cellphone webapp (5 mar 2016) first try with angular, ng2

  --- refreshed memory with RCyjs version
     cd ~/github/cellphone/explorations/
     go.R; reload()

  --- reproduced simple html/js only version
     cd ~/github/cellphone/explorations/plainHTML/
     cp ~/s/examples/cyjs/contributedDemos2/importFromCy3/x .   x: index.html, demo.js, network.js, vizmap.js, demo.css

  --- trim html/js version down to leaner operation
     cd ~/github/cellphone/explorations/plainHTML
     index.html script-includes network.json, vizmap.json
     displays nicely

  --- remind myself of elementary ng2 hello-world
    cd ~/s/study/angular2/book2/manuscript/code/first_app/hello-world
    npm run serve  # browser loads http://localhost:8080
    npm run go   # leads to tsc --watch: TypeScript compiler will recompile on changes to app.ts, reload the server

  --- ng2, first try
   cd ~/github/cellphone/explorations/ng2/try1
   copy minimum set of files from ~/s/study/angular2/book2/manuscript/code/first_app/hello-world
   grabbed: app.ts, index.html, package.json, styles.css, tsconfig.json
   npm install
   npm run go  # stays executing in shell, rebuilds and reloads on file change


*----------------------------------------------------------------------------------------------------
* biomaRt tips: get all genes (by symbol) on chr 5

   ensembl.hg38 <- useMart("ensembl", dataset="hsapiens_gene_ensembl")


   tbl <- getBM(attributes=c("entrezgene", "chromosome_name", "hgnc_symbol"), filters="chromosome_name", values="5", mart=ensembl.hg38)
   head(getBM(attributes=c("hgnc_symbol"), filters="chromosome_name", values="5", mart=ensembl.hg38))
     hgnc_symbol
1      MRPL36
2      CTNND2
3       SYNPO
4       THBS4
5       CTXN3

*----------------------------------------------------------------------------------------------------
* biomaRt tips:  get gene loc from gene symbol

library(biomaRt)
gene.loc <- function(geneSymbol) {
   if(!exists("ensembl.hg38"))
      ensembl.hg38 <- useMart("ensembl", dataset="hsapiens_gene_ensembl")
   getBM(attributes=c("entrezgene", "chromosome_name", "start_position", "end_position", "strand"),
         filters="hgnc_symbol", values=geneSymbol, mart=ensembl.hg38)
   }
getPromoterRegion <- function(geneSymbol, size=10000) {
   tbl.loc <- gene.loc(geneSymbol)
   if(tbl.loc$strand == 1){
      start <- tbl.loc$end_position
      end <- start + size
      }
   else{
       end <- tbl.loc$start_position
       start <- end - size
       }
   chrom <- sprintf("chr%s", tbl.loc$chromosome_name)
   return(list(chr=chrom, start=start, end=end))
   }

 in ~/github/snpFoot/inst/misc/constrainTFs/lasso/go.R

*----------------------------------------------------------------------------------------------------
* cory, snpFoot, trena, constraining tfs via lasso penalty by tf/motif frequency (4 apr 2016)

   use sqlite with table of per-tf footprint frequencies:

    db <- dbConnect(dbDriver("SQLite"), "~/github/snpFoot/inst/misc/sqlite.explorations/fpTf.sqlite")
    dbListTables(db)  # [1] "footprints"  "fpTfFreqs"   "humangene"   "motifsGenes"
    tbl.fpTfFreqs <- dbGetQuery(db, "select * from fpTfFreqs")
    fivenum(tbl.fpTfFreqs$fpCount) # [1]    241  11463  43495  92084 658334

   map these numbers into 0-1, penalize these tfs in lasso
*----------------------------------------------------------------------------------------------------
* cory, snpFoot: create rsqlite database for finding tfs for footprints via motifs (4 apr 2016)

   --- experimenting
     db <- dbConnect(dbDriver("SQLite"), "~/tmp/tmp.sqlite")
     dbWriteTable(db, "footprints", tbl.fpAnnotated, append=TRUE)      # just 12 seconds, 4692138 x 17
     dbWriteTable(db, "motifsGenes", tbl.motifToMultipleGenes, append=TRUE)  # 9289 x 2
     dbWriteTable(db, "humangenes", humangenes,  append=TRUE)  # 64216 x 5
     dbGetQuery(db, "select count(*) from footprints, motifsGenes, where motifName='MA0813.1'")
     dbGetQuery(db, "select * from footprints where motifName='MA0813.1' limit 4")

   --- first test: gene -> region -> footprints -> motif -> TFs


   ---- assign tfs to every footprint in the genome
   query <- paste(c("select fp.chr, fp.mfpStart, fp.mfpEnd, fp.pvalue, mg.motif, mg.tfs",
                 "from footprints fp",
                 "inner join motifsGenes mg",
                 "on fp.motifName=mg.motif"),
                 collapse=" ")

   system.time(tbl.tfFreq <- dbGetQuery(db, query))   # 70 seconds elapsed.  seemed like > 10 minutes
   dim(tbl.tfFreq)  #  62,876,576    6
   db2 <- dbConnect(dbDriver("SQLite"), "tfFreq.sqlite")
   dbWriteTable(db2, "tfFreqs", tbl.tfFreq)   # 3G

   --- save summary

     tbl.fpTfFreqs <- as.data.frame(sort(table(tbl.tfFreq$tfs)))
     colnames(tbl.fpTfFreqs) <- "fpCount"
     dim(tbl.fpTfFreqs) [1] 773   1
     head(tbl.fpTfFreqs, n=3); tail(tbl.fpTfFreqs, n=3)
           fpCount
     ZBED1     241
     ZBED2     241
     ZBED3     241
     ...
     SP7    658334
     SP8    658334
     SP9    658334

    dbWriteTable(db, "fpTfFreqs", tbl.fpTfFreqs)
    dbListTables(db)  # [1] "footprints"  "fpTfFreqs"   "humangene"   "motifsGenes"
    renamed this to ~/github/snpFoot/inst/misc/sqlite.explorations/fpTf.sqlite

   --- use it

    db <- dbConnect(dbDriver("SQLite"), "~/github/snpFoot/inst/misc/sqlite.explorations/fpTf.sqlite")
    dbListTables(db)  # [1] "footprints"  "fpTfFreqs"   "humangene"   "motifsGenes"
    tbl.fpTfFreqs <- dbGetQuery(db, "select * from fpTfFreqs")
    fivenum(tbl.fpTfFreqs$fpCount) # [1]    241  11463  43495  92084 658334

*----------------------------------------------------------------------------------------------------
* randomForest example, random forest example (31 mar 2016)

  using ~/github/TReNA/inst/unitTests/test_TReNA.R, the test_fitDREAM5_yeast function

   randomForest(t(mtx[tfs, ]), t(mtx["MET2",]))$importance
   randomForest(MET2 ~ CBF1 + MET32 + MET31 + MET4 + ACE2 + PHD1, data=t(mtx))$importance
         IncNodePurity
   CBF1      171.04479
   MET32     585.96066
   MET31      60.06936
   MET4      276.53179
   ACE2       71.41838
   PHD1       94.52314

   --- compare to lasso

    tbl.betas
                        1
   (Intercept)  0.7364848
   CBF1        -0.1069114
   MET32        0.6694136
   MET4         0.1254078
   PHD1         0.1491330


*----------------------------------------------------------------------------------------------------
* igv.js team, advice on displaying regions (bed-like, hint footprints) within a notebook into igv (19 aug 2016)

   If you create a subset of a bed file and save it locally to your
   Jupyter workspace, you should be able load the file into igv.js
   easily enough. The URL for the file will be something like
   http://localhost:8888/files/foo.bed, assuming that you're running
   Jupyter on your local machine.

   If you're working with your data in a pandas DataFrame, you'll need
   to write the data to disk first so it can be served up to igv.js as
   a file. (pandas.DataFrame.to_csv(sep='\t'))


   --- use the api
   dbsnp_track = Track(
       name="dbSNP 137",
       format="bed",
       url="https://data.broadinstitute.org/igvdata/annotations/hg19/dbSnp/snp137.hg19.bed.gz",
       index_url="https://data.broadinstitute.org/igvdata/annotations/hg19/dbSnp/snp137.hg19.bed.gz.tbi",
       visibility_window=200000)
   igv_instance.load_track(dbsnp_track)

*----------------------------------------------------------------------------------------------------
* igj.js tips: load hg38 gene annotation

  jim robinson adds gtf and gff3 support

  Hi, gtf (and gff3) are supported now, the URL above should
  work. These are big files, I suggest you put a limited on window
  size (visibilityWindow) such as the example below (set to
  10MB). Also set the indexURL

   {url: 'https://s3.amazonaws.com/igv.broadinstitute.org/data/hg38/gencode.v24.annotation.sorted.gtf.gz',
    indexURL: 'https://s3.amazonaws.com/igv.broadinstitute.org/data/hg38/gencode.v24.annotation.sorted.gtf.gz.tbi',
    name: 'Gencode v24',
    format: 'gtf',
    visibilityWindow: 10000000
    }

  --- try this out
    cd ~/s/examples/igv/igv-web/gtf-gff3/
    python -m http.server 8005
    browse to http://localhost:8005


    $(document).ready(function () {
        var div, options, browser;
        div = $("#myDiv")[0];
        options = {locus: "chr18:10,350,000-11,577,000",
                   reference: {fastaURL: "http://localhost:8005/Homo_sapiens.GRCh38.dna.chromosome.18.fa.gz"},
                   tracks: [
                     {url: 'https://s3.amazonaws.com/igv.broadinstitute.org/data/hg38/gencode.v24.annotation.sorted.gtf.gz',
                      indexURL: 'https://s3.amazonaws.com/igv.broadinstitute.org/data/hg38/gencode.v24.annotation.sorted.gtf.gz.tbi',
                      name: 'Gencode v24',
                      format: 'gtf',
                      visibilityWindow: 10000000
                      },
                     {url: "http://localhost:8005/chr18_CU0070F.shared.hg38.bed",
                       name: "eb",
                       indexed: false,
                       order: Number.MAX_VALUE,
                       displayMode: "EXPANDED"
                      }
                   ]
              }; // options
        browser = igv.createBrowser(div, options);
    });


   ---- where to get the reference data files?
     http://ftp.ensembl.org/pub/release-77/fasta/homo_sapiens/dna/Homo_sapiens.GRCh38.dna.chromosome.18.fa.gz
     but this file is not served up: must be downloaded and served up locally


    curl https://s3.amazonaws.com/igv.broadinstitute.org   # returns xml file, in need of parsing

      some results from here for hg38:
         annotations/hg38/genes/gencode.v24.annotation.sorted.gtf.gz
         annotations/hg38/genes/gencode.v24.annotation.sorted.gtf.gz.tbi
         annotations/hg38/rmsk/DNA.bed.gz
         annotations/hg38/rmsk/DNA.bed.gz.tbi
         annotations/hg38/rmsk/LINE.bed.gz
         annotations/hg38/rmsk/LINE.bed.gz.tbi
         annotations/hg38/rmsk/LTR.bed.gz
         annotations/hg38/rmsk/LTR.bed.gz.tbi
         annotations/hg38/rmsk/Low_complexity.bed.gz
         annotations/hg38/rmsk/Low_complexity.bed.gz.tbi
         annotations/hg38/rmsk/RC.bed.gz
         annotations/hg38/rmsk/RC.bed.gz.tbi
         annotations/hg38/rmsk/RNA.bed.gz
         annotations/hg38/rmsk/RNA.bed.gz.tbi
         annotations/hg38/rmsk/Retroposon.bed.gz
         annotations/hg38/rmsk/Retroposon.bed.gz.tbi
         annotations/hg38/rmsk/SINE.bed.gz
         annotations/hg38/rmsk/SINE.bed.gz.tbi
         annotations/hg38/rmsk/Satellite.bed.gz
         annotations/hg38/rmsk/Satellite.bed.gz.tbi
         annotations/hg38/rmsk/Simple_repeat.bed.gz
         annotations/hg38/rmsk/Simple_repeat.bed.gz.tbi
         annotations/hg38/rmsk/Unknown.bed.gz
         annotations/hg38/rmsk/Unknown.bed.gz.tbi
         annotations/hg38/rmsk/rRNA.bed.gz
         annotations/hg38/rmsk/rRNA.bed.gz.tbi
         annotations/hg38/rmsk/rmsk.bed.gz
         annotations/hg38/rmsk/rmsk.bed.gz.tbi
         annotations/hg38/rmsk/scRNA.bed.gz
         annotations/hg38/rmsk/scRNA.bed.gz.tbi
         annotations/hg38/rmsk/snRNA.bed.gz
         annotations/hg38/rmsk/snRNA.bed.gz.tbi
         annotations/hg38/rmsk/srpRNA.bed.gz
         annotations/hg38/rmsk/srpRNA.bed.gz.tbi
         annotations/hg38/rmsk/tRNA.bed.gz
         annotations/hg38/rmsk/tRNA.bed.gz.tbi


*----------------------------------------------------------------------------------------------------
* igv.js tips:  load hg38 gene annotation (29 mar 2016)

   cd ~/s/examples/igv/igv-web/snpFootBed/

--- Aw, Snap!
      comes only with python, not with node  (node server.js)
      but node, without reporting error or crashing, fails to display the gene track
      maybe head byte content-range is not active?  index file on the gff3 suggests that
      might be what is being tried
      [defer this for now]

   needed to sort and index gencode.v24.annotation.gff3
   used desktop igv tools to create, successively:

      1250525752 Mar 29 14:35 gencode.v24.annotation.sorted.gff3
         1544544 Mar 29 14:36 gencode.v24.annotation.sorted.gff3.idx

   http://www.gencodegenes.org/releases/current.html
   cd ~/s/examples/igv/igv-web/snpFootBed/
   got
   bgzip("gencode.v24.annotation.gff3", dest="gencode.v24.annotation.gff3.gz")



*----------------------------------------------------------------------------------------------------
* igv.js jupyter tips: hg39 ctor

pdfrom igv import IGV, Reference, Track
import pandas as pd

igv = IGV(locus=snpLocus, reference=Reference(id="hg38"),
          tracks=[Track(
                 name="Genes",
                 url="//s3.amazonaws.com/igv.broadinstitute.org/annotations/hg38/genes/gencode.v24.annotation.sorted.gtf.gz",
                 indexURL="//s3.amazonaws.com/igv.broadinstitute.org/annotations/hg38/genes/gencode.v24.annotation.sorted.gtf.gz.tbi",
                 display_mode="EXPANDED")])
igv

*------------------------------------------------------------------------------------------------------------------------
* igv.js tips, igv tips, specify genome

  http://igv.broadinstitute.org/  returns an xml file which can be searched to produce values like this:

   <Key>annotations/hg38/genes/gencode.v24.annotation.sorted.gtf.gz</Key>
   <Key>annotations/hg38/genes/gencode.v24.annotation.sorted.gtf.gz.tbi</Key>

     tracks: [
         {name: "Genes",
            url: "http://igv.broadinstitute.org/annotations/hg38/genes/gencode.v24.annotation.sorted.gtf.gz",
            index: "http://igv.broadinstitute.org/annotations/hg38/genes/gencode.v24.annotation.sorted.gtf.gz.tbi",
            displayMode: "EXPANDED"
         }
     ]

*------------------------------------------------------------------------------------------------------------------------
* igv.js tips, igv tips: display local bed file (29 mar 2016)

   ----

   cd ~/s/examples/igv/igv-web/snpFootBed
   [also see http://igv.org/web/demo/ga4gh-demo.html]
   [http://igv.org/web/demo/gtex.html takes forever to load, all of chr1]

   ~/s/examples/igv/igv-web/snpFootBed/index.html

    $(document).ready(function () {
        var div, options, browser;
        div = $("#myDiv")[0];
        options = {locus: "chr18:10,350,000-11,577,000",
                   reference: {fastaURL: "http://localhost:8005/Homo_sapiens.GRCh38.dna.chromosome.18.fa.gz"},
                   tracks: [
                     {url: "//dn7ywbm9isq8j.cloudfront.net/annotations/hg19/genes/gencode.v18.collapsed.bed",
                      name: "Genes",
                      order: 10000
                      },
                     {url: "http://localhost:8005/gencode.v24.annotation.gtf",
                      name: "gtf",
                      order: 10000
                      },
                     {url: "http://localhost:8005/chr18_CU0070F.shared.hg38.bed",
                       name: "eb",
                       indexed: false,
                       order: Number.MAX_VALUE,
                       displayMode: "EXPANDED"
                      }
                   ]
              }; // options
        browser = igv.createBrowser(div, options);
    });


*----------------------------------------------------------------------------------------------------
* expanded list off 44 genes, elizabeth blue, to 117 (28 mar 2016)

  cd ~/s/work/priceLab/cory/elizabethBlue/
  +/1 1M on either side of (from cory):

      # chr1    172863016     172888877
      # chr18	   10350847      11576013
      # PIEZ02: chr18:10,668,247-11,150,762
      # As a sanity check, the first region should be right between FASLG and
      # TNFSF18. The second region should be inside the PIEZO2 gene. Both
      # coordinates are in GRCh38.

  script: ~/s/work/priceLab/cory/elizabethBlue/identifyGenesOfInterest.R
  this saves 117 genes into
       save(genes.117, file="~/github/Private_Cory_Data/inst/extdata/trn10.genes44/genes.117.RData")

   --- now run old tfGrabber to create 10-trn, 117 gene bed file
     on whovian, cd ~/s/work/priceLab/cory/trn10
     go.R
     print(load("~/github/Private_Cory_Data/inst/extdata/trn10.genes44/genes.117.RData"))

   --- rather complicated procedure on whovian to create bed file.
   1)  whovian   ~/s/work/priceLab/cory/trn10/go.R,
         with genes.177 loaded from PrivateCoryData, loop through all 10 trns, promoter distance 1M
         save each data.frame to a separate file

   2) copy those RData files to 117genes
        cd ~/s/work/priceLab/cory/trn10/117genes/
        library(snpFoot)
        library('TxDb.Hsapiens.UCSC.hg38.knownGene')
        files <- grep("RData$", dir(), value=TRUE)
        tbl.bed <- combineBedTables(files)

    400k + footprints.  see what they look like on macbook
       cd ~/s/work/priceLab/cory/trn-10/117genes/
       scp pshannon@whovian:s/work/priceLab/cory/trn10/117genes/tbl.bed.117.RData .


*----------------------------------------------------------------------------------------------------
* ng2 book, simple reddit example (28 mar 2016)

  cd ~/s/study/angular2/book2/manuscript/code/first_app/angular2-reddit-base/
  tsc  --experimentalDecorators app.ts
  better:
     npm run go

*----------------------------------------------------------------------------------------------------
* mean, angular, loc8tr (28 mar 2016)

  cd ~/github
  git clone -b chapter-10 https://github.com/simonholmes/getting-MEAN.git

*----------------------------------------------------------------------------------------------------
* scrape ebi, get sra files for cory funk (25 mar 2016)

  https://gist.github.com/paul-shannon/092bf4ac7625a78292bb

  cd ~/s/work/priceLab/cory/ebi.sra.scrape/
  go.R

  library(RCurl)
  search.url <- "http://www.ebi.ac.uk/ebisearch/search.ebi?db=sra-experiment&t=fetal+brain+DNase"
  text <- getURL(search.url)
  lines <- strsplit(text, "\n")[[1]]
  experiment.lines <- grep("id=\\\"sra-experiment SRX", lines, value=TRUE)
  experiment.ids <- c()
  for(line in experiment.lines){
     line.2 <- sub("^.*experiment ", "", line)
     id <- sub("\\\">", "", line.2)
     printf("experiment: %s", id)
     experiment.ids <- c(experiment.ids, id)
     }

  ftp.urls <- c()

  for(id in experiment.ids){
      #printf("---- %s", id)
      text <- getURL(sprintf("http://www.ebi.ac.uk/ena/data/view/%s&display=xml", id))
      lines <- strsplit(text, "\n")[[1]]
      srr.line.raw <- grep("SRR", lines, value=TRUE)
      #print(srr.line.raw)
      srr.line.0 <- sub(".*<ID>", "", srr.line.raw)
      srr.line <- sub("</ID>", "", srr.line.0)
      srr.tokens <- strsplit(srr.line, "-")[[1]]
      for(srr.id in srr.tokens){
         ftp.url <- sprintf("ftp://ftp.sra.ebi.ac.uk/vol1/fastq/%s/%s/%s.fastq.gz",
                            substr(srr.id, 1, 6), srr.id, srr.id)
         #printf(ftp.url)
         ftp.urls <- c(ftp.urls, ftp.url)
         } # for srr.id
      } # for id

  for(ftp.url in ftp.urls)
      print(ftp.url)


*----------------------------------------------------------------------------------------------------
* scrape ebi, get sra files for cory funk (25 mar 2016)

  lots of trouble.  here might be a way through

  http://www.ebi.ac.uk/ebisearch/search.ebi?db=sra-experiment&t=fetal+brain+DNase gets a page of experiments ids


   of which SRX2018155 is one
   this is an experiment accession number
   with two run accession numbers: SRR609583, SRR609584
   which map directly to these ftp urls

     ftp.sra.ebi.ac.uk/vol1/fastq/SRR609/SRR609583/SRR609583.fastq.gz
     ftp.sra.ebi.ac.uk/vol1/fastq/SRR609/SRR609584/SRR609584.fastq.gz

   --- get there this way?

     curl "http://www.ebi.ac.uk/ena/data/view/SRX201815&display=xml" | grep SRR
         <ID>SRR609583-SRR609584</ID>

*----------------------------------------------------------------------------------------------------
* scrape ebi, get sra files for cory funk (25 mar 2016)

   cd ~/s/work/priceLab/cory/ebi.sra.scrape/
   http://www.ebi.ac.uk/ebisearch/search.ebi?db=sra-experiment&t=fetal+brain+DNase

*----------------------------------------------------------------------------------------------------
* ride around the sound lake washington boulevard temporary signs (24 mar 2016) email to jon urlie
   Jon.Urlie@Lung.org

   Dear Jon,

   I write somewhat apologetically.  I hope that I do not annoy!

   Though I admire — indeed I support — the Ride Around the Sound
   event coming up this fall, may I offer a perspective on the
   temporary signs which have just appeared promoting the event on
   Lake Washington Boulevard?

   Two perspectives, actually.  The first is that - judge us
   idiosyncratic if you will - many of us see promotional signs, no
   matter how worthy the fundraising cause, as a form of visual
   pollution.  Lake Washington Boulevard is a beautiful drive, a
   lovely walk, a breathtakingly beautiful place to ride.  Except in
   the Leschi business district, and except for traffic signs, one can
   travel those several miles free of advertising.  This, I suggest,
   is a public good.  We have preciously little such space left in the
   city.

   The second perspective is legal: the city code expressly prohibits
   signs, either temporary or permanent, in the public right of way,
   except in commercial districts.  One exception is in parking
   strips, with the express permission of the owner of adjacent
   property.  The text is a little involved, but please see Seattle
   Municipal Code 23.55.012.C.  Exceptions can be granted by permit:
   contact AnnualPermits@seattle.gov

   I am sorry to be such a scold, such a nag, such a complainer! -
   when you and your colleagues are doing such fine work, for such a
   worthy cause.  Please accept my apology.  But please, too, if you
   will: consider getting the word out about the Ride Around the Sound
   in other ways!

   - Paul Shannon Institute for Systems Biology 206.658.3789

*----------------------------------------------------------------------------------------------------
* seattle sign ordinance

23.55.012 - Temporary signs permitted in all zones.

   A. Real estate "for sale," "for rent" and "open house" temporary
   signs, temporary signs identifying the architect, engineer or
   contractor for work currently under construction, and temporary
   noncommercial messages displayed on fabric signs, flags or rigid
   signs shall be permitted in all zones at all times, provided they
   are not painted with light-reflecting paint or illuminated. The
   total area for these types of temporary signs in the aggregate
   shall not exceed eight (8) square feet per building lot in
   single-family zones, and twenty-four (24) square feet per building
   lot in all other zones, except as follows: the total area allowed
   for noncommercial messages may increase to a maximum of eight (8)
   square feet per dwelling unit for use by the occupant of that
   dwelling unit; and in buildings where there are eight (8) dwelling
   units or more, a real estate banner not exceeding thirty-six (36)
   square feet may be permitted for one (1) nine (9) month period
   starting from the date of the issuance of the certificate of
   occupancy.

   B.In addition to the signs described in subsection A of this
   section above, commercial or noncommercial messages may be
   displayed for a total of four (4) fourteen (14) consecutive day
   periods a calendar year; these additional four (4) periods are the
   maximum, whether the message is the same message or a different
   message. These messages may be displayed on banners, streamers,
   strings of pennants, fabric signs, festoons of lights, flags,
   wind-animated objects, rigid signs, balloons, searchlights,
   portable signs attached to vehicles, or devices of a carnival
   nature, and shall be allowed as temporary signs in all zones. The
   total area for all temporary signs per fourteen (14) day period,
   when combined with those signs authorized under subsection A of
   this section, in the aggregate shall not exceed thirty-two (32)
   square feet per building lot for signs made of rigid material, with
   no dimension greater than eight (8) feet, and one hundred (100)
   square feet per building lot for temporary signs not made of rigid
   material; provided that the total area allowed for noncommercial
   messages may increase to a maximum of thirty-two (32) square feet
   per dwelling unit, with no dimension greater than eight (8) feet,
   for signs made of rigid material, and one hundred (100) square feet
   per dwelling unit for temporary signs not made of rigid material,
   all for use by the occupant of that dwelling unit. No individual
   sign made of nonrigid material may exceed thirty-six (36) square
   feet.

   C. All signs authorized by this section are subject to the
   following regulations:

      1.No sign may be placed on public property or on the planting
      strips that abut public property, including planting strips
      forming a median in a public street, except as provided in
      subsection C3 below and except for portable signs attached to
      vehicles that are using the public streets.

      2.All signs must be erected with the consent of the occupant of
      the property on which the sign is located, except as provided in
      subsection C3 below.

      3.Temporary Signs on Public Property or in Planting Strips.

         a.Temporary signs with commercial or noncommercial messages
         may be located on public rights-of-way or in planting strips
         in business districts, subject to the requirements of City of
         Seattle Public Works Rules Chapter 4.60 or its successor
         Rule.

         b.Temporary signs with noncommercial messages, other than in
         subsection C3a above, may be located in the planting strip in
         front of private property with the consent of the occupant of
         that property and may not exceed eight (8) square feet or be
         supported by stakes that are more than one (1) foot into the
         ground. Signs in the planting strip shall be no more than
         twenty-four (24) inches in height as measured from street or
         driveway grade when located within thirty (30) feet from the
         curbline of intersections. Signs shall be no more than
         thirty-six inches (36") in height as measured from street or
         driveway grade when located thirty feet (30') or more from
         the curbline of intersections.

         c.In addition to commercial signs in business districts
         allowed in subsection C3a above, only temporary commercial
         "open house" signs may be placed in planting strips. One (1)
         "open house" temporary sign per street frontage of a lot may
         be located with the consent of the occupant and provided the
         occupant or seller is on the premises. The "open house" signs
         may not exceed eight (8) square feet per lot or be supported
         by stakes that are more than one foot (1') into the
         ground. The "open house" signs shall be no more than
         twenty-four inches (24") in height as measured from street or
         driveway grade when located within thirty feet (30') from the
         curbline of intersections, and shall be no more than
         thirty-six inches (36") in height as measured from street or
         driveway grade when located thirty feet (30') or more from
         the curbline of intersections.

         d.No sign placed in a planting strip may be displayed on
         banners, streamers, strings of pennants, festoons of lights,
         flags, wind-animated objects or balloons.

         e.The requirements of this subsection C3 shall be enforced by
         the Director of Seattle Department of Transportation pursuant
         to the enforcement provisions of that Department.

     4.No sign shall obstruct or impair access to a public sidewalk,
     public or private street or driveway, traffic control sign, bus
     stop, fire hydrant, or any other type of street furniture, or
     otherwise create a hazard, including a tripping hazard.

     5.Signs shall be designed to be stable under all weather
     conditions, including high winds.

     6.A temporary sign shall conform to the standards for roof signs,
     flashing, changing image or message board signs, for moving
     signs, and for lighting and height regulations for the zone or
     special review district in which the temporary sign is located,
     provided that balloons may exceed height regulations.

     7.The entire visible surface of the sign, exclusive of support
     devices, shall be included in area calculations.

    (Ord. 121477 § 35, 2004; Ord. 118409 § 203, 1996: Ord. 117555 § 2,
    1995: Ord. 112830 § 10(part), 1986.)

*----------------------------------------------------------------------------------------------------
* speed up tfGrabber.R for cory's all-trn, all-genes table (24 mar 2016)

   --- overall scheme
    for every named gene
      get all footprints in tss +/- 1M
      for each footprint, get motif
      for each motif, get tf
      for each gene, tf

   --- look at trn10.genes44
    f <- system.file(package="PrivateCoryData", "extdata", "trn10.genes44", "44genes-10trns-bedTable.RData")
    print(load(f))
    dim(tbl.out) # [1] 179837      4
    head(tbl.out)
    chr     start       end                                                                         name
   chr1 206496259 206496284 <html>CR1(gtex):&nbsp;MA0119.1<br>VENTX:&nbsp;0.06<br>HHEX:&nbsp;0.03</html>
   chr1 206496259 206496284                  <html>CR1(isb_AD):&nbsp;MA0119.1<br>DLX1:&nbsp;-0.16</html>
   chr1 206496259 206496284               <html>CR1(isb_cont):&nbsp;MA0119.1<br>BARX2:&nbsp;-0.07</html>
   chr1 206501435 206501458                 <html>CR1(isb_AD):&nbsp;MA0258.2<br>ESRRA:&nbsp;-0.14</html>


   -- goal
     create "full info file" like this, breaking out name into multiple rows with fixed columns
     create "bed file"

   -- 44 genes
ABCA7
APOE
BIN1
CASS4
CD2AP
CELF1
CLU
CR1
EPHA1
FERMT2
HLA
INPP5D
MEF2C
MS4A6A
NME8
PICALM
PTK2B
SLC24A4
RIN3
SORL1
ZCWWPW1
ABI3
IRF8
MS4A14
MS4A4A
MS4A7
PLCG1
PLCG2
TGFB1
TREM2
TTC3
UNC5C
PILRB
FASLG
TNFSF18
PIEZO2
NAPG
APCDD1
DNMBP
APP
BACE1
BACE2
PSEN1
PSEN2

genes.44 <- c("ABCA7", "APOE", "BIN1", "CASS4", "CD2AP", "CELF1", "CLU", "CR1",
              "EPHA1", "FERMT2", "HLA", "INPP5D", "MEF2C", "MS4A6A", "NME8", "PICALM",
              "PTK2B", "RIN3", "SORL1", "ZCWWPW1", "ABI3", "IRF8", "MS4A14",
              "MS4A4A", "MS4A7", "PLCG1", "PLCG2", "TGFB1", "TREM2", "TTC3", "UNC5C", "PILRB",
              "SLC24A4", "FASLG", "TNFSF18", "PIEZO2", "NAPG", "APCDD1", "DNMBP", "APP",
              "BACE1", "BACE2", "PSEN1", "PSEN2")
save(genes.44, file="~/github/Private_Cory_Data/inst/extdata/trn10.genes44/genes.45.RData")

*----------------------------------------------------------------------------------------------------
* speed up tfGrapper.R (in snpFoot.R)  (24 mar 2016)

   cd ~/github/snpFoot/inst/unitTests/
   in snpFoot.R, separate process out into these steps:
      1) find all fps in gene span + 1M padding
      2) add column for motif, all tfs
      3) collapse all down to a data.frame, put these in a list by gene, add target gene, trn name, and beta coef.
      4) save to disk
            chr mfpStart mfpEnd motifName                                                                                        tfs
        1 chr19   799185 799216  MA0024.3                                             E2F3, E2F2, E2F6, E2F4, E2F7, E2F1, E2F5, E2F8
        2 chr19    62548  62570  MA0103.2 TSHZ3, TSHZ2, ADNP, ZHX1, ZFHX4, ZFHX3, ZHX3, TSHZ1, ZEB1, ZHX2, ADNP2, ZEB2, HOMEZ, ZFHX2
        3 chr19   403596 403626  MA0103.2 TSHZ3, TSHZ2, ADNP, ZHX1, ZFHX4, ZFHX3, ZHX3, TSHZ1, ZEB1, ZHX2, ADNP2, ZEB2, HOMEZ, ZFHX2

      5) on a subsequent pass, with motif->TF mapping, create the bed file: all target genes, all trns
*----------------------------------------------------------------------------------------------------
* speed up tfGrabber.R (in snpFoot.R)  (23 mar 2016)

  appears to be slowed by data.frame subset.    before
     "[.data.frame"          0.412    34.05      0.438     36.20
     "gc"                    0.243    20.08      0.243     20.08
     "load"                  0.173    14.30      0.174     14.38
     "subset.data.frame"     0.128    10.58      0.772     63.80


   --- with data.frame subset identified as likely bottleneck:
   system.time(tbl.thisgene <- subset(tbl.fpAnnotated, chr==ichr & motifName %in% imotifs$motif &
                                     mfpStart >= startPosition & mfpEnd <= endPosition))
      user  system elapsed
     1.215   0.203   1.421

    system.time(tbl.thisgene <- subset(tbl.fpAnnotated, chr==ichr))
      user  system elapsed
     0.631   0.101   0.733

    system.time(tbl.thisgene <- subset(tbl.thisgene, mfpStart >= startPosition & mfpEnd <= endPosition))
      user  system elapsed
     0.013   0.004   0.017

    system.time(tbl.thisgene <- subset(tbl.thisgene, motifName %in% imotifs$motif))
       user  system elapsed
      0.001   0.000   0.000

  --- suggesting this strategy
     create per-chromsome data.frames out of tbl.fpAnnotated

*----------------------------------------------------------------------------------------------------
* learning angular, angular concepts, examples (23 mar 2016)

  next up: testing controllers, at https://docs.angularjs.org/guide/controller


*----------------------------------------------------------------------------------------------------
* learning angular, angular concepts, examples (22 mar 2016)

  https://docs.angularjs.org/guide/concepts

  cd ~/s/examples/webapps/angular/controllers/
  cd ~/s/examples/webapps/angular/dataBinding/

*----------------------------------------------------------------------------------------------------
* dream5 yeast expression network inference (21 mar 2016)

   cd ~/s/data/public/dream5/yeast

  wisdom of crowds paper: http://www.ncbi.nlm.nih.gov/pmc/articles/PMC3512113/

    Performance of network inference methods

     We used three gold standards for performance evaluation:
     experimentally validated interactions from a curated database
     (RegulonDB16) for E. coli; a high-confidence set of interactions
     supported by genome-wide transcription factor binding data17
     (ChIP-chip) and evolutionarily conserved binding motifs18 for
     S. cerevisiae; and the known network for the in silico dataset
     (Methods). Performance on S. aureus was evaluated separately (see
     below) as there currently does not exist a sufficiently large set
     of experimentally validated interactions.

     We assessed method performance for the E. coli, S. cerevisiae,
     and in silico datasets using the area under the precision-recall
     (AUPR) and receiver operating characteristic (AUROC) curves14,
     and an overall score that summarizes the performance across the
     three networks (Methods and Supplementary Note 4). Figure 2a
     shows the overall score and the performance on each network for
     all applied inference methods. On average, regulatory
     interactions were recovered much more reliably for the in silico
     and E. coli datasets compared to S. cerevisiae.


  from http://younglab.wi.mit.edu/cgi-bin/young_public/navframe.cgi?s=17&f=structures

  swi4 targets from sgd:

    SWI4 encodes a transcription factor of the Ig-fold superfamily,
    which contacts DNA using a series of flexible loops. As part of
    the SBF complex (Swi4p/Swi6p cell-cycle box (SCB) binding factor),
    Swi4p binds and activates G1/S genes with SCB-containing
    promoters, including G1 cyclins (CLN1, CLN2, PCL1, PCL2) and the
    HO endonuclease.

   mtx <- as.matrix(read.table("net4_expression_data.tsv", sep="\t",  header=TRUE, as.is=TRUE, row.names=NULL))
   dim(mtx) # [1]  536 5950   samples, genes
   tbl.ids <- read.table("net4_gene_ids.tsv", sep="\t", header=FALSE, as.is=TRUE)

   SWI4  YER111C    G112
   SWI6  YLR182W    G152
   CLN1  YMR199W    G610
   CLN2  YPL256C   G4867
   PCL1  YNL289W   G4822
   PCL2  YDL127W   G4318
   orfs <- c("YER111C", "YLR182W",  "YMR199W",  "YPL256C",  "YNL289W", "YDL127W")
   subset(tbl.ids, V2 %in% orfs)
           V1      V2
   112   G112 YER111C
   152   G152 YLR182W
   610   G610 YMR199W
   4867 G4867 YPL256C
   4822 G4822 YNL289W
   4318 G4318 YDL127W

   tfs <- c("G112", "G152")
   targets <- c("G610", "G4867", "G4822", "G4318")
   cor(mtx[, tfs[1]], mtx[,tfs[2]])     # [1] 0.5257177
   cor(mtx[, tfs[1]], mtx[,targets[1]]) # [1] 0.4148201
   cor(mtx[, tfs[1]], mtx[,targets[2]]) # [1] 0.3200902
   cor(mtx[, tfs[1]], mtx[,targets[3]]) # [1] 0.4828558
   cor(mtx[, tfs[1]], mtx[,targets[4]]) # [1] 0.03305795

   RIF1, G3811 is 0.71 correlated

   set.seed(31)
   orfs.all <- sort(unique(c(tfs, targets, colnames(mtx)[sample(1:ncol(mtx), size=50)])))
   mtx.sub <- mtx[, orfs.all]
   indices <- match(colnames(mtx.sub), tbl.ids$V1)
   colnames(mtxs) <- tbl.ids$V2[indices]
   deleters <- grep("decoy", colnames(mtx.sub))
   if(length(deleters) > 0)
      mtx.sub <- mtx.sub[, -deleters]
   dim(mtx.sub) # [1] 536  53
   cor(mtx.sub[, "YER111C"], mtx.sub[, "YLR182W"])  # [1] 0.5257177
   biocLite("org.Sc.sgd.db")
   library(org.Sc.sgd.db)
   db <- org.Sc.sgd.db
   keytypes(db)  # learn the columns
   tbl.ids <- select(db, keys=colnames(mtx.sub), keytype="ORF", columns <- c("ORF", "GENENAME"))
   failed.to.map <- which(is.na(tbl.ids$GENENAME))
   if(length(failed.to.map) > 0)
       tbl.ids$GENENAME[failed.to.map] <- tbl.ids$ORF[failed.to.map]
   QC: cor(mtx.sub[, "SWI4"], mtx.sub[, "SWI6"])  # [1] 0.5257177

   cor(mtx.sub[, "SWI4"], mtx.sub[, "SWI6"]) # [1] 0.5257177
   cor(mtx.sub[, "SWI4"], mtx.sub[, "CLN1"]) # [1] 0.4148201
   cor(mtx.sub[, "SWI4"], mtx.sub[, "CLN2"]) # [1] 0.3200902
   cor(mtx.sub[, "SWI4"], mtx.sub[, "PCL1"]) # [1] 0.4828558
   cor(mtx.sub[, "SWI4"], mtx.sub[, "PCL2"]) # [1] 0.03305795

   mtx <- t(mtx.sub)
   colnames(mtx) <- sprintf("sample.%03d", 1:ncol(mtx))
   save(mtx, file="~/github/TReNA/inst/extdata/yeast
*----------------------------------------------------------------------------------------------------
* Gene regulatory network inference using fused LASSO on multiple data set (21 mar 20160

   nature, feb 2016. uses dream5 data

   http://www.nature.com/articles/srep20533

*----------------------------------------------------------------------------------------------------
* getting mean (18 mar 2016)

   cd ~/s/examples/webapps/loc8tr

   node --version; npm --version; express --version; v4.4.0, 2.14.20, 4.13.1

*----------------------------------------------------------------------------------------------------
* learning lasso with mtcars and glmnet (18 mar 2016): fits model to mpg value of mtcars. cv.glmnet. predict

  cd ~/s/examples/R/lasso/mtcars/

library(glmnet)
# mtcars: 32 cars, 11 variables: mpg, cyl, disp, hp, drat, wt, qsec, vs, am, gear, carb
# in lasso model terms:  32 observations of 11 variables (novs x nvars)
# [, 1]    mpg     Miles/(US) gallon
# [, 2]    cyl     Number of cylinders
# [, 3]    disp    Displacement (cu.in.)
# [, 4]    hp      Gross horsepower
# [, 5]    drat    Rear axle ratio
# [, 6]    wt      Weight (lb/1000)
# [, 7]    qsec    1/4 mile time
# [, 8]    vs      V/S (V engine or straight engine)
# [, 9]    am      Transmission (0 = automatic, 1 = manual)
# [,10]    gear    Number of forward gears
# [,11]    carb    Number of carburetors

# find the best linear model for column 1, mpg
features <- as.matrix(mtcars[, -1])
target   <- mtcars[, 1]
fit <- glmnet(features, target)
plot(fit, xvar='lambda', label=TRUE)

# find the best lambda
cv.out <- cv.glmnet(features, target)
lines(c(lambda.optimal, lambda.optimal), c(-3, 3))
fit.2 = glmnet(features, target, lambda=lambda.optimal)
small.lambda.index <- which(cv.out$lambda == cv.out$lambda.min)
small.lambda.betas <- cv.out$glmnet.fit$beta[,small.lambda.index]
betas <- as.matrix(t(coef(cv.out,s="lambda.min")))
# the betas constitute the model:
#   (Intercept)        cyl disp          hp drat        wt qsec vs am gear carb
#            1    36.00002 -0.8860854    0 -0.01168438    0 -2.708147    0  0  0    0    0
>
# manual calculation of the model prediction for each car (each row):
# subtract the actual,
# sum all the errors, a very small number # [1] -2.664535e-13
# the "cbind(1," adds a constant to multiply by the intercept
sum(unlist(lapply(1:nrow(mtcars), function (row) as.numeric(betas %*% t(cbind(1, t(features[row,]))) - mtcars[row, "mpg"]))))
# predict mpg, compare to actual mpg
cbind(predict(fit.2, s=lambda.optimal, newx=features), mtcars[, "mpg", drop=FALSE])
#                            1  mpg
# Mazda RX4           22.39891 21.0
# Mazda RX4 Wag       21.68915 21.0
# Datsun 710          25.23731 22.8
# Hornet 4 Drive      20.72916 21.4
# Hornet Sportabout   17.48402 18.7
# Valiant             20.11135 18.1
# Duster 360          16.22459 14.3
# Merc 240D           23.19964 24.4
# Merc 230            22.88782 22.8
# Merc 280            19.93621 19.2
# Merc 280C           19.93621 17.8
# Merc 450SE          15.66638 16.4
# Merc 450SL          16.61273 17.3
# Merc 450SLC         16.47356 15.2
# Cadillac Fleetwood  12.06143 10.4
# Lincoln Continental 11.44890 10.4
# Chrysler Imperial   11.47644 14.7
# Fiat 128            25.91753 32.4
# Honda Civic         27.72532 30.4
# Toyota Corolla      26.94629 33.9
# Toyota Corona       24.76879 21.5
# Dodge Challenger    17.58192 15.5
# AMC Javelin         17.81851 15.2
# Camaro Z28          15.47308 13.3
# Pontiac Firebird    16.35676 19.2
# Fiat X1-9           26.65513 27.3
# Porsche 914-2       25.76396 26.0
# Lotus Europa        27.22704 30.4
# Ford Pantera L      17.10795 15.8
# Ferrari Dino        21.14793 19.7
# Maserati Bora       15.08419 15.0
# Volvo 142E          23.75179 21.4
*----------------------------------------------------------------------------------------------------
* learning lasso with mtcars and glmnet (17 mar 2016)

  regression models background using mtcars here:
     https://rstudio-pubs-static.s3.amazonaws.com/27590_5fabe6bffdb444fabbfcd640920caaf6.html
     shows exploratory method for doing feature selection

  excellent discussion here of mtcars and lasso here:
     http://stats.stackexchange.com/questions/154825/what-to-conclude-from-this-lasso-plot-glmnet

   cd ~/s/examples/R/lasso/mtcars

  --- cv.glmnet example with mtcars: http://www.umiacs.umd.edu/~jbg/teaching/DATA_DIGGING/solution_04.R
data(mtcars)

# Add two dummy columns full of noise
mtcars <- cbind(runif(nrow(mtcars)), runif(nrow(mtcars)), mtcars)
colnames(mtcars)[1:2] <- c("dummy1", "dummy2")

# Creating a training set

target <- as.matrix(mtcars$mpg)
features <- as.matrix(subset(mtcars, select=-c(mpg)))

library(glmnet)
reg.l2 <- glmnet(features, target, alpha=0)
reg.l1 <- glmnet(features, target, alpha=1)
models.l2 <- data.frame(t(rbind(matrix(reg.l2$lambda, nrow=1), as.matrix(reg.l2$beta))))
colnames(models.l2)[1] <- "lambda"
models.l2 <- melt(models, c("lambda"))
coef_l1 <- ggplot(models.l2) + aes(x=log(lambda), y=value, color=variable) + geom_line()

models.l1 <- data.frame(t(rbind(matrix(reg.l1$lambda, nrow=1), as.matrix(reg.l1$beta))))
colnames(models.l1)[1] <- "lambda"
models.l1 <- melt(models, c("lambda"))
coef_l2 <- ggplot(models.l2) + aes(x=log(lambda), y=value, color=variable) + geom_line()
# Cross validation resampling the training data for L2 regression and L1 regression
cv.l2 <- cv.glmnet(features, target, alpha=0)
cv.l1 <- cv.glmnet(features, target, alpha=1) plot(reglm.l1, main = "L1 n-fold cross validation error")
plot(reglm.l2, main = "L2 n-fold cross validation error") 
plot(reglm.l1, main = "L1 n-fold cross validation error") 



*----------------------------------------------------------------------------------------------------
* tfGrabber, tr10 footprints for cory's florida retreat

  --- all trns
   *  3553075113 Mar 14 20:29 trn.rtrim_gtex.RData
   *  1327722483 Mar 14 20:30 trn.rtrim_isb_AD_cer.RData
   -  1355964953 Mar 14 20:30 trn.rtrim_isb_AD.RData
   *  1737210755 Mar 14 20:31 trn.rtrim_isb_all_cer.RData
   *  2136109232 Mar 14 20:30 trn.rtrim_isb_all.RData
   -  1255398770 Mar 14 20:32 trn.rtrim_isb_cont_cer.RData
   -   1297334382 Mar 14 20:31 trn.rtrim_isb_cont.RData
   -  1711229756 Mar 14 20:32 trn.rtrim_rbAD.RData
   *  1727256189 Mar 14 20:32 trn.rtrim_rball.RData
   *  1698736977 Mar 14 20:33 trn.rtrim_rbnci.RData


  --- whovian /users/pshannon/s/work/priceLab/cory/trn10/thread2:
     2757063 Mar 16 01:40 gtex.1000-dist.14256-genes.results.RData
     1508912 Mar 16 05:50 isb_AD_cer.1000-dist.13462-genes.results.RData
                          isb_AD

  --- whovia /users/pshannon/s/work/priceLab/cory/trn10:
     3771591 Mar 16 03:10 isb_all.10000-dist.13535-genes.results.RData
     2305952 Mar 15 22:36 isb_all_cer.10000-dist.13216-genes.results.RData
                          isb_cont_cer

  --- book   /Users/paul/s/work/priceLab/cory/trn-10/tf_grabber:
     1154363 Mar 16 05:25 rball.1000-dist.8364-genes.results.RData
     1468724 Mar 16 01:08 rbnci.1000-dist.11851-genes.results.RData



*----------------------------------------------------------------------------------------------------
* linn gould suggests further sources of health disparity info (14 mar 2016)

  http://www.kingcounty.gov/healthservices/health/data/indicators.aspx
  http://www.communitiescount.org/


*----------------------------------------------------------------------------------------------------
* retrieve all genes annotated to a go term (13 mar 2016

  https://www.biostars.org/p/52101/

library(biomaRt)
ensembl = useMart("ensembl",dataset="hsapiens_gene_ensembl") #uses human ensembl annotations
#gets gene symbol, transcript_id and go_id for all genes annotated with GO:0007507
gene.data <- getBM(attributes=c('hgnc_symbol', 'ensembl_transcript_id', 'go_id'),
                   filters = 'go_id', values = 'GO:0007507', mart = ensembl)
*----------------------------------------------------------------------------------------------------
* tf go term? (13 mar 2016)

  transcription regulatory region DNA binding.
  from http://www.ebi.ac.uk/QuickGO/GTerm?id=GO:0044212

 GO:0044212, transcription regulatory region DNA binding, Molecular Function

  curl -s "http://www.ebi.ac.uk/QuickGO/GAnnotation?tax=9606&relType=IP&goid=%20GO:0044212%20&format=tsv" > 44212.tsv
  tbl.44212 <- read.table("44212.tsv", sep="\t", header=TRUE, as.is=TRUE) # 1328 14
  length(sort(unique(tbl.44212$Symbol))) # [1] 744
   table(tbl.44212$Evidence)
    IBA  IC IDA IEA IMP ISS NAS TAS
    163   6 447 560  28 120   1   3

  sequence-specific DNA binding transcription factor activity" (GO:0003700)
  GO:0003700

  curl -s "http://www.ebi.ac.uk/QuickGO/GAnnotation?tax=9606&relType=IP&goid=%20GO:0003700&format=tsv" > 3700.tsv
  tbl.3700 <- read.table("3700.tsv", sep="\t", header=TRUE, as.is=TRUE)
  dim(read.table("3700.tsv", sep="\t", header=TRUE, as.is=TRUE)) # [1] 1350   14
  length(unique(tbl.3700$Symbol)) # [1] 669
  length(unique(c(tbl.3700$Symbol, tbl.44212$Symbol))) # [1] 946

  --- fantom
    cd ~/s/work/priceLab/cory/trn-10/
    http://fantom.gsc.riken.jp/5/sstar/Browse_Transcription_Factors_hg19
    tbl.fantom <- read.table("fantomTF.csv", sep=",", header=TRUE, as.is=TRUE)
    length(unique(tbl.fantom$Symbol))  # [1] 1672


  --- A census of human transcription factors: function, expression and evolution: 1391 genes, nature genetics 2009

   Transcription factors are key cellular components that control gene expression: their activities
   determine how cells function and respond to the environment. Currently, there is great interest
   in research into human transcriptional regulation. However, surprisingly little is known about
   these regulators themselves. For example, how many transcription factors does the human genome
   contain? How are they expressed in different tissues? Are they evolutionarily conserved? Here, we
   present an analysis of 1,391 manually curated sequence-specific DNA-binding transcription
   factors, their functions, genomic organization and evolutionary conservation. Much remains to be
   explored, but this study provides a solid foundation for future investigations to elucidate
   regulatory mechanisms underlying diverse mammalian biological processes.


   Definition: Interacting selectively and non-covalently with a DNA region that regulates the
       transcription of a region of DNA, which may be a gene, cistron, or operon. Binding may occur as a
       sequence specific interaction or as an interaction observed only once a factor has been recruited
       to the DNA by other factors.

   Comment: The word "promoter" is used variously in the literature to describe the core promoter
       specifically or the entire proximal regulatory region (excluding any distal enhancers) including
       both the core promoter and the upstream region where activating transcription factors such as
       Gal4 in S. cerevisiae or catabolite activator protein (CAP) in E. coli bind. To minimize
       ambiguity in the use of the word "promoter" in GO, we have chosen the phrase "transcription
       regulatory region" in order to refer to all of the regulatory regions. Regulatory regions in the
       DNA which control initiation may include the "core promoter" where the basal transcription
       machinery binds, the "core promoter proximal region" where regulatory factors other than the
       basal machinery bind, and "enhancer" regions which are typically more distal from the core
       promoter. There are also additional regulatory regions, in both the DNA and the RNA transcript,
       which regulate elongation or termination of transcription. ANNOTATION NOTE: Regarding annotation
       to "transcription regulatory region DNA binding" (GO:0044212) and any of its is_a children, note
       that annotation to these terms specifies DNA binding only without any statement about
       transcription factor activity. To make an annotation about a function of transcription factor
       activity, consider "sequence-specific DNA binding transcription factor activity" (GO:0003700) or
       its is_a children which have has_part relationships to the appropriate kind of "transcription
       regulatory region DNA binding".



*----------------------------------------------------------------------------------------------------
* cory's 10 tissue specific trn networks (15 mar 2016) - put tfGrabber into snpFoot


*----------------------------------------------------------------------------------------------------
* cory's 10 tissue specific trn networks (15 mar 2016)

   cd ~/s/work/priceLab/cory/trn-10/tf_grabber/
   my evolution of hongdong's code: tfGrabber.R

   mount whovian
   dir /Volumes/local/Cory/for_Hongdong/
      3553075113 Mar 14 20:29 trn.rtrim_gtex.RData
      1355964953 Mar 14 20:30 trn.rtrim_isb_AD.RData
      1327722483 Mar 14 20:30 trn.rtrim_isb_AD_cer.RData
      2136109232 Mar 14 20:30 trn.rtrim_isb_all.RData
      1737210755 Mar 14 20:31 trn.rtrim_isb_all_cer.RData
      1297334382 Mar 14 20:31 trn.rtrim_isb_cont.RData
      1255398770 Mar 14 20:32 trn.rtrim_isb_cont_cer.RData
      1711229756 Mar 14 20:32 trn.rtrim_rbAD.RData
      1727256189 Mar 14 20:32 trn.rtrim_rball.RData
      1698736977 Mar 14 20:33 trn.rtrim_rbnci.RData

*----------------------------------------------------------------------------------------------------
* cory's 10 tissue specific trn networks (13 mar 2016)

  goal (i think) put these into one track, display in igv

   cd ~/s/work/priceLab/cory/trn-10
   saved hongdong's RData, about which he says:

   This is the motif_footprint bed data created by integrating TRN and footprint data.
     > names(trn) #    [1] "TRN"     "bed4igv"
   The bed4igv component  is the data you need which can be readily feed to your displayBedTable function.
   The TRN component is beta coefficients of regression models in trena.


   --- cory relatedly says:
   Here is where the 10 TRNs are located on whovian:  /local/Cory/for_Hongdong

    On Fri, Mar 11, 2016 at 4:26 PM, Hongdong Li <holi@systemsbiology.org> wrote:
    trn.list <- list(trn.rtrim_isb_AD_cer, trn.rtrim_isb_AD)
    trn=TF_grabber(rownames(trn.rtrim_isb_AD)[1:100],trn.list,label=c("isb_AD_cer","isb_AD"),promoterDist = 100000)
    displayBedTable(igv, trn$bed4igv,"test_TRN_whole1")



*----------------------------------------------------------------------------------------------------
* elizabeth blue's pilot project and tracks (11 mar 2016)

  cd ~/s/data/priceLab/AD/elizabethBlue

  --- heatmap of selected sections reveals sortof-haplotypes
    messy code, no clear stratification by phenotype, but maybe useful for further development some day

  --- saved tracks to
  In some of the linkage regions with multiple families with LOD>2, the two families share a rare
  non-coding haplotype. I've given you two of these haplotypes, see below. In each case, it is
  shared by one European and one Hispanic ancestry family. The attached .bed files include all
  variants in these regions for these families where the MAF is high enough that >= 1/2 of the
  sequenced cases could carry the variant. Some are shared across families (below) and some are not.

  chr01:172832156-172858017, about 25.9kb
   --> rs146071025,rs148018679,rs146894928,rs142949221
   --> According to HaploReg v4.1, these are in strong LD (r^2>0.8), 1kg EUR MAF near 3%,
       AMR MAF near 2%. The third SNP, rs146894928, is annotated with enhancer histone marks, DHS, and "motifs" changed.

  chr18:10350844-11576012, about 122.5kb
    --> rs111535147,rs28533014,rs112718958,rs117444648,rs111777036,rs144880461.
        In the Hispanic family, the number of carriers of the haplotype fluctuates: usually 5, but rs111535147 is
        observed in 9 and  rs111777036 is observed in 7 relatives.
   --> According to HaploReg, these AREN'T in LD at the population level. MAF ranges from unclear/unknown to 6%.
       Some are annotated as having enhancer histone markers and changing motifs. None are mentioned in DHS.
   --> Using Pat's multi-cell DHS bed file, I see that two of these appear in DHS:

 [em27@localhost ~]$ ~/programs/bedtools2/bin/intersectBed -a few.bed -b ~/AD/ADSP/multi-cell_tissue.master_dhs.counts.hg19.bed
 chr18  10350844        10350844        rs111535147
 chr18  11107811        11107811        rs111777036
 [em27@localhost ~]$ ~/programs/bedtools2/bin/intersectBed -a ~/AD/ADSP/multi-cell_tissue.master_dhs.counts.hg19.bed -b few.bed
 chr18  10350844        10350844        fKidney-DS16139_|6| 5.59246
 chr18  11107811        11107811        BE2_C-DS14635_|31|71.5276

   Looking at the haplotypes in the GTEx browser, I don't see anything for chr01, but for chr18, I
   see interesting hits in the cerebellum around APCDD1 and NAPG significant in cerebellum. APCDD1
   is a great candidate, NAPG isn't bad.

   An example gene of interest = DNMBP.  This gene has an interesting coding variant in a linkage
   region, the gene and variant are also significant in the WES case-control analyses.


  chr18_CU0070F.shared.bed
  chr18_LD0949F.shared.bed
  chr1_CU0039F.shared.bed
  chr1_UM0463F.shared.bed

*----------------------------------------------------------------------------------------------------
* audubon plant sale temporary signs, city ordinance (11 mar 2016)

  spoke with john merrick of sdot, he referred me to
     annualpermits@seattle.gov (email is best)
     in the street use permits office, 684.5267

  http://www.seattle.gov/transportation/stuse_permits.htm
  http://www.seattle.gov/transportation/stuse_insp.htm


*----------------------------------------------------------------------------------------------------
* audubon plant sale temporary signs, city ordinance (11 mar 2016)


  https://www.municode.com/library/wa/seattle/codes/municipal_code?nodeId=TIT23LAUSCO_SUBTITLE_IIILAUSRE_DIV2AUUSDEST_CH23.55SI_PT3AP_23.55.014OEMSI


  3. Temporary Signs on Public Property or in Planting Strips.

   a. Temporary signs with commercial or noncommercial messages may be
   located on public rights-of-way or in planting strips in business
   districts, subject to the requirements of City of Seattle Public
   Works Rules Chapter 4.60 or its successor Rule.

   b. Temporary signs with noncommercial messages, other than in
   subsection C3a above, may be located in the planting strip in front
   of private property with the consent of the occupant of that
   property and may not exceed eight (8) square feet or be supported
   by stakes that are more than one (1) foot into the ground. Signs in
   the planting strip shall be no more than twenty-four (24) inches in
   height as measured from street or driveway grade when located
   within thirty (30) feet from the curbline of intersections. Signs
   shall be no more than thirty-six inches (36") in height as measured
   from street or driveway grade when located thirty feet (30') or
   more from the curbline of intersections.

   c. In addition to commercial signs in business districts allowed in
   subsection C3a above, only temporary commercial "open house" signs
   may be placed in planting strips. One (1) "open house" temporary
   sign per street frontage of a lot may be located with the consent
   of the occupant and provided the occupant or seller is on the
   premises. The "open house" signs may not exceed eight (8) square
   feet per lot or be supported by stakes that are more than one foot
   (1') into the ground. The "open house" signs shall be no more than
   twenty-four inches (24") in height as measured from street or
   driveway grade when located within thirty feet (30') from the
   curbline of intersections, and shall be no more than thirty-six
   inches (36") in height as measured from street or driveway grade
   when located thirty feet (30') or more from the curbline of
   intersections.

  d. No sign placed in a planting strip may be displayed on banners,
  streamers, strings of pennants, festoons of lights, flags,
  wind-animated objects or balloons.

  e. The requirements of this subsection C3 shall be enforced by the
  Director of Seattle Department of Transportation pursuant to the
  enforcement provisions of that Department.


*----------------------------------------------------------------------------------------------------
* liftover tips: set seqinfo (22 mar 2016)

    seqinfo(gr) <- SeqinfoForUCSCGenome("hg19")[seqlevels(gr)]

*----------------------------------------------------------------------------------------------------
* liftover tips: seqlevelsStyle (22 mar 2016)

   seqmap <- genomeStyles()

   seqmap$Homo_sapiens
      circular  auto   sex NCBI  UCSC dbSNP Ensembl
   1     FALSE  TRUE FALSE    1  chr1   ch1       1
   2     FALSE  TRUE FALSE    2  chr2   ch2       2
   3     FALSE  TRUE FALSE    3  chr3   ch3       3
   4     FALSE  TRUE FALSE    4  chr4   ch4       4
   5     FALSE  TRUE FALSE    5  chr5   ch5       5
   6     FALSE  TRUE FALSE    6  chr6   ch6       6
   7     FALSE  TRUE FALSE    7  chr7   ch7       7
   8     FALSE  TRUE FALSE    8  chr8   ch8       8
   9     FALSE  TRUE FALSE    9  chr9   ch9       9
   10    FALSE  TRUE FALSE   10 chr10  ch10      10
   11    FALSE  TRUE FALSE   11 chr11  ch11      11
   12    FALSE  TRUE FALSE   12 chr12  ch12      12
   13    FALSE  TRUE FALSE   13 chr13  ch13      13
   14    FALSE  TRUE FALSE   14 chr14  ch14      14
   15    FALSE  TRUE FALSE   15 chr15  ch15      15
   16    FALSE  TRUE FALSE   16 chr16  ch16      16
   17    FALSE  TRUE FALSE   17 chr17  ch17      17
   18    FALSE  TRUE FALSE   18 chr18  ch18      18
   19    FALSE  TRUE FALSE   19 chr19  ch19      19
   20    FALSE  TRUE FALSE   20 chr20  ch20      20
   21    FALSE  TRUE FALSE   21 chr21  ch21      21
   22    FALSE  TRUE FALSE   22 chr22  ch22      22
   23    FALSE FALSE  TRUE    X  chrX   chX       X
   24    FALSE FALSE  TRUE    Y  chrY   chY       Y
   25     TRUE FALSE FALSE   MT  chrM  chMT      MT


*----------------------------------------------------------------------------------------------------
* liftover tips: convert an entire bedfile from hg19 to hg38 (22 mar 2016)

    saved in ~/github/snpFoot/R/liftoverAndDisplayhg19BedFiles.R

    liftoverBedFile.19.38 <- function(filename) {
       tbl <- read.table(filename, sep="\t", header=TRUE, as.is=TRUE)
       gr <- GRanges(Rle(tbl$chrom), IRanges(tbl$start, tbl$end))
       seqlevelsStyle(gr) <- "UCSC"
       seqinfo(gr) <- SeqinfoForUCSCGenome("hg19")[seqlevels(gr)]
       gr.38 <- unlist(liftOver(gr, chain.19to38))
       seqinfo(gr.38) <- SeqinfoForUCSCGenome("hg38")[seqlevels(gr)]
       tbl.out <- as.data.frame(gr.38)
       filename.out <- sub(".bed$", ".hg38.bed", filename)
       printf("writing %d rows to %s", nrow(tbl.out), filename.out)
       write.table(tbl.out[, c(1,2,3)], file=filename.out, col.names=FALSE, row.names=FALSE, quote=FALSE)
       } # liftoverBedFile.19.38

*----------------------------------------------------------------------------------------------------
* liftover tips

   --- convert a single location from hg38 to 19, extract from hg19 vcf, re-express as hg39
   ~/s/work/priceLab/cory/igvExamples/hongongQuery.R

library(VariantAnnotation)
library(rtracklayer)
library(PrivateCoryData)

chain.19to38 <- import.chain(system.file(package="PrivateCoryData", "data", "hg19ToHg38.over.chain"))
chain.38to19 <- import.chain(system.file(package="PrivateCoryData", "data", "hg38ToHg19.over.chain"))

hg19.loc <- 88030379
hg38.loc <- 88734562

gr.target <- GRanges(Rle("chr5"), IRanges(start=hg38.loc, end=hg38.loc))
seqlevelsStyle(gr.target) <- "UCSC"

gr.19 <- unlist(liftOver(gr.target, chain.38to19))
seqlevelsStyle(gr.19) <- "NCBI"

vcfFile <- "/Volumes/local/bdds/data/ADNI/ADNI.808_indiv.minGQ_21.pass.ADNI_ID.chr5.vcf.gz"
stopifnot(file.exists(vcfFile))
samples <- "002_S_1268"
params <- ScanVcfParam(which=gr.19, samples=samples)
vcf <- readVcf(TabixFile(vcfFile), "hg19", params)

body.19 <- rowRanges(vcf)
seqlevelsStyle(body.19) <- "UCSC"
body.38 <- unlist(liftOver(body.19, chain.19to38))
rowRanges(vcf) <- body.38


*----------------------------------------------------------------------------------------------------
* hongdong reports an interesting region in the ADNI vcfs ac chr5:88734562 (10 mar 2016)

   cd ~/s/work/priceLab/cory/igvExamples
   source("mef2c.R")
   the variant of interest is from the "AD_or_OtherDim_list"
   chr5, 88734562
   ID: 5:88030379_T/TTTG  (note hg19 coords)
   Reference: T*
   Alternate: TTTG
   Qual: 22002.1
   Type: INDEL
   Is Filtered Out: No

   Alleles:
     No Call: 8
     Allele Num: 12
     Allele Count: 2
     Allele Frequence: 0.083
     Minor Allele Fraction: 0.083

  Genotypes:
     Non Variant:9
       No Call: 4
       Hom Ref: 5
     Variant: 1
       Het: 1
       Hom Var: 0

  appears to be sample id: 002_S_1268 at chr5: 88734562   (88030379 hg19)

  --- explore using VariantAnnotations
    library(VariantAnnotation)
    library(rtracklayer)
    library(PrivateCoryData)

    chain.19to38 <- import.chain(system.file(package="PrivateCoryData", "data", "hg19ToHg38.over.chain"))
    chain.38to19 <- import.chain(system.file(package="PrivateCoryData", "data", "hg19ToHg38.over.chain"))

    gr.target <- GRanges("chr5", IRanges(start=88030375, end=88030385))
    body <- rowRanges(vcf)
  body.lifted <- unlist(liftOver(body, chain.19to38))
  rowRanges(vcf) <- body.lifted


    vcfFile <- "/Volumes/local/bdds/data/ADNI/ADNI.808_indiv.minGQ_21.pass.ADNI_ID.chr5.vcf.gz"


*----------------------------------------------------------------------------------------------------
setMethod('displayVcfRegion', 'igvR',

   function(obj, chrom, start, end, vcfDirectory, sampleIDs=character()) {
      stopifnot(grepl("^chr", chrom))
      filenames <- grep(chrom, list.files(vcfDirectory), value=TRUE, ignore.case=TRUE)
      gz.filename <- grep(".gz$", filenames, value=TRUE)
      gz.path <- file.path(vcfDirectory, gz.filename)
      tbi.filename <- paste(gz.filename, ".tbi", sep="")
      tbi.path <- file.path(vcfDirectory, tbi.filename)
      gr <- GRanges(chrom, IRanges(start, end))
      print(ranges(gr))
      params <- ScanVcfParam(which=gr, samples=sampleIDs)
      vcf <- readVcf(TabixFile(gz.path), "hg38", params)
      tempFile <- tempfile(fileext=".vcf")
      writeVcf(vcf, tempFile)
      tempFile.gz <- sprintf("%s.gz", tempFile)
      bgzip(tempFile, dest=tempFile.gz, overwrite=TRUE)
      tempFile.gz.tbi <- indexTabix(tempFile.gz, format="vcf")
      loadFile(obj, tempFile.gz)
      }) # vcfRegionDisplay

*-----------------------------------------------------------------------------------------------------------------------
* create a small chr22 sample vcf file for igvR.R (8 mar 2016)

  cd ~/github/snpFoot/inst/unitTests/

  file.gz <- file.path(system.file(package="VariantAnnotation", "extdata"), "chr22.vcf.gz")
  param <- ScanVcfParam(which=GRanges("22", IRanges(0, 50310000)))
  vcf <- readVcf(TabixFile(file.gz), "hg19", param)
  seqlevelsStyle(vcf) <- "UCSC"

  chain.file <- system.file(package="PrivateCoryData", "data", "hg19ToHg38.over.chain")
  chain.19to38 <- import.chain(chain.file)

  body <- rowRanges(vcf)
  body.lifted <- unlist(liftOver(body, chain.19to38))
  rowRanges(vcf) <- body.lifted
  writeVcf(vcf, "chr22-sub.vcf")
  bgzip("chr22-sub.vcf", dest="chr22-sub.vcf.gz", overwrite=TRUE)
  indexTabix("chr22-sub.vcf.gz", format="vcf")

  cp snpFoot/inst/unitTests/chr22-sub.vcf.* igvR/inst/extdata/


*----------------------------------------------------------------------------------------------------
* cory's AD categorization of vcf samples (8 mar 2016)

  /local/bdds/data/ADNI/test/*_list
ssh pshannon@whovian ls -l /local/bdds/data/ADNI/test/*_list
-rw-r--r--. 1 cfunk pricelab 5643 Mar  3 17:43 /local/bdds/data/ADNI/test/AD_or_OtherDim_list   513
-rw-r--r--. 1 cfunk pricelab  451 Mar  3 17:42 /local/bdds/data/ADNI/test/APOE4_NL_list          41
-rw-r--r--. 1 cfunk pricelab  836 Mar  3 17:42 /local/bdds/data/ADNI/test/APOE_dementia_list     76
-rw-r--r--. 1 cfunk pricelab 2618 Mar  3 17:42 /local/bdds/data/ADNI/test/control_CN_list       238

  --- from book, after mounting whovian:/local to /Volumes/local

 wc -l /Volumes/local/bdds/data/ADNI/test/*_list
     513 /Volumes/local/bdds/data/ADNI/test/AD_or_OtherDim_list
      41 /Volumes/local/bdds/data/ADNI/test/APOE4_NL_list
      76 /Volumes/local/bdds/data/ADNI/test/APOE_dementia_list
     238 /Volumes/local/bdds/data/ADNI/test/control_CN_list
     868 total

 cat /Volumes/local/bdds/data/ADNI/test/*_list | sort | uniq | wc -l
     756
*----------------------------------------------------------------------------------------------------
* xpath, sbml, matt's metabolic models (8 mar 2016)

  found 2013 xpath/bioc code:  ~/s/examples/sbml/R/asXml/go.R
  cd ~/s/work/priceLab/mattRichards/sbml

  wc -l *.xml
    19369 MaripaludisModel.xml
   18408 MaripaludisMorph.xml
   20237 MaripaludisReconstruction.xml

  cd ~/s/work/priceLab/mattRichards
  cp ~/s/examples/sbml/R/asXml/go.R parseToTables.R

*----------------------------------------------------------------------------------------------------
* xpath tips, xpath examples, with and without namespaces, for simple xml, and a slimmed-down sbml file (29 apr 2016)

   cd ~/s/examples/R/xml/xpath/w3schools-example/
   go.R

    library(XML)
    file <- "books.xml"
    stopifnot(file.exists(file))
    doc <- xmlParse(file)

    namespaces <-  c(BOOK="http://bookstore.org")


    book.nodes <-  getNodeSet(doc, "//book", namespaces)
       # each book has only one attribute, "category".  here are some ways to get at it
    names(xmlAttrs(book.nodes[[1]]))
    book.attributes <- xmlAttrs(book.nodes[[1]])
    book.attributes[["category"]]
    xmlAttrs(book.nodes[[1]])[["category"]]  # [1] "COOKING"

       # each book node has a single title child node
    title.elements <- getNodeSet(doc, "//book/title")
       # two ways to get the text content of a node, first version simpler
    unlist(lapply(getNodeSet(doc, "//book/title"), function(x) xmlValue(x)))
    unlist(lapply(getNodeSet(doc, "//book/title/text()"), function(x) xmlValue(x)))
       # [1] "Everyday Italian"  "Harry Potter"      "XQuery Kick Start" "Learning XML"
       # best yet, using xmlSApply
    xmlSApply(getNodeSet(doc, "//book/title"), function(n) xmlValue(n))
       #[1] "Everyday Italian"  "Harry Potter"      "XQuery Kick Start" "Learning XML"
       # also: go directly to the title nodes
    xmlSApply(getNodeSet(doc, "//title"), function(n) xmlValue(n))
       # [1] "Everyday Italian"  "Harry Potter"      "XQuery Kick Start" "Learning XML"
       # but this gets nothing: note the single /
    xmlSApply(getNodeSet(doc, "/title"), function(n) xmlValue(n))
       # list()

    *-----------------------------------------------------------------------------------------------------------------------
    # now try the more complicated sbml file, much reduced, containing just 1 reaction, 4 species, and one "gene_association"

    file <- "small.sbml"
    stopifnot(file.exists(file))
    doc <- xmlParse(file)

    namespaces <-  c(sbml="http://www.sbml.org/sbml/level2",
                     xhtml="http://www.w3.org/1999/xhtml",
                     MathML="http://www.w3.org/1998/Math/MathML")

    notes <- xmlSApply(getNodeSet(doc, "//reaction/notes/body/p", namespaces), function(n) xmlValue(n))

       # or: traverse the reaactions, got relative
    reactions <- getNodeSet(doc, "//reaction", namespaces)  # 688
    getNodeSet(reactions[[1]], "notes/body/p", namespaces)

     reactions <- getNodeSet(doc, "//reaction", namespaces)  # 688
     getNodeSet(reactions[[1]], "notes/body/p", namespaces)
     xmlSApply(getNodeSet(reactions[[1]], "notes/body/p", namespaces), function(x) xmlValue(x))
        #  "GENE_ASSOCIATION: (mmp0807 or mmp0486)"
        #  "SUBSYSTEM: Protocatechuate branch of beta-ketoadipate pathway"
        #  "EC Number: |4.1.1.44|"

*----------------------------------------------------------------------------------------------------
* xpath example, from bioc work with recon2, and matt's work with gap filling (29 apr 2016)

   ~/s/work/priceLab/mattRichards/parseToTables-old.R

   newParseReactionXref <- function() {
   ns <- c(rdf="http://www.w3.org/1999/02/22-rdf-syntax-ns#",
           bqmodel="http://biomodels.net/model-qualifiers/",
           vCard="http://www.w3.org/2001/vcard-rdf/3.0#",
           dcterms="http://purl.org/dc/terms/",
           dc="http://purl.org/dc/elements/1.1/",
           bqbiol="http://biomodels.net/biology-qualifiers/")

   if(!exists("sdoc"))
       sdoc <<- xmlParse("recon2.v02.xml")

   reactions <-  getNodeSet(sdoc, "//reaction")                                        # 7440
   reactionsA <- getNodeSet(sdoc, "//reaction[annotation//rdf:li]", namespaces=ns)     # 7146

   extract <- function(reactionElement){
      attributes <- as.list(xmlAttrs(reactionElement)[c("id", "name", "sboTerm", "reversible")])
      path <- sprintf("//reaction[@id='%s']//rdf:li", attributes$id)
      identifier.elements <- getNodeSet(sdoc, path, namespaces=ns)
      identifiers <- as.character(sapply(identifier.elements, xmlAttrs))
      ids.parsed <- lapply(identifiers, function(r) {
                     tokens<-strsplit(r, "/")[[1]]; list(source=tokens[4], value=tokens[5])})
      desc <- with(attributes, list(id=id, name=name, reversible=reversible, sboTerm=sboTerm))
      desc$pubmed <- NA
      for(id.parsed in ids.parsed)
         desc[[id.parsed$source]] <- id.parsed$value
      desc
      }
    x <- lapply(reactionsA, extract)
    id <- sapply(x, "[[", 1)
    name <- sapply(x, "[[",2)
    reversible <- sapply(x, "[[", 3)
    sboTerm <- sapply(x, "[[", 4)
    pubmed <- sapply(x, "[[", 5)
    #obo.eco <- sapply(x, "[[", 6)

    tbl <- data.frame(id=id, name=name, reversible=reversible,
                      pubmed=pubmed,
                      stringsAsFactors=FALSE)

    tbl.reactionXref <<- tbl
    save(tbl.reactionXref, file="tbl.reactionXref.RData")
    tbl.reactionXref
    }

*------------------------------------------------------------------------------------------------------------------------
* create a mini vcf file for the igvR package (7 mar 2016)

  cd ~/github/igvR/inst/extdata/vcf/
  library(VariantAnnotation)
  gr <- GRanges("5", IRanges(87500000, 89000000))
    # after mounting whoovian to laptop
  gz.filename <- "/Volumes/local/bdds/data/ADNI/ADNI.808_indiv.minGQ_21.pass.ADNI_ID.chr5.vcf.gz"
  tabix.filename <- sprintf("%s.tbi", gz.filename)
  file.exists(tabix.filename)
  params <- ScanVcfParam(which=gr)
  vcf <- readVcf(TabixFile(gz.filename), "gr19", params)   # takes 1-2 minutes
  length(vcf) # [1] 18664
  range(rowRanges(vcf))   5 [87500099, 88999914]      *
  seqlevelsStyle(vcf)  # [1] "NCBI"    "Ensembl"
  seqlevelsStyle(vcf) <- "UCSC"

  chain.file <- system.file(package="PrivateCoryData", "data", "hg19ToHg38.over.chain")
  chain.19to38 <- import.chain(chain.file)
  body <- rowRanges(vcf)
  body.lifted <- unlist(liftOver(body, chain.19to38))
  rowRanges(vcf) <- body.lifted
  writeVcf(vcf, "chr5-sub.vcf")
  bgzip("chr5-sub.vcf", dest="chr5-sub.vcf.gz", overwrite=TRUE)
  indexTabix("chr5-sub.vcf.gz", format="vcf")

*----------------------------------------------------------------------------------------------------
* command line igv (7 mar 2016)

  see ~/bin/igv

  /Applications/IGV_2.3.68.app/Contents/MacOS/JavaAppLauncher

*----------------------------------------------------------------------------------------------------
* seth's epigenomics tracks for igv (7 mar 2016)

  --- email today

  I've downloaded annotations of tissue-specific promoters and enhancers from the ROADMAP and FANTOM
  consortia to /proj/price1. These may be useful to incorporate into our visualizations.

  The most valuable tracks are probably the 25-state ChromHMM models of epigenomic states from the
  ROADMAP project. These are located at
  /proj/price1/sament/resources/ChromHMM/imputed_25state_model.

  There is a separate .bed file for each of 127 cell/tissue types, including about 15 different
  brain regions and brain cell types. The descriptions of the 25 distinct epigenetic states is at
  /proj/price1/sament/resources/ChromHMM/imputed_25state_model/README.txt. The metadata for the 127
  samples is at /proj/price1/sament/resources/ChromHMM/jul2013.roadmapData.qc -
  Consolidated_EpigenomeIDs_summary_Table.csv

  The FANTOM annotations of active promoters and enhancers in each tissue are also quite
  interesting. These are located at:
  /proj/price1/sament/resources/fantom5/hg38/facet_expressed_enhancers. Again, there are separate
  .bed files for each tissue.

  These annotations provide information about active regulatory regions that is independent of the
  DNase-seq data that Cory and I used in our footprinting analysis. So it should be useful for
  further annotating SNPs in these regions.

*----------------------------------------------------------------------------------------------------
* vcf tips: the 4.2 specification

   https://samtools.github.io/hts-specs/VCFv4.2.pdf
   tabix ADNI.808_indiv.minGQ_21.pass.ADNI_ID.chr5.vcf.gz 5:88249827-88249827

*----------------------------------------------------------------------------------------------------
* AD wgs vcf files (2 mar 2016)

  having found 5 snps upstream of mef2c on chr5, in cory's footprints, find out how to associate
  them with per-sample genotype data, and with cory's sample classifications.

   cd ~/s/work/priceLab/AD/wgs/
   goto(igv, "chr5", 88926400, 88939000)

   snp.locs <- c(88926433, 88927121, 88935675, 88936723, 88938929)

   --- the first one
      t(subset(tbl.vcf, start==88926433))
                 5:88222250_AT/A
    seqnames     "chr5"
    start        88926433
    end          88926434
    width        2
    strand       "*"
    paramRangeID "NA"
    REF          "AT"
    ALT          ?
    QUAL         293.92
    FILTER       "PASS"

  as.data.frame(table(unlist(lapply(unique(tbl.AD.snpfp$snp), function(loc) mut.freqs[[rownames(subset(tbl.vcf, start==loc))]]))))

*----------------------------------------------------------------------------------------------------
* VariantAnnotation, filter on sample id, for igvR (8 mar 2016)

  consulting https://www.bioconductor.org/packages/3.3/bioc/vignettes/VariantAnnotation/inst/doc/filterVcf.pdf
  operating on igvR::displayVcfRegion vcf object

  GT <- geno(vcf)$GT

   GT[1:10, 1:5]
                   003_S_1057 003_S_0908 003_S_1122 136_S_0695 136_S_0873
   rs797419        "0/1"      "0/1"      "0/1"      "0/1"      "1/1"
   5:88169020_C/A  "0/0"      "0/0"      "0/0"      "0/0"      "0/0"
   5:88169121_AT/A "0/0"      "0/0"      "0/0"      "0/0"      "0/0"
   5:88169151_C/T  "0/0"      "0/0"      "0/0"      "0/0"      "0/0"
   5:88169197_T/C  "0/0"      "0/0"      "0/0"      "0/0"      "0/0"
   5:88169235_C/T  "0/0"      "0/0"      "0/0"      "0/0"      "0/0"
   rs186220438     "0/0"      "0/0"      "0/0"      "0/0"      "0/0"
   5:88169311_AC/A "0/0"      "0/0"      "0/0"      "0/0"      "0/0"
   5:88169368_G/A  "0/0"      "0/0"      "0/0"      "0/0"      "0/0"
   5:88169369_G/GA "0/0"      "0/0"      "0/0"      "0/0"      "0/0"



*----------------------------------------------------------------------------------------------------
* AD wgs vcf files (2 mar 2016)

  cd ~/s/work/priceLab/AD/wgs/    go.R has sample, exploratory, learning run

  chr5 file, after mounting whovian to my macbook
     fgz <- "/Volumes/local/bdds/data/ADNI/ADNI.808_indiv.minGQ_21.pass.ADNI_ID.chr5.vcf.gz"

   geno(header(vcf))
             Number        Type                                                                                   Description
     GT           1      String                                                                                      Genotype
     AD           .     Integer                                Allelic depths for the ref and alt alleles in the order listed
     DP           1     Integer                     Approximate read depth (reads with MQ=255 or with bad mates are filtered)
     GQ           1     Integer                                                                              Genotype Quality
     MIN_DP       1     Integer                                                     Minimum DP observed within the GVCF block
     PL           G     Integer        Normalized, Phred-scaled likelihoods for genotypes as defined in the VCF specification
     SB           4     Integer Per-sample component statistics which comprise the Fisher's Exact Test to detect strand bias.


    ---- explore all genotype fields
       geno(vcf.hg38)  # names(7): GT AD DP GQ MIN_DP PL SB
       geno(vcf)$GT[1,1]     #  "0/0"
       geno(vcf)$AD[1,1]     # [[1]] [1] 40  0
       geno(vcf)$DP[1,1]     # [1] 40
       geno(vcf)$GQ[1,1][1]  # 99
       geno(vcf)$MIN_DP[1,1] # [1] NA
       geno(vcf)$PL[1,1]     # [[1]] [1]    0  102 1530
       geno(vcf)$SB[1,1,]    # [1] NA NA NA NA
   ---- get the genotype data
      GT <- geno(vcf)$GT
      GT[1:10, 1:5]
      dim(GT)  # 12437   808
      sort(unique(as.character(GT)))
         [1] "."   "0/0" "0/1" "0/2" "0/3" "0/4" "0/5" "0/6" "1/1" "1/2" "1/3" "1/4" "1/5" "1/6" "2/2" "2/3"
        [17] "2/4" "2/5" "2/6" "3/3" "3/4" "3/5" "3/6" "4/4" "4/5" "4/6" "5/5" "5/6" "6/6"
      as.data.frame(table(as.character(GT)))
         Var1    Freq
            .  123572
          0/0 9250262
          0/1  411783
          0/2   10162
          0/3    3046
          0/4    1347
          0/5     620
          0/6     523
          1/1  233067
          1/2    5181
          1/3    1965
          1/4     848
          1/5     336
          1/6     317
          2/2    2697
          2/3     992
          2/4     302
          2/5     222
          2/6     166
          3/3     594
          3/4     259
          3/5     142
          3/6     113
          4/4     197
          4/5      51
          4/6     105
          5/5      82
          5/6      58
          6/6      87



                        003_S_1057 003_S_0908 003_S_1122 136_S_0695 136_S_0873
      rs149325732       "0/0"      "0/0"      "0/0"      "0/0"      "0/0"
      rs181059497       "0/0"      "0/0"      "0/0"      "0/0"      "0/0"
      5:88000115_AT/ATT "0/0"      "0/1"      "0/0"      "0/0"      "1/1"
      rs189976883       "0/0"      "0/0"      "0/0"      "0/0"      "0/0"
      rs147447810       "0/0"      "0/0"      "0/0"      "0/0"      "0/0"
      5:88000301_T/C    "0/0"      "0/0"      "0/0"      "0/0"      "0/0"
      5:88000303_G/C    "0/0"      "0/0"      "0/0"      "0/0"      "0/0"
      5:88000304_C/T    "0/0"      "0/0"      "0/0"      "0/0"      "0/0"
      rs71639119        "0/0"      "0/0"      "0/0"      "0/0"      "0/0"
      rs138314112       "0/0"      "0/0"      "0/0"      "0/0"      "0/0"


*----------------------------------------------------------------------------------------------------
* hg19tohg38 liftover, using rtracklayer (1 mar 2016)

  cd ~/s/data/public/human/ucsc
  curl -O http://hgdownload.cse.ucsc.edu/goldenPath/hg19/liftOver/hg19ToHg38.over.chain.gz
  gunzip hg19ToHg38.over.chain.gz
  curl -O http://hgdownload.cse.ucsc.edu/goldenPath/hg38/liftOver/hg38ToHg19.over.chain.gz

  ---- use it
    library(rtracklayer)
    chain.19to38 <- import.chain("~/s/data/public/human/ucsc/hg19ToHg38.over.chain")
    x <- rowRanges(vcf)
    seqlevelsStyle(x) <- "UCSC"
    xx <- liftOver(x, chain.19to38)
    xxx <- unlist(xx)

  --- test & demo: convert both ways
    library(rtracklayer)
    chain.19to38 <- import.chain("~/s/data/public/human/ucsc/hg19ToHg38.over.chain")
    chain.38to19 <- import.chain("~/s/data/public/human/ucsc/hg38ToHg19.over.chain")

    hg19.min.loc <- 88000000
    hg19.max.loc <- 89000000

    tmp.19 <- GRanges('5', IRanges(hg19.min.loc, hg19.max.loc))
    seqlevelsStyle(tmp.19) <- "UCSC"
    tmp.38 <- unlist(liftOver(tmp.19, chain.19to38))
    tmp.19.recovered <- liftOver(tmp.38, chain.38to19)


*----------------------------------------------------------------------------------------------------
* vcf wgs ad, a second look (1 mar 2016)

  cd ~/s/work/priceLab/AD/wgs
  get all snps from chr5 in neighborhood of mef2c

  mount whovian using finder
   dir /Volumes/local/bdds/data/ADNI/*chr5*


   7575370075 Feb 26 14:07 ADNI.808_indiv.minGQ_21.pass.ADNI_ID.chr5.vcf.gz
       170875 Feb 26 14:22 ADNI.808_indiv.minGQ_21.pass.ADNI_ID.chr5.vcf.gz.tbi

  mef2c: chr5:88,716,241-88,906,105
  mef2c + upstream: chr5:88,716,241-89,193,599

  learn the seqname:
  gzip -cd /Volumes/local/bdds/data/ADNI/ADNI.808_indiv.minGQ_21.pass.ADNI_ID.chr5.vcf.gz | head -135 | tail -1
       5	11587	.	AACCCT	A	1901.59	PASS	.	GT:AD:DP:GQ:PL	./.:0,0:0:.:.	./.:0,0:0:.:.	./.:71,0:71:.:.	./.:0,0:0:.:.	./.:0,0:0:.:.	./.:2,0:2:.:.	./.:1,0:1:.:.	./.:1,0:1:.:.	./.:22,0:22:.:.	./.:0,0:0:.:.	./.:70,0:70:.:.	./.:64,0:64:.:.	./.:0,0:0:.:.	./.:3,0:3:.:.	./.:1,0:1:.:.	./.:61,0:61:.:.	./.:0,0:0:.:.	./.:30,0:30:.:.	./.:1,0:1:.:.	./.:2,0:2:.:.	./.:0,0:0:.:.	./.:0,0:0:.:.	./.:0,0:0:.:.	./.:1,0:1:.:.	./.:1,0:1:.:.	./.:1,0:1:.:.	./.:0,0:0:.:.	./.:1,0:1:.:.	./.:0,0:0:.:.	0/1:86,15:101:99:195,0,2074	./.:23,0:23:.:.	./.:1,0:1:.:.	./.:1,0:1:.:.	./.:1,0:1:.:.	./.:0,0:0:.:.	./.:1,0:1:.:.	./.:0,0:0:.:.	./.:0,0:0:.:.	./.:143,0:143:.:.	./.:0,0:0:.:.	./.:0,0:0:.:.	./.:0,0:0:.:.	./.:1,0:1:.:.	./.:104,0:104:.:.	./.:0,0:0:.:.	./.:1,0:1:.:.	./.:2,0:2:.:.	./.:0,0:0:.:.	./.:75,0:75:.:.	./.:3,0:3:.:.	./.:0,0:0:.:.	./.:9,0:9:.:.	./.:1,0:1:.:.	./.:14,0:14:.:.	./.:0,0:0:.:.	./.:0,0:0:.:.	./.:1,0:1:.:.	./.:0,0:0:.:.	./.:0,0:0:.:.	./.:1,0:1:.:.	./.:0,0:0:.:.	./.:0,0:0:.:.	./.:2,0:2:.:.	./.:0,0:0:.:.	./.:1,0:1:.:.	./.:0,0:0:.:.	./.:2,0:2:.:.	./.:7,0:7:.:.	./.:1,0:1:.:.	./.:2,0:2:.:.	./.:4,0:4:.:.	./.:1,0:1:.:.	./.:1,0:1:.:.	./.:14,0:14:.:.	./.:0,0:.:.:.	./.:1,0:1:.:.	0/1:82,14:96:99:155,0,1866	0/1:88,11:99:34:34,0,1977	./.:0,0:0:.:.	./.:1,0:1:.:.	./.:10,0:10:.:.	./.:1,0:1:.:.	./.:2,0:2:.:.	./.:1,0:1:.:.	./.:39,0:39:.:.	./.:1,0:1:.:.	./.:1,0:1:.:.	./.:1,0:1:.:.	./.:0,0:0:.:.	./.:3,0:3:.:.	./.:0,0:0:.:.	./.:1,0:1:.:.	./.:0,0:0:.:.	./.:7,0:7:.:.	./.:0,0:0:.:.	./.:1,0:1:.:.	./.:2,0:2:.:.	./.:0,0:0:.:.	./.:4,0:4:.:.	./.:1,0:1:.:.	./.:4,0:4:.:.	./.:0,0:0:.:.	./.:27,0:27:.:.	./.:1,0:1:.:.	./.:0,0:0:.:.	./.:0,0:0:.:.	./.:0,0:0:.:.	./.:1,0:1:.:.	./.:0,0:0:.:.	./.:0,0:0:.:.	./.:0,0:0:.:.	./.:1,0:1:.:.	./.:0,0:0:.:.	./.:15,0:15:.:.	./.:0,0:0:.:.	./.:0,0:0:.:.	./.:0,0:0:.:.	./.:2,0:2:.:.	./.:2,0:2:.:.	./.:1,0:1:.:.	./.:0,0:0:.:.	./.:2,0:2:.:.	./.:0,0:0:.:.	./.:0,0:0:.:.	./.:0,0:0:.:.	./.:0,0:0:.:.	./.:61,0:61:.:.	./.:0,0:0:.:.	./.:0,0:0:.:.	./.:1,0:1:.:.	./.:3,0:3:.:.	./.:0,0:0:.:.	./.:0,0:0:.:.	./.:0,0:0:.:.	./.:0,0:0:.:.	./.:0,0:0:.:.	./.:1,0:1:.:.	./.:0,0:0:.:.	./.:1,0:1:.:.	./.:0,0:0:.:.	./.:3,0:3:.:.	./.:0,0:0:.:.	./.:1,0:1:.:.	./.:1,0:1:.:.	./.:3,0:3:.:.	./.:13,0:13:.:.	./.:0,0:0:.:.	./.:2,0:2:.:.	./.:0,0:0:.:.	./.:23,0:23:.:.	./.:0,0:0:.:.	./.:1,0:1:.:.	./.:0,0:0:.:.	./.:1,0:1:.:.	./.:0,0:0:.:.	./.:83,10:93:2:2,0,1872	./.:0,0:0:.:.	./.:1,0:1:.:.	./.:0,0:0:.:.	./.:2,0:2:.:.	./.:3,0:3:.:.	./.:2,0:2:.:.	./.:0,0:0:.:.	./.:6,0:6:.:.	./.:1,0:1:.:.	./.:2,0:2:.:.	./.:17,0:17:.:.	./.:23,0:23:.:.	./.:0,0:0:.:.	./.:18,0:18:.:.	./.:3,0:3:.:.	./.:2,0:2:.:.	./.:0,0:0:.:.	./.:0,0:0:.:.	./.:1,0:1:.:.	./.:0,0:0:.:.	./.:0,0:0:.:.	./.:0,0:0:.:.	./.:0,0:0:.:.	./.:0,0:0:.:.	./.:0,0:0:.:.	./.:1,0:1:.:.	./.:0,0:0:.:.	./.:11,0:11:.:.	./.:1,0:1:.:.	./.:3,0:3:.:.	./.:0,0:0:.:.	./.:17,0:17:.:.	./.:2,0:2:.:.	./.:0,0:0:.:.	./.:18,0:18:.:.	./.:0,0:0:.:.	./.:32,0:32:.:.	./.:0,0:0:.:.	./.:0,0:0:.:.	./.:0,0:0:.:.	./.:0,0:0:.:.	./.:0,0:0:.:.	./.:0,0:0:.:.	./.:0,0:0:.:.	./.:1,0:1:.:.	./.:0,0:0:.:.	./.:0,0:0:.:.	./.:0,0:0:.:.	./.:0,0:0:.:.	./.:1,0:1:.:.	./.:0,0:0:.:.	./.:1,0:1:.:.	./.:2,0:2:.:.	./.:0,0:0:.:.	./.:1,0:1:.:.	./.:1,0:1:.:.	./.:15,0:15:.:.	./.:0,0:0:.:.	./.:0,0:0:.:.	./.:0,0:0:.:.	./.:1,0:1:.:.	./.:36,0:36:.:.	./.:0,0:0:.:.	./.:2,0:2:.:.	./.:1,0:1:.:.	./.:1,0:1:.:.	./.:0,0:0:.:.	./.:4,0:4:.:.	./.:82,0:82:.:.	./.:1,0:1:.:.	./.:0,0:0:.:.	./.:13,0:13:.:.	0/1:44,9:53:78:78,0,997	./.:1,0:1:.:.	./.:19,0:19:.:.	./.:0,0:0:.:.	./.:9,0:9:.:.	./.:1,0:1:.:.	./.:0,0:0:.:.	./.:0,0:0:.:.	./.:0,0:0:.:.	./.:1,0:1:.:.	./.:9,0:9:.:.	./.:25,0:25:.:.	./.:0,0:0:.:.	./.:1,0:1:.:.	./.:0,0:0:.:.	./.:1,0:1:.:.	./.:7,0:7:.:.	./.:0,0:0:.:.	./.:1,0:1:.:.	./.:2,0:2:.:.	./.:0,0:0:.:.	./.:56,0:56:.:.	./.:0,0:0:.:.	./.:1,0:1:.:.	./.:0,0:0:.:.	./.:0,0:0:.:.	./.:0,0:0:.:.	./.:42,0:42:.:.	./.:0,0:0:.:.	./.:9,0:9:.:.	./.:3,0:3:.:.	./.:0,0:0:.:.	./.:0,0:0:.:.	./.:27,0:27:.:.	./.:0,0:0:.:.	./.:0,0:0:.:.	./.:12,0:12:.:.	./.:0,0:0:.:.	./.:2,0:2:.:.	./.:0,0:0:.:.	./.:5,0:5:.:.	./.:1,0:1:.:.	./.:0,0:0:.:.	0/1:41,8:49:99:106,0,942	./.:16,0:16:.:.	./.:66,0:66:.:.	./.:0,0:0:.:.	./.:50,0:50:.:.	./.:1,0:1:.:.	./.:0,0:.:.:.	./.:42,0:42:.:.	./.:0,0:0:.:.	./.:84,0:84:.:.	./.:1,0:1:.:.	./.:0,0:0:.:.	./.:0,0:0:.:.	./.:0,0:0:.:.	./.:1,0:1:.:.	./.:11,0:11:.:.	./.:58,0:58:.:.	./.:1,0:1:.:.	./.:40,0:40:.:.	0/1:86,12:98:42:42,0,1542	0/1:43,6:49:45:45,0,1069	./.:0,0:0:.:.	./.:0,0:0:.:.	./.:103,0:103:.:.	./.:8,0:8:.:.	./.:0,0:0:.:.	./.:0,0:0:.:.	./.:0,0:0:.:.	./.:0,0:0:.:.	0/0:61,3:64:99:0,99,1551	./.:51,0:51:.:.	./.:1,0:1:.:.	./.:0,0:0:.:.	./.:106,0:106:.:.	./.:0,0:0:.:.	./.:1,0:1:.:.	./.:0,0:0:.:.	./.:44,0:44:.:.	./.:1,0:1:.:.	./.:2,0:2:.:.	./.:24,0:24:.:.	./.:0,0:0:.:.	./.:0,0:0:.:.	./.:0,0:0:.:.	./.:1,0:1:.:.	./.:0,0:0:.:.	./.:1,0:1:.:.	./.:1,0:1:.:.	./.:1,0:1:.:.	./.:0,0:0:.:.	./.:57,0:57:.:.	./.:79,0:79:.:.	./.:1,0:1:.:.	./.:72,0:72:.:.	./.:0,0:0:.:.	./.:62,0:62:.:.	./.:0,0:0:.:.	./.:1,0:1:.:.	./.:1,0:1:.:.	./.:0,0:0:.:.	./.:8,0:8:.:.	0/1:111,16:127:99:125,0,2670	./.:1,0:1:.:.	./.:0,0:0:.:.	./.:0,0:0:.:.	./.:0,0:0:.:.	./.:1,0:1:.:.	./.:1,0:1:.:.	./.:35,0:35:.:.	0/0:72,6:78:45:0,45,1552	./.:2,0:2:.:.	./.:2,0:2:.:.	./.:0,0:0:.:.	./.:45,0:45:.:.	./.:0,0:0:.:.	./.:31,0:31:.:.	./.:0,0:0:.:.	0/1:69,12:81:44:44,0,1606	./.:0,0:0:.:.	./.:53,0:53:.:.	./.:0,0:0:.:.	0/0:114,11:125:71:0,71,2600	./.:0,0:0:.:.	./.:53,0:53:.:.	./.:0,0:0:.:.	./.:5,0:5:.:.	0/1:66,14:80:99:170,0,1407	./.:0,0:0:.:.	./.:75,0:75:.:.	./.:1,0:1:.:.	./.:1,0:1:.:.	./.:81,0:81:.:.	./.:0,0:0:.:.	./.:0,0:0:.:.	./.:0,0:0:.:.	./.:0,0:0:.:.	./.:0,0:0:.:.	./.:0,0:0:.:.	./.:0,0:0:.:.	./.:0,0:0:.:.	./.:0,0:0:.:.	./.:1,0:1:.:.	./.:0,0:0:.:.	./.:1,0:1:.:.	./.:20,0:20:.:.	./.:1,0:1:.:.	./.:0,0:0:.:.	./.:0,0:0:.:.	./.:1,0:1:.:.	./.:62,0:62:.:.	./.:1,0:1:.:.	./.:1,0:1:.:.	./.:0,0:0:.:.	./.:61,0:61:.:.	./.:0,0:0:.:.	./.:0,0:0:.:.	./.:0,0:0:.:.	./.:1,0:1:.:.	./.:1,0:1:.:.	./.:67,0:67:.:.	./.:46,0:46:.:.	./.:84,0:84:.:.	./.:0,0:0:.:.	./.:1,0:1:.:.	./.:0,0:0:.:.	./.:2,0:2:.:.	./.:0,0:0:.:.	./.:2,0:2:.:.	./.:47,0:47:.:.	./.:0,0:0:.:.	0/0:73,8:81:43:0,43,1665	./.:0,0:0:.:.	./.:3,0:3:.:.	./.:1,0:1:.:.	./.:0,0:0:.:.	./.:0,0:0:.:.	./.:0,0:0:.:.	./.:0,0:.:.:.	./.:0,0:0:.:.	./.:80,0:80:.:.	./.:0,0:0:.:.	./.:60,0:60:.:.	./.:1,0:1:.:.	./.:0,0:0:.:.	./.:0,0:0:.:.	./.:4,0:4:.:.	./.:0,0:0:.:.	./.:83,0:83:.:.	./.:85,10:95:15:0,15,2064	./.:0,0:0:.:.	./.:30,0:30:.:.	./.:0,0:0:.:.	./.:66,0:66:.:.	./.:4,0:4:.:.	./.:0,0:0:.:.	./.:6,0:6:.:.	./.:8,0:8:.:.	./.:1,0:1:.:.	./.:1,0:1:.:.	./.:2,0:2:.:.	./.:1,0:1:.:.	./.:2,0:2:.:.	./.:0,0:0:.:.	./.:1,0:1:.:.	./.:1,0:1:.:.	./.:0,0:0:.:.	./.:0,0:0:.:.	./.:0,0:0:.:.	./.:0,0:0:.:.	./.:0,0:0:.:.	./.:1,0:1:.:.	./.:12,0:12:.:.	./.:1,0:1:.:.	./.:0,0:0:.:.	./.:0,0:0:.:.	./.:2,0:2:.:.	./.:2,0:2:.:.	./.:105,0:105:.:.	./.:0,0:0:.:.	./.:53,0:53:.:.	./.:0,0:0:.:.	./.:3,0:3:.:.	./.:1,0:1:.:.	./.:52,0:52:.:.	./.:1,0:1:.:.	./.:2,0:2:.:.	./.:1,0:1:.:.	./.:0,0:0:.:.	./.:58,0:58:.:.	./.:0,0:0:.:.	./.:2,0:2:.:.	./.:0,0:0:.:.	./.:2,0:2:.:.	./.:0,0:0:.:.	./.:124,0:124:.:.	0/1:51,8:59:51:51,0,1081	./.:0,0:0:.:.	./.:0,0:0:.:.	./.:1,0:1:.:.	./.:0,0:0:.:.	./.:1,0:1:.:.	./.:0,0:0:.:.	./.:1,0:1:.:.	./.:0,0:0:.:.	./.:0,0:0:.:.	./.:77,0:77:.:.	./.:0,0:0:.:.	./.:0,0:0:.:.	./.:0,0:0:.:.	./.:1,0:1:.:.	./.:0,0:0:.:.	./.:0,0:0:.:.	./.:2,0:2:.:.	./.:52,0:52:.:.	./.:42,0:42:.:.	./.:2,0:2:.:.	0/1:49,11:60:99:156,0,907	./.:1,0:1:.:.	./.:0,0:0:.:.	./.:1,0:1:.:.	./.:2,0:2:.:.	./.:5,0:5:.:.	./.:1,0:1:.:.	./.:3,0:3:.:.	./.:2,0:2:.:.	./.:0,0:0:.:.	./.:24,0:24:.:.	./.:1,0:1:.:.	./.:0,0:0:.:.	./.:69,0:69:.:.	./.:3,0:3:.:.	./.:0,0:0:.:.	./.:20,0:20:.:.	./.:53,0:53:.:.	./.:2,0:2:.:.	./.:0,0:0:.:.	./.:112,0:112:.:.	./.:0,0:0:.:.	./.:1,0:1:.:.	./.:1,0:1:.:.	./.:0,0:0:.:.	./.:0,0:0:.:.	./.:0,0:0:.:.	./.:0,0:0:.:.	./.:39,0:39:.:.	./.:0,0:0:.:.	./.:0,0:0:.:.	./.:0,0:0:.:.	./.:2,0:2:.:.	./.:2,0:2:.:.	./.:0,0:0:.:.	./.:4,0:4:.:.	./.:0,0:0:.:.	./.:2,0:2:.:.	./.:2,0:2:.:.	./.:3,0:3:.:.	./.:0,0:0:.:.	./.:0,0:0:.:.	./.:1,0:1:.:.	./.:1,0:1:.:.	./.:3,0:3:.:.	./.:2,0:2:.:.	./.:59,0:59:.:.	./.:1,0:1:.:.	./.:0,0:0:.:.	./.:0,0:0:.:.	./.:55,0:55:.:.	./.:0,0:0:.:.	./.:1,0:1:.:.	./.:50,0:50:.:.	./.:0,0:0:.:.	./.:0,0:0:.:.	./.:1,0:1:.:.	./.:80,0:80:.:.	./.:1,0:1:.:.	./.:0,0:0:.:.	./.:0,0:0:.:.	./.:1,0:1:.:.	./.:0,0:0:.:.	./.:1,0:1:.:.	./.:3,0:3:.:.	./.:2,0:2:.:.	./.:0,0:0:.:.	./.:1,0:1:.:.	./.:0,0:0:.:.	./.:0,0:0:.:.	./.:77,7:84:15:0,15,1720	./.:22,0:22:.:.	./.:0,0:0:.:.	./.:0,0:0:.:.	./.:40,0:40:.:.	./.:0,0:0:.:.	./.:2,0:2:.:.	./.:0,0:0:.:.	./.:69,8:77:15:15,0,1555	0/1:68,9:77:25:25,0,1603	./.:0,0:0:.:.	./.:15,0:15:.:.	./.:0,0:0:.:.	./.:0,0:0:.:.	./.:2,0:2:.:.	0/1:55,9:64:95:95,0,1288	./.:2,0:2:.:.	./.:42,0:42:.:.	./.:50,0:50:.:.	./.:11,0:11:.:.	./.:0,0:0:.:.	./.:1,0:1:.:.	./.:0,0:0:.:.	./.:1,0:1:.:.	./.:1,0:1:.:.	./.:0,0:0:.:.	./.:0,0:0:.:.	./.:0,0:0:.:.	./.:12,0:12:.:.	./.:0,0:0:.:.	./.:0,0:0:.:.	./.:0,0:0:.:.	./.:68,9:77:8:8,0,1482	./.:0,0:0:.:.	./.:0,0:0:.:.	./.:1,0:1:.:.	./.:1,0:1:.:.	./.:62,0:62:.:.	./.:0,0:0:.:.	./.:2,0:2:.:.	./.:91,0:91:.:.	./.:1,0:1:.:.	./.:0,0:0:.:.	./.:30,0:30:.:.	./.:2,0:2:.:.	./.:0,0:0:.:.	./.:1,0:1:.:.	./.:0,0:0:.:.	./.:0,0:0:.:.	./.:0,0:0:.:.	./.:0,0:0:.:.	./.:0,0:0:.:.	./.:0,0:0:.:.	./.:1,0:1:.:.	./.:2,0:2:.:.	./.:0,0:0:.:.	./.:0,0:0:.:.	./.:0,0:0:.:.	./.:0,0:0:.:.	./.:0,0:0:.:.	./.:47,0:47:.:.	./.:0,0:0:.:.	./.:71,0:71:.:.	./.:1,0:1:.:.	./.:1,0:1:.:.	./.:0,0:0:.:.	./.:0,0:0:.:.	./.:43,0:43:.:.	./.:24,0:24:.:.	./.:43,0:43:.:.	./.:106,0:106:.:.	./.:4,0:4:.:.	./.:0,0:0:.:.	./.:0,0:0:.:.	./.:1,0:1:.:.	./.:1,0:1:.:.	./.:1,0:1:.:.	./.:0,0:0:.:.	./.:1,0:1:.:.	./.:0,0:0:.:.	./.:2,0:2:.:.	./.:3,0:3:.:.	./.:0,0:0:.:.	0/1:91,15:106:99:144,0,2116	./.:2,0:2:.:.	./.:0,0:0:.:.	./.:23,0:23:.:.	./.:1,0:1:.:.	./.:0,0:0:.:.	./.:0,0:0:.:.	./.:1,0:1:.:.	./.:0,0:0:.:.	./.:0,0:0:.:.	./.:3,0:3:.:.	./.:2,0:2:.:.	./.:23,0:23:.:.	./.:3,0:3:.:.	./.:0,0:0:.:.	./.:1,0:1:.:.	0/1:57,8:65:46:46,0,1109	./.:3,0:3:.:.	./.:0,0:0:.:.	./.:0,0:0:.:.	./.:0,0:0:.:.	./.:0,0:0:.:.	./.:1,0:1:.:.	./.:0,0:0:.:.	0/1:70,14:84:99:164,0,1699	./.:0,0:0:.:.	./.:2,0:2:.:.	./.:1,0:1:.:.	./.:0,0:0:.:.	./.:20,0:20:.:.	./.:3,0:3:.:.	./.:0,0:0:.:.	./.:1,0:1:.:.	./.:1,0:1:.:.	./.:3,0:3:.:.	./.:78,0:78:.:.	./.:2,0:2:.:.	./.:2,0:2:.:.	./.:0,0:0:.:.	./.:53,0:53:.:.	./.:1,0:1:.:.	./.:1,0:1:.:.	./.:1,0:1:.:.	./.:15,0:15:.:.	./.:41,0:41:.:.	./.:0,0:0:.:.	./.:0,0:0:.:.	0/1:75,13:88:99:128,0,1904	./.:53,0:53:.:.	./.:2,0:2:.:.	./.:0,0:0:.:.	./.:0,0:0:.:.	./.:1,0:1:.:.	./.:1,0:1:.:.	./.:0,0:0:.:.	./.:1,0:1:.:.	./.:0,0:0:.:.	./.:1,0:1:.:.	./.:0,0:0:.:.	./.:1,0:1:.:.	./.:0,0:.:.:.	./.:1,0:1:.:.	./.:0,0:0:.:.	./.:1,0:1:.:.	./.:132,0:132:.:.	./.:0,0:0:.:.	./.:32,0:32:.:.	./.:65,0:65:.:.	./.:2,0:2:.:.	./.:4,0:4:.:.	./.:1,0:1:.:.	./.:0,0:0:.:.	./.:0,0:0:.:.	./.:1,0:1:.:.	./.:2,0:2:.:.	./.:1,0:1:.:.	./.:81,0:81:.:.	./.:9,0:9:.:.	./.:3,0:3:.:.	./.:0,0:0:.:.	./.:0,0:0:.:.	./.:0,0:0:.:.	./.:30,0:30:.:.	./.:14,0:14:.:.	./.:1,0:1:.:.	0/1:56,8:64:57:57,0,1393	./.:61,0:61:.:.	./.:0,0:0:.:.	./.:16,0:16:.:.	./.:7,0:7:.:.	./.:1,0:1:.:.	./.:2,0:2:.:.	./.:0,0:0:.:.	./.:0,0:0:.:.	./.:36,0:36:.:.	./.:0,0:0:.:.	./.:2,0:2:.:.	./.:0,0:0:.:.	./.:42,0:42:.:.	./.:1,0:1:.:.	./.:1,0:1:.:.	./.:54,0:54:.:.	./.:0,0:0:.:.	./.:0,0:0:.:.	./.:77,0:77:.:.	./.:0,0:0:.:.	./.:1,0:1:.:.	./.:1,0:1:.:.	./.:2,0:2:.:.	./.:49,0:49:.:.	./.:2,0:2:.:.	./.:1,0:1:.:.	./.:0,0:0:.:.	./.:1,0:1:.:.	./.:1,0:1:.:.	./.:0,0:0:.:.	./.:66,0:66:.:.	./.:0,0:0:.:.	./.:2,0:2:.:.	./.:2,0:2:.:.	./.:75,0:75:.:.	./.:0,0:0:.:.	./.:5,0:5:.:.	./.:1,0:1:.:.	./.:1,0:1:.:.	./.:1,0:1:.:.	./.:0,0:0:.:.	./.:49,0:49:.:.	./.:0,0:0:.:.	./.:0,0:0:.:.	./.:0,0:0:.:.	./.:4,0:4:.:.	./.:1,0:1:.:.	./.:7,0:7:.:.	./.:2,0:2:.:.	./.:21,0:21:.:.	./.:1,0:1:.:.	./.:3,0:3:.:.	./.:0,0:0:.:.	./.:0,0:0:.:.	./.:0,0:0:.:.	./.:1,0:1:.:.	./.:1,0:1:.:.	./.:1,0:1:.:.	./.:2,0:2:.:.	./.:93,0:93:.:.	./.:1,0:1:.:.	./.:0,0:0:.:.	./.:1,0:1:.:.	./.:0,0:0:.:.	./.:97,0:97:.:.	./.:1,0:1:.:.	./.:1,0:1:.:.	./.:0,0:0:.:.	./.:0,0:0:.:.	./.:0,0:0:.:.	./.:45,0:45:.:.	./.:1,0:1:.:.	./.:0,0:0:.:.	./.:10,0:10:.:.	./.:0,0:0:.:.	./.:0,0:0:.:.	./.:2,0:2:.:.	./.:1,0:1:.:.	0/1:114,16:130:99:125,0,2547	./.:3,0:3:.:.	./.:3,0:3:.:.	./.:172,0:172:.:.


  mef2cPlus.gr <- GRanges('5', IRanges(88716241, 89193599))
  params <- ScanVcfParam(which=chr7.gr)
  vcf <- readVcf(TabixFile(fgz), 'hg19', params)


*----------------------------------------------------------------------------------------------------
* lasso tips, exploring basics of glmnet in context of TReNA (17 mar 2016)

  cd  ~/github/TReNA/inst/unitTests/
    test_TReNA.R has function test_fitRandomMatrix
*----------------------------------------------------------------------------------------------------
* lasso tips: the Least Absolute Shrinkage and Selection Operator


   minimizes the residual sum of squares subject to the sum of the aboslute coefficients being
   less than a constant.  this tends to produce some coefficients that are exactly zero and
   hence gives interpretable models

   The LASSO (Least Absolute Shrinkage and Selection Operator) is a regression method that involves
   penalizing the absolute size of the regression coefficients.

   By penalizing (or equivalently constraining the sum of the absolute values of the estimates) you
   end up in a situation where some of the parameter estimates may be exactly zero. The larger the
   penalty applied, the further estimates are shrunk towards zero.

   This is convenient when we want some automatic feature/variable selection, or when dealing with
   highly correlated predictors, where standard regression will usually have regression coefficients
   that are 'too large'

   A simple explanation of the Lasso and Least Angle Regression

    Give a set of input measurements x1, x2 ...xp and an outcome measurement y, the lasso fits a linear model

      yhat=b0 + b1*x1+ b2*x2 + ... bp*xp

   The criterion it uses is:

       Minimize sum( (y-yhat)^2 ) subject to sum[absolute value(bj)] <= s

       The first sum is taken over observations (cases) in the dataset. The bound "s" is a tuning
       parameter. When "s" is large enough, the constraint has no effect and the solution is just
       the usual multiple linear least squares regression of y on x1, x2, ...xp.

       However when for smaller values of s (s>=0) the solutions are shrunken versions of the least
       squares estimates. Often, some of the coefficients bj are zero. Choosing "s" is like choosing
       the number of predictors to use in a regression model, and cross-validation is a good tool
       for estimating the best value for "s".

     1) Start with all coefficients bj equal to zero.
     2) Find the predictor xj most correlated with y, and add it into the model. Take residuals r= y-yhat.
     3) Continue, at each stage adding to the model the predictor most correlated with r.
     4) Until: all predictors are in the model

    shrinkage: setting some coefficients to zero

    ridge regression penalty is the sum of beta^2.  lasso regression penalty is the sum of abs(beta)

*----------------------------------------------------------------------------------------------------
* lasso tips: cross-validation

   http://stats.stackexchange.com/questions/26528/how-to-estimate-shrinkage-parameter-in-lasso-or-ridge-regression-with-50k-varia

   The function cv.glmnet from the R package glmnet does automatic cross-validation on a grid of λλ
   values used for ℓ1ℓ1-penalized regression problems. In particular, for the lasso. The glmnet
   package also supports the more general elastic net penalty, which is a combination of ℓ1ℓ1 and
   ℓ2ℓ2 penalization. As of version 1.7.3. of the package taking the αα parameter equal to 0 gives
   ridge regression (at least, this functionality was not documented until recently).

   Cross-validation is an estimate of the expected generalization error for each λλ and λλ can
   sensibly be chosen as the minimizer of this estimate. The cv.glmnet function returns two values
   of λλ. The minimizer, lambda.min, and the always larger lambda.1se, which is a heuristic choice
   of λλ producing a less complex model, for which the performance in terms of estimated expected
   generalization error is within one standard error of the minimum. Different choices of loss
   functions for measuring the generalization error are possible in the glmnet package. The argument
   type.measure specifies the loss function.


  -- The function glmnet returns a sequence of models for the users to choose from. In many cases,
     users may prefer the software to select one of them. Cross-validation is perhaps the simplest
     and most widely used method for that task.


*----------------------------------------------------------------------------------------------------
* lasso tips: lambda (a penalty used to avoid overfitting)

   --- http://stackoverflow.com/questions/13810814/lasso-and-ridge-estimator
   Lambda is the strength of the penalty, See this to understand better the effect of
   lambda. Generally, you select this value by try-and-error or using cross validation procedure.

   Both Lasso and Ridge estimation help to reduce the model over fitting by limiting the value of
   the parameters to be estimated. The main difference between them is the shape of the penalty
   function.

   Lasso can result in a sparse model where some parameters can be exactly zero, while Ridge can
   lead to parameters with very small value but not exactly zero.

*----------------------------------------------------------------------------------------------------
* learn glmnet in preparation for TReNA refactoring (29 feb 2016)

  cd ~/s/examples/R/glmnet/
  reload()

  ---- http://stats.stackexchange.com/questions/72251/an-example-lasso-regression-using-glmnet-for-binary-outcome
    predict asthma (yes/no) from age, gender, bmi (body mass index, weight/height), m_edu, p_edu, f_color

 age (age of child in years) - continuous
 gender - binary (1 = male; 0 = female)
 bmi_p (BMI percentile) - continuous
 m_edu (mother highest education level) - ordinal (0 = less than high school; 1 = high school diploma; 2 = bachelors degree; 3 = post-baccalaureate degree)
 p_edu (father highest education level) - ordinal (same as m_edu)
 f_color (favorite primary color) - nominal ("blue", "red", or "yellow")
 asthma (child asthma status) - binary (1 = asthma; 0 = no asthma)

 age <- c(4,8,7,12,6,9,10,14,7)
 gender <- c(1,0,1,1,1,0,1,0,0)
 bmi_p <- c(0.86,0.45,0.99,0.84,0.85,0.67,0.91,0.29,0.88)
 m_edu <- c(0,1,1,2,2,3,2,0,1)
 p_edu <- c(0,2,2,2,2,3,2,0,0)
 f_color <- c("blue", "blue", "yellow", "red", "red", "yellow", "yellow", "red", "yellow")
 asthma <- c(1,1,0,1,0,0,0,1,1)
 df <- data.frame(age, gender, bmi_p, m_edu, p_edu, f_color, asthma)

f_color <- as.factor(f_color)
xfactors <- model.matrix(asthma ~ gender + m_edu + p_edu + f_color)[,-1]
x <- as.matrix(data.frame(age, bmi_p, xfactors))

#note alpha =1 for lasso only and can blend with ridge penalty down to alpha=0 ridge only
glmmod<-glmnet(x,y=as.factor(asthma),alpha=1,family='binomial')

#plot variable coefficients vs. shrinkage parameter lambda.
plot(glmmod,xvar="lambda")
grid()


  --- my own dumb data:
    height <- as.integer(runif(10) * 100)
    weight <- as.integer(runif(10) * 100)
    x <- as.matrix(data.frame(height=height, weight=weight))
    rownames(x) <- LETTERS[1:10]
    y <- (3*height) + (-2* weight)
    fit <- glmnet(x, y)
       # one curve for each variable (labled with x matrix column number)
       # values of the coefficients on the y axis
       # top x axis: number of non-zero coefficients at the current lambda (aka, the effective degrees
       #    of freedom (df) for the lasso
       # bottom x axis: the l1 norm of the whol coefficent vector as lambda varies
    plot(fit, label=TRUE)

  --- regularization: https://www.youtube.com/watch?v=sO4ZirJh9ds

*----------------------------------------------------------------------------------------------------
* get genes on chromosome 5 (26 feb 2016)

   library(TxDb.Hsapiens.UCSC.hg38.knownGene)
   txdb <- TxDb.Hsapiens.UCSC.hg38.knownGene
   genes.gr <- genes(txdb)

   txdb <- TxDb.Hsapiens.UCSC.hg38.knownGene
   genes.gr <- genes(txdb)
   genes.chr5.gr  <- genes.gr[seqnames(genes.gr) == "chr5"]
   genes.chr5.gr <- sort(genes.chr5.gr)

   head(genes.chr5.gr)
   GRanges object with 6 ranges and 1 metadata column:
               seqnames                 ranges strand |     gene_id
                  <Rle>              <IRanges>  <Rle> | <character>
     100113384     chr5 [  9548827,   9548914]      + |   100113384
     100126347     chr5 [ 15935182,  15935260]      + |   100126347
     100126299     chr5 [136080498, 136080597]      - |   100126299
     100126343     chr5 [137647572, 137647649]      - |   100126343
         10011     chr5 [140550067, 140558093]      - |       10011
         10007     chr5 [142000669, 142013055]      - |       10007
   gene.ids <- mcols(genes.chr5.gr)

   tbl.ids <- select(org.Hs.eg.db, keys=as.character(gene.ids$gene_id), keytype="ENTREZID", columns <- c("ENTREZID", "SYMBOL"))
   genes.chr5.gr$symbol <- tbl.ids$SYMBOL
   head(genes.chr5.gr)

     153478     chr5 [140258, 189972]      + |      153478    PLEKHG4B
     389257     chr5 [191511, 195353]      + |      389257     LRRC14B
       6389     chr5 [218241, 256699]      + |        6389        SDHA
      10016     chr5 [271621, 314974]      + |       10016       PDCD6
      57491     chr5 [304177, 438290]      + |       57491        AHRR
      11336     chr5 [443219, 467294]      + |       11336       EXOC3

   which(genes.chr5.gr$symbol == "MEF2C")  # [1] 792
   genes.chr5.gr[782:802]$symbol
    [1] "TMEM167A"     "SCARNA18"     "HAPLN1"       "EDIL3"        "MIR4280"
    [6] "CCNH"         "TMEM161B"     "LOC102546226" "LINC00461"    "MIR9-2"
   [11] "MEF2C"        "MIR3660"      "CETN3"        "MBLAC2"       "LYSMD3"
   [16] "LUCAT1"       "ARRDC3"       "NR2F1-AS1"    "FAM172A"      "MIR2277"   [21] "POU5F2"



*----------------------------------------------------------------------------------------------------
* old cellphone java webstart app

  http://baliga.systemsbiology.net/drupal/education/?q=content/cell-phone-simulation
  http://baliga.systemsbiology.net/cytoscape/cellphone/cy.jnlp

   need to open up both macos and java security seetings, from System Preferences
   ~/github/cellphone/explorations/webStartScreenshots/

      mainWindow.png
      knockoutByCarrier.png
      knockoutByProperty.png


*------------------------------------------------------------------------------------------------------------------------
* cellphone webapp (26 feb 2016)

  --- reproduced graph with layout using rcyjs
     ~/github/cellphone/explorations/go.R
     reload()

*----------------------------------------------------------------------------------------------------
* put BrowserViz.js up on github cdn (26 feb 2016)

   https://github.com/paul-shannon/CDN/tree/master/js/BrowserViz.js

  production (release):  <script src="https://cdn.rawgit.com/paul-shannon/CDN/master/js/BrowserViz.js"></script>
  devel:                 <script src="https://rawgit.com/paul-shannon/CDN/master/js/BrowserViz.js"></script>


  --- maybe use this?     <script src="//d3js.org/d3.v3.min.js" charset="utf-8"></script>
   to improve upon from BrowserVizDemo 1.3.4, 4 mar 2016
      <head>
         <title>BrowserVizDemo</title>
         <script src="https://ajax.googleapis.com/ajax/libs/jquery/2.2.0/jquery.min.js"></script>
         <script src="https://cdn.rawgit.com/paul-shannon/CDN/master/js/BrowserViz.js"></script>
         <script src="http://s3.amazonaws.com/oncoscape/js/d3.min.js"></script>
      <style>




*----------------------------------------------------------------------------------------------------
* dani bergey, learning R (25 feb 2016)

  cd ~/s/study/R/lm/basic

*----------------------------------------------------------------------------------------------------
* tiny trena example (29 feb 2016)

   print(load("~/github/TReNA/inst/exploratory/earlyDemoFromCory/small.test.expr.matrix.RData))
   print(load("~/github/TReNA/inst/exploratory/earlyDemoFromCory/mtx.demoExpr.RData") # mtx.demoExpr
   dim(mtx.demoExpr) # 21 x 278
   rownames(mtx.demoExpr)

   "TMEM167A"  "HAPLN1"    "EDIL3"     "CCNH"      "TMEM161B"  "LINC00461"
   "MEF2C"     "CETN3"     "MBLAC2"    "LYSMD3"    "ARRDC3"    "NR2F1-AS1"
   "FAM172A"   "POU5F2"    "STAT4"     "SATB2"     "HLF"       "FOXP2"
   "TSHZ2"     "CUX2"      "LHX6"

   head(colnames(mtx.demoExpr))
     # "11344_TCX" "11316_TCX" "11431_TCX" "11341_TCX" "11289_TCX" "11327_TCX"

   mtx.sum <- (t(apply(mtx.demoExpr, 1, fivenum)))

   mtx.sum[order(mtx.sum[, 5], decreasing=TRUE),]
                  [,1]       [,2]        [,3]       [,4]        [,5]
   EDIL3     31.805829 205.164152 271.5549220 374.181001 1090.786483
   MEF2C     11.068868 137.900343 221.4282635 317.784575  617.815626
   ARRDC3     9.078110  28.910941  36.4809300  48.639690  275.154387
   HLF       11.604189  87.474681 124.1363925 160.107768  261.643235
   TMEM167A  42.578641  89.023152 101.0967715 111.995143  152.310389
   SATB2      2.032497  35.492431  50.3712655  64.991759  100.037901
   CUX2       0.374329  15.081279  24.1819320  35.183606   83.971717
   LINC00461 11.612576  27.902572  34.4578455  41.617880   73.908590
   NR2F1-AS1  9.362836  32.718272  38.4921415  43.301342   55.620154
   FAM172A   20.976925  33.565068  37.6147780  41.895210   54.877703
   STAT4      0.274662   7.844307  15.2063285  22.416041   51.532884
   CCNH      10.351259  20.709194  25.9768475  30.563016   50.054168
   TSHZ2      2.114895   8.436852  13.0707760  18.757757   42.208044
   MBLAC2     6.532963  15.181665  18.7990070  22.540741   37.544812
   LYSMD3     7.592341  15.499346  18.2974720  20.421048   30.388006
   CETN3      6.088976  11.507644  13.4148000  15.380844   25.465864
   LHX6       0.933850   6.592531   9.8080785  13.117460   25.401198
   FOXP2      1.318376   6.731203   9.8737020  13.671961   25.319951
   TMEM161B   2.148390  11.251962  13.3338875  16.179036   22.869447
   HAPLN1     0.054932   1.291205   2.4538250   3.640642   10.126581
   POU5F2     0.022037   0.354361   0.4960795   0.655726    1.157929



*----------------------------------------------------------------------------------------------------
* cory's initial trena demo (26 feb 2016)

   cd ~/github/TReNA/inst/exploratory/earlyDemoFromCory

   https://drive.google.com/a/systemsbiology.org/file/d/0ByzX_6fy4I8cejhVX0NVRnF4NjA/view?usp=drive_web

   tbl <- read.table("AMP-AD_MayoBB_UFL-Mayo-ISB_IlluminaHiSeq2000_TCX_GeneCounts_Normalized_JulyRerun.txt", sep="\t", header=TRUE)
   mtx <- as.matrix(tbl)
   dim(mtx)  # 64253   278
   as.integer(fivenum(mtx))  # [1]      0      0      0      1 644605

   mtx[1:10, 1:5]
                     X11344_TCX X11316_TCX X11431_TCX X11341_TCX X11289_TCX
     ENSG00000000003  10.690786  15.237268  13.177868  11.059819  10.416230
     ENSG00000000005   0.124892   0.061194   0.101057   0.137176   0.093002
     ENSG00000000419  23.005173  17.562634  17.058468  18.947442  16.833371
     ENSG00000000457  10.865635   7.251471   8.832406  10.425380   7.068156
     ENSG00000000460   6.869080   6.486548   5.517727   6.704480   5.642124
     ENSG00000000938   6.968994  10.311163   5.032652   5.349866   3.937087
     ENSG00000000971  26.876836  47.670006  24.839878  23.199900   8.184180
     ENSG00000001036  18.783811  17.899200  17.462697  17.009830  14.632323
     ENSG00000001084  52.754533  49.597612  39.028319  59.791612  50.686118
     ENSG00000001167  28.125760  29.801403  27.447155  29.818644  15.624344


   --- all files mentioned in "all_trns3.R"
     AMP-AD_MayoBB_UFL-Mayo-ISB_IlluminaHiSeq2000_TCX_GeneCounts_Normalized_JulyRerun.txt
     /mnt/mcTRN.r
     /mnt/AMP-AD_MayoBB_UFL-Mayo-ISB_IlluminaHiSeq2000_TCX_Covariates_Flowcell_1.csv
     /mnt/AMP-AD_MayoBB_UFL-Mayo-ISB_IlluminaHiSeq2000_TCX_GeneCounts_Normalized_JulyRerun.txt
     /mnt/AMP-AD_ROSMAP_Rush-Broad_Clinical.csv
     /mnt/AMP-AD_ROSMAP_Rush-Broad_IDKey.csv
     /mnt/AMP_AD_ROSMAP_Broad-Rush_IlluminaHiSeq_RSEM_gene_FPKM_normalized_plate1-6.tsv
     /mnt/AMP_AD_ROSMAP_Broad-Rush_IlluminaHiSeq_RSEM_gene_FPKM_normalized_plate7-8.tsv

topTFs(xx, "MEF2C")
Top Regulators for MEF2C
Showing top 7 of 7 regulators.
    Symbol 	 TRN Coefficient
    STAT4 	 0.24
    SATB2 	 0.17
    HLF 	 0.1
    FOXP2 	 0.08
    TSHZ2 	 0.08
    CUX2 	 0.07
    LHX6 	 0.06


file <-"AMP-AD_MayoBB_UFL-Mayo-ISB_IlluminaHiSeq2000_TCX_Covariates_Flowcell.csv"
covar_hum  <- read.delim(file, header = TRUE, sep = ",")

#located on one of our servers (buffy). This won't work by just importing the file from Synapes as there is an empty value for what is the equivalent of cell 1,1 where the word "row.names" needs to be added.
expr_hum = as.matrix(read.table("AMP-AD_MayoBB_UFL-Mayo-ISB_IlluminaHiSeq2000_TCX_GeneCounts_Normalized_JulyRerun.txt" , header = T, sep = "", check.names = F, strip.white=TRUE))

#optional-- create a trn using just the control data or just the AD data
# control_sub  <- subset(covar_hum, Diagnosis == "Control")
# cont_data <- expr_hum[match(control_sub$ID, colnames(expr_hum))]
#
# AD_sub <- subset(covar_hum, Diagnosis == "AD")
# AD_data <- expr_hum[match(AD_sub$ID, colnames(expr_hum))]


#get rid of genes that aren't appreciably expressed
RowM <- apply(expr_hum[,1:ncol(expr_hum)],1,median)
less0.1 <- which(RowM < 0.4)
expr1 = (expr_hum[-less0.1,])

#get a list of all the gene names in your file
gene_names <- rownames(expr1)

#get a list of all ensembl ids and gene names
mart=useMart("ENSEMBL_MART_ENSEMBL", dataset="hsapiens_gene_ensembl",host="www.ensembl.org")
results=getBM(attributes=c("ensembl_gene_id","hgnc_symbol"),mart=mart)
gene_map <- results[match(gene_names,results$ensembl_gene_id),c("ensembl_gene_id","hgnc_symbol")]

#convert data to a matrix (devoid of anything with strings)
expr2 = as.matrix(expr1)
rownames(expr2) = gene_map$hgnc_symbol

topTFs(xx, "MEF2C")

Top Regulators for MEF2C
Showing top 7 of 7 regulators.
    Symbol 	 TRN Coefficient
    STAT4 	 0.24
    SATB2 	 0.17
    HLF 	 0.1
    FOXP2 	 0.08
    TSHZ2 	 0.08
    CUX2 	 0.07
    LHX6 	 0.06

  tfs <- c("STAT4", "SATB2", "HLF", "FOXP2", "TSHZ2", "CUX2", "LHX6")
  mef2c.and.neighbors <-   c("TMEM167A", "SCARNA18", "HAPLN1", "EDIL3", "MIR4280",
                             "CCNH", "TMEM161B", "LOC102546226", "LINC00461", "MIR9-2",
                             "MEF2C", "MIR3660", "CETN3", "MBLAC2", "LYSMD3",
                             "LUCAT1", "ARRDC3", "NR2F1-AS1", "FAM172A", "MIR2277",
                             "POU5F2")
  mef2c.and.neighbors <- intersect(mef2c.and.neighbors, rownames(expr2))
 [1] "TMEM167A"  "HAPLN1"    "EDIL3"     "CCNH"      "TMEM161B"  "LINC00461"
 [7] "MEF2C"     "CETN3"     "MBLAC2"    "LYSMD3"    "ARRDC3"    "NR2F1-AS1"
[13] "FAM172A"   "POU5F2"
intersect(c(mef2c.and.neighbors, tfs), rownames(expr2))
 [1] "TMEM167A"  "HAPLN1"    "EDIL3"     "CCNH"      "TMEM161B"  "LINC00461"
 [7] "MEF2C"     "CETN3"     "MBLAC2"    "LYSMD3"    "ARRDC3"    "NR2F1-AS1"
[13] "FAM172A"   "POU5F2"    "STAT4"     "SATB2"     "HLF"       "FOXP2"
[19] "TSHZ2"     "CUX2"      "LHX6"

   create an expr2
my.expr <- expr2[intersect(c(mef2c.and.neighbors, tfs), rownames(expr2)), ]
> dim(my.expr)
[1]  21 278
> save(my.expr, file="small.test.expr.matrix.RData")


*----------------------------------------------------------------------------------------------------
* vcf wgs ad, a quick look (25 feb 2016)

  whovian: /local/bdds/data/ADNI/

  gzip -cd /local/bdds/data/ADNI/ADNI.808_indiv.minGQ_21.pass.ADNI_ID.chr1.vcf.gz | head -135 | tail -1
   1       10172   .       CCCTAA  C       102188  PASS    .       GT:AD:DP:GQ:PL
0/0:63,0:63:42:0,42,630
0/0:39,0:39:21:0,21,315
./.:42,0:42:20:0,20,540
1/1:4,12:16:30:522,30,0
0/0:59,0:59:33:0,33,495
0/0:63,0:63:60:0,60,900
0/0:34,0:34:30:0,30,450
0/0:51,0:51:51:0,51,765
0/0:91,0:91:81:0,81,1215
./.:55,0:55:0:0,0,1405
0/0:69,0:69:63:0,63,945
./.:52,0:52:0:0,0,1388
0/0:64,0:64:24:0,24,360
0/0:43,0:43:42:0,42,630
0/0:65,0:65:30:0,30,720
0/0:49,0:49:24:0,24,360
0/0:34,0:34:33:0,33,495
0/0:54,0:54:24:0,24,360
0/0:41,0:41:21:0,21,405
0/0:44,0:44:30:0,30,450
0/1:10,13:23:58:472,0,58
0/0:46,0:46:21:0,21,315
0/0:52,0:52:72:0,72,1080
0/0:50,0:50:30:0,30,450
0/0:53,0:53:31:0,31,585
0/0:71,0:71:66:0,66,990
0/0:65,0:65:30:0,30,450
0/0:56,0:56:24:0,24,360
0/0:78,0:78:60:0,60,900
0/0:65,0:65:22:0,22,450
0/0:58,0:58:60:0,60,900
0/0:55,0:55:27:0,27,405
0/0:50,0:50:63:0,63,990
0/0:60,0:60:46:0,46,810
0/0:42,0:42:24:0,24,360
0/0:65,0:65:66:0,66,990
0/0:65,0:65:52:0,52,1914
./.:32,0:32:0:0,0,786
0/0:101,0:101:75:0,75,1125
0/0:80,0:80:24:0,24,360
0/0:48,0:48:21:0,21,450
0/0:69,0:69:74:0,74,1350
0/0:60,0:60:48:0,48,720
0/0:68,0:68:78:0,78,1170
0/0:35,0:35:27:0,27,405
./.:33,0:33:15:0,15,225
1/1:3,12:15:49:530,49,0
0/0:43,0:43:30:0,30,450
1/1:3,11:14:99:672,108,0
0/0:43,0:43:31:0,31,675
0/0:61,0:61:24:0,24,585
0/0:59,0:59:37:0,37,810
0/0:55,0:55:21:0,21,315
0/0:52,0:52:75:0,75,1125
0/0:46,0:46:21:0,21,315
0/0:42,0:42:33:0,33,495
0/0:45,0:45:24:0,24,360
0/0:45,0:45:21:0,21,720
0/0:51,0:51:30:0,30,450
0/0:54,0:54:51:0,51,765
0/0:47,0:47:24:0,24,450
0/0:43,0:43:27:0,27,405
0/0:41,0:41:27:0,27,405
0/0:49,0:49:41:0,41,810
0/0:41,0:41:21:0,21,315
0/0:50,0:50:33:0,33,630
0/0:52,0:52:30:0,30,450
1/1:4,11:15:75:623,75,0
0/0:81,0:81:69:0,69,1035
0/0:83,0:83:24:0,24,810
0/0:101,0:101:81:0,81,1215
0/0:66,0:66:27:0,27,405
0/0:92,0:92:66:0,66,990
0/0:64,0:64:72:0,72,1080
0/0:75,0:75:51:0,51,765
0/0:46,0:46:39:0,39,585
0/0:69,0:69:29:0,29,585
1/1:6,11:17:22:499,22,0
./.:48,0:48:20:0,20,675
0/0:56,0:56:27:0,27,405
0/0:57,0:57:30:0,30,1517
0/0:45,0:45:25:0,25,405
0/0:52,0:52:60:0,60,900
./.:9,22:31:2:766,2,0
0/0:46,0:46:42:0,42,630
0/0:57,0:57:21:0,21,315
0/1:8,11:19:31:545,0,31
0/0:74,0:74:27:0,27,405
0/0:88,0:88:75:0,75,1125
0/0:73,0:73:28:0,28,855
./.:33,0:33:0:0,0,868
0/0:43,0:43:36:0,36,540
0/0:42,0:42:28:0,28,630
0/0:57,0:57:69:0,69,1035
0/0:46,0:46:21:0,21,315
1/1:5,16:21:99:858,152,0
0/0:89,0:89:63:0,63,945
1/1:3,17:20:26:497,26,0
0/0:48,0:48:24:0,24,450
1/1:7,12:19:77:700,77,0
0/0:52,0:52:36:0,36,540
0/0:54,0:54:27:0,27,585
0/0:67,0:67:45:0,45,675
0/0:54,0:54:33:0,33,495
0/1:13,16:29:99:560,0,190
0/0:48,0:48:69:0,69,1035
0/0:67,0:67:60:0,60,900
0/0:54,0:54:27:0,27,405
0/0:57,0:57:60:0,60,900
0/0:36,0:36:21:0,21,315
0/0:48,0:48:21:0,21,495
0/0:57,0:57:36:0,36,540
0/0:47,0:47:21:0,21,315
./.:78,0:78:.:.
0/0:60,0:60:51:0,51,765
0/0:61,0:61:30:0,30,450
0/0:90,0:90:71:0,71,1215
0/0:59,0:59:21:0,21,315
0/0:66,0:66:42:0,42,630
0/0:72,0:72:27:0,27,405
0/0:97,0:97:78:0,78,1170
0/0:47,0:47:29:0,29,540
0/0:48,0:48:60:0,60,900
0/0:51,0:51:24:0,24,450
0/0:75,0:75:72:0,72,1080
0/0:67,0:67:60:0,60,900
0/0:32,0:32:21:0,21,315
0/0:51,0:51:63:0,63,945
0/0:50,0:50:23:0,23,855
0/1:12,7:19:99:266,0,255
0/0:67,0:67:24:0,24,360
0/0:36,0:36:24:0,24,540
0/0:46,0:46:33:0,33,495
0/0:51,0:51:44:0,44,720
./.:0,0:.:.:.
0/0:55,0:55:60:0,60,900
1/1:7,23:30:87:961,87,0
./.:5,12:17:12:576,0,12
0/0:52,0:52:27:0,27,405
./.:41,0:41:17:0,17,1165
0/0:69,0:69:31:0,31,540
0/0:19,0:19:21:0,21,315
./.:73,0:73:0:0,0,1943
0/0:95,0:95:84:0,84,1260
0/0:82,0:82:69:0,69,1035
0/0:24,0:24:21:0,21,315
./.:54,0:54:15:0,15,225
0/0:74,0:74:25:0,25,540
0/0:52,0:52:25:0,25,540
1/1:6,28:34:99:1202,171,0
0/0:97,0:97:60:0,60,900
0/0:75,0:75:75:0,75,1125
0/0:76,0:76:63:0,63,945
0/0:40,0:40:24:0,24,360
0/0:70,0:70:67:0,67,1910
0/0:69,0:69:60:0,60,900
0/0:56,0:56:21:0,21,315
0/0:92,0:92:75:0,75,1350
0/0:60,0:60:26:0,26,855
0/0:49,0:49:27:0,27,405
0/0:80,0:80:30:0,30,450
0/0:58,0:58:63:0,63,945
./.:6,19:25:14:748,14,0
0/0:64,0:64:22:0,22,4
*------------------------------------------------------------------------------------------------------------------------
* filter AD gwas snps for footprint proximity (25 feb 2016)  all chroms

   cd ~/s/data/priceLab/AD/

   library(GeneRegulationUtilities)
   library(TxDb.Hsapiens.UCSC.hg19.knownGene)
   if(!exists("tbl.fpAnnotated")) data(tbl.fpAnnotated)
   if(!exists("tbl.motifToMultipleGenes")) data(tbl.motifToMultipleGenes)
   if(!exists("tbl.gwas")) print(load("tbl.gwas.level_1.RData"))  # tbl.gwas, already filtered for pval <- 0.05
   all.chromosomes <- paste("chr", c(1:22, "X", "Y"), sep="")
   chrom.lengths <- as.list(seqlengths(seqinfo(TxDb.Hsapiens.UCSC.hg19.knownGene))[all.chromosomes])
   for(chrom in rev(all.chromosomes)){
      snps <- subset(tbl.gwas, CHR==chrom)$BP
      if(length(snps) == 0)
          next
      chrom.start <- 1
      chrom.end <- chrom.lengths[[chrom]]
      printf("%s: checking for %d snps between %d and %d", chrom, length(snps), chrom.start, chrom.end)
      tbl.oneChromSnpInFp <-findSNPsInFootprints(tbl.fpAnnotated, tbl.motifToMultipleGenes,
                                                 chrom, chrom.start, chrom.end,
                                                 chrom, snps,
                                                 transcriptionFactors=NA,
                                                 padding=10)
      save(tbl.oneChromSnpInFp, file=sprintf("tbl.snpInFp-%s.RData", chrom))
      }

    serialized.files <- c("tbl.snpInFp-chr1.RData",
                          "tbl.snpInFp-chr2.RData",
                          "tbl.snpInFp-chr3.RData",
                          "tbl.snpInFp-chr4.RData",
                          "tbl.snpInFp-chr5.RData",
                          "tbl.snpInFp-chr6.RData",
                          "tbl.snpInFp-chr7.RData",
                          "tbl.snpInFp-chr8.RData",
                          "tbl.snpInFp-chr9.RData",
                          "tbl.snpInFp-chr10.RData",
                          "tbl.snpInFp-chr11.RData",
                          "tbl.snpInFp-chr12.RData",
                          "tbl.snpInFp-chr13.RData",
                          "tbl.snpInFp-chr14.RData",
                          "tbl.snpInFp-chr15.RData",
                          "tbl.snpInFp-chr16.RData",
                          "tbl.snpInFp-chr17.RData",
                          "tbl.snpInFp-chr18.RData",
                          "tbl.snpInFp-chr19.RData",
                          "tbl.snpInFp-chr20.RData",
                          "tbl.snpInFp-chr21.RData",
                          "tbl.snpInFp-chr22.RData")
   tbl.gwasADsnpsInFp <- data.frame()
   for(file in serialized.files){
      load(file)
      tbl.gwasADsnpsInFp <- rbind(tbl.gwasADsnpsInFp, tbl.oneChromSnpInFp)
      }
   dim(tbl.gwasADsnpsInFp)  # [1] 28404     9
   save(tbl.gwasADsnpsInFp, file="tbl.gwasADsnpsInFp.05pval.igap2013.RData")  # [1] 28404     9
   save

*----------------------------------------------------------------------------------------------------
* filter AD gwas snps for footprint proximity (24 feb 2016)  chr1 only

  cd ~/s/data/priceLab/AD/
  print(load("tbl.gwas.level_1.RData"))
  chr1.snps <- subset(tbl.gwas, CHR=="chr1")$BP
  tbl.snpfp.chr1 <-findSNPsInFootprints(tbl.fpAnnotated, tbl.motifToMultipleGenes, "chr1", 1, 247249000, "chr1",

  system.time(tbl.snpfp.chr1.a <-findSNPsInFootprints(tbl.fpAnnotated, tbl.motifToMultipleGenes, "chr1", 1, 50000000, "chr1", snp.loc=chr1.snps))
  system.time(tbl.snpfp.chr1.b <-findSNPsInFootprints(tbl.fpAnnotated, tbl.motifToMultipleGenes, "chr1", 50000001, 100000000, "chr1", snp.loc=chr1.snps))
  system.time(tbl.snpfp.chr1.c <-findSNPsInFootprints(tbl.fpAnnotated, tbl.motifToMultipleGenes, "chr1", 100000001, 150000000, "chr1", snp.loc=chr1.snps))
  system.time(tbl.snpfp.chr1.d <-findSNPsInFootprints(tbl.fpAnnotated, tbl.motifToMultipleGenes, "chr1", 150000000, 250000000, "chr1", snp.loc=chr1.snps))

  tbl.gwas.snp.fp.chr1 <- rbind(tbl.snpfp.chr1.a,tbl.snpfp.chr1.b,tbl.snpfp.chr1.c,tbl.snpfp.chr1.d)

  save(tbl.gwas.snp.fp.chr1, file="tbl.gwas.snp.fp.chr1.RData")

   print(load("tbl.gwas.level_1.RData"))
   displayGWASTable(igv, tbl.gwas, "gwas level 1")
   displayBedTable(igv, tbl.gwas.snp.fp.chr1[, c("chr", "mfpStart", "mfpEnd", "name")], "gwas snp in fp")

*----------------------------------------------------------------------------------------------------
* AD gwas data, from nature meta-analysis paper (23 feb 2016): get more (many?) tracks

  [see below for paper title, pmid, abstract]

  cd ~/s/data/priceLab/AD/

  --- first try level 1
    unzip -p snp.zip SNP_from_Nilufer/IGAP_summary_statistics/IGAP_stage_1.txt.lifted > IGAP_stage_1.txt.lifted
       7M lines
    tbl.full <- read.table("IGAP_stage_1.txt.lifted", header=TRUE, sep="\t", as.is=TRUE)
    dim(tbl.full)  #  7 055 881       9
    tbl <- subset(tbl.full, Pvalue <= 0.05)  # 438696      9
    deleters <- grep("liftover_failed", tbl$position38)   # 87
    if (length(deleters) > 0) tbl <- tbl[-deleters,]
    zeroPval <- which(tbl$Pvalue < 1.0e-150)
    if(length(zeroPval) > 0)
        tbl$Pvalue[zeroPval] <- 1.0e-150

    dim(tbl)  # [1] 438609      9
    tbl$position38 <- as.integer(tbl$position38)
    tbl <- tbl[order(tbl$Chromosome, tbl$position38, decreasing=FALSE),]
    head(tbl)
      Chromosome Position position38 MarkerName Effect_allele Non_Effect_allele    Beta     SE  Pvalue
               1   978193    1042813  rs2710873             A                 G -0.0824 0.0389 0.03412
               1   998395    1063015  rs7526076             A                 G -0.0512 0.0229 0.02543
               1  1000156    1064776 rs11584349             C                 T -0.0536 0.0224 0.01687
               1  1001177    1065797  rs4970401             G                 C -0.0530 0.0224 0.01812
               1  1002387    1067007 rs74048003             G                 A  0.0609 0.0285 0.03236
               1  1002932    1067552  rs4246502             C                 G -0.0505 0.0223 0.02352
    tbl$Chromosome <- paste("chr", tbl$Chromosome, sep="")

       # use the official igv/gwas column names
    colnames(tbl) <- c("CHR", "oldPos", "BP", "SNP", "Effect_allele", "Non_Effect_allele", "Beta", "SE", "P")
    tbl.gwas <- tbl
    save(tbl.gwas, file="tbl.gwas.level_1.RData")
    displayGWASTable(igv, tbl.gwas, "gwas level 1")

    ---- add these checks to displayGWASTable

    --- display the footprints for all chromosomes
      displayBedTable(igv, tbl.fpAnnotated[, c(1, 16, 17)], "cory footprints")

*----------------------------------------------------------------------------------------------------
* AD gwas data, from nature meta-analysis paper (23 feb 2016): get just state_1_2_combined

  Meta-analysis of 74,046 individuals identifies 11 new susceptibility loci for Alzheimer's disease
  pmid: 24162737

  --- abstract

    Eleven susceptibility loci for late-onset Alzheimer's disease (LOAD) were identified by previous
    studies; however, a large portion of the genetic risk for this disease remains unexplained. We
    conducted a large, two-stage meta-analysis of genome-wide association studies (GWAS) in
    individuals of European ancestry. In stage 1, we used genotyped and imputed data (7,055,881
    SNPs) to perform meta-analysis on 4 previously published GWAS data sets consisting of 17,008
    Alzheimer's disease cases and 37,154 controls. In stage 2, 11,632 SNPs were genotyped and tested
    for association in an independent set of 8,572 Alzheimer's disease cases and 11,312 controls. In
    addition to the APOE locus (encoding apolipoprotein E), 19 loci reached genome-wide significance
    (P < 5 × 10(-8)) in the combined stage 1 and stage 2 analysis, of which 11 are newly associated
    with Alzheimer's disease.

  --- from hondong local/hongdong/snp.zip

   Currently I am using the IGAP_stage_1_2_combined.txt.lifted.sorted
   in the “IGAP_summary_statistics” subfolder. The position38 column
   is what I added (lifted from the original GRCh37 to 38).

  --- extract just that one file
    cd /Users/paul/s/data/priceLab/AD

    unzip -p snp.zip SNP_from_Nilufer/IGAP_summary_statistics/IGAP_stage_1_2_combined.txt.lifted.sorted  > IGAP_stage_1_2_combined.txt.lifted.sorted

  --- take a look in R
    tbl <- read.table("IGAP_stage_1_2_combined.txt.lifted.sorted", sep="\t", as.is=TRUE, header=TRUE)
    tbl <- tbl[order(tbl$Chromosome, tbl$position38, decreasing=FALSE),]
    dim(tbl)  # 11632 9
    tbl$Chromosome <- paste("chr", tbl$Chromosome, sep="")

       # use the official igv/gwas column names
    colnames(tbl) <- c("CHR", "oldPos", "BP", "SNP", "Effect_allele", "Non_Effect_allele", "Beta", "SE", "P")
    tbl$score <- -log10(tbl$P)
    head(tbl[order(tbl$Pvalue),])
      Chromosome  Position position38 MarkerName Effect_allele Non_Effect_allele    Beta     SE    Pvalue
    1       chr2 127892810  127135234  rs6733839             T                 C  0.1965 0.0141 6.941e-44
    2       chr2 127894484  127136908   rs730482             T                 A  0.1583 0.0144 5.430e-28
    3       chr2 127894615  127137039   rs744373             G                 A  0.1548 0.0143 3.091e-27
    4       chr2 127889637  127132061  rs7561528             A                 G  0.1466 0.0136 3.777e-27
    5      chr11  85867875   86156833 rs10792832             A                 G -0.1400 0.0133 9.320e-26
    6       chr2 127847930  127090354 rs35114168             A                 G  0.1416 0.0135 1.053e-25
  write.table(tbl, file="test.gwas", row.names=FALSE, col.names=TRUE, quote=FALSE, sep="\t")

   --- load track into igv
    library(igvR)
    igv <- igvR()
    connected(igv)
    file.exists("/Users/paul/s/data/priceLab/AD/test.gwas")
    loadFile(igv, "/Users/paul/s/data/priceLab/AD/test.gwas")   # works!

   --- try a gwas file: http://www.broadinstitute.org/software/igv/GWAS
      File extensions for GWAS files are: .linear, .logistic, .assoc, .qassoc, .gwas
      GWAS file must contain four columns (case-insensitive):

      CHR: chromosome (aliases chr, chromosome)
      BP: nucleotide location (aliases bp, pos, position)
      SNP: SNP identifier (aliases snp, rs, rsid, rsnum, id, marker, markername)
      P: p-value for the association (aliases p, pval, p-value, pvalue, p.value)

      Columns can be in any order.  Other columns besides the required ones are allowed.  The file
      must be sorted by start position in ascending order.  The p-value will be transformed to
      -log10 scale for plotting.


   --- now add our snps-in-footprint track
     library(GeneRegulationUtilities)
     chrom <- "chr5"
     min.loc <- 88000000
     max.loc <- 90000000
     data(tbl.fpAnnotated)
     data(tbl.motifToMultipleGenes)
     file <- "~/s/work/priceLab/cory/footprintFinderExperiments/mef2c-related-snps-from-mariette.tsv"
     candidate.snps <- read.table(file, header=TRUE, as.is=TRUE, sep="\t")$BP

     tbl.snpsFP <- findSNPsInFootprints(tbl.fpAnnotated, tbl.motifToMultipleGenes, chrom, min.loc, max.loc,
                                        chrom, candidate.snps, transcriptionFactors=NA, padding=10)

     displayBedTable(igv, tbl.snpsFP[, c("chr", "mfpStart", "mfpEnd")], "footprints")
*----------------------------------------------------------------------------------------------------
* 124 abca7 GRCh38 SNPs inferred from 1000 genomes (23 feb 2016)

  put these into the GeneRegulationUtilities package for now

   GeneRegulationUtilities/inst/extdata/dir inst/extdata/abca7-associated-snps-1kg.tsv

*----------------------------------------------------------------------------------------------------
* hector corrado bravo demos with cory's trena mef2c footprints (19 feb 2016, 23 feb 2016)

~/s/work/cory/snpfp/mef2c/forHector/
library(epivizr)

load("footprints.chr5.granges.RData")
load("snpsDelta.granges.RData")

mgr <- epivizr::startEpiviz(chr="chr5", start=88e6, end=89e6)

mgr$addDevice(footprints, "Footprints")
mgr$addDevice(snps, "SNPS")
mgr$stopServer()


*----------------------------------------------------------------------------------------------------
* the hunt for a sequence viewer controlled from R (18 feb 2016)

  installed igv 2.3.68
  sean davi's SRAdb package
  by default, uses port 60151
  loosely following the vignette.  this works!
     library(SRAdb)
     sock <- IGVsocket(host = "localhost", port = 60151) #          Socket connection # 4 to on port 60151
     dataDir <- system.file(package="SRAdb", "extdata")
     bamFiles <- grep(".bam$", dir(system.file(package="SRAdb", "extdata")), v=TRUE)
     bamFilesFullPaths <- file.path(dataDir, bamFiles)
     IGVgenome(sock, "hg18")
     IGVload(sock, bamFilesFullPaths)
     IGVgoto(sock, "chr1:1-1000")

   - http://www.broadinstitute.org/igv/PortCommands

   - reproduce example sent to hector corrado bravo

      write.table(tbl.fp, file="fp.bed", row.names=FALSE, colnames=FALSE, quote=FALSE, sep="\t")
      IGVgoto(sock, "chr5:88642485-89001910")

*----------------------------------------------------------------------------------------------------
* install grunt (18 feb 2016)

   sudo npm install -g grunt-cli
    dir /usr/local/bin/grunt
       lrwxr-xr-x  1 root  admin  39 Feb 18 10:02 /usr/local/bin/grunt -> ../lib/node_modules/grunt-cli/bin/grunt

*----------------------------------------------------------------------------------------------------
* SRAdb for socket access to desktop igv (18 feb 2016)
*----------------------------------------------------------------------------------------------------
* igv-js "unsupported compression method" bug (18 feb 2016)

  tried (and failed) to submit this as github issue: https://github.com/igvteam/igv.js/issues/new

title: trying to host .bw files locally for local igv.js: "unsupported compression method"

In my first efforts to learn igv.js, and use it with some locally held data, I took these steps and encountered the problem shown below:

 - cloned the repo
 - started a simple python 3.5 webserver in the antisense directory: python -m http.server 8004
 - saw that it ran without trouble
 - switched the first track to a local url:

    url: "http://localhost:8004/dUTP.76.pairs.F.bw",
     name: "dUTP F",
     format: "bigwig",
     color: "rgb(56,117,215)",
     min: 0,
     max: 1.0e-6

From the webserver log I see that the file is, in some sense, returned appropriately by the webserver.  The status code is 200.  When I enter the above url directly into the browser address bar, I can download it via the server.

igv.js reports trouble, however.  From the js console:

19igv-beta.js:25090 Uncaught Error: unsupported compression method
@ igv-beta.js:25090(anonymous function)
@ igv-beta.js:3612subbuffer
@ igv-beta.js:2970igvxhr.loadArrayBuffer.success
@ igv-beta.js:2955xhr.onload
@ igv-beta.js:16845

Maybe the Broad webserver provides some special handling, of a sort igv.js needs, but which a minimal python web server does not, when serving up .bw files?

Any advice?   Thanks - and thanks for this very promising software!

- Paul



*------------------------------------------------------------------------------------------------------------------------
* running my own igv-web demo (29 mar 2016)

  cd ~/s/examples/igv/igv-web/antisense
  python -m http.server 8008
  http://localhost:8008/antisense.html

*------------------------------------------------------------------------------------------------------------------------
* igv-web (18 feb 2016)

  cd ~/github
  git clone https://github.com/igvteam/igv.js.git
  cd igv.js
     # with grunt installed (see above):
  npm install   # installed 204 node modules
  grunt

   --- sheila says (email 27 jan 2016)

      Phyliss (cc'd) has done some integration with IGV and can respond with
      more technical details.  As I mentioned last week, Jim Robinson has done
      some work to make it so that IGV can query data from our BigQuery tables
      as well as showing sequence data from either a bam file in Cloud Storage
      or the same type of information that has been uploaded into Google
      Genomics.

  --- use their minimal example, ~/github/igv.js/demo/antisense.html, to create my own version

*----------------------------------------------------------------------------------------------------
* update bioc-data

  DREAM4
  ConnectivityMap

  cd ~/s/bioc-data
  svn co --depth empty  --username p.shannon --password zaTd3euK https://hedgehog.fhcrc.org/bioc-data/trunk
*----------------------------------------------------------------------------------------------------
* update all my bioc maintainer addresses (18 feb 2016)


   biocbuild@zin2:~/bbs-3.3-data-experiment/meat$ grep -li shannon */DESCRIPTION
      ConnectivityMap/DESCRIPTION
      DREAM4/DESCRIPTION


  --- release
     BrowserViz 1.2.1
     BrowserVizDemo 1.2.1
     MotifDb 1.12.0
     PSICQUIC 1.8.2
     RCy3 1.0.0
     RCyjs 1.2.1
     RCytoscaep 1.20.0
     RefNet 1.6.0

*----------------------------------------------------------------------------------------------------
* add kegg to neo4j?

  cd ~/s/work/priceLab/neo4j/kegg/

  status: KEGGgraph parser produces meager output. see tbl-all.tsv below for possible improvement

     > tbl <- parseKGML2DataFrame("kgml/kegg-00010.kgml", reactions=TRUE)
     > dim(tbl)
     [1] 304   3
     > tbl
                                        from         to  subtype
     hsa:226~hsa:2203.subtype        hsa:226   hsa:2203 compound
     hsa:226~hsa:8789.subtype        hsa:226   hsa:8789 compound
     hsa:226~hsa:5211.subtype        hsa:226   hsa:5211 compound
     hsa:226~hsa:5213.subtype        hsa:226   hsa:5213 compound
     hsa:226~hsa:5214.subtype        hsa:226   hsa:5214 compound
     hsa:226~hsa:7167.subtype        hsa:226   hsa:7167 compound
     hsa:226~hsa:2597.subtype        hsa:226   hsa:2597 compound
     hsa:226~hsa:26330.subtype       hsa:226  hsa:26330 compound
     hsa:229~hsa:2203.subtype        hsa:229   hsa:2203 compound
     ....



  see ~/s/examples/R/kegg/


   tbl <- read.table("tbl-all.tsv", header=FALSE, as.is=TRUE)
   dim(tbl)  # [1] 1751    3

   table(tbl$V2)

   catalyzes    productOf substrateFor
         994          377          380

        V1        V2     V3
   1  1738 catalyzes R07618
   2  4967 catalyzes R00621
   3 55753 catalyzes R00621
   4  4967 catalyzes R03316
   5 55753 catalyzes R03316
   6  1743 catalyzes R02570


*------------------------------------------------------------------------------------------------------------------------
* github tips:  fork and generate a pull request, a pr

   https://gist.github.com/Chaser324/ce0505fbed06b947d962

*------------------------------------------------------------------------------------------------------------------------
* github tips: create repo from existing project (31 may 2016)

  create empty repo at github
  cd metnetViz/
  git init
  git add .
  git commit -m "first commit"
     # at github, create new repo, maybe initialize with license
  git remote add origin https://github.com/PriceLab/metnetsViz
  git remote -v
  git push origin master    # git push --force origin master any files were added to new repo (e.g., license)


*------------------------------------------------------------------------------------------------------------------------
* github tips: TReNA (17 feb 2016)

  book, cd ~/github
  git clone https://github.com/PriceLab/TReNA.git

  --- add README.md as quick test

*----------------------------------------------------------------------------------------------------
* github tips: setup push/pull privileges to existing github repo

  whovian
  mkdir ~/github; cd github
  git clone https://github.com/paul-shannon/clevelandHighSchool.git
  cd clevelandHighSchool
   # edit README.md
  git add README.md
  git commit -m "test from whovian"
  git push origin master   # prompted for
    Username for 'https://github.com': paul-shannon
    Password for 'https://paul-shannon@github.com': old animal
    # saw changes appear on github repo
  even though this was also setup:
  git config --global -l
     user.name=paul-shannon
     user.email=paul.thurmond.shannon@gmail.com
  git --version  # git version 1.8.3.1

*----------------------------------------------------------------------------------------------------
* d3 map: make it responsive to window resizes (16 feb 2016)

  cd ~/s/examples/js/d3/geographicMaps/usaDemo/
  in another shell: python -m http.server 8081

  modify this according to suggestions found at

   http://eyeseast.github.io/visible-data/2013/08/26/responsive-d3/ "responsive maps with d3"


*----------------------------------------------------------------------------------------------------
* GeneRegulationUtilities package: add findSNPsInFootprints (22 feb 2016)

  using chr5 snps which mariette associates with mef2c

   file <- "~/s/work/priceLab/cory/footprintFinderExperiments/mef2c-related-snps-from-mariette.tsv"
   tbl <- read.table(file, header=TRUE, as.is=TRUE, sep="\t")  # [1] 156  16
   fivenum(tbl$BP)   # [1] 87972135 88072384 88159592 88252952 88333548
   mef2c (hg39, from igv): chr5:88,716,241-88,906,105

   --- look for some good test cases. first, identify upstream footprints
     mef2c, - strand: hg39 chr5:88,716,241-88,906,105
     tbl <- subset(tbl.fpAnnotated, chr=="chr5" & mfpStart > 88906000 & mfpEnd < 90000000)[, c(1, 12, 13, 4, 5)]
     dim(tbl) # 1409 5
     displayBedTable(igv, tbl, "xx4")

   --- identify upstream snps

     file <- "~/s/work/priceLab/cory/footprintFinderExperiments/mef2c-related-snps-from-mariette.tsv"
     tbl.snps <- read.table(file, header=TRUE, as.is=TRUE, sep="\t")   # 156  18

     displayBedTable(igv, (data.frame(chr="chr5", start=tbl.snps$GRCh38.liftover, end=tbl.snps$GRCh38.liftover, name=tbl.snps$SNP, stringsAsFactors=FALSE)), "snps")
     no true overlap of fps & snps from these two sets. so ...

  --- cory provides locations of snps inferred via haplotype from 1kgeneoms
    snp.locs <- scan("~/s/work/priceLab/cory/footprintFinderExperiments/1kgenomeHaplotypeSnpLocs.txt", sep="\n", what=integer(0))
    tbl.1kg.snps <- data.frame(chr="chr5", start=snp.locs, end=snp.locs, stringsAsFactors=FALSE)

*----------------------------------------------------------------------------------------------------
* update tbl.fpAnnotated in priceLab GeneRegulationUtilities package (16 feb 2016)

  starting with package version 1.0.1
  cd  ~/github/GeneRegulationUtilities/inst/unitTests/

  print(load("../../data/tbl.fpAnnotated.RData"))  # tbl.fpAnnotated
  dim(tbl.fpAnnotated)  # [1] 4692138      16
  t(tbl.fpAnnotated[1,])
    chr      "chr1"
    start    "1000065"
    end      "1000077"
    score    "50.4"
    strand   "-"
    name     "MA0813.1"
    info     "Name=MA0813.1;ID=MA0813.1-8462-1;pvalue=9.15e-06;qvalue="
    sequence "0.492;sequence=CGCCCTAGGGGCT;"
    width    "8"
    chrom    "1"
    bigStart "1000050"
    bigEnd   "1000075"
    x        "Unnamed953494"
    y        "-10.17376"
    z        "+"
    zz       "10"

   --- two links from cory.  first: fimo
     http://meme-suite.org/doc/examples/fimo_example_output_files/fimo.html?man_type=web
     fimo output reference:
        Motif      Sequence Name   Strand      Start        End       p-value    q-value    Matched Sequence
     MA0060.1               chr2        -   60221163    60221178     3.36e-09     0.00194   CTCGGCCAATCAGAGC

    which looks a lot like a rational treatment of our jumbled info & sequences columns

   ---- second: wellington, from https://github.com/jpiper/pyDNase
      http://pythonhosted.org/pyDNase/tutorial.html#interpreting-wellington-s-output

  --- going back to bed file provided by cory.
    cd ~/s/work/priceLab/cory/footprintFinderExperiments
    wc -l *.bed reveals that uniq_fimo_fp.bed has same number of lines as tb.fpAnnotated has rows:
    dim(tbl.fpAnnotated)  #  4692138      16
    4692138 uniq_fimo_fp.bed

  --- strategy: use orig?  work from RData form?  let's try the latter, the copy in footprintFinderExperiments
    relatively simple steps, some of them a little time consuming to run, in

   ~/s/work/priceLab/cory/footprintFinderExperiments/fixTbl., culminating in
      save(tbl.fpAnnotated, file="~/s/work/priceLab/cory/footprintFinderExperiments/tbl.fpAnnotated-colnamesFixed.RData")
   which can now be retrofitted into the GeneRegulationUtilities.


R> as.data.frame(t(tbl.fpAnnotated[c(1:2,38),])) # browser 3 columns at random

chr                        chr1            chr1            chr1
motifStart              1000065         1000065       100029991
motifEnd                1000077         1000077       100030001
motifScore                 50.4            53.2            55.1
motifStrand                   -               -               +
name                   MA0813.1        MA0815.1        MA0601.1
id              MA0813.1-8462-1 MA0815.1-4616-1 MA0601.1-2480-1
pvalue                 9.15e-06        4.82e-06         3.1e-06
qvalue                    0.492           0.462           0.342
sequence          CGCCCTAGGGGCT   CGCCCTAGGGGCT     ATATTAATAAA
experimentCount               8               8              10
fpStart                 1000050         1000050       100029978
fpEnd                   1000075         1000075       100029999
fpScore               -10.17376       -10.17376       -11.17498
fpStrand                      +               +               +
motifFpOverlap               10              10               8


   --- cory adds two additional change
     cd ~/s/work/priceLab/cory/footprintFinderExperiments

     ~/s/work/priceLab/cory/footprintFinderExperiments/removeFpStrandAddMfpBounds.R

     remove footprintStrand
        add mfpStart mfpEnd, calculated from the min(motifStart, fpStart) .. max (motifEnd, fpEnd)
        ran some sanity checks seeing that

      fivenum(fpWidth) [1] 11 19 23 25 25
      fivenum(mWidth)  [1]  7 10 12 14 28
     fivenum(mfpWidth) [1] 11 23 25 29 52
  tbl.fpAnnotated <- tbl
  save(tbl.fpAnnotated, file="tbl.fpAnnotated-colnamesFixed-mfpStartEndColsAdded.RData")

  cp tbl.fpAnnotated-colnamesFixed-mfpStartEndColsAdded.RData ~/github/GeneRegulationUtilities/data/

*----------------------------------------------------------------------------------------------------
* sed tips
  sed -e s/xxFILENAMExx/foo.txt/ fill-interactions-template.cql

   --- break up long json line into multplie lines
   cat tiny.json
    g = [{"id":"n99324","x":34087.9375,"y":5474.07},{"id":"n99325","x":34087.9375,"y":5544.07},{"id":"n99326","x":32965.4375,"y":5594.07},{"id":"n99327","x":1509.5,"y":5644.07}];
   sed -e s/\},\{/\},X\{/g tiny.json | tr X '\n'

g = [{"id":"n99324","x":34087.9375,"y":5474.07},
{"id":"n99325","x":34087.9375,"y":5544.07},
{"id":"n99326","x":32965.4375,"y":5594.07},
{"id":"n99327","x":1509.5,"y":5644.07}];



*----------------------------------------------------------------------------------------------------
* txdb tips, gene location, genes, promoters, org.Hs.eg.db,  TxDb.Hsapiens.UCSC.hg38.knownGene (3 may 2016)

   use this in the footprint finder rather than use the sometimes broken biomaRt

  library(TxDb.Hsapiens.UCSC.hg38.knownGene)
  txdb <- TxDb.Hsapiens.UCSC.hg38.knownGene
  mef2c <- select(db, keys="MEF2C", keytype="SYMBOL", columns=c("ENTREZID"))$ENTREZID[1]
  as.data.frame(range(promoters(txdb, vals=c(gene_id=mef2c), upstream=100, downstream=0)))
      seqnames    start      end width strand
    1     chr5 88823928 88904205 80278      -

      # many possible promoters, so choose just the first:
   as.data.frame(range(promoters(txdb, vals=c(gene_id="4208"), upstream=100, downstream=0)[1]))
     seqnames    start      end width strand
   1     chr5 88823928 88824027   100      -


  gene <- "MEF2C"
  gene.id <- select(db, keys="MEF2C", keytype="SYMBOL", columns=c("ENTREZID"))$ENTREZID[1]) # 4208

  promoters(txdb, vals=c(gene_id="4028"),


* select tips, OrgDb, AnnotationDbi tips

  library(org.Hs.eg.db)
  db <- org.Hs.eg.db
  keytypes(db)  # used both to identify type of search term, and the columns to be returned
    "ACCNUM"       "ALIAS"        "ENSEMBL"      "ENSEMBLPROT"  "ENSEMBLTRANS" "ENTREZID"     "ENZYME"
    "EVIDENCE"     "EVIDENCEALL"  "GENENAME"     "GO"           "GOALL"        "IPI"          "MAP"
    "OMIM"         "ONTOLOGY"     "ONTOLOGYALL"  "PATH"         "PFAM"         "PMID"         "PROSITE"
    "REFSEQ"       "SYMBOL"       "UCSCKG"       "UNIGENE"      "UNIPROT"

  --- get ensembl gene id from gene symbol
  select(db, keys="TDO2", keytype="SYMBOL", columns=c("GENENAME", "ENSEMBL", "ENTREZID"))
     SYMBOL                   GENENAME         ENSEMBL ENTREZID
   1   TDO2 tryptophan 2,3-dioxygenase ENSG00000151790     6999
   2   TDO2 tryptophan 2,3-dioxygenase ENSG00000262635     6999


*----------------------------------------------------------------------------------------------------
* neo4j, constrained shortestpath, stackoverflow (17 feb 2016)

   --- i asked
    from the tutorial:

      MATCH p=shortestPath((keanu:Person)-[:KNOWS*]-(kevin:Person)) WHERE keanu.name="Keanu Reeves" and kevin.name = "Kevin Bacon" RETURN length(p)

    Imagine each Person node has an age property and an occupation. Every KNOWS
    edge has a "length of acquaintance" property.

    What Cypher query would return a shortest path with, for instance, age > 40
    years not (occupation = ACTOR) lengthOfAcquaintance > 10 years

    In molecular biology interaction data, we wish to make yet more complex
    queries - probably of the sort which cypher handles well, but just how
    eludes me. For example:

    Find the shortest paths between receptor molecule A and transcription factor
    B, where most edges are from small-scale experiments, most of the genes are
    annotated as kinases, and evidence (weight) for the edges is greater than 0.5

    These queries probably come up in lots of settings. Can anyone point me
    towards readings and examples which will help me understand how this is
    done? And maybe provide a modest extension of the "Bacon Number" query which
    accommodates one node and one edge property?


  -- christophe willemsen (Neo4j Senior Consultant at GraphAware)
   I think that what you are looking for is the ALL predicate.
   Here are a couple of examples using it :

   --- ShortestPath where all actors in the paths should have an age > 40 :

     MATCH p=shortestPath( (keanu:Person)-[:KNOWS*]-(kevin:Person) )
     WHERE keanu.name = "Keanu Reeves"
     AND kevin.name = "Kevin Bacon"
     AND ALL(x IN nodes(p) WHERE x.age > 40)
     RETURN p

   --- ShortestPath where all edges should have a lengthOfAcquaintance > 10

     MATCH p=shortestPath( (keanu:Person)-[:KNOWS*]-(kevin:Person) )
     WHERE keanu.name = "Keanu Reeves"
     AND kevin.name = "Kevin Bacon"
     AND ALL(x in rels(p) WHERE x.lengthOfAcquaintance > 10
     RETURN p

    --- Of course you can combine the both :

     MATCH p=shortestPath( (keanu:Person)-[:KNOWS*]-(kevin:Person) )
     WHERE keanu.name = "Keanu Reeves"
     AND kevin.name = "Kevin Bacon"
     AND ALL(x in rels(p) WHERE x.lengthOfAcquaintance > 10
     AND ALL(x in nodes(p) WHERE x.age > 40
     RETURN p

*----------------------------------------------------------------------------------------------------
* genemania in neo4j, try out christophe willemsen's constrained shortest path queries (17 feb 2016)
  also: use list comprehension to extract properties from nodes in a path

   --- set the stage, following his style:
     MATCH(tdo2:Molecule) WHERE tdo2.name = "TDO2" return tdo2;
     MATCH(egfr:Molecule) WHERE egfr.name = "EGFR" return egfr;

   MATCH p=shortestPath((tdo2:Molecule)-[*]-(egfr:Molecule))
   WHERE tdo2.name = "TDO2"
     AND egfr.name = "EGFR"
     AND ALL(x in rels(p) WHERE x.weight > 0.1)
   RETURN [x in nodes(p) | x.name],
          [r in rels(p)  | r.weight];

   MATCH p=allShortestPaths((tdo2:Molecule)-[*]-(egfr:Molecule))
   WHERE tdo2.name = "TDO2"
     AND egfr.name = "EGFR"
     AND ALL(x in rels(p) WHERE x.weight > 0.1)
   RETURN DISTINCT nodes(p);


*----------------------------------------------------------------------------------------------------
* kegg in neo4j (14 feb 2016)

  cd ~/s/work/priceLab/neo4j/kegg


*----------------------------------------------------------------------------------------------------
* genemania in neo4j (14 feb 2016)

  cd ~/s/work/priceLab/neo4j/genemania

  --- use case: TDO2
    library(org.Hs.eg.db)
    db <- org.Hs.eg.db
    select(db, keys="TDO2", keytype="SYMBOL", columns="ENSEMBL")$ENSEMBL
       # "ENSG00000151790" "ENSG00000262635"

   grep -c ENSG00000151790 Co-expression*.txt; grep -c ENSG00000262635 Co-expression*.txt;
   found lots of entries for the second id: ENSG00000262635

  --- first try.  choose one source file by representation of TDO2

     Co-expression.Kim-Paik-2011.txt:93,  493233 total lines, pmid 21947828
        "Estrogen Receptor (ESR1) mRNA Expression and Benefit From Tamoxifen in
         the Treatment and Prevention of Estrogen Receptor–Positive Breast Cancer"

   or Co-expression.Hessel-Tilley-2014.txt:39
      "Intraflagellar transport gene expression associated with short cilia in smoking and COPD"

  --- create a pipeline

    tbl.mnfst <- read.table("networks.txt", header=TRUE, sep="\t", fill=TRUE)
    as.data.frame(sort(table(tbl.mnfst$Network_Group_Name), decreasing=TRUE))
                      Var1 Freq
             Co-expression  284
     Physical interactions  189
                 Predicted   42
      Genetic interactions    7
                   Pathway    6
           Co-localization    3
                       GEO    3
    Shared protein domains    2
                      IREF    1

   ---- created molecules.tsv (inefficiently.  next time just use org.Hs.ed.db)
     cat *.txt | cut -f 1,8 > molecules.tsv
     cat *.txt | cut -f 2,9 >> molecules.tsv
     sort molecules.tsv | uniq > molecules.sorted.unique.tsv   # an hour to run...

     wc -l molecules.tsv  18583
     added colnames; ensg symbol

    --- fill them
     make fillMolecules  #   neo4j-shell -file fill-molecules.cql -v
        Nodes created: 18583
        Properties set: 74332
        Labels added: 18583
        1268 ms
    --- simple test
      ~/bin/neo4j-shell
      match(n) return(count(n));
      match(n) where n.name="TDO2" return(count(n));  # 2
      match(n) where n.name="TDO2" return(n);
      +-------------------------------------------------------------------------------+
      | Node[96428]{type:"gene",id:"TDO2",name:"TDO2",subtype:"generic"}              |
      | Node[116418]{subtype:"gene",type:"molecule",id:"ENSG00000262635",name:"TDO2"} |
      +-------------------------------------------------------------------------------+

    --- fill the interactions.  first a test with TDO2.  3 physical interactions in
      Physical_interactions.IREF-BIOGRID.txt:3
      neo4j-shell -file fill-interactions.cql -v
         Relationships created: 127207
         Properties set: 508828
         17776 ms

           create constraint on (interaction:Interaction) assert interaction.id is unique;
           LOAD CSV WITH HEADERS FROM
              "file:///Users/paul/s/work/priceLab/neo4j/genemania/neo4jReady/Physical_interactions.IREF-BIOGRID.txt"
               AS line FIELDTERMINATOR '\t'
               MATCH (a:Molecule {id: line.Gene_A}), (b:Molecule {id: line.Gene_B})
               CREATE (a)-[:Interaction {type: line.Network_Group_Name, pmid: line.Pubmed_ID, source: line.Source, weight: line.Weight}]->(b);

     --- test this single file fill
       match(a)-[r]->(b) return(count(r));   // 306618
       match(a)-[r]->(b) return(collect(distinct(r.type)));   //  ["Physical interactions"]
       match(a)-[r]->b where a.name="TDO2" or b.name="TDO2" return(count(r));
       match(a)-[r]->b where a.name="TDO2" or b.name="TDO2" return a.name, r.type, r.weight, b.name;
          +--------------------------------------------------------+
          | a.name  | r.type                  | r.weight | b.name  |
          +--------------------------------------------------------+
          | "TDO2"  | "Physical interactions" | "0.62"   | "ASMTL" |
          | "TDO2"  | "Physical interactions" | "0.057"  | "PRMT6" |
          | "KDM1A" | "Physical interactions" | "0.027"  | "TDO2"  |
          +--------------------------------------------------------+

   --- load multiple files into neo4j:
      see ~/s/work/priceLab/neo4j/genemania/neo4jReady/runFill.R

   --- neo4j property type: string vs int or float
     seems that incoming load csv data is treated as strings by default, but toFloat (or toInt)
     save the day:

       USING PERIODIC COMMIT
       LOAD CSV WITH HEADERS FROM
          "file:///Users/paul/s/work/priceLab/neo4j/genemania/neo4jReady/xxFILENAMExx"
          AS line FIELDTERMINATOR '\t'
          MATCH (a:Molecule {id: line.Gene_A}), (b:Molecule {id: line.Gene_B})
          CREATE (a)-[:Interaction {type: line.Network_Group_Name,
                                    pmid: line.Pubmed_ID,
                                    source: line.Source,
                                    weight: toFloat(line.Weight)}]->(b);

    this also works after the fact in match/queries:
    match(a)-[r]->b where (a.name="TDO2" or b.name="TDO2") and toFloat(r.weight) > 0.5 return a.name, r.type, r.weight, b.name;


   --- find shortest path between TDO2 and EGFR in these physical reactions:
      match(a:Molecule{name:"TDO2"}),(b:Molecule{name:"EGFR"}), p=shortestpath((a)-[*..99]-(b)) return p;
       [Node[190750]{subtype:"gene",type:"molecule",id:"ENSG00000262635",name:"TDO2"},
          :Interaction[1916442]{type:"Physical interactions",weight:0.077,source:"IREF",pmid:"NA"},
       Node[181184]{type:"molecule",name:"KLHL8",subtype:"gene",id:"ENSG00000145332"},
          :Interaction[1940499]{type:"Physical interactions",weight:0.0071,source:"IREF",pmid:"NA"},
       Node[189712]{type:"molecule",name:"UBA52",subtype:"gene",id:"ENSG00000221983"},
          :Interaction[2009834]{type:"Physical interactions",weight:7.5E-4,source:"IREF",pmid:"NA"},
       Node[181358]{subtype:"gene",type:"molecule",id:"ENSG00000146648",name:"EGFR"}]


  --- find allShortestPaths
    match(a:Molecule{name:"TDO2"}),(b:Molecule{name:"EGFR"}), p=allShortestPaths((a)-[*..99]-(b)) return count(p);  // 255

    match(a)-[r]->(b) where (a.name="TDO2" or b.name="TDO2"), return a.name,  r.type, r.weight, b.name;

   --- find 4-node path between TDO2 and EGFR
     match(a{name:"TDO2"})-[r0]-(b)-[r1]-(c)-[r2]-(d{name:"EGFR"}) where r0.weight > 0.1  return b.name, c.name;
     match(a{name:"TDO2"})-[r0]-(b)-[r1]-(c)-[r2]-(d{name:"EGFR"})
           where r0.weight > 0.1  return r0.weight, b.name, r1.weight, c.name, r2.weight;

      +------------------------------------------------------+
      | r0.weight | b.name  | r1.weight | c.name | r2.weight |
      +------------------------------------------------------+
      | 0.63      | "ASMTL" | 0.001     | "UBC"  | 1.6E-4    |
      | 0.63      | "ASMTL" | 0.001     | "UBC"  | 4.1E-5    |
      | 0.4       | "GALE"  | 0.0043    | "UBC"  | 1.6E-4    |
      | 0.4       | "GALE"  | 0.0043    | "UBC"  | 4.1E-5    |
      | 0.54      | "ASMTL" | 0.001     | "UBC"  | 1.6E-4    |
      | 0.54      | "ASMTL" | 0.001     | "UBC"  | 4.1E-5    |
      | 1.0       | "ASMTL" | 0.001     | "UBC"  | 1.6E-4    |
      | 1.0       | "ASMTL" | 0.001     | "UBC"  | 4.1E-5    |
      | 0.62      | "ASMTL" | 0.001     | "UBC"  | 1.6E-4    |
      | 0.62      | "ASMTL" | 0.001     | "UBC"  | 4.1E-5    |
      +------------------------------------------------------+

     see that UBC (ubiquitin) is the c node, and since ubiquitin is, er, ubiquitous in its relationships,
     exclude it, and add another node to the path

      match(a{name:"TDO2"})-[r0]-(b)-[r1]-(c)-[r2]-(d)-[r3]-(e{name:"EGFR"})
         where r0.weight > 0.1 and r1.weight > 0.1 and (not c.name = "UBC")
         return r0.weight, b.name, r1.weight, c.name, r2.weight;

       match(a{name:"TDO2"})-[r0]-(b)-[r1]-(c)-[r2]-(d)-[r3]-(e)-[r4]-(f{name:"EGFR"})
          where r0.weight > 0.1 and r1.weight > 0.1 and r2.weight > 0.1 and r3.weight > 0.1 and (not c.name = "UBC")
          return a.name, r0.weight, b.name, r1.weight, c.name, r2.weight, d.name, r3.weight, e.name, r4.weight, f.name;

       +--------------------------------------------------------------------------------------------------------------------+
       | a.name | r0.weight | b.name | r1.weight | c.name  | r2.weight | d.name  | r3.weight | e.name  | r4.weight | f.name |
       +--------------------------------------------------------------------------------------------------------------------+
       | "TDO2" | 0.4       | "GALE" | 0.36      | "GALK2" | 0.12      | "DOCK1" | 0.57      | "CRK"   | 0.002     | "EGFR" |
       | "TDO2" | 0.4       | "GALE" | 0.36      | "GALK2" | 0.12      | "DOCK1" | 0.57      | "CRK"   | 0.0059    | "EGFR" |
       | "TDO2" | 0.4       | "GALE" | 0.36      | "GALK2" | 0.12      | "DOCK1" | 0.57      | "CRK"   | 0.0013    | "EGFR" |
       | "TDO2" | 0.4       | "GALE" | 0.36      | "GALK2" | 0.12      | "DOCK1" | 0.57      | "CRK"   | 0.0043    | "EGFR" |
       | "TDO2" | 0.4       | "GALE" | 0.36      | "GALK2" | 0.12      | "DOCK1" | 0.57      | "CRK"   | 0.0013    | "EGFR" |
       | "TDO2" | 0.4       | "GALE" | 0.36      | "GALK2" | 0.12      | "DOCK1" | 0.57      | "CRK"   | 0.033     | "EGFR" |
       | "TDO2" | 0.4       | "GALE" | 0.12      | "MVK"   | 0.14      | "GSS"   | 0.15      | "GAPDH" | 0.0021    | "EGFR" |
       | "TDO2" | 0.4       | "GALE" | 0.12      | "MVK"   | 0.14      | "GSS"   | 0.15      | "GAPDH" | 0.0037    | "EGFR" |
       | "TDO2" | 0.4       | "GALE" | 0.12      | "MVK"   | 0.14      | "GSS"   | 0.15      | "GAPDH" | 0.021     | "EGFR" |
       | "TDO2" | 0.4       | "GALE" | 0.12      | "MVK"   | 0.14      | "GSS"   | 0.15      | "GAPDH" | 0.005     | "EGFR" |
       | "TDO2" | 0.4       | "GALE" | 0.12      | "MVK"   | 0.14      | "GSS"   | 0.15      | "GAPDH" | 0.0017    | "EGFR" |
       | "TDO2" | 0.4       | "GALE" | 0.12      | "MVK"   | 0.14      | "GSS"   | 0.15      | "GAPDH" | 0.079     | "EGFR" |
       +--------------------------------------------------------------------------------------------------------------------+

       match(a{name:"TDO2"})-[r:]-(b)-[r1]-(c)-[r2]-(d)-[r3]-(e)-[r4]-(f{name:"EGFR"})

   --- try to sneak up on shortest path between TDO2 and EGFR, constrained by weights on all edges
       use label
       match (a)-[r:Interaction]-(b) where r.weight > 0.8 return (count(r));   // 2912
       match (a)-[r]-(b) where r.weight > 0.8 return (count(r));               // 2912

       match (a)-[r:Interaction*2]-(b) where r.weight > 0.8 return (count(r));
       WARNING: Type mismatch: expected Map, Node or Relationship but was Collection<Relationship>

       match (a)-[r:Interaction*2]-(b) where r.weight > 0.8 return (count(r));

       match (a{name:"TDO2"})-[*2]-(b{name:"GALK2"}) return b;
          +--------------------------------------------------------------------------------+
          | Node[182443]{type:"molecule",name:"GALK2",subtype:"gene",id:"ENSG00000156958"} |
          +--------------------------------------------------------------------------------+

     match (a{name:"TDO2"})-[r:Interaction*2]-(b{name:"GALK2"}) return r;
     [:Interaction[1916441]{type:"Physical interactions",weight:0.4,source:"IREF",pmid:"NA"},
      :Interaction[1917463]{type:"Physical interactions",weight:0.36,source:"IREF",pmid:"NA"}]

     match p = (a{name:"TDO2"})-[r:Interaction*2]-(b{name:"GALK2"}) return p;
         [Node[190750]{subtype:"gene",type:"molecule",id:"ENSG00000262635",name:"TDO2"},
          :Interaction[1916441]{type:"Physical interactions",weight:0.4,source:"IREF",pmid:"NA"},
          Node[177404]{subtype:"gene",type:"molecule",id:"ENSG00000117308",name:"GALE"},
          :Interaction[1917463]{type:"Physical interactions",weight:0.36,source:"IREF",pmid:"NA"},
          Node[182443]{type:"molecule",name:"GALK2",subtype:"gene",id:"ENSG00000156958"}]


     match p = (a{name:"TDO2"})-[r:Interaction*2..3]-(b{name:"GALK2"}) return count(p);  # 10
     match p = (a{name:"TDO2"})-[r:Interaction*3]-(b{name:"GALK2"}) return count(p);     # 9
     match p = (a{name:"TDO2"})-[r:Interaction*4]-(b{name:"GALK2"}) return count(p);     # terminated after 5 minutes
     match p = (a{name:"TDO2"})-[r:Interaction*3]-(b{name:"GALK2"}) return p;  # 9 rows
     [Node[190750]{subtype:"gene",type:"molecule",id:"ENSG00000262635",name:"TDO2"},
      :Interaction[1738125]{type:"Physical interactions",weight:0.027,source:"IREF",pmid:"NA"},
      Node[173017]{type:"molecule",name:"KDM1A",subtype:"gene",id:"ENSG00000004487"},
      :Interaction[1732341]{type:"Physical interactions",weight:4.5E-5,source:"IREF",pmid:"NA"},
      Node[181786]{subtype:"gene",type:"molecule",id:"ENSG00000150991",name:"UBC"},
      :Interaction[1742302]{type:"Physical interactions",weight:0.016,source:"IREF",pmid:"NA"},
      Node[182443]{type:"molecule",name:"GALK2",subtype:"gene",id:"ENSG00000156958"}] |

     [Node[190750]{subtype:"gene",type:"molecule",id:"ENSG00000262635",name:"TDO2"},
      :Interaction[1871061]{type:"Physical interactions",weight:0.023,source:"IREF",pmid:"NA"},
      Node[173017]{type:"molecule",name:"KDM1A",subtype:"gene",id:"ENSG00000004487"},
      :Interaction[1732341]{type:"Physical interactions",weight:4.5E-5,source:"IREF",pmid:"NA"},
      Node[181786]{subtype:"gene",type:"molecule",id:"ENSG00000150991",name:"UBC"},
      :Interaction[1742302]{type:"Physical interactions",weight:0.016,source:"IREF",pmid:"NA"},
      Node[182443]{type:"molecule",name:"GALK2",subtype:"gene",id:"ENSG00000156958"}] |

     [Node[190750]{subtype:"gene",type:"molecule",id:"ENSG00000262635",name:"TDO2"},
      :Interaction[1916441]{type:"Physical interactions",weight:0.4,source:"IREF",pmid:"NA"},
      Node[177404]{subtype:"gene",type:"molecule",id:"ENSG00000117308",name:"GALE"},
      :Interaction[1735183]{type:"Physical interactions",weight:0.0043,source:"IREF",pmid:"NA"},
      Node[181786]{subtype:"gene",type:"molecule",id:"ENSG00000150991",name:"UBC"},
      :Interaction[1742302]{type:"Physical interactions",weight:0.016,source:"IREF",pmid:"NA"},
      Node[182443]{type:"molecule",name:"GALK2",subtype:"gene",id:"ENSG00000156958"}]    |

     [Node[190750]{subtype:"gene",type:"molecule",id:"ENSG00000262635",name:"TDO2"},
      :Interaction[1916442]{type:"Physical interactions",weight:0.077,source:"IREF",pmid:"NA"},
      Node[181184]{type:"molecule",name:"KLHL8",subtype:"gene",id:"ENSG00000145332"},
      :Interaction[1737340]{type:"Physical interactions",weight:0.0014,source:"IREF",pmid:"NA"},
      Node[181786]{subtype:"gene",type:"molecule",id:"ENSG00000150991",name:"UBC"},
      :Interaction[1742302]{type:"Physical interactions",weight:0.016,source:"IREF",pmid:"NA"},
      Node[182443]{type:"molecule",name:"GALK2",subtype:"gene",id:"ENSG00000156958"}] |

     [Node[190750]{subtype:"gene",type:"molecule",id:"ENSG00000262635",name:"TDO2"},
      :Interaction[1763003]{type:"Physical interactions",weight:0.62,source:"IREF",pmid:"NA"},
      Node[184754]{subtype:"gene",type:"molecule",id:"ENSG00000169093",name:"ASMTL"},
      :Interaction[1763002]{type:"Physical interactions",weight:0.001,source:"IREF",pmid:"NA"},
      Node[181786]{subtype:"gene",type:"molecule",id:"ENSG00000150991",name:"UBC"},
      :Interaction[1742302]{type:"Physical interactions",weight:0.016,source:"IREF",pmid:"NA"},
      Node[182443]{type:"molecule",name:"GALK2",subtype:"gene",id:"ENSG00000156958"}]   |

     [Node[190750]{subtype:"gene",type:"molecule",id:"ENSG00000262635",name:"TDO2"},
      :Interaction[1836758]{type:"Physical interactions",weight:1.0,source:"IREF",pmid:"NA"},
      Node[184754]{subtype:"gene",type:"molecule",id:"ENSG00000169093",name:"ASMTL"},
      :Interaction[1763002]{type:"Physical interactions",weight:0.001,source:"IREF",pmid:"NA"},
      Node[181786]{subtype:"gene",type:"molecule",id:"ENSG00000150991",name:"UBC"},
      :Interaction[1742302]{type:"Physical interactions",weight:0.016,source:"IREF",pmid:"NA"},
      Node[182443]{type:"molecule",name:"GALK2",subtype:"gene",id:"ENSG00000156958"}]    |

     [Node[190750]{subtype:"gene",type:"molecule",id:"ENSG00000262635",name:"TDO2"},
      :Interaction[1879068]{type:"Physical interactions",weight:0.54,source:"IREF",pmid:"NA"},
      Node[184754]{subtype:"gene",type:"molecule",id:"ENSG00000169093",name:"ASMTL"},
      :Interaction[1763002]{type:"Physical interactions",weight:0.001,source:"IREF",pmid:"NA"},
      Node[181786]{subtype:"gene",type:"molecule",id:"ENSG00000150991",name:"UBC"},
      :Interaction[1742302]{type:"Physical interactions",weight:0.016,source:"IREF",pmid:"NA"},
      Node[182443]{type:"molecule",name:"GALK2",subtype:"gene",id:"ENSG00000156958"}]   |

     [Node[190750]{subtype:"gene",type:"molecule",id:"ENSG00000262635",name:"TDO2"},
      :Interaction[1924479]{type:"Physical interactions",weight:0.63,source:"IREF",pmid:"NA"},
      Node[184754]{subtype:"gene",type:"molecule",id:"ENSG00000169093",name:"ASMTL"},
      :Interaction[1763002]{type:"Physical interactions",weight:0.001,source:"IREF",pmid:"NA"},
      Node[181786]{subtype:"gene",type:"molecule",id:"ENSG00000150991",name:"UBC"},
      :Interaction[1742302]{type:"Physical interactions",weight:0.016,source:"IREF",pmid:"NA"},
      Node[182443]{type:"molecule",name:"GALK2",subtype:"gene",id:"ENSG00000156958"}]   |

     [Node[190750]{subtype:"gene",type:"molecule",id:"ENSG00000262635",name:"TDO2"},
      :Interaction[1916441]{type:"Physical interactions",weight:0.4,source:"IREF",pmid:"NA"},
      Node[177404]{subtype:"gene",type:"molecule",id:"ENSG00000117308",name:"GALE"},
      :Interaction[1940176]{type:"Physical interactions",weight:0.063,source:"IREF",pmid:"NA"},
      Node[190446]{subtype:"gene",type:"molecule",id:"ENSG00000258728",name:"NA"},
      :Interaction[1940199]{type:"Physical interactions",weight:0.06,source:"IREF",pmid:"NA"},
      Node[182443]{type:"molecule",name:"GALK2",subtype:"gene",id:"ENSG00000156958"}]       |

     ---- match (a{name:"TDO2"})-[r:Interaction*2]-(b{name:"GALK2"}) return r;
      [:Interaction[1916441]{type:"Physical interactions",weight:0.4,source:"IREF",pmid:"NA"},
       :Interaction[1917463]{type:"Physical interactions",weight:0.36,source:"IREF",pmid:"NA"}]

     ---- match (a{name:"TDO2"})-[r:Interaction*2]-(b{name:"GALK2"}) return [x in r where x.weight > 0.38];
        the set of r's is an array, a collection.  the list comprehension "is a syntactic construct
        available n Cypher for creating a collection based on existing collections. It follows the
        form of the mathematical set-builder notation (set comprehension) instead of the use of map
        and filter functions.

        +------------------------------------------------------------------------------------------+
        | [x in r where x.weight > 0.38]                                                           |
        +------------------------------------------------------------------------------------------+
        | [:Interaction[1916441]{type:"Physical interactions",weight:0.4,source:"IREF",pmid:"NA"}] |
        +------------------------------------------------------------------------------------------+

     --- the goal, however, is to reject the entire array unless all elements meet threshold

      MATCH p = shortestPath((a:Molecule {name: 'TDO2' })-[:Interaction]-(b:Molecule{name: 'EGFR' }))

    --- [from http://stackoverflow.com/questions/27005120/filtering-shortest-path-cypher-query-with-a-relation-property-restriction]

      MATCH p = shortestPath((a:Party { currency: 'GBP' })-[r:IN_ESCROW] -(b:Party { currency: 'USD' }))
      WHERE all(x IN r WHERE x.status = 'cleared')

    --- try to apply it here
      match p = shortestpath((a{name:"TDO2"})-(r)-(b{name:"EGFR"})) where all(x in r where x.weight > 0.2) return p;


    --- backtracking:
     match(a:Molecule{name:"TDO2"}),(b:Molecule{name:"EGFR"}), p=allshortestpaths((a)-[*..4]-(b)) return count(p); // 255
     match(a:Molecule{name:"TDO2"}),(b:Molecule{name:"EGFR"}), p=shortestpath((a)-[*..4]-(b)) return count(p);     //   1
     match(a:Molecule{name:"TDO2"}),(b:Molecule{name:"EGFR"}), p=allshortestpaths((a)-[*]-(b)) return count(p);    // 255
     match(a:Molecule{name:"TDO2"}),(b:Molecule{name:"EGFR"}), p=allshortestpaths((a)-[*]-(b)) return count(rels(p));
     match(a:Molecule{name:"TDO2"}),(b:Molecule{name:"EGFR"}), p=allshortestpaths((a)-[*]-(b)) return count(rels(p)); // 255
     match(a:Molecule{name:"TDO2"}),(b:Molecule{name:"EGFR"}), p=allshortestpaths((a)-[*]-(b)) return rels(p) limit 3; // 255
      [:Interaction[1871061]{type:"Physical interactions",weight:0.023,source:"IREF",pmid:"NA"},
       :Interaction[1979374]{type:"Physical interactions",weight:0.006,source:"IREF",pmid:"NA"},
       :Interaction[1979422]{type:"Physical interactions",weight:0.0017,source:"IREF",pmid:"NA"}]
      [:Interaction[1871061]{type:"Physical interactions",weight:0.023,source:"IREF",pmid:"NA"},
       :Interaction[1979374]{type:"Physical interactions",weight:0.006,source:"IREF",pmid:"NA"},
       :Interaction[1756588]{type:"Physical interactions",weight:0.003,source:"IREF",pmid:"NA"}]  |
      [:Interaction[1738125]{type:"Physical interactions",weight:0.027,source:"IREF",pmid:"NA"},
       :Interaction[1979374]{type:"Physical interactions",weight:0.006,source:"IREF",pmid:"NA"},
       :Interaction[1979422]{type:"Physical interactions",weight:0.0017,source:"IREF",pmid:"NA"}] |

      match(a:Molecule{name:"TDO2"}),(b:Molecule{name:"EGFR"}), p=allshortestpaths((a)-[*]-(b)) return rels(p) limit 3;
         [:Interaction[1871061]{type:"Physical interactions",weight:0.023,source:"IREF",pmid:"NA"},:Interaction[1979374]{type:"Physical interactions",weight:0.006,source:"IREF",pmid:"NA"},:Interaction[1979422]{type:"Physical interactions",weight:0.0017,source:"IREF",pmid:"NA"}] |
         [:Interaction[1871061]{type:"Physical interactions",weight:0.023,source:"IREF",pmid:"NA"},:Interaction[1979374]{type:"Physical interactions",weight:0.006,source:"IREF",pmid:"NA"},:Interaction[1756588]{type:"Physical interactions",weight:0.003,source:"IREF",pmid:"NA"}]  |
         [:Interaction[1738125]{type:"Physical interactions",weight:0.027,source:"IREF",pmid:"NA"},:Interaction[1979374]{type:"Physical interactions",weight:0.006,source:"IREF",pmid:"NA"},:Interaction[1979422]{type:"Physical interactions",weight:0.0017,source:"IREF",pmid:"NA"}] |

     match(a:Molecule{name:"TDO2"}),(b:Molecule{name:"EGFR"}), p=allshortestpaths((a)-[*]-(b)) return nodes(p) limit 3;

         [Node[190750]{subtype:"gene",type:"molecule",id:"ENSG00000262635",name:"TDO2"},Node[173017]{type:"molecule",name:"KDM1A",subtype:"gene",id:"ENSG00000004487"},Node[184164]{subtype:"gene",type:"molecule",id:"ENSG00000166501",name:"PRKCB"},Node[181358]{subtype:"gene",type:"molecule",id:"ENSG00000146648",name:"EGFR"}] |
         [Node[190750]{subtype:"gene",type:"molecule",id:"ENSG00000262635",name:"TDO2"},Node[173017]{type:"molecule",name:"KDM1A",subtype:"gene",id:"ENSG00000004487"},Node[184164]{subtype:"gene",type:"molecule",id:"ENSG00000166501",name:"PRKCB"},Node[181358]{subtype:"gene",type:"molecule",id:"ENSG00000146648",name:"EGFR"}] |
         [Node[190750]{subtype:"gene",type:"molecule",id:"ENSG00000262635",name:"TDO2"},Node[173017]{type:"molecule",name:"KDM1A",subtype:"gene",id:"ENSG00000004487"},Node[184164]{subtype:"gene",type:"molecule",id:"ENSG00000166501",name:"PRKCB"},Node[181358]{subtype:"gene",type:"molecule",id:"ENSG00000146648",name:"EGFR"}] |

      match(a:Molecule{name:"TDO2"}),(b:Molecule{name:"EGFR"}), p=allshortestpaths((a)-[*]-(b))
      where all(x in filter(x in rels(p) where x:weight > 0.1));

-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+


+---------------------------------------------------------------------------------


*----------------------------------------------------------------------------------------------------
* install python websocket-client on eager (13 feb 2016)

  mkdir ~/Downloads
  cd Downloads/
  curl -O  https://pypi.python.org/packages/source/w/websocket-client/websocket_client-0.35.0.tar.gz
  tar zxvf websocket_client-0.35.0.tar.gz
  cd websocket_client-0.35.0
  python setup.py install --user
  dir ~/.local/lib/python2.6/site-packages/

  dir ~/.local/lib/python2.6/site-packages/
      backports.ssl_match_hostname-3.5.0.1-py2.6.egg/
      easy-install.pth
      six-1.10.0-py2.6.egg/
      websocket_client-0.35.0-py2.6.egg/

  --- findable?
     python   # 2.6.6
     import sys
     sys.path
     ['', '/home/ISB/pshannon/.local/lib/python2.6/site-packages/websocket_client-0.35.0-py2.6.egg',
      '/home/ISB/pshannon/.local/lib/python2.6/site-packages/backports.ssl_match_hostname-3.5.0.1-py2.6.egg',
      '/home/ISB/pshannon/.local/lib/python2.6/site-packackages',
      '/usr/lib64/python2.6/site-packages',
      '/usr/lib64/python2.6/site-packages/gtk-2.0',
      '/usr/lib/python2.6/site-packages',
      '/usr/lib/python2.6/site-packages/setuptools-0.6c11-py2.6.egg-info']

   --- what is an egg?
     Same concept as a .jar file in Java, it is a .zip file with some metadata files renamed .egg,
     for distributing code as bundles

*----------------------------------------------------------------------------------------------------
* jquery drop down nested menu (12 feb 2016)

*----------------------------------------------------------------------------------------------------
* git-lfs, installed (12 feb 2016)

  /usr/local/bin/git-lfs 11037564 Feb 12 08:48
  git lfs install

  cd ~/github/GeneRegulationUtilities/data
  git lfs track "*.RData"

    # results in ~/github/GeneRegulationUtilities/data/.gitattributes
    *.RData filter=lfs diff=lfs merge=lfs -text

*----------------------------------------------------------------------------------------------------
* demo function for cory, now a package: footprintFinder (10 feb 2016)

   cd ~/s/work/priceLab/cory/footprintFinderExperiments
   scp pshannon@whovian:/local/Cory/trn/footprints/tfdb_1mb_GRCh38.83.bed .  # 19,548,652,509

  --- as package
    cd  ~/github/shGeneRegulationUtilities


*----------------------------------------------------------------------------------------------------
* cleveland ehc, on eager.systemsbiology.net (9 feb 2016)

   sudo -u www <your commands>
   sudo -u www -i   #  if you want to just run as the www user

  --- from russ (9 feb 2016)
   1. I've allowed your user to login to the see server (eager.systemsbiology.net) using ssh/scp/sftp
   2. I've created a directory in /local named ehc for your ehc app
   3. I've created a www user account for your app to run as and given you sudo rights to run commands as the www user
   4. I've installed R version 3.2.3
   5. I've configured apache to forward http requests for clevelandehc.systemsbiology.net on port 80 to port 7001.


   --- clone
     ssh pshannon@eager
     cd github
     git clone -b pshannon-refactor-server-2 https://github.com/FredHutch/Oncoscape.git

*----------------------------------------------------------------------------------------------------
* go slim, neo4j (9 feb 2016)

*----------------------------------------------------------------------------------------------------
* convert entrez geneIDs to hugo symbols, find first by chromloc chromosomal location (9 feb 2016)

  mef2c <- "4208"
   biocLite("TxDb.Hsapiens.UCSC.hg38.knownGene")
  library(TxDb.Hsapiens.UCSC.hg38.knownGene)
  txdb <- TxDb.Hsapiens.UCSC.hg38.knownGene
  genes.gr <- genes(txdb)
  genes.chr5.gr  <- genes.gr[seqnames(genes.gr) == "chr5"]
  mef2c.start <- start(genes.chr5.gr["4208"])   # [1] 88718241
  mef2c.end <-  end(genes.chr5.gr["4208"])      # [1] 88904105
  mef2c.mid <- mef2c.start + (mef2c.end - mef2c.start)/2
  halfSpan <- 5000000
  a <- mef2c.mid - halfSpan
  b <- mef2c.mid + halfSpan
  geneIds <- (unique(subset(genes.chr5.gr, start >= a & end <= b)$gene_id))
  syms <- select(org.Hs.eg.db, keys=geneIds, columns="SYMBOL")$SYMBOL   # 30 total

   [1] "ARRDC3-AS1"   "MIR2277"      "MIR4280"
   [4] "MIR3607"      "MIR3660"      "LOC100505878"
   [7] "TMEM161B-AS1" "LUCAT1"       "EDIL3"
  [10] "LOC101929380" "MEF2C-AS1"    "LOC102546226"
  [13] "POLR3G"       "CETN3"        "LYSMD3"
  [16] "POU5F2"       "COX7C"        "MBLAC2"
  [19] "TMEM161B"     "NBPF22P"      "MIR9-2"
  [22] "MEF2C"        "NR2F1-AS1"    "ARRDC3"
  [25] "RASA1"        "LINC00461"    "NR2F1"
  [28] "LOC731157"    "ADGRV1"       "CCNH"

*----------------------------------------------------------------------------------------------------
* cory on mef2c data

  mef2c_fimo: bed file, all the cis motifs in the region, about 4000
     (fimo is a motif finder within meme suite, uses jaspar pwms)

   mef2c2_all_fp: all the footprints in the encode

   MEF2C_snps: chr4, snp locations  (from mariette)

  MEF2C_fp: subset of footprints, those which intersect with MEF2C_fimo

*----------------------------------------------------------------------------------------------------
* bioc geneomStyles,

  seqlevelsStyle(wh) <- "NCBI"
  genomeStyles("Homo_sapiens")
       circular  auto   sex NCBI  UCSC dbSNP Ensembl
    1     FALSE  TRUE FALSE    1  chr1   ch1       1
    2     FALSE  TRUE FALSE    2  chr2   ch2       2
    3     FALSE  TRUE FALSE    3  chr3   ch3       3
    4     FALSE  TRUE FALSE    4  chr4   ch4       4
    5     FALSE  TRUE FALSE    5  chr5   ch5       5
    6     FALSE  TRUE FALSE    6  chr6   ch6       6
    7     FALSE  TRUE FALSE    7  chr7   ch7       7
    8     FALSE  TRUE FALSE    8  chr8   ch8       8
    9     FALSE  TRUE FALSE    9  chr9   ch9       9
    10    FALSE  TRUE FALSE   10 chr10  ch10      10
    11    FALSE  TRUE FALSE   11 chr11  ch11      11
    12    FALSE  TRUE FALSE   12 chr12  ch12      12
    13    FALSE  TRUE FALSE   13 chr13  ch13      13
    14    FALSE  TRUE FALSE   14 chr14  ch14      14
    15    FALSE  TRUE FALSE   15 chr15  ch15      15
    16    FALSE  TRUE FALSE   16 chr16  ch16      16
    17    FALSE  TRUE FALSE   17 chr17  ch17      17
    18    FALSE  TRUE FALSE   18 chr18  ch18      18
    19    FALSE  TRUE FALSE   19 chr19  ch19      19
    20    FALSE  TRUE FALSE   20 chr20  ch20      20
    21    FALSE  TRUE FALSE   21 chr21  ch21      21
    22    FALSE  TRUE FALSE   22 chr22  ch22      22
    23    FALSE FALSE  TRUE    X  chrX   chX       X
    24    FALSE FALSE  TRUE    Y  chrY   chY       Y
    25     TRUE FALSE FALSE   MT  chrM  chMT      MT


*----------------------------------------------------------------------------------------------------
* Gviz, gene model, footprints, snps for mef2c (8 feb 2016)

   cd ~/s/work/cory/snpfp/mef2c/

   --- demo sent to hector, for reproduction in epivizr
     cd ~/s/work/cory/snpfp/mef2c/forHector

     14793 Feb 12 10:19 footprints.chr5.granges.RData
      1138 Feb 12 10:42 forHector.R
      1406 Feb 12 10:41 snpsDelta.granges.RData

*----------------------------------------------------------------------------------------------------
* ggbio, gene model, footprints, snps for mef2c (8 feb 2016)

  [abandoned.  too many things did not work]

  cd ~/s/work/cory/snpfp/mef2c/
  library(ggbio)
  library(Homo.sapiens)
  library(BSgenome.Hsapiens.NCBI.GRCh38)
  seqlevelsStyle(BSgenome.Hsapiens.NCBI.GRCh38) <- "UCSC"

  data(genesymbol, package="biovizBase")
   --- display gene model, with 7 splice variants
    wh <- genesymbol["MEF2C"]
    wh
       GRanges object with 1 range and 2 metadata columns:
               seqnames               ranges strand |      symbol      ensembl_id
                  <Rle>            <IRanges>  <Rle> | <character>     <character>
         MEF2C     chr5 [88014058, 88199922]      - |       MEF2C ENSG00000081189
         -------
         seqinfo: 45 sequences from an unspecified genome; no seqlengths

    autoplot(Homo.sapiens, which = wh, label.color = "black", color = "brown",fill = "brown")

  library(BSgenome.Hsapiens.NCBI.GRCh38)
  bg <- BSgenome.Hsapiens.NCBI.GRCh38   # for convenience

*----------------------------------------------------------------------------------------------------
* borges' chinese taxonomy (8 feb 2016)

  1) Those that belong to the emperor
  2) Embalmed ones
  3) Those that are trained
  4) Suckling pigs
  5) Mermaids (or Sirens)
  6) Fabulous ones
  7) Stray dogs
  8) Those that are included in this classification
  9) Those that tremble as if they were mad
  10) Innumerable ones
  11) Those drawn with a very fine camel hair brush
  12) Et cetera
  13) Those that have just broken the flower vase
  14) Those that, at a distance, resemble flies


*----------------------------------------------------------------------------------------------------
* display footprints and snps together for mef2c

  me2fc:  chr5:88,717,117-88,904,257   187kbp
  cd ~/s/work/cory/snpfp/mef2c

  scp pshannon@whovian:/local/Cory/trn/working/for_seth/MEF2C_* .

  ./loop.sh MEF2C_fp MEF2C_snps 1


*----------------------------------------------------------------------------------------------------
* neo4j learn match and pattern on brain12 trn (8 feb 2016)  weight > 0.0, looking for APOE

  cd ~/s/work/cory/brain12trn/
  reload(); fill.prep(0.0)
     [1] writing tbl.interactions, 179412 x 3 to interactions.tsv
     [1] writing tbl.molecules,    14336 x 4 to molecules.tsv

  make clear fill report:
    14335 nodes, 179411 edges

  start neo4j-shell
    match(a)-[r {type: 'regulates'}]->(b {name:'APOE'})  return a.name, b.name, r.type, r.weight;


  --- now try this in R
    see ~/s/work/cory/brain12trn/query.R:
     if(!exists("gdb"))
       gdb <- startGraph("http://localhost:7474/db/data/", username="neo4j", password="isb");

     *-----------------------------------------------------------------------------------------------------------------------
     findRegulators <- function(target) {
       query <- "match(a)-[r {type: 'regulates'}]->(b {name: {name}})  return a.name, b.name, r.type, r.weight"
       result <- cypherToList(gdb, query, name=target)
       tbl.result <- ldply(result, data.frame, stringsAsFactors=FALSE)
       tbl.result$r.weight <- as.numeric(tbl.result$r.weight)
       tbl.result
       } # findRegulators

     findTargets <- function(regulator){
       query <- "match(a {name: {name}})-[r {type: 'regulates'}]->(b)  return a.name, b.name, r.type, r.weight"
       result <- cypherToList(gdb, query, name=regulator)
       tbl.result <- ldply(result, data.frame, stringsAsFactors=FALSE)
       tbl.result$r.weight <- as.numeric(tbl.result$r.weight)
       tbl.result
       } # findTargets

   findRegulators("APOE")
        a.name b.name    r.type   r.weight
   1   TEAD3   APOE regulates 0.07893624
   2    ZHX3   APOE regulates 0.01587308
   3  TCF7L1   APOE regulates 0.22415536
   4  SREBF1   APOE regulates 0.20210029
   5  NFE2L2   APOE regulates 0.03381679
   6   NR1H3   APOE regulates 0.42315041
   7     NRL   APOE regulates 0.20147364
   8    KLF1   APOE regulates 0.01318050
   9   KLF15   APOE regulates 0.03873119
   10   BATF   APOE regulates 0.11565688

   tbl.nr1h3 <- findTargets("NR1H3")  # 472 x 4
   head(tbl.nr1h3[(order(tbl.nr1h3$r.weight, decreasing=TRUE)),])
         a.name   b.name    r.type  r.weight
     472  NR1H3   TDRD10 regulates 0.5234681
     47   NR1H3 C17orf89 regulates 0.4500173
     298  NR1H3     PGLS regulates 0.4409612
     30   NR1H3   ALG1L2 regulates 0.4293711
     390  NR1H3    TTC22 regulates 0.4265322
     39   NR1H3     APOE regulates 0.4231504

   see if any of these are correlated in expression with apoe
   nr1h3, pmid 22027013: Genetic analysis of genes involved in amyloid-β degradation and clearance in Alzheimer's disease.

*----------------------------------------------------------------------------------------------------
* neo4j learn match and pattern on brain12 trn (8 feb 2016)  weight > 0.5

  cd ~/s/work/cory/brain12trn/
  reload(); fill.prep(0.5)
     [1] writing tbl.interactions, 1791 x 3 to interactions.tsv
     [1] writing tbl.molecules,    2044 x 4 to molecules.tsv

  make clear
  make fill
  make report #     2044 nodes,   1791 edges

  --- cat makefile
     njshell = /Applications/Neo4j\ Community\ Edition.app/Contents/Resources/app/bin/neo4j-shell
     clear:
     	$(njshell) -file clear.cql -v
     fill:
     	$(njshell) -file fill.cql -v
     report:
     	R -f reportCypher.R



  ----  prepare to export, in neo4j-shell
   match(n) return(count(n));          // 2044
   match(a)-[r]->(b) return(count(r)); // 1791
   match(a)-[r]-(b)  return(count(r)); // 3582
   match(a)-[r]-(b)  return(r) limit 1; // :Interaction[87589]{weight:"0.773734647861828",type:"regulates"}
   match(a {name:'RFX2'})-[r]-(b {name:'TEKT1'})  return(r); // :Interaction[88175]{weight:"1.00766473348977",type:"regulates"}
   match(a {name:'RFX2'})-[r:Interaction]-(b {name:'TEKT1'}) return(r);
         //  :Interaction[88175]{weight:"1.00766473348977",type:"regulates"}
   match(a {name:'RFX2'})-[r:Interaction {type: 'regulates'}]-(b {name:'TEKT1'}) return(r);
         //  :Interaction[88175]{weight:"1.00766473348977",type:"regulates"}
   match(a {name:'RFX2'})-[r {type: 'regulates'}]-(b {name:'TEKT1'})  return(r);
         //  :Interaction[88175]{weight:"1.00766473348977",type:"regulates"}

   neo4j-shell -c dump > x.cypher






*----------------------------------------------------------------------------------------------------
* neo4j, rneo4j: learn the match command, from R (8 feb 2016)

  --- install the movie database, full version

    cd ~/s/data/neo4j/movies/
    curl -O http://example-data.neo4j.org/files/cineasts_12k_movies_50k_actors_2.1.6.zip # 25 MB
    unzip cineasts_12k_movies_50k_actors_2.1.6.zip
    creates ~/s/data/neo4j/movies/cineasts_12k_movies_50k_actors.db/

  --- run shell on movie database
    neo4j-shell -path cineasts_12k_movies_50k_actors.db -config neo4j.config
    (using ~/bin/neo4j-shell and neo4j.config: allow_store_upgrade=true)

  --- match (http://neo4j.com/docs/stable/query-match.html)
    match(n) return (count(n));   63042

*----------------------------------------------------------------------------------------------------
* macos java jvm command line version (8 feb 2016)

  problem: Unable to find any JVMs matching version "1.7". when running neo4j-shell from R via make
  suspect: see this analysis from oracle:

  [https://java.com/en/download/help/version_manual.xml#cmdline]

Using the Command-line to find Java Versions - Mac OS X

The Java Runtime (JRE) that you download from java.com or oracle.com contains a plugin to run Java content from your browser. In order to use the command line tools, you will need to download the Java Development Kit (JDK). The JRE and JDK are separate and can coexist on your system. Only one JRE can be installed on Mac OS X. There can be multiple JDKs installed on a system, as many as you wish.

JRE Version Command Line on Mac OS X
Type the following in a Terminal window:
/Library/Internet\ Plug-Ins/JavaAppletPlugin.plugin/Contents/Home/bin/java -version

Determining the Default Version of the JDK on Mac OS X
When launching a Java application through the command line, the system uses the default JDK. It is possible for the version of the JRE to be different than the version of the JDK.

You can determine which version of the JDK is the default by typing java -version in a Terminal window. If the installed version is 7u55, you will see a string that includes the text 1.7.0_55. For example:

java -version
java version "1.7.0_55"
Java(TM) SE Runtime Environment (build 1.7.0_55-b13)
Java HotSpot(TM) 64-Bit Server VM (build 24.55-b03, mixed mode)

*----------------------------------------------------------------------------------------------------
* RNeo4j tips: all functions

ls(search()[3])
 [1] "addConstraint"    "addIndex"         "addLabel"         "allDijkstra"
 [5] "allShortestPaths" "appendCypher"     "browse"           "clear"
 [9] "commit"           "createNode"       "createRel"        "cypher"
[13] "cypherToList"     "delete"           "deleteProp"       "dijkstra"
[17] "dropConstraint"   "dropIndex"        "dropLabel"        "endNode"
[21] "getConstraint"    "getID"            "getIndex"         "getLabel"
[25] "getLabeledNodes"  "getNodes"         "getOrCreateNode"  "getPaths"
[29] "getRels"          "getSingleNode"    "getSinglePath"    "getSingleRel"
[33] "getType"          "getUniqueNode"    "importSample"     "incomingRels"
[37] "newTransaction"   "nodes"            "outgoingRels"     "rels"
[41] "shortestPath"     "startGraph"       "startNode"        "updateProp"
>
*----------------------------------------------------------------------------------------------------
* rneo4j tips (8 feb): shortestPath

  [using graph created in ~/s/work/cory/brain12trn/go.R"

  query <- "match (m:Molecule {name:{name}}) return m"
  rfx2 <- getSingleNode(gdb, query, name = "RFX2")
  tekt1 <- getSingleNode(gdb, query, name = "TEKT1")

  startNode(outgoingRels(rfx2)[[1]])$name  # [1] "RFX2"
  endNode(outgoingRels(rfx2)[[1]])$name    # [1] "CCDC60"
  endNode(outgoingRels(rfx2)[[2]])$name   # [1] "TEKT1"

  startNode(incomingRels(tekt1)[[1]])$name  # [1] "RFX2"
  endNode(incomingRels(tekt1)[[1]])$name    # [1] "TEKT1"

  but:
    length(shortestPath(rfx2, "regulates", tekt1))  # [1] 0

   --- try as a native cql query:
     [from http://www.markhneedham.com/blog/2015/05/19/neo4j-finding-all-shortest-paths]

   query <- "MATCH (m1:Molecule {name: {source}}), (m2:Molecule {name: {target}}), path = shortestpath((m1)-[r]-(m2)) RETURN path"
   query <- "MATCH (m1:Molecule {name: {source}}), (m2:Molecule {name: {target}}), path = shortestpath((m1)-[r]-(m2)) RETURN nodes(path)"
   query <- "MATCH (m1:Molecule {name: {source}}), (m2:Molecule {name: {target}}), path = shortestpath((m1)-[r]-(m2)) RETURN relationships(path)"
   path <- cypherToList(gdb, query, source="RFX2", target="TEKT1")

   hard to parse that path object into a useful R object.  therefore try web interface:
    MATCH (m1:Molecule {name: 'RFX2'}), (m2:Molecule {name: 'TEKT1'}), path = shortestpath((m1)-[r]-(m2)) RETURN path
    returns 2 molecules and 1 interaction

    query <- "MATCH (m1:Molecule {name: 'RFX2'}), (m2:Molecule {name: 'TEKT1'}), path = shortestpath((m1)-[r]-(m2)) RETURN path"
    path <- cypherToList(gdb, query)
    path   # [[1]]
           # [[1]]$path
           # < Path >
           #$length
           # [1] 1


   -- next: create a dataframe of  source, target, relationship, weight of all the interactions in the shortest path


*----------------------------------------------------------------------------------------------------
* neo4j tips: list all nodes and edges


*----------------------------------------------------------------------------------------------------

*----------------------------------------------------------------------------------------------------
* rneo4j tips (8 feb): getSingleNode, getNodes

  [using graph created in ~/s/work/cory/brain12trn/go.R"
  query <- "match (m:Molecule {name:{name}}) return m"
  getSingleNode(gdb, query, name = "RFX2")
   < Node > Molecule
   $id [1] "RFX2"
   $name [1] "RFX2"
   $subtype [1] "tf"
   $type [1] "gene"

   length(getNodes(gdb, query, name = "RFX2")) # [1] 1

   --- ?getSingleNode has instructive query for finding oldest person
     query = "MATCH (p:Person)
                      WITH p
                      ORDER BY p.age DESC
                      RETURN p
                      LIMIT 1"
     getSingleNode(graph, query)


*----------------------------------------------------------------------------------------------------
* RNeo4j tips (7 feb 2016)

  --- ~/s/examples/neo4j/R/demo.R
   calls startGraph, createNode, createRel, query via cypher of several types
   shortestPath,

   --- get an aleady created node for, e.g., shortestPath

    rfx2 <-  getOrCreateNode(gdb, "Molecule", id="RFX2")
         < Node >  Molecule
          $id [1] "RFX2"
          $name [1] "RFX2"
          $subtype [1] "tf"
          $type [1] "gene"
    ccdc60 <- getOrCreateNode(gdb, "Molecule", id="CCDC60")

    in db filled with nodes via this cql:
    LOAD CSV WITH HEADERS FROM
      "file:///Users/paul/s/work/cory/brain12trn/molecules.tsv"
       AS line FIELDTERMINATOR '\t'
       create (:Molecule {id: line.id, name: line.name, type: line.type, subtype: line.subtype});

     --- getRels
        getRels(gdb, "MATCH(:Molecule {name:{name}})-[r]->(target)return target", name="RFX2")
        [[1]] < Node >  Molecule
          $id[1] "TEKT1"
          $subtype [1] "generic"
          $name [1] "TEKT1"
          $type [1] "gene"
        [[2]] < Node >  Molecule
          $id[1] "CCDC60"
          $subtype [1] "generic"
          $name [1] "CCDC60"
          $type [1] "gene"


     --- shortestPath  (doesn't work yet, see  http://neo4j.com/docs/stable/query-match.html)
       shortestPath(rfx2, "regulates", ccdc60, direction="all", max_depth=3)


     --- create a shortestPath convenience function, joining graphNEL and rneo4j
        sp <- function(a, b){
           stopifnot(a %in% graph::nodes(g))
           stopifnot(b %in% graph::nodes(g))
           node.a <- getOrCreateNode(gdb, "molecule", name=a)
           node.b <- getOrCreateNode(gdb, "molecule", name=b)
           path <- shortestPath(node.a, "regulates", node.b, direction="all")
           }

        test.sp <- function() {
           p <- sp("SPI1", "NCF1")
           checkEquals(p$length, 1)
           checkEquals(sort(unlist(lapply(nodes(p), function(element) element$name))), c("NCF1", "SPI1"))
           checkEqualsNumeric(rels(p)[[1]]$weight, 0.3000525, tol=10e-4)
           checkEquals(attributes(rels(p)[[1]])$type, "regulates")
           } # test.sp



*----------------------------------------------------------------------------------------------------
* cory's 12-region brain trn, 1200 gtex rna samples (5 feb 2016)

  cd ~/s/work/cory/brain12trn
  scp pshannon@whovian:/local/Cory/gtex/trn/gtex_brain_trn.RData .     3.5G
  print(load("gtex_brain_trn.RData"))  # [1] "trn0_brain" "trn.rtrim"
  names(trn0_brain)
     [1] "fits.proximal"                 "fits.distal"
     [3] "actual.expression"             "predicted.expression"
     [5] "predicted.expression.proximal" "beta.coefficients"
     [7] "r2.predVactual"                "r2.predVactual.proximal"
     [9] "location"
  dim(trn.rtrim)  # [1] 14256   637
  mtx <- trn.rtrim
  length(which(mtx > 0)) [1] 179411
  length(which(mtx > 0))/ (dim(mtx)[1] * dim(mtx)[2])  # 20% of possible edges are non-zero 0.01975659
  fivenum(mtx[which(mtx > 0)])   # [1] 0.01000005 0.03359509 0.06893328 0.13505386 1.19448007

  --- transform these into neo4j nodes and relations
    follow recon2 example in   ~/s/data/priceLab/recon2/

*----------------------------------------------------------------------------------------------------
* pca plot example for cory, with colored dots and labels, from expression data (4 feb 2016) mds, cmdscale also

   cd ~/s/examples/R/pca/forCory/
   go.R

*----------------------------------------------------------------------------------------------------
* neo4j, trena, cypher, RCyjs experiments (4 feb 2016)

  cd ~/s/work/cory/gbmTRN    go.R

  also: cd ~/s/examples/neo4j/tfs


*----------------------------------------------------------------------------------------------------
* renv, from dan (4 feb 2016)

  https://github.com/dtenenba/renv
  installed ruby script renv in ~/bin
  cd /Library/frameworks

    lrwxr-xr-x   1 root  wheel    37 Feb  4 10:10 R.framework -> /Library/Frameworks/R.framework.300ud
    drwxrwxr-x   8 root  admin   272 Feb  4 10:01 R.framework.300ud/
    drwxrwxr-x   8 root  admin   272 Feb  3 17:12 R.framework.323/

    bash> renv
    *300ud 3.3.0 70074 Under development (unstable) 2016-02-02 darwin13.4.0
    323 3.2.3 69752 (none) 2015-12-10 darwin13.4.0

   --- install a new version of R
     cd /Library/frameworks
     sudo rm R.framework (which should only be a symlink)
     <install new version>
     mv R.framework R.framework.331
     renv 331

*----------------------------------------------------------------------------------------------------
* seth's workflow and task suggestions (10 feb 2016)

   /proj/price1/sament/human_aba/README.human_brain_trn.txt
   cd ~/Documents
   scp pshannon@whovian:/proj/price1/sament/human_aba/README.human_brain_trn.txt .
   wc -l ~/Documents/README.human_brain_trn.txt   # 45 lines

*----------------------------------------------------------------------------------------------------
* install seth's trena package (3 feb 2016)

  version 1.0, putatively from 2015-05-18

  cd ~/s/work/cory/cory-trena
  R CMD install trena
  or
  R CMD ~/s/work/cory/cory-trena/install trena

*----------------------------------------------------------------------------------------------------
* build igraph from source, cannot find libXML2.2.dylib (3 feb 2016)

   biocLite("igraph")  # after upgrading to R devel, 3.3.0 in the making

  Error in dyn.load(file, DLLpath = DLLpath, ...) : unable to load shared object
    '/Library/Frameworks/R.framework/Versions/3.3/Resources/library/igraph/libs/igraph.so':
    dlopen(/Library/Frameworks/R.framework/Versions/3.3/Resources/library/igraph/libs/igraph.so,
    6): Library not loaded: libxml2.2.dylib
    Referenced from:
     /Library/Frameworks/R.framework/Versions/3.3/Resources/library/igraph/libs/igraph.so

   but since R install cleans up after itself, dan's recommended strategy did not work:

    Find igraph.so ( look in the igraph directory under .LibPaths()).
    Then do
       otool -L igraph.so |grep libxml2
    That will give you the path where it is looking for libxml2, it may not match
    what is in DYLD_LIBRARY_PATH. Copy or symlink your existing library to that
    location and try again.

  --- next attempt a solution: get source tarball, try again.  location of libxm2.2 we can now see, is incorrect

    R CMD install --no-clean-on-error igraph_1.0.1.tar.gz

     otool -L igraph.so | head
       igraph.so:
         igraph.so (compatibility version 0.0.0, current version 0.0.0)
         libxml2.2.dylib (compatibility version 12.0.0, current version 12.2.0)
         libz.1.dylib (compatibility version 1.0.0, current version 1.2.8)
         /usr/lib/libiconv.2.dylib (compatibility version 7.0.0, current version 7.0.0)

      --> install is looking for libxml2.2.dylib in the current directory, not in /usr/lib/ where
          it actually is, and from which other libraries are found.

   --- yet another try, suggested by dan
      establish that the path to libxml2.2.dylib is indeed wrong:
      otool -L igraph.so | grep xml
	libxml2.2.dylib (compatibility version 12.0.0, current version 12.2.0)
      verify that it is where it is supposed to be:
          2395024 Dec  2 22:35 /usr/lib/libxml2.2.dylib
      now change igraph.so
        install_name_tool -change libxml2.2.dylib /usr/lib/libxml2.2.dylib igraph.so
      verify the change
        otool -L igraph.so | grep xml
           /usr/lib/libxml2.2.dylib (compatibility version 12.0.0, current version 12.2.0)
   --- but it fails
     unable to load shared object '/Library/Frameworks/R.framework.300ud/Versions/3.3/Resources/library/igraph/libs/igraph.so':
     dlopen(/Library/Frameworks/R.framework.300ud/Versions/3.3/Resources/library/igraph/libs/igraph.so, 6): Library not loaded: /usr/lib/libxml2.2.dylib
     Referenced from: /Library/Frameworks/R.framework.300ud/Versions/3.3/Resources/library/igraph/libs/igraph.so
     Reason: Incompatible library version: igraph.so requires version 12.0.0 or later, but libxml2.2.dylib provides version 10.0.0




*----------------------------------------------------------------------------------------------------
* seth's collaboration topics (3 feb 2016)

  ~/s/notes/README.human_brain_trn.txt

*----------------------------------------------------------------------------------------------------
* igraph tips, dynamic library load problem LD_LIBRARY_PATH

  --- from dan
    Find igraph.so ( look in the igraph directory under .LibPaths()).
    Then do
       otool -L igraph.so |grep libxml2
    That will give you the path where it is looking for libxml2, it may not match what is in DYLD_LIBRARY_PATH.
    Copy or symlink your existing library to that location and try again.


*----------------------------------------------------------------------------------------------------
* coryTry0: use epivizr on footprints

  cd ~/s/examples/bioc/epivizr/coryTry0/

   here is the file that has all the footprints:  /local/Cory/trn/footprints/tfdb_1mb_GRCh38.83.bed
   Seth made a motif-to-tf map here:
      /local/sament/tfbs/human_brain/motif_to_tf_mappings_with_tfclass_include_multiple.csv
   To find the TSS for a gene, I made the following file:
      /local/Cory/trn/working/for_seth/GRCh38.83.tss.bed
   COL6A1 has several TSSs (I found them by grepping ENSG00000142156 on the tss file).

   chr21:45,971,737-46,015,050

   --- import of supplied file reports error, try just chr21

      grep "^21" tfdb_1mb_GRCh38.83.bed > tmp

   --- closer look reveals unorthodox but fixable format

     chr       search region  gene           ?       chr      start   end   score strand     name
     21      4011799 6011799 ENSG00000279493 1       21      5011618 5011630 51.2    +       MA0813.1
     21      4011799 6011799 ENSG00000279493 1       21      5021865 5021879 53      -       MA0697.1
     21      4011799 6011799 ENSG00000279493 1       21      5021865 5021879 51.4    -       MA0751.1
     21      4011799 6011799 ENSG00000279493 1       21      5021953 5021967 52.3    -       MA0516.1
     21      4011799 6011799 ENSG00000279493 1       21      5021954 5021967 56.4    -       MA0162.2


   canonical bed + 3
      chrom:  chrN
      chromStart
      chromEnd
      name
      score
      strand

   tbl.21 <- read.table("chr21.bed", sep="\t", as.is=TRUE);  dim(tbl.21)  # [1] 930769     22
   tbl.21fixed <- tbl.21[, c(6, 7, 8, 11, 9, 10)]
   colnames(tbl.21fixed) <- c("chrom", "chromStart", "chromEnd", "name", "score", "strand")
   tbl.21fixed$chrom <- paste("chr", tbl.21fixed$chrom, sep="")


    --- a smaller example
      grep ENSG00000142156 chr21.bed > COL6A1.bed
     tbl.col6a1 <- read.table("col6a1.bed", sep="\t", as.is=TRUE)
     tbl.col6a1.fixed <- tbl.col6a1[, c(6, 7, 8, 11, 9, 10)]
     colnames(tbl.col6a1.fixed) <- c("chrom", "chromStart", "chromEnd", "name", "score", "strand")
     tbl.col6a1.fixed$chrom <- paste("chr", tbl.col6a1.fixed$chrom, sep="")

     head(tbl.col6a1.fixed)
     chrom chromStart chromEnd     name score strand
  1 chr 21   44982832 44982839   MAZ.p2  50.9      +
  2 chr 21   44982833 44982843 MA0471.1  53.4      +
  3 chr 21   44982834 44982842 GTF2I.p2  56.5      +
  4 chr 21   44982894 44982908 MA0591.1  52.9      -
  5 chr 21   44982895 44982905 MA0478.1  51.3      +
  6 chr 21   44982895 44982905 MA0490.1  52.0      +

   write.table(tbl.col6a1.fixed, file="footprints.col6a1.tsv", row.names=FALSE, col.names=FALSE, quote=FALSE, sep="\t")
     5647 lines
   xx <- import(BEDFile("footprints.col6a1.tsv"))
   xx
   GRanges object with 5646 ranges and 2 metadata columns:
            seqnames               ranges strand |        name     score
               <Rle>            <IRanges>  <Rle> | <character> <numeric>
        [1]    chr21 [44982833, 44982839]      + |      MAZ.p2      50.9
        [2]    chr21 [44982834, 44982843]      + |    MA0471.1      53.4
        [3]    chr21 [44982835, 44982842]      + |    GTF2I.p2      56.5
        [4]    chr21 [44982895, 44982908]      - |    MA0591.1      52.9
        [5]    chr21 [44982896, 44982905]      + |    MA0478.1      51.3
        ...      ...                  ...    ... .         ...       ...
     [5642]    chr21 [46006268, 46006277]      - |    MA0741.1      58.1
     [5643]    chr21 [46006268, 46006277]      - |    MA0746.1      59.0
     [5644]    chr21 [46006269, 46006277]      + |    MA0039.2      63.8
     [5645]    chr21 [46006269, 46006278]      - |    MA0493.1      52.8
     [5646]    chr21 [46006269, 46006277]      - |    MA0599.1      58.0
     -------
     seqinfo: 1 sequence from an unspecified genome; no seqlengths

   table(width(xx))
   7    8    9   10   11   12   13   14   15   16   17   18   19   20   24   28
  93  190  846 1203  352  400  681  699  185  191  261   82  186  237   16   24


*----------------------------------------------------------------------------------------------------
* maike aurich's explanation of data in the recon204 + gut biome + metabolic diseases matlab data network

   see email:  "structure of the Matlab recon2 (and etc.) data?"  reply (2 feb 2016)

   Length provides insight into which vector the variable is associated to rxns (reactions)=7440, mets(metabolites)=5063, genes=2194.

   --- Matrices
      S– matrixofreactionstoichiometry(associatesmetabolitesandreactions) rxnGeneMat – matrix for association of reactions and genes

   --- Reaction variables

      rxns – reaction abbreviations (same as you find in the database) rxnsNames – full reaction name
      subSystems – sorts reactions into ‘metabolic subsystem/pathways’ rxnsKeggID – Kegg ID
      rxnECNumbers – E.C. numbers (enzyme identifyer)
      rxnsConfidenceScore – depends on the support (literature/experimental) that is associated with the reaction (check Nature Protokol Table 2)
      rxnsConfidenceEcoIDA – alternative confidence scoring system recon 2 (explained in the supplement of recon 2 paper) Evidence Code Ontology, an ontology created by the Gene Ontologyconsortium
      rxnReferences – references associated with the reaction rxnNotes – comments on reactions

   ---- Variables for modeling (reactions)

      rev – reaction reversibility
      rules – Gene-Proteine-reaction associations
      grRules - Gene-Proteine-reaction associations
      b - equality constraint (nothing should be consumed or produced, for optimization) c – vector specifying the objective
      lb – lower bound (reaction constraint)
      ub – upper bound (reaction constraint)

   --- Concerning metabolites
      mets - metabolite abbreviations (human metabolism database) metNames - metabolite Name (human metabolism database) metFormula - metabolite Formula
      metCharge – metabolite charge
      metCHEBIID - metabolite identifier
      metKeggID - metabolite identifier
      metpubChemID - metabolite identifier
      metInchiString - metabolite identifier
      metHMDB - metabolite identifier
      metHepatoNetID- metaboliteIDinHepatonet-appliestothosemetabolitesthatoriginatefrom Hepatonet
      metEHMNID - metabolite ID in EHMNID - applies to those metabolites that originate from Hepatonet

   --- Boolean vectors (to easily identify reaction sets)
      ExchRxnBool–(probablyredundantforEXRxnBool,doesnotidentifyanyreaction) EXRxnBool – identifies exchange reactions
      DMRxnBool - identifies demand reactions
      SinkRxnBool - identifies sink reactions
      SIntRxnBool - identifies internal reactions



*----------------------------------------------------------------------------------------------------
* r tips: extract R code from a knitr markdown file

  file.exists(system.file(package="epivizr", "doc", "IntroToEpivizr.Rmd"))
  library(knitr)
  purl(system.file(package="epivizr", "doc", "IntroToEpivizr.Rmd"))

*----------------------------------------------------------------------------------------------------
* python simple http server (1 feb 2016)

   old: python -m  SimpleHTTPServer <port>
   new: python -m http.server <port>
*----------------------------------------------------------------------------------------------------
* create ssh keys between riptide and whovian (1 feb 2016)

  riptide>
    cd;   ssh-keygen -b 1025 -t rsa
    scp .ssh/id_rsa.pub pshannon@whovian:tmp/

  whovian>
    create ~/.ssh
    append id_rsa.pub to ~/.ssh/authorized_keys
    chmmod 700 ~/.ssh
    chmod 600 ~/.ssh/authorized_keys

   ---

*----------------------------------------------------------------------------------------------------
* matrix subset, after filtering as.vector by threshold (1 feb 20160

  cd ~/s/work/cory/gbmTRN/

  print(load("tcga.trn.prodxist.RData"))
  fivenum(trn.rtrim)   # -0.5082266  0.0000000  0.0000000  0.0000000  0.7175353
  threshold <- 0.5
  threshold <- 0.65
  indices <- which(trn.rtrim > threshold)
  mtx <- trn.rtrim
  rows <- unique(1 + (indices - 1) %% nrow(mtx))
  cols <- unique(1 + (indices -1) %/% nrow(mtx))
  mtx.top <- mtx[rows, cols]   # 8 x 8


#               ELF3     FOXM1     GRHL2    HOXD12      IRF6
# ESRP2   0.70553104 0.0000000 0.0000000 0.0000000 0.0000000
# LSR     0.67745841 0.0000000 0.0000000 0.0000000 0.0000000
# ASPM    0.00000000 0.7036587 0.0000000 0.0000000 0.0000000
# NUSAP1  0.00000000 0.6585088 0.0000000 0.0000000 0.0000000
# SPAG5   0.00000000 0.6726775 0.0000000 0.0000000 0.0000000
# ALDH3B2 0.00000000 0.0000000 0.6944855 0.0000000 0.0000000
# GNAT3   0.00000000 0.0000000 0.0000000 0.6520412 0.0000000
# GRHL2   0.05940236 0.0000000 0.0000000 0.0000000 0.7175353



*----------------------------------------------------------------------------------------------------
* alex stupin recommends mongoose (python) over cobra (also python) (1 feb 2016)

  nature paper:
     http://www.nature.com/ncomms/2014/141007/ncomms5893/full/ncomms5893.html
  website:
     http://groups.csail.mit.edu/cb/mongoose/

*----------------------------------------------------------------------------------------------------
* cory's first trn project (1 feb 2016)

     mtx.deg (aka topDEGs$table): 1500 x 5, most deg when most active TWIST1 samples are
        compared to the least active TWIST1 samples

                    logFC   logCPM        LR       PValue          FDR
        TWIST1 -1.6030088 6.768507 201.09261 1.206154e-45 1.596586e-41
        COL6A3 -0.9951046 6.850813  90.68677 1.683145e-21 1.113990e-17
        MFAP2  -0.8852914 6.561603  56.31734 6.166926e-14 2.721053e-10
        TDO2   -0.8829902 6.554340  55.66277 8.603239e-14 2.847027e-10
        TFPI2  -0.9637676 6.254009  49.61160 1.874022e-12 4.154439e-09
        PCOLCE -0.6770598 7.011692  49.60212 1.883103e-12 4.154439e-09
        ....

    tbl.twist (aka twist_enrich) 375 tfs, ranked by association with the degs

    fivenum(trn.rtrim[, "FOSL2"])
          PTPN4     DPYSL4      MDFIC     SEMA5A      LOXL2
     -0.2074487  0.0000000  0.0000000  0.0000000  0.3763563


   all the files are again located on whovian: /local/Cory/trn/working/for_Paul/


  --- tcga_adj_trn.R
     used to normalize the TCGA data:

  --- tcga_cel_norm_deg.R
     Here is the script I used to create the list of DEGs (the top/bottom 10% of TWIST expressing samples):


  ---- topDEGs.RData
     using twist expression, find the top 10% of TCGA samples.  find the bottom 10%.
     use edgeR to compare these sample groups, identifying the 200 most differentially expressed genes

     Since I'm not sending you the cel files, here is the output from the script above:
     I then get the the top 200 genes from topDEGs and do the following function (from trena):
     twist_enrich <- setEnrich(trn.rtrim, top_twist, universe = NULL)
     This gives me the following file (sort of--I'll explain below):
          twist_enrich.RData

      for the twist_enrich.RData, I actually did something slightly different. I went into the giant
      correlation matrix Seth builds called trn.rtrim and pulled out the correlation values for everything
      relative to TWIST. I took the top 200 genes from this list to run through the setEnrich function. You
      should be able to reproduce my exact list (twist_enrich.RData) by doing this.

*------------------------------------------------------------------------------------------------------------------------
* cory's first alzheimer's trn (1 feb 2016)

   cd ~/s/work/cory/alzheimersTRN/
   scp pshannon@whovian:/local/Cory/trn/working/for_Paul/tcga.trn.prodxist.RData .

   print(load("tcga.trn.prodxist.RData"))  # [1] "trn0"      "trn.rtrim"
   dim(trn.rtrim)  # [1] 4356  582

   lapply(trn0, length)
      $fits.proximal: [1] 13237
      $fits.distal: [1] 13237
      $actual.expression: [1] 7386246
      $predicted.expression: [1] 7386246
      $predicted.expression.proximal: [1] 7386246
      $beta.coefficients: [1] 8431969
      $r2.predVactual: [1] 13237
      $r2.predVactual.proximal: [1] 13237
      $location: [1] 8431969

     fivenum(trn.rtrim)  # [1] -0.5082266  0.0000000  0.0000000  0.0000000  0.7175353
     length(which(trn.rtrim > 0.5))

     trn.rtrim[1:10, 1:10]

             ADNP ADNP2 AHR AIRE ALX1 ALX3 ALX4 AR     ARID1A ARID3A
      MARCH1    0     0   0    0    0    0    0  0 0.00000000      0
      SEPT11    0     0   0    0    0    0    0  0 0.00000000      0
      SEPT2     0     0   0    0    0    0    0  0 0.00000000      0
      MARCH3    0     0   0    0    0    0    0  0 0.00000000      0
      SEPT4     0     0   0    0    0    0    0  0 0.00000000      0
      MARCH5    0     0   0    0    0    0    0  0 0.00000000      0
      MARCH6    0     0   0    0    0    0    0  0 0.05447751      0
      MARCH7    0     0   0    0    0    0    0  0 0.00000000      0
      SEPT7     0     0   0    0    0    0    0  0 0.00000000      0
      MARCH8    0     0   0    0    0    0    0  0 0.14718161      0

    length(which(trn.rtrim > 0.5)) [1] 95
    length(which(trn.rtrim > 0.65)) [1] 8

    --- for a first look, get just these 8 reactions out into a data.frame
      indices <- which(trn.rtrim > 0.65)
      mtx <- trn.rtrim
      rows <- 1 + (indices - 1) %% nrow(mtx)
      cols <- 1 + (indices -1) %/% nrow(mtx)
      vals = unlist(lapply(1:length(indices), function(i) mtx[rows[i], cols[i]]))

data.frame(row=rownames(mtx)[rows],
col=colnames(mtx)[cols],
val=vals, stringsAsFactors=FALSE)

*----------------------------------------------------------------------------------------------------
* modest working version of http & ws forwarding in node, cleveland webapp (30 jan 2016)

  --- source code modification
     ~/github/Oncoscape/Oncoscape/inst/scripts/hub/Module.js:  allow index.pre to supply uri.
          hub.start(socketURI) calls hub.initializeWebSocket(socketURI)
        rather than (as traditional) that uri is learned from module variable
           var socketURI = window.location.href.replace("http://", "ws://");

       ~/github/clevelandHighSchool/webapplets/maps/index.pre
         hub.start(); // old
         hub.start("ws://localhost:8080"); // new, but now reverted to old

  --- two shells
  cd  /Users/paul/github/clevelandHighSchool/webapplets/maps; make

  cd /Users/paul/s/examples/node/wsWithForwardingInParts; node bothForwarding.js
  then browse to http://localhost:8080
     - bothFowarding.js http redirects the 8080 request to 8084 (the Chinook server for the cleveland app)
     - javascript in browser, temporarily hard-coded:
           hub.start("ws://localhost:8080");
  we have
     a ws server listening on 8080
     a ws client connected to the R server on 8084

   javascaript ws requests to 8080 get forwarded on to 8084

  --- test adding python to the conversation
   python testWebSocketOperations.py
       {'datasets': 'SouthSeattleHealthImpacts'}
    the server sees this:
       [1] --- ChinookServer dispatchMessage: getDatasetNames

*----------------------------------------------------------------------------------------------------
* map affy probe ids to ENSG using hgu133plu2.db from bioc (29 jan 2016)

  ~/s/work/cory/affyProbeMatching/map.R

  --- cory's aggregate command

     aggSel<-aggregate( .~hgnc,p, max)
    hgnc is the column by which I'm collapsing. p is my dataframe.

*----------------------------------------------------------------------------------------------------
* create a node middleMan.js websocket and zmq message hub (28 jan 2016)

  using npm module and sample server code, Current Version: 1.0.22 — Released 2015-09-28,
   82k downloads in the last month, top 2% of 231k packages

  obtained https://www.npmjs.com/package/websocket
  found that this works with simple python3 client, with library poorly identified by
     from websocket import create_connection
  cd ~/s/examples/node/wsWithForwarding/
  got stuck till I realized we do not use subprotocols
  var connection = request.accept(null, request.origin);

*----------------------------------------------------------------------------------------------------
* github/bioc git/bioc tips

  --- get the releaes version of rcy3
    git clone https://github.com/Bioconductor-mirror/RCy3.git
    R CMD INSTALL RCy3

  -- get the devel version
    cd RCy3
    git checkout release-3.2     # verify version # is correct
    cd ..
    R CMD INSTALL RCy3

*----------------------------------------------------------------------------------------------------
* neo4j tips: fill from makefile

   cat ~/s/work/priceLab/neo4j/genemania/neo4jReady/makefile

     njshell = /Applications/Neo4j\ Community\ Edition.app/Contents/Resources/app/bin/neo4j-shell
     clear:
     	$(njshell) -file clear.cql -v

     fillMolecules:
     	$(njshell) -file fill-molecules.cql -v

     fillInteractions:
     	R -f runFill.R

     report:
     	R -f reportCypher.R

   ---- an sql (cql?) file
     head fill-interactions-1455562347.24895.sql
     create constraint on (interaction:Interaction) assert interaction.id is unique;

     USING PERIODIC COMMIT
     LOAD CSV WITH HEADERS FROM
        "file:///Users/paul/s/work/priceLab/neo4j/genemania/neo4jReady/Physical_interactions.Chen-Ge-2013.txt"
        AS line FIELDTERMINATOR '\t'
        MATCH (a:Molecule {id: line.Gene_A}), (b:Molecule {id: line.Gene_B})
        CREATE (a)-[:Interaction {type: line.Network_Group_Name, pmid: line.Pubmed_ID, source: line.Source, weight: line.Weight}]->(b);

    --- the above file is created dynamically by runFill.R, then excuted:

     cat ~/s/work/priceLab/neo4j/genemania/neo4jReady/runFill.R
     interaction.files <- list.files(pattern=".*.txt$")
     interaction.files <- interaction.files[grep("Physical", interaction.files)]
     neo4jShell <- "/Users/paul/bin/neo4j-shell"

     template.filename <- "fill-interactions-template.cql"
     transformed.filename <- sprintf("fill-interactions-%s.sql", as.numeric(Sys.time()))

     for(interaction.filename in interaction.files){
        printf(" creating and running %d/%d: %s, %s",
               match(interaction.filename, interaction.files), length(interaction.files),
               interaction.filename, transformed.filename);
        #browser()
        cmd.edit <- sprintf("sed -e s/xxFILENAMExx/%s/ %s > %s", interaction.filename,
                            template.filename, transformed.filename)
        system(cmd.edit)
        cmd.fill <-sprintf("%s -file %s", neo4jShell, transformed.filename)
        system(cmd.fill)
        }

*------------------------------------------------------------------------------------------------------------------------
* neo4j tips, some useful cypher commands

  [from http://www.remwebdevelopment.com/blog/sql/some-basic-and-useful-cypher-queries-for-neo4j-201.html]

  count nodes: match(n) return (count(n))
  count edges: match n-[r]->() return (count(r))
               match n-[r]-() return (count(r))
  delete all edges then all nodes (execute these in the gui separately, ctrl-enter for each one)
      start n=node(*) match n-[r]-() delete r
      start n=node(*) match n delete n

  find all molecules with name "H2O"
  match (molecule:Molecule) where molecule.name="H2O" return count(molecule)   // 5
  match (molecule:Molecule) where molecule.name="H2O" return count(molecule.id)   // 5
     M_h2o_c M_h2o_m M_h2o_e M_h2o_x M_h2o_r

  count reactions in recon202 involving water
  match (m:Molecule)-[r]-() where m.name="H2O" return count(m)   // 1630

*----------------------------------------------------------------------------------------------------
* recon2 & neo4j, learning the ropes (26 jan 2016)

  cd ~/s/data/priceLab/recon2
  start neo server from the icon app in the dock, which points to /Applications/Neo4j....
  might have forgotten login/password.  default is neo4j/neo4j, change to neo4j/isb
  reload()
  view graph

*----------------------------------------------------------------------------------------------------
* RUnit demo for alison paquette (26 jan 2016)

  cd ~/s/work/alisonPaquette/mergeMicroarrays/Processing-Microarray-Data-master/
  code from https://github.com/alipaquette/Processing-Microarray-Data
  csv file from her email

  modest RUnit file:
     ~/s/work/alisonPaquette/mergeMicroarrays/Processing-Microarray-Data-master/processAndMerge.R

*----------------------------------------------------------------------------------------------------
*----------------------------------------------------------------------------------------------------
* neo4j (25 jan 2016)

  installed, db in ~/dbs/neo4j
  user neo4j, pw=isb
  northwind example:
     cd ~/s/examples/neo4j

  pip install py2neo

*----------------------------------------------------------------------------------------------------
* neo4j tips, cypher tips


   --- get edges (paths)   [operating on the graph created in ~/s/data/priceLab/recon2/go.R]

    modifies.paths <- getPaths(gdb, "match p= (:obj)-[:modifies]->(:obj) return p")
    s0 <- startNode(modifies.paths[[1]])
    class(s0)
    getLabel(startNode(modifies.paths[[1]])) # [1] "obj"
    getID(startNode(modifies.paths[[1]]))    # 9
      # what properties on this node?
    names(startNode(modifies.paths[[1]]))   # [1] "id"   "name" "type"
      #
    startNode(modifies.paths[[1]])$type     # [1] "gene"
    startNode(modifies.paths[[1]])$name     # [1] "AOC2"
    startNode(modifies.paths[[1]])$id       # [1] "_314_1_c"

  --- get all enzymes (modifiers) of R_MAOX    methylamine oxidase    using R's subset

       subset(tbl.recon202, b.orig == "R_MAOX" & interaction=="modifies")[, 1:8]
            a.orig interaction b.orig a.name              b.name a.type a.geneID a.uniprot
   14840   _26_1_c    modifies R_MAOX   ABP1 Methylamine oxidase   gene     <NA>    P19801
   14841  _314_2_c    modifies R_MAOX   AOC2 Methylamine oxidase   gene      314      <NA>
   14847 _8639_1_c    modifies R_MAOX   AOC3 Methylamine oxidase   gene     8639    Q16853
   14849  _314_1_c    modifies R_MAOX   AOC2 Methylamine oxidase   gene      314    O75106

  --- get all enzymes (modifiers) of R_MAOX    methylamine oxidase    using RNeo4j's cypher
    length(getPaths(gdb, "match p=(:obj)-[:modifies]->(:obj  {id: 'R_MAOX'}) return p"))  # [1] 4
    paths <- getPaths(gdb, "match p=(:obj)-[:modifies]->(:obj  {id: 'R_MAOX'}) return p")

    lapply(modifies.paths, function(path) {return (c(startNode(path)$name, endNode(path)$name))})
        "AOC2"                "Methylamine oxidase"
        "AOC3"                "Methylamine oxidase"
        "AOC2"                "Methylamine oxidase"
        "ABP1"                "Methylamine oxidase"

*----------------------------------------------------------------------------------------------------
* neo4j tips: good cypher load website (27 jan 2016)

  http://jexp.de/blog/2014/06/load-csv-into-neo4j-quickly-and-successfully/

*----------------------------------------------------------------------------------------------------
* neo4j, destroy database, clean start (28 jan 2016)

  --- my attempt
    shutdown server from mac app
    rm ~/Documents/Neo4j/default.graphdb/
    restart from mac app (in dock)

  --- from stackoverflow

    Shut down your Neo4j server, do a rm -rf data/graph.db and start up the server again. This
    procedure completely wipes your data, so handle with care.

*----------------------------------------------------------------------------------------------------
* neo4j tips, batch insert (28 jan 2016)

   ---  http://neo4j.com/docs/stable/batchinsert.html

   Neo4j has a batch insertion facility intended for initial imports, which bypasses transactions
   and other checks in favor of performance. This is useful when you have a big dataset that needs
   to be loaded once.



*----------------------------------------------------------------------------------------------------
* rneo4j: build graph in database from R (3 feb 2016)

  [http://nicolewhite.github.io/2014/05/30/demo-of-rneo4j-part1.html]

   gdb <- startGraph("http://localhost:7474/db/data/", username="neo4j", password="isb")
   clear(gdb)

*----------------------------------------------------------------------------------------------------
* neo4j, load all of recon2 (27 jan 2016)

  cd ~/s/data/priceLab/recon2/
  the whole table, all duplicates removed
     8936 molecules.tsv
     7908 reactions.tsv
    48906 roles.tsv

  R -f prepCypher.R
  wc -l *.tsv
        48938 molecules.tsv
        10555 reactions.tsv
        48938 roles.tsv
      108442 total
  neo4j-shell -file clear.cypher -v
  neo4j-shell -file fill.cypher -v
  R -f reportCypher.R
    59491 nodes

*----------------------------------------------------------------------------------------------------
* neo4j tips: find and run neo4j-shell (27 jan 2016)

  /Applications/Neo4j\ Community\ Edition.app/Contents/Resources/app/bin/neo4j-shell

  dir /Applications/Neo4j\ Community\ Edition.app/Contents/Resources/app/bin
       -rw-r--r--   1 paul  admin        21 Jan 25 12:28 .dblocation
       drwxr-xr-x@ 25 paul  admin       850 Jan 12 17:00 Neo4j-Management/
       -rw-r--r--@  1 paul  admin      1707 Jan 12 16:58 Neo4j-Management.psd1
       -rw-r--r--@  1 paul  admin      3633 Jan 12 16:58 Neo4jImport.bat
       -rw-r--r--@  1 paul  admin      3209 Jan 12 16:58 Neo4jShell.bat
       -rw-r--r--@  1 paul  admin       112 Jan 12 16:58 install.properties
       -rw-r--r--@  1 paul  admin       232 Jan 12 16:58 neo4j-community.vmoptions
       -rw-r--r--@  1 paul  admin  67620822 Jan 12 16:58 neo4j-desktop-2.3.2.jar
       -rwxr-xr-x@  1 paul  admin      3652 Jan 12 16:58 neo4j-import
       -rwxr-xr-x@  1 paul  admin      3520 Jan 12 16:58 neo4j-shell
       -rwxr-xr-x   1 paul  admin       332 Jan 26 11:41 openNeoTerminal.sh

   Error: JAVA_HOME is not defined correctly.


*----------------------------------------------------------------------------------------------------
* neo4j tips: load database from tsv file (26 jan 2016)

  -- make sure you can find, read, load and minimally parse.  last line is displayed
    LOAD CSV WITH HEADERS FROM
    "file:///Users/paul/s/data/priceLab/recon2/demo.tsv"
    AS line FIELDTERMINATOR '\t'
    return line

  -- read, create -- this just adds nodes.  see below
     LOAD CSV WITH HEADERS FROM
     "file:///Users/paul/s/data/priceLab/recon2/demo.tsv"
     AS line FIELDTERMINATOR '\t'
     create (:interaction {a: line.a_orig, b: line.b_orig, type: line.interaction,
     })

  -- create 3 files: molecules, reactions, roles

    tbl.molecules <- tbl[, grep("^a", colnames(tbl), v=TRUE)]
    new.colnames <- sub("^a\\.", "", colnames(tbl.molecules))
    new.colnames[1] <- "id"
    new.colnames <- sub(".", "_", new.colnames, fixed=TRUE)
    colnames(tbl.molecules) <- new.colnames
    write.table(tbl.molecules, file="molecules.tsv", sep="\t", quote=FALSE, row.names=FALSE, col.names=TRUE)

    reaction.cols <- colnames(tbl)[-(grep("^a", colnames(tbl)))]
    remover <- grep("interaction", reaction.cols)
    if(length(remover) > 0)
       reaction.cols <- reaction.cols[-remover]
    tbl.reaction <- unique(tbl[, reaction.cols])
    colnames(tbl.reaction) <- sub("^b\\.", "", colnames(tbl.reaction))
    write.table(tbl.reaction, file="reactions.tsv", sep="\t", quote=FALSE, row.names=FALSE, col.names=TRUE)

    tbl.role <- tbl[, c("a.orig", "b.orig", "interaction")]
    colnames(tbl.role) <- c("a", "b", "type")
    write.table(tbl.role, file="roles.tsv", sep="\t", quote=FALSE, row.names=FALSE, col.names=TRUE)

  --- load the 3 files
     LOAD CSV WITH HEADERS FROM
       "file:///Users/paul/s/data/priceLab/recon2/molecules.tsv"
        AS line FIELDTERMINATOR '\t'
        create (:Molecule {id: line.id, name: line.name, type: line.type,
                           geneID: line.geneID, uniprot: line.uniprot,
                           sboTerm: line.sboTerm, chebi: line.chebi,
                           kegg_compound: line.kegg_compound,
                           kegg_genes: line.kegg_genes,
                           kegg_drug: line.kegg_drug, hmdb: line.hmdb,
                           pubchem_substance: line.pubchem_substance});

     LOAD CSV WITH HEADERS FROM
        "file:///Users/paul/s/data/priceLab/recon2/reactions.tsv"
         AS line FIELDTERMINATOR '\t'
         create (:Reaction {id: line.orig, name: line.name, reversible: line.reversible,
                            pubmed: line.pubmed, compartment: line.compartment});

     LOAD CSV WITH HEADERS FROM
       "file:///Users/paul/s/data/priceLab/recon2/roles.tsv"
       AS line FIELDTERMINATOR '\t'
       MATCH (molecule:Molecule {id: line.a}), (reaction:Reaction {id: line.b})
       CREATE (molecule)-[:Interaction {type: line.type}]->(reaction);

    ---- look
      x <- getRels(gdb, "match (:Molecule)-[r]->(:Reaction) return r")
      length(x) # 8
      startNode(x[[1]])$name # [1] "H2O"
      endNode(x[[1]])$name  # [1] "Methylamine oxidase"

    LOAD CSV WITH HEADERS FROM
      "file:///Users/paul/s/data/priceLab/recon2/reactions.tsv"

MATCH (person:Person { id: toInt(csvLine.personId)}),(movie:Movie { id: toInt(csvLine.movieId)})
CREATE (person)-[:PLAYED { role: csvLine.role }]->(movie)
roles.csv



*----------------------------------------------------------------------------------------------------
* neo4j tips: how to retrieve edge attributes (properties on a relation) (26 jan 2016)


   --- my example, using a bit of recon2, using ~/s/data/priceLab/recon2/go.R

   paths <- getPaths(gdb, "match p =(:obj)-[:modifies]->(:obj) return p")  # no attributes
   edges <- getRels(gdb,  "match (:obj)-[r:modifies]->(:obj) return r")    # all attributes
   edges[[1]]   < Relationship >modifies
      $pubmed  [1] "9131641"
      $interaction  [1] "modifies"
      $reversible [1] FALSE
      $compartment [1] "c"

   --- nicole's example
     with full credentials specified: gdb <- startGraph("http://localhost:7474/db/data/", username="neo4j", password="isb")
     graph = startGraph("http://localhost:7474/db/data/")clear(graph)
        bob = createNode(graph, "Person", name = "Bob")
        rel = createRel(alice, "WORKS_WITH", bob, props)
      endNode(rel) query = " WHERE a.name = 'Alice' AND b.name = 'Bob' RETURN p "
     path = cypherToList(graph, query)[[1]]$p

*----------------------------------------------------------------------------------------------------
* neo4j tips

  start from the icon app in the dock

  gdb <- startGraph("http://localhost:7474/db/data/", username="neo4j", password="isb");
  clear(gdb, input=FALSE)  # removes all nodes, edges, indexes, constraints

  in R, get nodes:   length(getNodes(gdb, "MATCH n RETURN n"))

  traverse all:
   query <- "match(n)
      return n"
   cypher(gdb, query)

  -- in web browser
     match(n)   [shift-enter]
     return (n) [ctrl-enter]


  -- get all nodes passing filter  from  ?getNodes

    graph = startGraph("http://localhost:7474/db/data/")
    clear(graph)
    createNode(graph, "Person", name = "Alice", age = 23)
    createNode(graph, "Person", name = "Bob", age = 22)
    createNode(graph, "Person", name = "Charles", age = 25)
    query = "MATCH (p:Person)
             WHERE p.age < 25
             RETURN p"
    younger_than_25 = getNodes(graph, query)
    sapply(younger_than_25, function(p) p$name)
    query = "MATCH (p:Person)
             WHERE p.age > {age}
             RETURN p"
    older_than_22 = getNodes(graph, query, age = 22)
    sapply(older_than_22, function(p) p$name)



*----------------------------------------------------------------------------------------------------
* recon2 (25 jan 2016)

  cd ~/s/data/priceLab/recon2

  --- also got matlab file from VMH: https://vmh.uni.lu
     cd  ~/s/data/priceLab/recon2/vmh
     x <- readMat("Recon2.v04.mat")
     save(x, file="vmn.RData")

  --- get data from 13may2014:

    cp -p ~/s/data/public/refnet/annotationHubPrep/recon2/createSingleTableFromXML/tbl.recon202.RData .


*----------------------------------------------------------------------------------------------------
* simple zmq pub/sub in node, sub client in R (23 jan 2016)
   updated (29 may 2016)

   cd ~/s/examples/node/zmq/

   npm install zmq  # did fresh install related to python version: needs < 3.0, /usr/bin/python
   date > tmp

   ---- node server
    node zmq-filer-rep.js
      Listening for zmq requesters...
      Received request to get: tmp
      Sending response content

   ---- node client
   node zmq-filer-req.js tmp
      Sending request for tmp
     Received response: { content: 'Sun May 29 15:49:31 PDT 2016\n',
                        timestamp: 1464563201739,
                         pid: 57918 }

   ---- zmq-watcher-pub.js
     'use strict';
     const
       fs = require('fs'),
       zmq = require('zmq'),
       publisher = zmq.socket('pub'),
       filename = process.argv[2];
     fs.watch(filename, function(){
       publisher.send(JSON.stringify({
         type: 'changed',
         file: filename,
         timestamp: Date.now()
         }));
       });
     publisher.bind('tcp://*:5432', function(err) {
       console.log('Listening for zmq subscribers...');
     });

   ---- zmq-watcher-sub.js
     "use strict";
     const
       zmq = require('zmq'),
       subscriber = zmq.socket('sub');
     subscriber.subscribe("");
     subscriber.on("message", function(data) {
       let message = JSON.parse(data),
           date = new Date(message.timestamp);
       console.log("File '" + message.file + "' changed at " + date);
       });
     subscriber.connect("tcp://localhost:5432");

   ---- zmq-sub.R
     library(rzmq)
     library(jsonlite)
     context = init.context()
     socket = init.socket(context,"ZMQ_SUB")
     connect.socket(socket,"tcp://localhost:5432")
     subscribe(socket, "")
     i <- 0
     while (i < 5) {
        res <- receive.socket(socket, unserialize=FALSE)
        print(class(res))
        print(res)
        x <- fromJSON(rawToChar(res))
        print(x)
        i <- i + 1
        }
*----------------------------------------------------------------------------------------------------
* install homebrew on riptide, in order to install zmq library, node zmq module (22 jan 2016)

  ruby -e "$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/master/install)"

   node-gyp requires python <= 3.0.0   (2.7?)
   switched paths in ~/.bashrc so that the old /usr/bin/python is found
   allowing npm to install zmq:

   test:
     node --harmony -p -e 'require("zmq")'
*----------------------------------------------------------------------------------------------------
* build CortexTranscriptCounts example data package for cory (21 jan 2016)

  cd ~/s/examples/R/assembleDataPackageFromTextFiles

*----------------------------------------------------------------------------------------------------
* node examples

   from book, node.js the right way

  --- watch file
    cd ~/s/examples/node/fs
*----------------------------------------------------------------------------------------------------
* docker tips: run a container interactively vs as a daemonized service

    docker run -i -t ubuntu /bin/bash
       -i: keep the container's stdin op;en
       -t: assign a pseudo-tty (stdout?) to the container we are creating

   root@ccb18c5ef6d2:/root@ccb18c5ef6d2:/#  hostname    # ccb18c5ef6d2
   root@ccb18c5ef6d2:/root@ccb18c5ef6d2:/#  whoami      # root


*----------------------------------------------------------------------------------------------------
* docker tips:   docker info

   echo $DOCKER_HOST  #    tcp://192.168.99.100:2376

   docker info
   Containers: 45
   Images: 81
   Server Version: 1.9.1
   Storage Driver: aufs
    Root Dir: /mnt/sda1/var/lib/docker/aufs
    Backing Filesystem: extfs
    Dirs: 171
    Dirperm1 Supported: true
   Execution Driver: native-0.2
   Logging Driver: json-file
   Kernel Version: 4.1.13-boot2docker
   Operating System: Boot2Docker 1.9.1 (TCL 6.4.1); master : cef800b - Fri Nov 20 19:33:59 UTC 2015
   CPUs: 1
   Total Memory: 1.956 GiB
   Name: default
   ID: MDIE:P4NG:5HYQ:RENM:HRJJ:HTN2:LZCI:SLPP:GQLL:USX4:F34D:GYVS
   Debug mode (server): true
    File Descriptors: 12
    Goroutines: 20
    System Time: 2016-02-03T00:39:11.608919707Z
    EventsListeners: 0
    Init SHA1:
    Init Path: /usr/local/bin/docker
    Docker Root Dir: /mnt/sda1/var/lib/docker
   Username: pshannon
   Registry: https://index.docker.io/v1/
   Labels:
    provider=virtualbox

*------------------------------------------------------------------------------------------------------------------------
* docker tips whalesay

   do all of this in the docker bash client shell, which can be started from the Kitematic File-> menu

  cd ~/s/examples/docker/mydockerbuild
  cat Dockerfile
    FROM docker/whalesay:latest                            # specifies existing image our new one will be based on
    RUN apt-get -y update && apt-get install -y fortunes   # install "fortunes" app into the image we are creating here
    CMD /usr/games/fortune -a | cowsay                     # tell docker to execute this wne the image is loaded

  docker built -t docker-whale .                           # builds image from ./Dockerfile, calls it docker-whale

     Sending build context to Docker daemon 2.048 kB
     Step 1 : FROM docker/whalesay:latest
     latest: Pulling from docker/whalesay
     Digest: sha256:178598e51a26abbc958b8a2e48825c90bc22e641de3d31e18aaf55f3258ba93b
     Status: Downloaded newer image for docker/whalesay:latest
      ---> ded5e192a685
     Step 2 : RUN apt-get -y update && apt-get install -y fortunes
      ---> Using cache
      ---> 9e6628740176
     Step 3 : CMD /usr/games/fortune -a | cowsay
      ---> Using cache
      ---> 7ca3a08b402b
     Successfully built 7ca3a08b402b

*----------------------------------------------------------------------------------------------------
* docker tips: login to a Docker registery server

   credentials saved in ~/.docker/config.json
   if no server is specified "https://index.docker.io/v1/" is the default.



*----------------------------------------------------------------------------------------------------
* docker tips

  must have docker server running
  must use docker client (which Kitematic (from mac os Launcher tool) gives you a menu
    with which to start:
        Kitematic -> File -> Open Docker Command Line Terminal
    which seems to execute this command (but this command does not start client from my regular bash shell)
      bash -c "clear && DOCKER_HOST=tcp://192.168.99.100:2376 DOCKER_CERT_PATH=/Users/paul/.docker/machine/machines/default DOCKER_TLS_VERIFY=1 /bin/bash"

   that tcp://ip address:  docker is configured to use the default machine with IP 192.168.99.100

  once client is started, the functional equivalent of ls:

    bash-docker-clientShell> docker images

      REPOSITORY              TAG                 IMAGE ID            CREATED             VIRTUAL SIZE
      pshannon/docker-whale   latest              7ca3a08b402b        12 days ago         274.2 MB
      hello-world             latest              0a6ba66e537a        3 months ago        960 B

    bash-docker-clientShell> docker run pshannon/docker-whale  # displays whale with quote

   docker run hello-world
     Hello from Docker.
     This message shows that your installation appears to be working correctly.

    To generate this message, Docker took the following steps:
     1. The Docker client contacted the Docker daemon.
     2. The Docker daemon pulled the "hello-world" image from the Docker Hub.
     3. The Docker daemon created a new container from that image which runs the
        executable that produces the output you are currently reading.
     4. The Docker daemon streamed that output to the Docker client, which sent it
        to your terminal.

      To try something more ambitious, you can run an Ubuntu container with:
     $ docker run -it ubuntu bash   # seems to pull down a full ubuntu image with bash from docker hub, and runs it



*------------------------------------------------------------------------------------------------------------------------
* docker tips, use ps to learn about recent containers run, and their status

  docker ps -l   # last
  docker ps -a   # all
*------------------------------------------------------------------------------------------------------------------------
* docker tips, use client to find daemon from regular old emacs

  /usr/local/bin/docker
  eval $(docker-machine env default)

  printenv | grep -i docker
  DOCKER_HOST=tcp://192.168.99.100:2376
  DOCKER_MACHINE_NAME=default
  DOCKER_TLS_VERIFY=1
  DOCKER_CERT_PATH=/Users/paul/.docker/machine/machines/default

*------------------------------------------------------------------------------------------------------------------------
* docker tips, bioc

   https://hub.docker.com/r/bioconductor/devel_base/
   docker pull bioconductor/devel_base
   docker images

   eval $(docker-machine env default)
   docker run -ti --name dockeR bioconductor/devel_base R

*------------------------------------------------------------------------------------------------------------------------
* docker tips: the model, the architecture

   [from https://viget.com/extend/how-to-use-docker-on-os-x-the-missing-guide]

   Docker is a client-server application. The Docker server is a
   daemon that does all the heavy lifting: building and downloading
   images, starting and stopping containers, and the like. It exposes
   a REST API for remote management.

   The Docker client is a command line program that communicates with
   the Docker server using the REST API. You will interact with Docker
   by using the client to send commands to the server.

   The machine running the Docker server is called the Docker
   host. The host can be any machine—your laptop, a server in the
   Cloud™, etc—but, because Docker uses features only available to
   Linux, that machine must be running Linux (more specifically, the
   Linux kernel).




*----------------------------------------------------------------------------------------------------
* example simple docker build, run, push, pull, run (21 jan 2016)

  --- prerequisites  (2 feb 2016)

    install the Docket Toolbox, which has
         /usr/local/bin/docker-machine, docker, docker-compose
         Kitematic, the Docker GUI
         a shell preconfigured ofr a Docker command-line environment
         Oracle vm virtual box

    create the docker daemon
       docker-machine create --driver virtualbox localhost

    login to docker hub: hub.docker.com: pshannon, old animal
    launch Kitematic from LaunchPad

  cd ~/s/examples/docker/mydockerbuild

  Dockerfile:
     FROM docker/whalesay:latest
     RUN apt-get -y update && apt-get install -y fortunes
     CMD /usr/games/fortune -a | cowsay

  docker build -t docker-whale .
  docker images

    REPOSITORY          TAG                 IMAGE ID            CREATED             VIRTUAL SIZE
    docker-whale        latest              5249c0810b67        6 minutes ago       274.2 MB
    hello-world         latest              0a6ba66e537a        3 months ago        960 B


   docker run docker-whale   # works

   docker tag 5249c0810b67 pshannon/docker-whale:latest
   docker images
     REPOSITORY              TAG                 IMAGE ID            CREATED             VIRTUAL SIZE
     pshannon/docker-whale   latest              5249c0810b67        9 minutes ago       274.2 MB
     docker-whale            latest              5249c0810b67        9 minutes ago       274.2 MB
     hello-world             latest              0a6ba66e537a        3 months ago        960 B

   docker run pshannon/docker-whale # also works

   docker login --username=pshannon --email=paul.thurmond.shannon@gmail.com
   docker push pshannon/docker-whale

     # remove these local images
   docker rmi -f pshannon/docker-whale
   docker rmi -f docker-whale   # complaints about this one

     # do fresh pull and run

   docker run pshannon/docker-whale


*----------------------------------------------------------------------------------------------------
* first use of aws with cory, trena & etc (21 jan 2016).  get two buckets

   ssh whovian
   aws configure                      # /usr/bin/aws
   mkdir cory-trena; cd cory-trena
   aws s3 cp s3://cory-trena/ . --recursive --dryrun
   aws s3 cp s3://cory-trena/ . --recursive

   cd
   mkdir -p cory-rosto/tcga
   cd cory-rosto/tcga
   aws s3 cp s3://cory-rosto/ . --recursive

   --- copied everything to book
      cd ~/s/work/cory

   --- ran trina
    cd ~/s/work/cory/cory-rosto/tcga/
    source("tcga_trn2.R")
    dim(trn.rtrim)  # [1] 6698  565
    save(trn.rtrim, file="trn.rtrim.RData")
    trn.rtrim[1:5, 1:5]
               PKNOX2 ZHX3 EP300 HIC2 TBX10
     AACS  0.00000000    0     0    0     0
     FSTL1 0.00000000    0     0    0     0
     ELMO2 0.08736112    0     0    0     0
     RPS11 0.00000000    0     0    0     0
     PNMA1 0.00000000    0     0    0     0
   "SP1" %in% rownames(trn.rtrim)  # [1] FALSE
   "SP1" %in% colnames(trn.rtrim)  # [1] TRUE
   head(trn.rtrim[, "SP1"])
     AACS  FSTL1  ELMO2  RPS11  PNMA1 SAMD4A
        0      0      0      0      0      0
   fivenum(trn.rtrim[, "SP1"])
        RAB4B     MTMR11       TTC1        APP       RFX3
   -0.1555359  0.0000000  0.0000000  0.0000000  0.1537406
   sum(abs(trn.rtrim[, "SP1"]))  # [1] 1.16108


*----------------------------------------------------------------------------------------------------
* mount viola price1-3 on book (21 jan 2016)

  finder, Go, Connect to server, pshannon, isb T99 password
*----------------------------------------------------------------------------------------------------
* ben heavner on s3, cluster, and unix logins (20 jan 2016)

   we've got a few servers - commonly used ones include whovian,
   buffy, and viola. Once you have the unix account, you can ssh to
   any of them; meanwhile, from a mac, you can connect to viola in
   Finder via Go -> Connect to Server ->
   smb://viola.systemsbiology.net and use your ISB login details and
   select a volume to mount. I think this works for buffy too, but not
   whovian without unix credentials (not sure on that point).

  I've put your aws username and access key details on viola on the
  price 1 volume at paul_foo

  You can login to the AWS web console via
  http://pricelab.signin.aws.amazon.com/ You're in the lab members
  group, which should have a slightly more limited ability to break
  things, but it's pretty permissive, so be paranoid. I am happy to
  add you administrator group later, so if you need permission to do
  most anything there.

  At some point, you may want to use our starcluster infrastructure
  for managing cluster jobs. It's something we'd like to mothball
  eventually, but we don't have a better approach at the moment, so
  we're keeping the old system alive still. I've documented it's
  installation and usage here:
  https://docs.google.com/a/systemsbiology.org/document/d/1oH-Ephi4w9iBafjkSMwu7cxrv8EB6cZQf5BDp92fPag/edit?usp=sharing


*----------------------------------------------------------------------------------------------------
* clone oncoscape to book at isb (20 jan 2016)

  cd ~/github
  git clone https://github.com/FredHutch/Oncoscape.git
*----------------------------------------------------------------------------------------------------
* install crossbar.io on book (20 jan 2016)

  installed as /Users/paul/anaconda/bin/crossbar

  --- try the python demo
    cd ~/s/examples/crossbar
    crossbar init --template hello:python --appdir hello
    seems to work well.

  -- try node
    installed v5.4.1 Stable from https://nodejs.org/en   to /usr/local/bin/node
    cd ~/s/examples/crossbar
    crossbar init --template hello:nodejs --appdir helloNode


*----------------------------------------------------------------------------------------------------
* Groups package, fill TCGAbrain/inst/extdata/tumorGrade.RData (16 jan 2015)

  cd ~/oncogit/Oncoscape/dataPackages/Groups/inst/extdata/TCGA.tumors
  print(load("../../../../TCGAbrain/inst/extdata/tumorGrade.RData"))   # tbl.grade
  head(tbl.grade)                             table(tbl.grade$cluster)
                cluster color                 G2  G3  G4  NA
   TCGA.CS.6290      G3  blue                218 241 548  72
   TCGA.DU.5847      G3  blue
   TCGA.DU.5849      G2 green
   TCGA.DU.5852      G3  blue
   TCGA.DU.5854      G3  blue
   TCGA.DU.5855      G3  blue
   ...

   --- destination: add new files to Groups/inst/extdata/TCGA.tumors; extend two files in each dataPackage that uses them

     first: 4 new files in Groups/inst/extdata/TCGA.tumors:  glioma.grade.G2, .G3, .G4, .unclassified

    second: extend the per-dataPackage list of lists to include, eg, glioma.grade=list(glioma.grade.G2, glioma.grade.G3, ...)
        print(load("/Users/pshannon/oncogit/Oncoscape/dataPackages/DEMOdz/inst/extdata/tumorGroups.Rdata"))   # tumorGroups

     third: extend the existing group groupVizProps table in each relevant tumor site dataPackage
        print(load("~/oncogit/Oncoscape/dataPackages/DEMOdz/inst/extdata/tbl.groupVizProps.RData")) # "tbl.groupVizProps"
        head(tbl.groupVizProps)
                     group  type           id     color   shape
        1 verhaak.2010.gbm tumor        GCIMP      blue ellipse
        2 verhaak.2010.gbm tumor  Mesenchymal     green ellipse
        3 verhaak.2010.gbm tumor       Neural    purple ellipse
        4 verhaak.2010.gbm tumor    Proneural turquoise ellipse
        5 verhaak.2010.gbm tumor    Classical chocolate ellipse
        6 verhaak.2010.gbm tumor unclassified lightgray ellipse


  1) create 4 new files in Groups/inst/extdata/TCGA.tumors from tbl.grade
     glioma.grade.2 <- rownames(subset(tbl.grade, cluster=="G2"))
     glioma.grade.3 <- rownames(subset(tbl.grade, cluster=="G3"))
     glioma.grade.4 <- rownames(subset(tbl.grade, cluster=="G4"))
     glioma.grade.unassigned <- rownames(subset(tbl.grade, cluster=="NA"))

     write(glioma.grade.2, sep="\n", file="glioma.grade.2")
     write(glioma.grade.3, sep="\n", file="glioma.grade.3")
     write(glioma.grade.4, sep="\n", file="glioma.grade.4")
     write(glioma.grade.unassigned, sep="\n", file="glioma.grade.unassigned")

     tumorGroups[["glioma.grade"]] <-as.list(grep("glioma.grade", ls(), v=TRUE))
     save(tumorGroups, file="/Users/pshannon/oncogit/Oncoscape/dataPackages/DEMOdz/inst/extdata/tumorGroups.Rdata")
     tbl.new <- data.frame(group="glioma.grade", type="tumor",
                          id=grep("glioma.grade.", ls(), v=TRUE, fixed=TRUE),
                          color="lightgray",
                          shape="ellipse")
     tbl.new$color <- unique(tbl.grade)$color
     tbl.new$id <- sub("glioma.grade.", "", tbl.new$id, fixed=TRUE)
     tbl.new
              group  type         id color   shape
     1 glioma.grade tumor          2  blue ellipse
     2 glioma.grade tumor          3 green ellipse
     3 glioma.grade tumor          4   red ellipse
     4 glioma.grade tumor unassigned  gray ellipse

   tbl.groupVizProps <- rbind(tbl.groupVizProps, tbl.new)
   save(tbl.groupVizProps, file="~/oncogit/Oncoscape/dataPackages/DEMOdz/inst/extdata/tbl.groupVizProps.RData")

   do fresh install of DEMOdz

*----------------------------------------------------------------------------------------------------
* Groups package: how to fill, how to use (16 jan 2015)

  cd  ~/oncogit/Oncoscape/dataPackages/Groups/

  -- input data?

    inst/extdata contains 1 level of subdirectories
    these are not semantically important -- not visible to users of the package -- but do
      help to organize the input data

    currently two subdirectories:
       TCGA.tumors:
       genes:  random.24, random.40, test4 (all used by DEMOdz, in PCA analysis)
       TCGA.tumors:

         glioma8.lggCIMP.del1p19q.mutCIC.mutFUBP1
         glioma8.lggCIMP.del1p19q.wtCIC.wtFUBP1         verhaak.2010.gbm.Classical
         glioma8.lggCIMP.not1p19q.mutATRX.mutTP53       verhaak.2010.gbm.GCIMP
         glioma8.lggCIMP.not1p19q.wtATRX.mutTP53        verhaak.2010.gbm.Mesenchymal
         glioma8.nonCIMP.gainNRAS.mutTP53               verhaak.2010.gbm.Neural
         glioma8.nonCIMP.gainNRAS.wtTP53                verhaak.2010.gbm.Proneural
         glioma8.nonCIMP.wtNRAS.mutTP53                 verhaak.2010.gbm.unclassified
         glioma8.nonCIMP.wtNRAS.wtTP53

      ---- glioma8.nonCIMP.gainNRAS.mutTP53
        TCGA.DU.A5TT
        TCGA.DU.8165
        ...
        TCGA.76.6283

    --- use these groups in, e.g., R server support for the pca webapplet, where we wish to
        color plotted points by tumor category

         library(DEMOdz)
         dataset <- DEMOdz()
         "tumorGroups" %in% getManifest(dataset)$variable
         getItem(dataset, "tumorGroups")   # a list of lists
           $verhaakPlusCIMP
           $verhaakPlusCIMP[[1]]
           [1] "verhaak.2010.gbm.Classical"
           $verhaakPlusCIMP[[2]]
           [1] "verhaak.2010.gbm.GCIMP"
           $verhaakPlusCIMP[[3]]
           [1] "verhaak.2010.gbm.Mesenchymal"
           $verhaakPlusCIMP[[4]]
           [1] "verhaak.2010.gbm.Neural"
           $verhaakPlusCIMP[[5]]
           [1] "verhaak.2010.gbm.Proneural"
           $verhaakPlusCIMP[[6]]
           [1] "verhaak.2010.gbm.unclassified"

    --- add a new set of groups to a Dataset
      library(Groups)
      g <- Groups()
        [1] "glioma8.lggCIMP.del1p19q.mutCIC.mutFUBP1" "glioma8.lggCIMP.del1p19q.wtCIC.wtFUBP1"
        [3] "glioma8.lggCIMP.not1p19q.mutATRX.mutTP53" "glioma8.lggCIMP.not1p19q.wtATRX.mutTP53"
        [5] "glioma8.nonCIMP.gainNRAS.mutTP53"         "glioma8.nonCIMP.gainNRAS.wtTP53"
        [7] "glioma8.nonCIMP.wtNRAS.mutTP53"           "glioma8.nonCIMP.wtNRAS.wtTP53"
        [9] "random.24"                                "random.40"
       [11] "test4"                                    "verhaak.2010.gbm.Classical"
       [13] "verhaak.2010.gbm.GCIMP"                   "verhaak.2010.gbm.Mesenchymal"
       [15] "verhaak.2010.gbm.Neural"                  "verhaak.2010.gbm.Proneural"
       [17] "verhaak.2010.gbm.unclassified"

      glioma8.subcats <- grep("^glioma8", getGroupNames(g), v=TRUE)
      verhaak.subcats <- grep("^verhaak",  getGroupNames(g), v=TRUE)
      tumorGroups <- list(verhaak.2010.gbm=as.list(verhaak.subcats), glioma8=as.list(glioma8.subcats))
      save(tumorGroups, file="../../dataPackages/DEMOdz/inst/extdata/tumorGroups.RData")
      update DEMOdz manifest:
          entity.count: length(tumorGroups)                           # 2
         feature.count: length(unlist(tumorGroups, use.names=FALSE))  # 14
      rebuild and install DEMOdz

   --- get node color by id
      library(DEMOdz)
      library(Groups)
      dataset <- DEMOdz()
      gdb <- Groups()
      metagroupName <- "glioma8"
      metagroupName <- "verhaakPlusCIMP"
      metagroup <- tumorGroups[[metagroupName]];  # i.e., all glimoa8 groups, or all verhaak.2010.gbmp groups
      subgroup.names <- unlist(metagroup, use.names=FALSE)
      ids.by.group <- lapply(subgroup.names, function(group) intersect(ids, getGroup(gdb, group)))
      names(ids.by.group) <- subgroup.names



*----------------------------------------------------------------------------------------------------
* create tbl.groupVizProps in DEMOdz, specifying color and shape for each member of a tumor group (15 jan 2016)

  cd ~/oncogit/Oncoscape/dataPackages/DEMOdz/inst/extdata/
  tbl.groupVizProps <- read.table("groupVisualProperties.tsv", sep="\t", header=TRUE, as.is=TRUE)
  save(tbl.groupVizProps, file="tbl.groupVizProps.RData")


*----------------------------------------------------------------------------------------------------
* ggtree supports phylip tree format

  http://www.r-bloggers.com/ggtree-supports-phylip-tree-format/?utm_source=feedburner&utm_medium=email&utm_campaign=Feed%3A+RBloggers+%28R+bloggers%29

*----------------------------------------------------------------------------------------------------
* create first Groups for DEMOdz (15 jan 2016)

  cd ~/oncogit/Oncoscape/dataPackages/Groups/inst/unitTests/
  g <- Groups()
  tumorGroups=list(verhaakPlusCIMP=as.list(sort(grep("verhaak", getGroupNames(g), v=TRUE))))
  save(tumorGroups, file="~/oncogit/Oncoscape/dataPackages/DEMOdz/inst/extdata/tumorGroups.Rdata")

  geneSets <- list("random.24", "random.40", "test4")
  save(geneSets, file="~/oncogit/Oncoscape/dataPackages/DEMOdz/inst/extdata/geneSets.Rdata")

*----------------------------------------------------------------------------------------------------
* oncoscape tips: express days as xx.xx years (14 jan 2016)

  head(x2$FirstProgression)   # [1] 137  40 302 518 264 351
  as.integer((head(x2$FirstProgression) * 100) / 365.25) / 100    # 0.37 0.10 0.82 1.41 0.72 0.96
*----------------------------------------------------------------------------------------------------
* python3 tips: keys, list, urllib, quote, decode, urlopen, urllib.request, urllib.parse

  --- get hash/dict keys as list
      list(hash.keys)

  --- new libraries for web access
     old: from urllib2 import *
     new, with some json manipulation as well

        from urllib.request import urlopen
        from urllib.parse import quote
        from json import *
        payload = [5.4964085, 0.7883715, 6.4879698, 4.9685336, 7.1878731]
        msg = quote(dumps({"cmd": "numericVectorSummaryStats", "status": "request", "callback": "", "payload": payload}))
        request = "http://localhost:4038?jsonMsg='%s'" % msg
        rawResult = urlopen(request).read()
        result = loads(rawResult.decode())   # bytes.decode()



*----------------------------------------------------------------------------------------------------
* andy sheffer, seattle parks, contact on protecting doug firs at seward playground (11 jan 2016)

  684-7041
  --- (11 jan 2016)
    andy says this comes up on his schedule in march 2016.  he asked for, and I sent, an email
    to close the loop.  he will include me in the work, sending me Maggi's design.

  --- left message (6 jan 2016)
     andy called back at 7pm

*----------------------------------------------------------------------------------------------------
* finding that a BrowserViz port is invisible in jupyter/R notebook, trying python (7 jan 2016)

  pip install git+https://github.com/aaugustin/websockets.git
  Collecting git+https://github.com/aaugustin/websockets.git
    Cloning https://github.com/aaugustin/websockets.git to /var/folders/sq/k3wp6zzn2bn86jdr1z_ckd8r0000gr/T/pip-a7nqabik-build
  Installing collected packages: websockets
    Running setup.py install for websockets
  Successfully installed websockets-3.0


  cd ~/s/src
  git clone https://github.com/aaugustin/websockets.git
  cd websockets
  make   # python -m unittest
*----------------------------------------------------------------------------------------------------
* add aux port and interactive R/Jupyter client connection to a chinook webapp (7 jan 2015)

  bash> jupyter console
    start a new R kernel

*----------------------------------------------------------------------------------------------------
* add aux port and interactive R client connection to a chinook webapp (7 jan 2015)

  in  ~/s/work/chinookWebapps/southSeattleEnvironmentalFactors/browser/Module.js

  --- add variables at module scope:
     var auxSocketURL = "ws://localhost:9003";
     var auxSocket;

  --- ain initializeModule:
     auxSocket = new WebSocket(auxSocketURL);
     setupSpecialSocket(auxSocket);

  ----new functions:

     function setupSpecialSocket(websocket) {
        websocket.onopen    = function(evt) {onOpen(evt) };
        websocket.onclose   = function(evt) {onClose(evt) };
        websocket.onmessage = function(evt) {onMessage(evt) };
        websocket.onerror   = function(evt) {onError(evt) };
        }
     function onOpen(evt) {
        console.log("GeneSetTTests special socket CONNECTED");
        }
     function onClose(evt) {
        console.log("GeneSetTTest special socket DISCONNECTED");
        }
     function onMessage(evt) {
        //console.log("GeneSetTTest special socket RESPONSE: " + evt.data);
        msg = JSON.parse(evt.data);
        hub.dispatchMessage(msg);
        }
     function onError(evt) {
        console.log("GeneSetTTest special socket ERROR: " + evt.data);
        }
     function doSend(message) {
        writeToScreen("GeneSetTTest special socket SENT: " + message);
        websocket.send(message);
        }

  --- start R
     library(BrowserViz)
     app <- BrowserVizDemo(9003, quiet=TRUE)
     send(app, list(cmd="ready", callback="", status="request", payload=""))
     send(app, list(cmd="datasetSpecified", callback="", status="request", payload="SouthSeattleHealthImpacts"))
        // select a (left) data category in the browser
     send(app, list(cmd="ssEFgetLeftDataCategory", callback="", status="request", payload="SouthSeattleHealthImpacts"))

   --- result
     data loaded, maps displayed, menus loaded, app fully alive!

    --- sequencing
      start BrowserVizDemo
      then start cleveland webapp

*----------------------------------------------------------------------------------------------------
* cleveland environmental factors map (chinook) app: use with python and jupyter (6 jan 2015)

  ~/s/work/chinookWebapps/southSeattleEnvironmentalFactors/browser/
  make

*----------------------------------------------------------------------------------------------------
* develop and test chinook, forward to aux port (6 jan 2016)

  --- all working, demonstrated and tested via:
     cd ~/oncogit/Oncoscape/Oncoscape/inst/unitTests
     make
        (cd ../..; R CMD INSTALL . --no-test-load)
        R -f test_ChinookServer.R
        kill `ps aux | grep runEmptyChinookServer.R | grep -v grep | awk '{print $2}'`
        bash R --no-save --silent -f ./runEmptyChinookServer.R &
        sleep 10
        python testEmptyChinookServer.py

     where testEmptyChinookServer.py has these functions:

            from websocket import create_connection
            from json import *
            from urllib.request import urlopen
            from urllib.parse import quote
            *---------------------------------------------------------------------------------------------------
            PORT = 6001
            ws = create_connection("ws://localhost:%d" % PORT)
            wsAux = create_connection("ws://localhost:%d" % (PORT+1))
            *---------------------------------------------------------------------------------------------------
            # make chinook 4-field json request over websocket
            def sendWsMain(cmd, payload):

               msg = dumps({"cmd": cmd, "status":"request", "callback":"", "payload": payload})
               ws.send(msg)
               result = loads(ws.recv())
               return(result["payload"])

            *---------------------------------------------------------------------------------------------------
            # make chinook 4-field json request over websocket
            def sendWsAux(cmd, payload):

               msg = dumps({"cmd": cmd, "status":"request", "callback":"", "payload": payload})
               wsAux.send(msg)
               result = loads(wsAux.recv())
               return(result["payload"])

            *---------------------------------------------------------------------------------------------------
            # do a simple get, check a "hello" comes back
            def checkMainBasicHttpResponse():

               response = urlopen("http://localhost:%d" % PORT).read().decode()
               print("main response: %s" % response)
               assert(response == 'hello from ChinookServer main port')
               print("http server running fine on main port %d" % PORT)

            *---------------------------------------------------------------------------------------------------
            # do a simple get, check a "hello" comes back
            def checkAuxBasicHttpResponse():

               response = urlopen("http://localhost:%d" % (PORT + 1)).read().decode()
               print("aux response: %s" % response)
               assert(response == 'hello from ChinookServer auxiliary port')
               print("http server running fine on aux port %d" % (PORT + 1))

            *---------------------------------------------------------------------------------------------------
            # make chinook 4-field json request over http
            def sendHttpMain(cmd, payload):

               msg = quote(dumps({"cmd": cmd, "status":"request", "callback":"", "payload": payload}))
               request = "http://localhost:%s?jsonMsg='%s'" % (PORT, msg)
               rawResult = urlopen(request).read()
               result = loads(rawResult.decode())   # bytes.decode()
               payload = result["payload"]
               return(payload)

            *---------------------------------------------------------------------------------------------------
            # make chinook 4-field json requestover http
            def sendHttpAux(cmd, payload):

               msg = quote(dumps({"cmd": cmd, "status":"request", "callback":"", "payload": payload}))
               request = "http://localhost:%s?jsonMsg='%s'" % ((PORT+1), msg)
               rawResult = urlopen(request).read()
               result = loads(rawResult.decode())   # bytes.decode()
               payload = result["payload"]
               return(payload)

            *---------------------------------------------------------------------------------------------------

   and makes these calls

            checkMainBasicHttpResponse();
            checkAuxBasicHttpResponse();
            messageNames = sendHttpMain("getRegisteredMessageNames", "")
            messageNames2 = sendWsMain("getRegisteredMessageNames", "")
            assert(messageNames2 == messageNames)
            messageNames3 = sendHttpAux("getRegisteredMessageNames", "")
            assert(messageNames3 == messageNames)
            messageNames4 = sendWsAux("getRegisteredMessageNames", "")
            assert(messageNames4 == messageNames)


*----------------------------------------------------------------------------------------------------
* build chinook app outside of chinook tree (1 jan 2016)

  export M4PATH=/Users/pshannon/oncogit/Oncoscape/Oncoscape/inst/scripts
*----------------------------------------------------------------------------------------------------
* test ChinookServer, ChinookDataset using http, python, R (31 dec 2015)

  --- in python

   cat dataPackages/ChinookDataset/inst/unitTests/testHttpOperations.py
   from urllib.request import urlopen
   from urllib.parse import quote
   from json import *

   msg = quote(dumps({"cmd": "getDatasetManifest", "status":"request", "callback":"", "payload": "DEMOdz"}))
   request = "http://localhost:4019?jsonMsg='%s'" % msg
   rawResult = urlopen(request).read()
   result = loads(rawResult.decode())   # bytes.decode()
   payload = result["payload"]

   fieldNames = list(payload.keys())
   assert(len(fieldNames) == 4)
   assert(fieldNames.index("mtx") >= 0)
   assert(fieldNames.index("colnames") >= 0)
   assert(fieldNames.index("rownames") >= 0)
   assert(fieldNames.index("datasetName") >= 0)

   assert(payload["datasetName"][0] == "DEMOdz")
   print(True)

  --- in R
    library(RCurl)
    library(jsonlite)
    getURL(URLencode("http://localhost:7001"))   # [1] "hello from ChinookServer main port"
    json <- URLencode('{"cmd":"getDatasetManifest","status":"request","callback":"","payload":"SouthSeattleHealthImpacts"}')
    url <- sprintf("http://localhost:7001?jsonMsg='%s'", json)
    fromJSON(getURL(url))
    $cmd
    [1] ""

    $status
    [1] "success"

    $callback
    [1] ""

    $payload
    $payload$datasetName
    [1] "SouthSeattleHealthImpacts"

    $payload$colnames
    [1] "category"    "subcategory" "rows"        "cols"        "row type"    "column type" "minValue"    "maxValue"    "provenance"

    $payload$rownames
    [1] "tbl.factors.RData"       "tbl.neighborhoods.RData" "zipCodes-json.RData"

    $payload$mtx
         [,1]          [,2]                            [,3] [,4] [,5]       [,6]             [,7] [,8] [,9]
    [1,] "environment" "health-related factors"        "10" "25" "zip code" "factors"        NA   NA   "Duwamish Valley Cumulative Health Impacts Analysis, Gould & Cummings"
    [2,] "geography"   "neighborhood names by zipcode" "10" " 4" "zip code" "name,lat,long"  NA   NA   "manual curation by Paul Shannon"
    [3,] "geography"   "zipcode boundaries"            "32" NA   "zip code" "lat,long pairs" NA   NA   "US government"


*----------------------------------------------------------------------------------------------------
* create the cleveland chinook webapp (30 dec 2015)

  cd ~/s/work/chinookWebapps/southSeattleEnvironmentalFactors


*----------------------------------------------------------------------------------------------------
* r tips, uninstall package

   remove.packages("SttrDataPackage", .libPaths())

   see also: ~/oncogit/Oncoscape/removeInstalledOncoscapePackages.R

*----------------------------------------------------------------------------------------------------
* cleveland project (26 dec 2015)

   cd ~/s/work/cleveland/environmentalHealth/
   start python -m http.server .
   http://localhost:8000

   displays 20 or so button, dynamically created

   next up: read from global dataTable using category name, in
      function loadCategoryData(categoryName), line 274

*----------------------------------------------------------------------------------------------------
* d3 map pan and zoom:   Rolling pan and zoom with Mercator projection

  http://bl.ocks.org/patricksurry/6621971

*----------------------------------------------------------------------------------------------------
* responsive svg, scale svg, window resize svg

  --- my experiments, based on eyeseast, below

    cd ~/s/work/cleveland/environmentalHealth/
    python -m http.server
    http://localhost:8000
    default scale is 220000

    -- in js console
      projection.scale(22000);
      svg.selectAll('path').attr('d', path);  # redraws


    tx = $("#mapDiv").width()/2; ty = $("#mapDiv").height()/2; projection.translate([tx, ty]); svg.selectAll('path').attr('d', path);

  --- manipulate the d3 map projection
      http://eyeseast.github.io/visible-data/2013/08/26/responsive-d3/

   var margin = {top: 10, left: 10, bottom: 10, right: 10};
   var width = parseInt(d3.select('#map').style('width'))
   width = width - margin.left - margin.right;
   var mapRatio = .5
   var height = width * mapRatio;


   var projection = d3.geo.albersUsa()
       .scale(width)
       .translate([width / 2, height / 2]);

   var path = d3.geo.path()
      .projection(projection);


   d3.select(window).on('resize', resize);
   function resize() {
     width = parseInt(d3.select('#map').style('width'));
     width = width - margin.left - margin.right;
     height = width * mapRatio;
     projection.translate([width / 2, height / 2]).scale(width);
     map.style('width', width + 'px')..style('height', height + 'px');
     map.select('.land').attr('d', path);
     map.selectAll('.state').attr('d', path);
     }

  --- wide discussion
  https://css-tricks.com/scale-svg/

*----------------------------------------------------------------------------------------------------
* contact chinook from jupyter-notebook (22 dec 2015)

  --- start chinook server
  cd ~/oncogit/Oncoscape/analysisPackages/chinookAnalysisDemo/ChinookSimpleSummaryStats/inst/unitTests
  make   (default targets: kill, server, delay, py (both a ws and an http test; leaves server running)

  --- install (re-install) websocket library
    from https://pypi.python.org/pypi/websocket-client/ got
    type pip # pip is /Users/pshannon/anaconda/bin/pip
    pip install ~/Downloads/websocket_client-0.34.0.tar.gz
    test it:
       python (3.5.1, anaconda)
       import websocket  # good

   ---- start up a simple chinook instance: runChinookSimpleSummaryStatsServer.R
        library(ChinookServer)
        library(ChinookSimpleSummaryStats)
        analysisPackages = "ChinookSimpleSummaryStats"
        datasets <- NA_character_
        browserFile <- NA_character_
        userCredentials <- "test@nowhere.net"
        chinook <- ChinookServer(port=4001, analysisPackages, datasets, browserFile, userCredentials)
        run(chinook)


   --- start jupyter  (not sure why these apps, in ~/anacoda/bin do not respond to tab completeion)
      jupyter console --classic
        from websocket import create_connection
        from json import *
        ws = create_connection("ws://localhost:4001")   # the main chinook server port
        payload = [5.4964085, 0.7883715, 6.4879698, 4.9685336, 7.1878731]
        msg = dumps({"cmd": "numericVectorSummaryStats", "status":"request", "callback":"", "payload": payload})
        ws.send(msg)
        result = loads(ws.recv())
        payload = result["payload"]



   --- create a notebook
     cd ~/s/work/notebooks/
     start jupyter-notebook, open a new python3 kernal, pasted this in, named it, saved it

     import sys
     import time
     from websocket import create_connection
     from json import *
     ws = create_connection("ws://localhost:4001")
     payload = [5.4964085, 0.7883715, 6.4879698, 4.9685336, 7.1878731]
     msg = dumps({"cmd": "numericVectorSummaryStats", "status":"request", "callback":"", "payload": payload})
     ws.send(msg)
     result = loads(ws.recv())


  --- do PCA from a notebook
    cd ~/oncogit/Oncoscape/analysisPackages/ChinookPCA/inst/unitTests/; make # starts server, leaves it running


*----------------------------------------------------------------------------------------------------
* anaconda: python version 3.5.1, anaconda 2.4.1,  jupyter v 4.0.6  (22 dec 2015)

  https://www.continuum.io/downloads

  Anaconda  is a  completely free  Python distribution  (including for
  commercial use and redistribution). It includes more than 300 of the
  most  popular Python  packages for  science, math,  engineering, and
  data analysis.

  offers choice of py 2.7 and 3.5.  (opting for 3.5 this time, seems I got 2.7 before)
  open ~/Desktop/Anaconda3-2.4.1-MacOSX-x86_64.pkg
  installed to ~/anaconda
  put this very near the top of my ~/.bashrc PATH statements
     PATH=$PATH:/Users/pshannon/anaconda/bin
     source ~/.bashrc
  type -a python
    python is /Users/pshannon/anaconda/bin/python
    python is /usr/bin/python
 python --version
    Python 3.5.1 :: Anaconda 2.4.1 (x86_64)
 type -a jupyter
    jupyter is /Users/pshannon/anaconda/bin/jupyter


  jupyter-notebook   # starts at http://localhost:8888/tree#  displays full contents of pwd

*----------------------------------------------------------------------------------------------------
* allan reuss, swing guitar
  also bix
  http://swingguitar.blogspot.com/search?q=van+eps
   Arnold Ross Quintet f/Benny Carter - Bye Bye Blues
Lionel Hampton - Rhythm, Rhythm
Jack Teagarden Orchestra - Pickin' for Patsy
Coleman Hawkins - Stuffy
Benny Goodman Orchestra - Rosetta

George Van Eps - Although he is now famous mostly for inventing and
playing 7-string guitar, Van Eps was a fantastic 6-string rhythm and
chordal player.

Adrian Rollini Orchestra - Somebody Loves Me
George Van Eps - Ain't Misbeavin'
Jess Stacy - Indiana


Carmen Mastren - Another great rhythm player, Mastren started out with Wingy Manone, but most famously he played with the Tommy Dorsey Orchestra and even did some arranging for the band. He later joined the Glenn Miller Army Air Force Band during World War II.
Delta Four - Swingin' on that Famous Door
Bechet-Spanier Big Four - If I Could Be With You

Carl Kress - Kress' chordal style descended from extented Tenor Guitar / Banjo tuning. He famously recorded duets with Eddie Lang. After Lang's death in 1933, he partnered with Dick McDonough, until that guitarist's death in 1938. Kress also did duets with Tony Mattola, and later George Barnes. Here he is presented without another guitar player.
Edmund Hall All Star Quintet - Seein' Red
Edmund Hall All Star Quintet - Rompin' in '44

*----------------------------------------------------------------------------------------------------
* refactoring the oncoscape core (14 dec 2015)

  current constructor:

    onco <- OncoDev14(port=port, scriptDir=scriptDir, userID=userID, datasetNames=current.datasets)

  new form

    app <- Oncoscape(port, analysisPackages, datasets, browserFile, userCredentials)

     analysisPackages: a list of R package names, each of which is derived from
                       the SttrAnalysisPackage base class
     datasets: a list of R package names, each of which is derived from the
               the SttrDataPackage base class

     browserFile: name of a file combining HTML, CSS and Javascript
     userCredentials: an instance of the UserCredentials class (or a subclass)

   Three abstract base classes are needed:

       SttrDataPackage: need add open-ended support for indirect data (local database, remote
          database, cloud, etc.)
       SttrAnalaysisPackage: provides template and some shared methods for, e.g., PCA, PLSR, and
          future additions
       UserCredentials:  open-ended design, from simple userID and no password, to LDAP, AD, and etc.

   Both SttrDataPackage and SttrAnalysisPackage follow the loose definition of SOA, service oriented
   architecture (https://en.wikipedia.org/wiki/Service-oriented_architecture):

       "a component that is encapsulated behind an interface"

   The PCA analysis package behaves like this (these calls are made by the Oncoscape server)

       packge.name <- "PCA"    # or "PCA.SOA.AmazonS3" or ...
       library(package.name)   # load the code, which may be self-contained, or a facade to a
                               # adaptive distributed system deployed in the cloud, or ...
                               # crucial: the server has no idea how the PCA calculations are actually
                               # performed, nor where the data actually is

       eval(parse(text=sprintf("pkg <- %s(server)", package.name)))
       register(pkg)           # the pkg tells the server the websocket messages it wants to receive

       the server provides data and message passing services to the pkg.


   Two app constructor examples to demonstrate the spectrum of uses:

    1) reproduce current style of use:

        app <- Oncoscape(7001, c("PCA", "PLSR"), c("DEMOdz", "TCGAbrain"),
                          "index.html", "demo@nowhere.org");

    2) demonstrate distributed shared data, analysis, high security.  "

        app <- Oncoscape(7001, c("PCA.SOA.AmazonS3", "PLSR.immediate"),
                         c("DEMOdz.immediate", "TCGAbrain.Amazon"),
                         "index.html",
                         "HutchPHI")

        note that the actual values of the the user's credentials is deferred to
        an as-yet unspecified but arbitrarily complex, arbitrarily secure class.

    Data and analysis packages, and credentials, all depend upon the Factory design
    pattern, in which a character strings are passed to the appropriate factory,
    which returns a (possibly intricate, possibly simple) object of the appropriate
    derived class.  Each of these concrete objects (an SttrDataPackage, an SttrAnalysisPackage,
    a UserCredential instance) supports the methods of their base class, so each
    can be used in Oncoscape interchangeably.

    For example, imagine the use of a private BRCA data set stored with many layers of security
    on the Amazon cloud.

      app <- Oncoscape(7001,
                       c("TCGAbrca.SOA.AmazonS3", "BRCA4013.SOA.AmazonS3.PHIlevel.10"),
                       c("PCA.immediate", "HOBO.hutchCluster"),
                       "index.html",
                       "HutchCredentials.PHI.level.10")

     As the app starts up:
        1) the specified credentials object is created, and the user must establish
               a) she has a secure connection
               b) she is authorized
        2) TCGAbrca.SOA.AmazonS3 is created, needs no credentials (or maybe just enough
           for billing purposes)
        3) BRCA4013.SOA.AmazonS3.PHIlevel.10 is created.  the high security credentials
           from step 1 must be supplied
        4) a PCA package is loaded and initialized; it runs in-process with Oncoscape
        5) a hobo similarity calculator, peruaps already running on the hutch cluster,
           is contacted.  maybe credentials are needed, if only to track which lab
           is using the cluster.




*----------------------------------------------------------------------------------------------------
* next up, monday (14 dec 2015)

   cd ~/oncogit/Oncoscape/dataPackages/NetworkMaker/inst/unitTests/
   test_NetworkMaker.R
   create a tiny network from big TCGAbrain, with some unrecognized (but mappable) gene names
   test.fullDisplay.14genes.someObsolete.TCGAbrain <- function()


*----------------------------------------------------------------------------------------------------
* update TCGAbrain's tbl.glioma8 with hamid's cluster names (10 dec 2015)

   ---- his email (09 dec 2015)

    You _should_ find that the non-CIMP LGGs all fall in the left-hand
    cloud of points in the sample-similarity plot, and the CIMP-LGGs
    are all in the 2 right-hand clouds.

     Given the above definitions, here are the derivations of the 8 groups (not needed, just FYI):

     grp1 <- intersect(nonCIMP, intersect(gainNRAS, mutTP53))                            nonCIMP.gainNRAS.mutTP53
     grp2 <- intersect(nonCIMP, intersect(gainNRAS, wtTP53))                             nonCIMP.gainNRAS.wtTP53
     grp3 <- intersect(nonCIMP, intersect(wtNRAS, wtTP53))                               nonCIMP.wtNRAS.wtTP53
     grp4 <- intersect(nonCIMP, intersect(wtNRAS, mutTP53))                              nonCIMP.wtNRAS.mutTP53
     grp5 <- intersect(intersect(CIMP.like.LGG, not1p19q), intersect(mutATRX, mutTP53))  lggCIMP.not1p19q.mutATRX.mutTP53
     grp6 <- intersect(intersect(CIMP.like.LGG, not1p19q), intersect(wtATRX, mutTP53))   lggCIMP.not1p19q.wtATRX.mutTP53
     grp7 <- intersect(CIMP.like.LGG, intersect(del.1p19q, c(mutCIC, mutFUBP1)))         lggCIMP.del1p19q.mutCIC.mutFUBP1
     grp8 <- intersect(CIMP.like.LGG, intersect(del.1p19q, intersect(wtCIC, wtFUBP1)))   lggCIMP.del1p19q.wtCIC.wtFUBP1

     My suggestion is that compose the group labels by concatenating
     the sample group IDs in each derviation above. For example
     group1's name would be:   nonCIMP.gainNRAS.mutTP53



*----------------------------------------------------------------------------------------------------
* cyjs update style (7 dec 2015)

  cd ~/oncogit/Oncoscape/dataPackages/networks/experiments/cssPrecedence/

  strategy:  get the style in json.  identify the element to change, and change it.  reassign all styles.

  style = cwMarkers.style().json()
  style.forEach(function(element){ console.log(element.selector)})
     node
     node:selected
     edge

  JSON.stringify(style[1])
     "{"selector":"node:selected","style":{"border-width":"10px","background-color":"lightgreen"}}"

  style[1] = {selector: "node:selected", style:{"border-width": "3px", "background-color": "yellow"}}
  cy.style(style)

*----------------------------------------------------------------------------------------------------
* tzarmedia scam (7 dec 2015)

  Reference Number: 51722117

  Dear Paul,

  This message is to inform you that your membership with TzarMedia
  has been cancelled effective immediately and that we have refunded
  the following transaction(s):

  Refund Issued: $29.95
  Refund Date: December 07, 2015
  Card Type: Visa
  You will retain access to tzarmedia.com until Dec 07, 2015

  Please Note: Refunds may take 5 to 10 business days before appearing
  on your statement. Thank you for using TzarMedia, if you have
  additional questions or comments, please do not hesitate to contact
  us.


   Toll-free No: 1-877-747-0005

   Primary No: 1-302-722-4141


*----------------------------------------------------------------------------------------------------
* jupyter on wombat, with R (5 dec 2015)

  cd ~/s/work/jupyter
  ---- install the R kernal
     git clone https://github.com/IRkernel/IRkernel.git
     start R
      # had to do these one at a time.
     install.packages(c('rzmq','repr','IRkernel','IRdisplay'), repos = c('http://irkernel.github.io/', getOption('repos')))
        # run these in R launched in iTerm, so path to jupyter is picked up
     library(IRkernel)
     IRkernel::installspec()

  --- start the notebook server
    cd ~/s/work/jupyter/
    ipython notebook     #  R and python2 kernels available,  R kernel apparently installed in the commands just above

  ---- try it
     http://localhost:8888

  --- try it with chinook
     http://localhost:8888
     from jupyter home/files tab, at far left find menu "New" - start python
      cd ~/oncogit/Oncoscape/analysisPackages/chinookAnalysisDemo/ChinookSimpleSummaryStats/inst/unitTests/
      make   # starts server on 4001, aux on 4002, leaves
       ps x | grep runChinookSi | grep -v grep   # ensure server is running
      in jupyter python

import sys
import time
from websocket import create_connection
from json import *
ws = create_connection("ws://localhost:4001")

payload = [5.4964085, 0.7883715, 6.4879698, 4.9685336, 7.1878731]

msg = dumps({"cmd": "numericVectorSummaryStats", "status":"request", "callback":"", "payload": payload})
ws.send(msg)
result = loads(ws.recv())




*----------------------------------------------------------------------------------------------------
* jupyter installation, making custon R bundle, R kernel
  ---- also of note: revolution analytics installation guide
    Step 1: install miniConda
       Get and install miniConda for Python 3 at http://conda.pydata.org/miniconda.html
       Important: install python 3

    Step 2: open an OS terminal window:
      conda install -c r ipython-notebook r-irkernel
      ipython notebook

   ---- creating your custom R bundle
     https://www.continuum.io/blog/developer/jupyter-and-conda-r

*----------------------------------------------------------------------------------------------------
* SttrDataPackage assessment sample code, gretchen heinrich (4 dec 2015)

   ~/s/examples/oncoscapeExplorations/gretchen/
   go.R

*----------------------------------------------------------------------------------------------------
* "a picture held us captive"  philosophical investigations wittgenstein  (4 dec 2015)  by ray monk

   where the picture referred to is the augustinian picture of meaning, with which PI begins,
   associating word and object.

  To grasp these important things, we need not to reason verbally, but rather to look more
  attentively at what lies before us. “Don’t think, look!” Wittgenstein urges in Philosophical
  Investigations. Philosophical confusion, he maintained, had its roots not in the relatively
  superficial thinking expressed by words but in that deeper territory studied by Freud, the
  pictorial thinking that lies in our unconscious and is expressed only involuntarily in, for
  example, our dreams, our doodles and in our “Freudian slips”. “A picture held us captive,”
  Wittgenstein says in the Investigations, and it is, he thinks, his job as a philosopher not to
  argue for or against the ￼￼truth of this or that proposition but rather to delve deeper and
  substitute one picture for another. In other words, he conceived it as his task to make us, or at
  least to enable us, to see things differently.

  The importance Wittgenstein attached to seeing was vividly portrayed – in an appropriately visual
  form – in the “Wittgenstein: Philosophy and Photography” exhibition at the London School of
  Economics earlier this summer and, before that, at the University of Cambridge. The exhibition
  brought together a range of fascinating photographs that included studio portraits of the
  Wittgenstein family (he had four brothers and three sisters) in their palatial homes in Vienna;
  pictures of Wittgenstein himself as, in turn, a baby, a navy-suited young boy, a student, a
  soldier and finally a professor; photographs of the modernist house he designed in Vienna for his
  sister Gretl; holiday snapshots that Wittgenstein took on a cheap camera he had bought in
  Woolworths; pages from his photo album containing tiny pictures of his friends and family members;
  and a series of (frankly rather weird) photographs that Wittgenstein took in a photo booth in
  which he changed his expression and the direction of his eyes after each shot so that the series
  might be put together in a flip-book that forms the nearest thing we have to moving images of the
  great philosopher.


  The exhibition began with its most intriguing item: a composite photograph made up of four
  portraits of Wittgenstein and his three sisters (see above). At first, it looks like a picture of
  a single person, albeit one of indeterminate sex; a very effeminate man perhaps, or else a rather
  “butch” woman. But then one notices details of the various component photographs. Around the neck,
  for example, one sees a strange assortment of accessories: Helene’s scarf com- bining oddly with
  Gretl’s necklace and the ghost of Ludwig’s open-necked shirt. And yet the eyes, the nose and the
  mouth look like they belong to the same person, enabling one to see directly the very strong
  family resemblances that existed between these four siblings.

  The notion of “family resemblances” is crucial to Wittgenstein’s later philosophy. It plays a
  critical role in his attempt to unseat the pic- ture that he regards as the root of most
  philosophical confusion, namely the “Augustinian picture of meaning”. Philosophical Investigations
  begins with a passage not from a work of philosophy but from an autobiography: St Augustine’s
  Confessions. In it, Augustine describes how he learned to speak. “When [my elders] named some
  object,” he says, “I grasped that the thing was called by the sound they uttered”; thus, hearing
  words used in this way repeatedly, he “gradually learned to understand what objects they
  signified”.

  This passage, Wittgenstein says, gives us “a particular picture of the essence of human language”,
  a picture that represents meaning as a relationship between a word and an object. This picture is
  relatively harmless when we confine ourselves to such words as “table”, “chair” and so on but when
  applied to the more complex notions that philosophers consider – the mind, the soul, justice,
  truth, meaning – it leads to confusion. We ask, “What is the mind?” and expect the answer to take
  the form of identifying some thing that the word “mind” refers to.

  To overcome this, Wittgenstein suggests we understand words as picking out not some sin- gle thing
  but a group of things that need not have anything in common. Rather, like members of the same
  family, they might have a series of similarities and dissimilarities that overlap and criss-cross
  in various complicated ways. Some Wittgensteins (such as Ludwig and his sisters) might have the
  same nose, the same mouth, the same eyes but, say, different foreheads. There need not be one
  thing that all members of the family have in common. Likewise, there need not be any one thing
  that all instances of the word “truth” have in common. The philoso- phical task of looking for the
  essence of truth, then, is unending, not because it is deep but because it is an example of the
  ways in which we can be captured by a picture.

  Thus, at the heart of Wittgenstein’s philosophy is what he calls “the understanding which consists
  in ‘seeing connections’ ”. Here “seeing” is meant not metaphorically, but literally. That is why,
  towards the end of the book, he devotes so much space to a discussion of the phenomenon of seeing
  ambiguous figures such as the duck-rabbit. When we “change the aspect” under which we look at the
  picture, seeing it now as a duck, now as a rabbit, what changes? Not the picture, for that stays
  the same. What changes is not any object but rather the way we look at it; we see it differently,
  just as we see a face differently when we look at it, first as an expression of happiness and then
  as an expression of pride.

  “You don’t take enough notice of people’s faces,” Wittgenstein once admonished his friend Maurice
  Drury. “It is a fault you ought to correct.” The great merit of “Wittgenstein: Philosophy and
  Photography” was that it provided us with an opportunity to take his advice.

  Ray Monk is professor of philosophy at the University of Southampton and the author of "Ludwig
  Wittgenstein: the Duty of Genius" (Vintage, £12.99)


*----------------------------------------------------------------------------------------------------
* javascript error monitoring

  https://trackjs.com/pricing/
*----------------------------------------------------------------------------------------------------
* similarity plots, oncoscape:  a dist which handles NA, missing values (3 dec 2015)

  http://stackoverflow.com/questions/18117174/function-dist-not-behaving-as-expected-on-vectors-with-missing-values
  argues (and see example ~/s/examples/R/dist/withNA.R) that

    If somewhere you have a NA for dimension i, a reasonable guess for
    the contribution of dimension i to the squared sum is the mean
    contribution of all other dimensions. Hence the linear up-scaling.

  that is, it is as if any NA at any position (any dimension of measurement) eliminates that
  dimension

     set.seed(123)
     v1 <- sample(c(1:3, NA), 100, TRUE)
     v2 <- sample(c(1:3, NA), 100, TRUE)
     dist(rbind(v1, v2))
     #          v1
     # v2 12.24745
     na.idx <- is.na(v1) | is.na(v2)
     v1a  <- v1[!na.idx]
     v2a  <- v2[!na.idx]
     sqrt(sum((v1a - v2a)^2) * length(v1) / length(v1a))
     # [1] 12.24745


  ---- "a sensibly chosen default: the mean or median value of each feature"
     http://stats.stackexchange.com/questions/79215/similarity-measures-with-missing-values

     As far as I know, there isn't any formal theoretical framework
     that describes how to do this. A heuristic technique that I've
     seen used in the past for similar types of missing-data problems
     is to replace missing values (but for purposes of performing the
     relative distance calculation only, not for the rest of your
     analysis!) with a sensibly chosen default value. In your case, a
     sensible default might be to choose the mean or median of each
     feature value, tabulated over all instances which do have the
     feature present. Alternatively, if you wanted to penalize
     instances with missing values a little bit (i.e., causing them to
     be treated a little more "conservatively", or more likely
     dissimilar, since you just don't know for sure) you might
     substitute missing feature values with the mean value plus some
     margin, say one sigma or something like that. As I said, it's a
     heuristic technique, so there's no well-defined "correct answer",
     you'd have to use your own judgment in deciding precisely which
     values to substitute for the missing instances.

   --- same exchange "or do an imputation (such as, for example, hot-deck imputation)"

      https://en.wikipedia.org/wiki/Imputation_%28statistics%29

      In statistics, imputation is the process of replacing missing
      data with substituted values. When substituting for a data
      point, it is known as "unit imputation"; when substituting for a
      component of a data point, it is known as "item
      imputation". Because missing data can create problems for
      analyzing data, imputation is seen as a way to avoid pitfalls
      involved with listwise deletion of cases that have missing
      values. That is to say, when one or more values are missing for
      a case, most statistical packages default to discarding any case
      that has a missing value, which may introduce bias or affect the
      representativeness of the results. Imputation preserves all
      cases by replacing missing data with an estimated value based on
      other available information. Once all missing values have been
      imputed, the data set can then be analysed using standard
      techniques for complete data.[1]

*----------------------------------------------------------------------------------------------------
* get hamid's hobo plot for gbm (1 dec 2015)

  rhino:/shared/silo_researcher/Holland_E/HollandLabShared/Hamid/Oncoscape2015/GBM/MDS.SNV.CNV.RData

  --- email today

     Paul; Try 'MDS.SNV.CNV.RData' from 'HollandLabShared/Hamid/Oncoscape2015/GBM'.
     In my HoBo plot (attached, 2nd panel from right, top row), it looked OK.


   cd ~/oncogit/Oncoscape/dataPackages/TCGAgbm/inst/utils
   scp rhino:/shared/silo_researcher/Holland_E/HollandLabShared/Hamid/Oncoscape2015/GBM/MDS.SNV.CNV.RData .

    5538 bytes, from (31 aug 2015)

    print(load("MDS.SNV.CNV.RData"))   # ] "MDS.SNV.CNV"
   dim(MDS.SNV.CNV)  # [1] 273   2



*----------------------------------------------------------------------------------------------------
* oncoscape markers slowdown: 60 reps of loading and displaying TCGAgbm (30 nov 2015)

   cd ~/oncogit/Oncoscape/Oncoscape/inst/scripts/markersAndSamples/analysis/
   getGraph.py, 100 reps, loads 1,151,137 bytes at average time of 1.07 seconds
     # mean(scan("tmp", what=integer(0), sep="\n")) # Read 100 items, [1] 1.07

   ---  see plot of logged events from within test run of oncoscape
       open ~/oncogit/Oncoscape/Oncoscape/inst/scripts/markersAndSamples/analysis/TCGAgbm-60reps.png

   --- produced thus
     cd ~/oncogit/Oncoscape/Oncoscape/inst/unitTests
     make server
     cd ~/oncogit/Oncoscape/Oncoscape/inst/scripts/markersAndSamples/analysis/
     start python in separate shell, these contents in
         getGraph.py

             *---------------------------------------------------------------------------------------------------
             import sys
             import time
             from websocket import create_connection
             from json import *
             ws = create_connection("ws://localhost:6001")
             *---------------------------------------------------------------------------------------------------
             cmd = "specifyCurrentDataset"
             callback = "datasetSpecified"
             dataset = "TCGAgbm";
             payload = dataset
             msg = dumps({"cmd": cmd, "status": "request", "callback": callback, "payload": payload})
             ws.send(msg)
             result = loads(ws.recv())
             assert(result["payload"]["datasetName"] == dataset);
             assert(result["cmd"] == callback)
             cmd = "getMarkersNetwork"
             callback = "displayMarkersNetwork"
             msg = dumps({"cmd": cmd, "status": "request", "callback": callback, "payload": payload})
             for i in range(0, 100):
                start = time.time()
                ws.send(msg)
                result = loads(ws.recv())
                end = time.time()
                json = result["payload"]
                print "%d) %d secs to load %d bytes" % (i, end-start, len(json))

     ---- from within oncoscape
      cd ~/oncogit/Oncoscape/Oncoscape/inst/scripts/markersAndSamples
      make test   # R -f runMarkers.R  autotest.60@nowhere.org.exitOnCompletion "TCGAgbm"
      open ~/oncogit/Oncoscape/Oncoscape/inst/scripts/markersAndSamples/analysis/TCGAgbm-60reps.png


     --- possible next steps
       javascript gets two very fast dataDeliveries, about 1 second each., followed by 10 and rising
       at least in this one run.
       devtools heap profile should therefore show problem right away - no need for a long run.



*----------------------------------------------------------------------------------------------------
* cleveland high school projects, grant storey (29 nov 2015)

   cd ~/s/work/cleveland/environmentalHealth/
   start python -m SimpleHTTPServer
   http://localhost:8000

   displays 20 or so button, dynamically created

   next up: read from global dataTable using category name, in
      function loadCategoryData(categoryName), line 274


*----------------------------------------------------------------------------------------------------
* non-custodial parent form for hampshire finacial aid, college board, leo (26 nov 2015)

   --- successful login (30 nov 2015)
     https://ncprofile.collegeboard.com/ncpWeb/pageflows/Main/NcpMainController.jpf
       css id: 2065328
       leo's college board login and password for nc parent (30 nov 2015):
          css id 2065328, snowbo8rd (no underscore!), first pet? bandit
  --- completed form, saved pdf to
     ~/s/taxes/collegeForLeo/collegeBoardNonCustodialParent.pdf

   --- failed login
     leo's college board login and password (26 apr 2015): leodshannon2, snow_bo8rd
     noncustodial parent css id: 3065328 (from cduva 24nov2015), pw = snow_bo8rd
     https://ncprofile.collegeboard.com/ncpWeb/pageflows/Main/NcpMainController.jpf



*----------------------------------------------------------------------------------------------------
* javascript event reduction: throttle and debounce (25 nov 2015)

  --- what i use in Module.markers: ~15 lines of code from

     https://davidwalsh.name/javascript-debounce-function


One of the biggest mistakes I see when looking to optimize existing code is the absence of the debounce function.  If your web app uses JavaScript to accomplish taxing tasks, a debounce function is essential to ensuring a given task doesn't fire so often that it bricks browser performance.

Advertisement
For those of you who don't know what a debounce function does, it limits the rate at which a function can fire. A quick example:  you have a resize listener on the window which does some element dimension calculations and (possibly)  repositions a few elements.  That isn't a heavy task in itself but being repeatedly fired after numerous resizes will really slow your site down.  Why not limit the rate at which the function can fire?

Here's the basic JavaScript debounce function (as taken from Underscore.js):

// Returns a function, that, as long as it continues to be invoked, will not
// be triggered. The function will be called after it stops being called for
// N milliseconds. If `immediate` is passed, trigger the function on the
// leading edge, instead of the trailing.
function debounce(func, wait, immediate) {
	var timeout;
	return function() {
		var context = this, args = arguments;
		var later = function() {
			timeout = null;
			if (!immediate) func.apply(context, args);
		};
		var callNow = immediate && !timeout;
		clearTimeout(timeout);
		timeout = setTimeout(later, wait);
		if (callNow) func.apply(context, args);
	};
};




  from max franz:


     https://lodash.com/docs#debounce
     http://drupalmotion.com/article/debounce-and-throttle-visual-explanation
     http://benalman.com/projects/jquery-throttle-debounce-plugin/

*----------------------------------------------------------------------------------------------------
* uninstall, reinstall chrome (25 nov 2015)

  is the auto updater present?
     defaults read com.google.Keystone.Agent   # any results indicate yes
  disable updates:
     defaults write com.google.Keystone.Agent checkInterval 0

   ~/Library/Google/GoogleSoftwareUpdate/GoogleSoftwareUpdate.bundle/Contents/Resources/GoogleSoftwareUpdateAgent.app/Contents/Resources/ksinstall --uninstall

  rm -rf ~/Library/Google/
  rm -rf ~/Library/Caches/com.google*
  rm -rf ~/Library/Preferences/com.google*
  rm -rf ~/Library/Preferences/com.google*    # nothing there today


*----------------------------------------------------------------------------------------------------
* install jupyter via anaconda

   https://www.continuum.io/downloads#_macosx
   got python 2.7 maocOSX 64-bit command-line installer
   bash Anaconda2-2.4.0-MacOSX-x86_64.sh
   installs to ~/anaconda2

   source ~/.bash_profile
   type -a jupyter   #   ~/anaconda2/bin/jupyter-notebook

   sudo pip install websocket-client
   Successfully installed websocket-client-0.34.0

    cd ~/s/work/notebooks/
    jupyter-notebook .

*----------------------------------------------------------------------------------------------------
* python/oncoscape remote control test (19 nov 2015)

  cd ~/s/work/notebooks/
  ~/anaconda2/bin/jupyter-notebook .

  import sys
  import time
  from websocket import create_connection
  from json import *
  ws = create_connection("ws://localhost:7576")

  payload = {"value": "EGFR", "count": 1, "source": "pythonShell"};
  msg = dumps({"cmd": "sendSelectionTo_MarkersAndPatients", "status":"forBrowser", "callback":"", "payload": payload})
  ws.send(msg)

    added Oncoscape/R/AuxPort.R

  sudo pip install websocket-client

*----------------------------------------------------------------------------------------------------
* title and abstract for isb talk (18 nov 2015)

No More Silos:  a tiny protocol for linking analyses, visualizations, and assembling bioinformatic web sites

Bioinformatic and computational biology software and web sites abound. Many have
great power and utility, and are often excellent for one (or a few) analytical
tasks. Thus we have fine tools for sequence analysis, network inference,
structural analysis, data reduction, and visualizations of all kinds.
Interoperability is, however, weak.

On the assumption that the user interface for all these tools is (or should be)
a web browser, and that flexible semantics allows us to sidestep many of the
difficulties of data integration, I will present and demonstrate a tiny protocol
(JSON messages over web sockets) for assembling powerful data exploration and
analysis environments.


*----------------------------------------------------------------------------------------------------
* interactive data science with R in apache zeppelin notebook. (16 nov 2015)

  add an R interpreter to oncocape?
  http://www.r-bloggers.com/interactive-data-science-with-r-in-apache-zeppelin-notebook/?utm_source=feedburner&utm_medium=email&utm_campaign=Feed%3A+RBloggers+%28R+bloggers%29
*----------------------------------------------------------------------------------------------------
* Annotables: R data package for annotating/converting Gene IDs

*----------------------------------------------------------------------------------------------------
* hoc, hallmarks of cancer, angiogenesis, with TCGAbrca, any signal?  no...(15 nov 2015)

  ~/s/examples/oncoscapeExplorations/hocgsea/go.R

  using this:

   score <- function(id, genes) {
     copy.number <- sum(abs(mtx.cn[id, genes]))
      mut <- 5 * sum(which(nchar(mtx.mut[id, genes]) > 0))
      vec.expr <- mtx.mrna[id, genes]
      vec.expr[which(is.na(vec.expr))] <- 0
      #mrna <- sum((abs(vec.expr - mrna.mean)/mrna.sd))
      mrna <- sum(abs(vec.expr))
      #browser()
     #printf("cn: %f  mut: %f  mrna: %f", copy.number, mut, mrna)
      copy.number + mut # + mrna
     } # score


   x <- lapply(ids, function(id) score(id, genes))
   > fivenum(unlist(x, use.names=FALSE))
   [1]   0   4   9  13 276
  genes.random <- noncancer.genes[sample(1:length(noncancer.genes), length(genes))]
   x.random <- lapply(ids, function(id) score(id, genes.random))
 fivenum(unlist(x.random, use.names=FALSE)) # [1]   0.9352696   8.2746271  17.6662096  27.1642616 131.6237329
    [1]   0   5   8  12 275
    [1]   0   4   8  13 269

  no apparent difference between genes.angi and several sets of genes.random

*-----------------------------------------------------------  -----------------------------------------
* response to lisa's suggestion of a meeting (11 nov 2015)

I look forward to meeting, and Friday afternoon is fine with me.
Let's work out an agenda before we meet.

Oncoscape is growing and changing.  Many of our procedures will change;
new lines of authority are needed.  How do we choose and evlove this
new way of working together?  I'd like to think that our slogan "We are
smarter together than we are apart" has some applicability.

The past week has beenI propose the following agenda.  Please help me shape it into an agenda that
serves us both.

Topic: New roles and responsibilities in Oncoscape, communication methods.

The problem to be addressed, general form:  large policy changes are being
instituted without open discussion.

Specific form: last week I was blind-sided by two very substantial
policy changes, one explicit, one inferred (perhaps incorrectly):

   - I am no longer allowed to check-in code

   - My involvement with, and my responsibility for the
     SttrDataPackage has been terminated.  (I infer this from hearing
     no response to my three related refactoring proposals.)


end, let us work out an agenda for this meeting.



I say this, not to be difficult, but because it appears
that the topics to be discussed are very consequential, both for me and for
the Oncoscape project.  Preparation will pay off.  An ad hoc meeting


I look forward to meeting, and Friday afternoon is fine with me.
However, I want to be very clear on the purpose and scope of the meeting
before hand.  I say this, not to be difficult, but because it appears
that the topics to be discussed are very consequential, both for me and for
the Oncoscape project.  Preparation will pay off.  An ad hoc meeting
on topics of consequence, without symmetrical preparation, cannot do
justice to those topics.

Our project is undergoing a lot of change.  One new staff member has
been added, two more will join us soon. Our previous operational
methods must adapt.  So it is clear that changes are needed.

In the last 18 months we have written some fine software.  Along the
way we also developed a working style which we have captured via the
slogan, "We are smarter together than we are apart".  Adopting more
formal management and planning methods does not preclude continuing
with that approach. Thinking things through together remains a good
idea.

Therefore I ask, before we meet, that you describe:

  - the purpose of the meeting, and
  - the proposals you are offering

I will respond in kind, offering  my assessment of the benefits and costs
of your proposals, and possibly offering counter-proposals in repsonse.

My purpose here is to remedy the current, suddenly-arising and difficult
situation, in which my role and responsibilities appear to have been quite
radically changed without prior warning to, nor consultation with, me.



*----------------------------------------------------------------------------------------------------
* wednesday (nov 11 2015) up

  cd ~/oncogit/Oncoscape/dataPackages/NetworkMaker/inst/unitTests/
  source("test_NetworkMaker.R"); runTests()   # should run without error
  next up:
    change package name to constructed instance for NetworkMaker ctor.
    review all code, look especially for duplications
    try on TCGAbrain


*----------------------------------------------------------------------------------------------------
* good d3 choropleth demo (8 nov 2015)

  ~/s/work/cleveland/usaDemo/
  start python -m SimpleHTTPServer to view index.html

*----------------------------------------------------------------------------------------------------
* https://github.com/openseattle/seattle-boundaries  in geojson

  zip codes, census tracts, city boundaries

*----------------------------------------------------------------------------------------------------
* cleveland high school projects, grant storey

   cd ~/s/work/cleveland/
          environmentalHealth/

   learned the ropes from ~/s/work/cleveland/usaDemo/index.html, us.json (counties), data.csv

   Duwamish Valley Cumulative Health Impacts Analysis: Seattle, Washington: ppt as pdf
     by Linn Gould

   http://justhealthaction.org/resources/jha-publications/
       all docs listed here

   got ~/s/work/cleveland/environmentalHealth/C1-Raw-data-for-Figures-2-17.xlsx

   http://justhealthaction.org/wp-content/uploads/2013/03/CHIA-EPA-TRI-Conference-DC-May-2014.pdf
     page 18 has georgetown map showing cleveland as an "unhealthy area"
     CBPR: health mapping  (community-based participatory research)

   very good table, page 11
   Table A-1: Cumulative Health Impacts Analysis using All Indicators, by ZIP code, Seattle, Washington (Scenario 2)
     http://duwamishcleanup.org/wp-content/uploads/2013/03/CHIA_AppendixA_lowres.pdf

   one subdivision, environmental exposures (rank 1-10)


      Diesel Particulate matter (ug/m3 annual av) 10 6 3 5 6 10 2 1 4 1
                       Benzene (ug/m3 annnual av) 9 7 1 2 5 10 2 1 3 1
Confirmed and suspected contaminated sites (ISIS) 10 2 1 4 3 2 1 3 2 2


98108 Beacon Hill Georgetown South Park
98144 South Central District Mt Baker
98178 Rainier Beach
98106 White Center Delridge
98122 North Central District Madrona
98102 Eastlake
98116 Alki
98107 Ballard
98105 University District Laurelhurst
98199 Magnolia


*----------------------------------------------------------------------------------------------------
* friday (6 nov 2015)  next up

  cd  ~/oncogit/Oncoscape/dataPackages/NetworkMaker/inst/unitTests/
  working on ~/oncogit/Oncoscape/dataPackages/NetworkMaker/R/NetworkMaker-class.R
     calculateSimilarity method
     add copy number to calculation
     call from
   ~/oncogit/Oncoscape/dataPackages/NetworkMaker/inst/unitTests/test_NetworkMaker.R
      test.calculateSimilarity


*----------------------------------------------------------------------------------------------------
* explore cyjs zooming in on overlapping nodes (6 nov 2015)

   emulates google maps

   cd ~/oncogit/Oncoscape/dataPackages/networks/experiments/zoomCorrectedNodePositioning/
   open ~/oncogit/Oncoscape/dataPackages/networks/experiments/zoomCorrectedNodePositioning/zooming.html

*----------------------------------------------------------------------------------------------------
* cyjs static template: two nodes, 1 edge, a reset button, cyjs 2.5.0 (5 nov 2015)

  ~/oncogit/Oncoscape/dataPackages/networks/experiments/basic/basic.html

*----------------------------------------------------------------------------------------------------
* hutch payroll self-service, selfservice

  https://admaims17.fhcrc.org:7002/psp/HR8PROD/?cmd=login&languageCd=ENG&

*----------------------------------------------------------------------------------------------------
* review and merge jenny's dataset branch (3 nov 2015)

    git ls-remote --heads origin
    git fetch
    git checkout -b dataPackage

*----------------------------------------------------------------------------------------------------
* github tips, git tips: return to a previous commit (12 jan 2016)

  git reset --hard 891a870953a83b04f4b077c43fef2539cf2604c8
  git checkout -b pshannon-refactor-server-2
  git add .
  git commit -m "creating a new branch to which commit 891a870953a83b04f4b077c43fef2539cf2604c8 has been restored"

*----------------------------------------------------------------------------------------------------
* github tips, git tips:  merge my branch with the (already moved ahead) develop branch

   git checkout develop
   git pull
   git checkout pshannon-networkMaker-zoomSpreader
   git merge develop


  --- as actually run (14 dec 2015)

  git status
      # found 2 changed files.  add them, commit, push
  git add dataPackages/NetworkMaker/DESCRIPTION
  git add dataPackages/NetworkMaker/inst/unitTests/test_NetworkMaker.R
  git commit -m "unit test complete w/o error"
  git push origin  pshannon-networkMaker-zoomSpreader

     # now bring down the current develop branch, off of which came pshannon-networkMaker-zoomSpreader weeks ago
  git checkout develop
  git pull

     # switch to my branch, merge
  git checkout pshannon-networkMaker-zoomSpreader
  git merge develop    # conflicts reported

     CONFLICT (modify/delete): dataPackages/makefile deleted in HEAD and modified in develop.
                               Version develop of dataPackages/makefile left in tree.
     Auto-merging dataPackages/TCGAcoad/inst/unitTests/test_TCGAcoad.R
     CONFLICT (content): Merge conflict in dataPackages/TCGAcoad/inst/unitTests/test_TCGAcoad.R
     Removing README.txt
     Removing Oncoscape/inst/scripts/patientTimelines/ModuleTest.js
     Removing Oncoscape/inst/scripts/patientTimelines/Module2.js
     Removing Oncoscape/inst/scripts/apps/oncoscape/nohup.out
     Auto-merging Oncoscape/R/OncoDev14.R
     Automatic merge failed; fix conflicts and then commit the result.


     # find and fix the conflicts.  then add, commit and push these changes up to my branch on githu

  dir dataPackages/makefile
  git add dataPackages/makefile
  git commit "accepting develop's makefile"
  git merge develop
  git add dataPackages/TCGAcoad/inst/unitTests/test_TCGAcoad.R
  git merge develop
  git commit -m "fixed conflicts"
  git merge develop
  git branch
  dir dataPackages/TCGAbrain/inst/extdata/
  git status
  git push origin  pshannon-networkMaker-zoomSpreader





*----------------------------------------------------------------------------------------------------
* genesets for oncoscape (2 nov 2015)

    cd ~/s/examples/oncoscapeExplorations/hocgsea

    ~/Desktop/hallmarksOfCancerGenesets-JAMA-2015.pdf   787877 Nov 14 16:41
   Cancer Hallmark–Based Gene Sets and Personalized Medicine for Patients With Stage II Colon Cancer ONLINE FIRST
    Greg Yothers, PhD1,2; Nan Song, PhD1,2; Thomas J. George Jr, MD2,3
    JAMA Oncol. Published online October 22, 2015. doi:10.1001/jamaoncol.2015.3614

  cd ~/github/oncoscape/Oncoscape/dataPackages/NetworkMaker/inst/unitTests/
  --- brca
    f <- "~/s/data/public/human/cancer/geneLists/sangerCancerGeneCensus.tsv"
    sangerCancerGeneCensus <- read.table(f, sep="\t", header=TRUE, fill=TRUE)$Symbol
    length(sangerCancerGeneCensus) # 427
    f <- "~/s/data/public/human/cancer/geneLists/cancer_gene_census.tsv"
    sangerCancerGeneCensus <- read.table(f, sep="\t", header=TRUE, fill=TRUE)$Symbol
    length(sangerCancerGeneCensus) # 513

    f <- "~/s/data/public/human/cancer/geneLists/tcgaRankedGenes.tsv"
    tbl <- read.table(f, sep="\t", header=TRUE, fill=TRUE)
    tcga.score.gt2 <- subset(tbl, score > 2)$symbol
    length(tcga.score.gt2)  # 1188

    genesets <- list(sangerCancerGeneCensus=sangerCancerGeneCensus, tcgaRankedScore.gt2=tcga.score.gt2)
    sapply(genesets, length)
    sangerCancerGeneCensus    tcgaRankedScore.gt2
                       513                   1188

    length(intersect(sangerCancerGeneCensus, tcga.score.gt2))   # [1] 280

  --- networkMaker
    print(load("../../../TCGAgbm/inst/extdata/genesets.RData"))
    genesets["sangerCancerGeneCensus"] <- sangerCancerGeneCensus
    genesets[["sangerCancerGeneCensus"]] <- sangerCancerGeneCensus
    genesets[["tcga.score.gt2"]] <- tcga.score.gt2
    names(genesets)  # [1] "tcga.GBM.classifiers"   "marker.genes.545"       "sangerCancerGeneCensus" "tcga.score.gt2"
    f <- "~/oncogit/Oncoscape/dataPackages/NetworkMaker/inst/extdata/genesets.RData"
    save(genesets, file=f)



*----------------------------------------------------------------------------------------------------
* eric's todo list (29 oct 2015)

  --- markers
     1) dynanimically separate nodes which now overlap on the chrom layout
     2) add a new tumor group:  diagnosis.   see tumor grade work, and diag column now ignored
     3) widen mouseover readout
     4) make centromere rectangles and labels larger
     5) experiment with using cn +/-1   some chroms have very important LOH data
     6) hamid's mutation table different from mine in TCGAbrain.  top right TCGAbrain clustered
        tumors all of p53 mutations in the hobo data.  not so for mine
     7) pathway displays

*----------------------------------------------------------------------------------------------------
* vip's sequence files (29 oct 2015)

   --- pipeline set up for david macpherson

   --- lisa says:

    The BAM files are separated by sample and under our shared folder on the fast drive:
         /fh/fast/_HB/STTR/delivery/McFerrinL/data

    If you need a reference sequence, there is Sample_NA12878 that NYGC used for comparison.


  --- 2 bam files from the 50 already analyzed

   /fh/fast/_HB/STTR/delivery/McFerrinL/data/Project_MCF_10047_WGS
   dir Sample_2010/analysis/*.ba*
            8889216 Mar 26  2015 Sample_2010/analysis/2010.final.bai
       195837237662 Mar 26  2015 Sample_2010/analysis/2010.final.bam
   dir Sample_NA12878/analysis/*.ba*
           8835632 Mar 28  2015 Sample_NA12878/analysis/NA12878.final.bai
      193582361156 Mar 28  2015 Sample_NA12878/analysis/NA12878.final.bam



*----------------------------------------------------------------------------------------------------
* oncoscape/cyjs timings (28 oct 2015)  display markers network

  ---- cyjs 2.4.4 min: 15, 14, 15, 15, 17, 15, 16, 16, 16, 18  (slightly longer)

    display markers network       request 1446061815  MarkersAndPatients TCGAbrain 2015-10-28 12:50:15  1.4.90
    display markers network data received 1446061815  MarkersAndPatients TCGAbrain 2015-10-28 12:50:15  1.4.90
    display markers network      complete 1446061830  MarkersAndPatients TCGAbrain 2015-10-28 12:50:30  1.4.90

    display markers network       request 1446061850  MarkersAndPatients TCGAbrain 2015-10-28 12:50:50  1.4.90
    display markers network data received 1446061851  MarkersAndPatients TCGAbrain 2015-10-28 12:50:50  1.4.90
    display markers network      complete 1446061864  MarkersAndPatients TCGAbrain 2015-10-28 12:51:04  1.4.90

    display markers network       request 1446061885  MarkersAndPatients TCGAbrain 2015-10-28 12:51:24  1.4.90
    display markers network data received 1446061885  MarkersAndPatients TCGAbrain 2015-10-28 12:51:25  1.4.90
    display markers network      complete 1446061901  MarkersAndPatients TCGAbrain 2015-10-28 12:51:40  1.4.90

    display markers network       request 1446061925  MarkersAndPatients TCGAbrain 2015-10-28 12:52:04  1.4.90
    display markers network data received 1446061925  MarkersAndPatients TCGAbrain 2015-10-28 12:52:05  1.4.90
    display markers network      complete 1446061941  MarkersAndPatients TCGAbrain 2015-10-28 12:52:20  1.4.90

    display markers network       request 1446061965  MarkersAndPatients TCGAbrain 2015-10-28 12:52:44  1.4.90
    display markers network data received 1446061965  MarkersAndPatients TCGAbrain 2015-10-28 12:52:44  1.4.90
    display markers network      complete 1446061981  MarkersAndPatients TCGAbrain 2015-10-28 12:53:01  1.4.90

    display markers network       request 1446062004  MarkersAndPatients TCGAbrain 2015-10-28 12:53:24  1.4.90
    display markers network data received 1446062005  MarkersAndPatients TCGAbrain 2015-10-28 12:53:24  1.4.90
    display markers network      complete 1446062020  MarkersAndPatients TCGAbrain 2015-10-28 12:53:39  1.4.90

    display markers network       request 1446062042  MarkersAndPatients TCGAbrain 2015-10-28 12:54:02  1.4.90
    display markers network data received 1446062042  MarkersAndPatients TCGAbrain 2015-10-28 12:54:02  1.4.90
    display markers network      complete 1446062058  MarkersAndPatients TCGAbrain 2015-10-28 12:54:18  1.4.90

    display markers network       request 1446062083  MarkersAndPatients TCGAbrain 2015-10-28 12:54:43  1.4.90
    display markers network data received 1446062083  MarkersAndPatients TCGAbrain 2015-10-28 12:54:43  1.4.90
    display markers network      complete 1446062100  MarkersAndPatients TCGAbrain 2015-10-28 12:54:59  1.4.90

    display markers network       request 1446062123  MarkersAndPatients TCGAbrain 2015-10-28 12:55:23  1.4.90
    display markers network data received 1446062123  MarkersAndPatients TCGAbrain 2015-10-28 12:55:23  1.4.90
    display markers network      complete 1446062139  MarkersAndPatients TCGAbrain 2015-10-28 12:55:39  1.4.90

    display markers network       request 1446062162  MarkersAndPatients TCGAbrain 2015-10-28 12:56:01  1.4.90
    display markers network data received 1446062162  MarkersAndPatients TCGAbrain 2015-10-28 12:56:02  1.4.90
    display markers network      complete 1446062177  MarkersAndPatients TCGAbrain 2015-10-28 12:56:16  1.4.90



  ---- with cyjs 2.5.0 usntable 7, 10 reps: 15, 15, 15, 15, 14, 14, 15, 14, 15, 14

                  eventName   eventStatus       secs userID     moduleOfOrigin   dataset                time version comment
    display markers network       request 1446060492  MarkersAndPatients TCGAbrain 2015-10-28 12:28:12  1.4.90 comment
    display markers network data received 1446060492  MarkersAndPatients TCGAbrain 2015-10-28 12:28:12  1.4.90 comment
    display markers network      complete 1446060507  MarkersAndPatients TCGAbrain 2015-10-28 12:28:27  1.4.90 comment

    display markers network       request 1446060530  MarkersAndPatients TCGAbrain 2015-10-28 12:28:50  1.4.90 comment
    display markers network data received 1446060531  MarkersAndPatients TCGAbrain 2015-10-28 12:28:50  1.4.90 comment
    display markers network      complete 1446060546  MarkersAndPatients TCGAbrain 2015-10-28 12:29:05  1.4.90 comment

    display markers network       request 1446060569  MarkersAndPatients TCGAbrain 2015-10-28 12:29:29  1.4.90 comment
    display markers network data received 1446060571  MarkersAndPatients TCGAbrain 2015-10-28 12:29:31  1.4.90 comment
    display markers network      complete 1446060586  MarkersAndPatients TCGAbrain 2015-10-28 12:29:46  1.4.90 comment

    display markers network       request 1446060610  MarkersAndPatients TCGAbrain 2015-10-28 12:30:10  1.4.90 comment
    display markers network data received 1446060612  MarkersAndPatients TCGAbrain 2015-10-28 12:30:11  1.4.90 comment
    display markers network      complete 1446060627  MarkersAndPatients TCGAbrain 2015-10-28 12:30:26  1.4.90 comment

    display markers network       request 1446060651  MarkersAndPatients TCGAbrain 2015-10-28 12:30:51  1.4.90 comment
    display markers network data received 1446060653  MarkersAndPatients TCGAbrain 2015-10-28 12:30:53  1.4.90 comment
    display markers network      complete 1446060668  MarkersAndPatients TCGAbrain 2015-10-28 12:31:07  1.4.90 comment

    display markers network       request 1446060693  MarkersAndPatients TCGAbrain 2015-10-28 12:31:33  1.4.90 comment
    display markers network data received 1446060696  MarkersAndPatients TCGAbrain 2015-10-28 12:31:36  1.4.90 comment
    display markers network      complete 1446060710  MarkersAndPatients TCGAbrain 2015-10-28 12:31:50  1.4.90 comment

    display markers network       request 1446060736  MarkersAndPatients TCGAbrain 2015-10-28 12:32:16  1.4.90 comment
    display markers network data received 1446060739  MarkersAndPatients TCGAbrain 2015-10-28 12:32:19  1.4.90 comment
    display markers network      complete 1446060754  MarkersAndPatients TCGAbrain 2015-10-28 12:32:34  1.4.90 comment

    display markers network       request 1446060779  MarkersAndPatients TCGAbrain 2015-10-28 12:32:59  1.4.90 comment
    display markers network data received 1446060783  MarkersAndPatients TCGAbrain 2015-10-28 12:33:03  1.4.90 comment
    display markers network      complete 1446060797  MarkersAndPatients TCGAbrain 2015-10-28 12:33:17  1.4.90 comment

    display markers network       request 1446060823  MarkersAndPatients TCGAbrain 2015-10-28 12:33:43  1.4.90 comment
    display markers network data received 1446060827  MarkersAndPatients TCGAbrain 2015-10-28 12:33:47  1.4.90 comment
    display markers network      complete 1446060842  MarkersAndPatients TCGAbrain 2015-10-28 12:34:02  1.4.90 comment

    display markers network       request 1446060869  MarkersAndPatients TCGAbrain 2015-10-28 12:34:29  1.4.90 comment
    display markers network data received 1446060874  MarkersAndPatients TCGAbrain 2015-10-28 12:34:33  1.4.90 comment
    display markers network      complete 1446060888  MarkersAndPatients TCGAbrain 2015-10-28 12:34:47  1.4.90 comment



  ---- with cyjs 2.5.0 unstable 7:  15/16 seconds to render

   display markers network       request 1446057329  MarkersAndPatients TCGAbrain 2015-10-28 11:35:28  1.4.90
   display markers network data received 1446057329  MarkersAndPatients TCGAbrain 2015-10-28 11:35:29  1.4.90
   display markers network      complete 1446057345  MarkersAndPatients TCGAbrain 2015-10-28 11:35:44  1.4.90

   display markers network       request 1446057370  MarkersAndPatients TCGAbrain 2015-10-28 11:36:10  1.4.90
   display markers network data received 1446057370  MarkersAndPatients TCGAbrain 2015-10-28 11:36:10  1.4.90
   display markers network      complete 1446057386  MarkersAndPatients TCGAbrain 2015-10-28 11:36:26  1.4.90


   --- with cyjs 2.5.0 unstable <=6 (actual version unknown, but from 06oct2015):  16/21 seconds to render

                 eventName   eventStatus       secs      moduleOfOrigin   dataset                time version
   display markers network       request 1446058342  MarkersAndPatients TCGAbrain 2015-10-28 11:52:22  1.4.90
   display markers network data received 1446058342  MarkersAndPatients TCGAbrain 2015-10-28 11:52:22  1.4.90
   display markers network      complete 1446058358  MarkersAndPatients TCGAbrain 2015-10-28 11:52:38  1.4.90
   display markers network       request 1446058385  MarkersAndPatients TCGAbrain 2015-10-28 11:53:05  1.4.90
   display markers network data received 1446058386  MarkersAndPatients TCGAbrain 2015-10-28 11:53:05  1.4.90
   display markers network      complete 1446058406  MarkersAndPatients TCGAbrain 2015-10-28 11:53:26  1.4.90


*----------------------------------------------------------------------------------------------------
* add TCGAbrain "diagnosis" tumor categorization (9 dec 2015)

   " 2) add a new tumor group:  diagnosis.   see tumor grade work, and diag column now ignored"

   cd ~/oncogit/Oncoscape/dataPackages
   mkdir -p tumorCategories/TCGAbrain/rawData

   cd ~/oncogit/Oncoscape/dataPackages/tumorCategories/TCGAbrain/rawData
       # both from (27 jul 2015)
   cp -p ~/oncodev/hbolouri/dataPackages/RawData/TCGAgbm/Clinical_2-10-15/clinical_patient_gbm.txt .
   cp -p ~/oncodev/hbolouri/dataPackages/RawData/TCGAlgg/Clinical_2-10-15/nationwidechildrens.org_clinical_patient_lgg.txt .

    --- figure out where the diagnosis information is found
    table(tbl.gbm$histological_type)
       Glioblastoma Multiforme (GBM)             Treated primary GBM Untreated primary (de novo) GBM
                                  27                              20                             545
*----------------------------------------------------------------------------------------------------
* add "coloring of the patients in markers and patients by grade"  urgent from eric (22 oct 2015)

  --- from eric
    someone important just got a diagnosis of a grade 3 oligodendroglioma, and I
    need to be able to figure out who has what grade on the plot in order to
    figure out if there is anything in oncoscape that can help this person.

  --- from hamid
    You already have this info in the GBM and LGG clinical files.

  --- from eric (25 sep 2015)
    It was actually the LGG diagnosis slide (oligodendroglioma, oligo-astro,
    and astrocytoma).  And the grade 2 and grade 3 LGG slide.

  ---  where is the clinical data?  gbm
    ~/oncogit/Oncoscape/dataPackages/TCGAgbm/inst/import/history/createEventList.R
       refers to
         setwd("../../../../RawData/TCGAgbm/Clinical_2-10-15/")
         study="TCGAgbm"
         tbl.pt <- read.table("clinical_patient_gbm.txt", quote="", sep="\t", header=TRUE, as.is=TRUE)

  ---  where is the clinical data?  lgg
     ~/oncodev/hbolouri/dataPackages/RawData/TCGAlgg/Clinical_2-10-15/
     9 files here; which has grade assignments?
     grep -i -c oligodendroglioma *
       nationwidechildrens.org_clinical_cqcf_lgg.txt:173
       nationwidechildrens.org_clinical_omf_v4.0_lgg.txt:3
       nationwidechildrens.org_clinical_patient_lgg.txt:174

     tbl <- read.table("nationwidechildrens.org_clinical_patient_lgg.txt", sep="\t", header=TRUE, as.is=TRUE) # 461 * 69
     tbl <- tbl[-1,]   # an extra header row, with (apparently) more detail on the nature of the column
     table(tbl$histologic_diagnosis)
      Astrocytoma    CDE_ID:3081934  Oligoastrocytoma Oligodendroglioma
              171                 1               114               174
     sum(table(tbl$histologic_diagnosis))  # [1] 460
     tbl.cat <- tbl[, c("bcr_patient_barcode", "histologic_diagnosis", "tumor_grade")]
       # ger rid of the first line
       #         bcr_patient_barcode histologic_diagnosis    tumor_grade
       #2      CDE_ID:2673794       CDE_ID:3081934 CDE_ID:2785839
       #3        TCGA-CS-6290          Astrocytoma             G3
     tbl.lggGrade <- tbl.cat[-1,]

    table(tbl.lggGrade$diagnosis, tbl.lggGrade$grade)
                            G2  G3
         Astrocytoma        57 114
         Oligoastrocytoma   61  53
         Oligodendroglioma 100  74

    --- add a column
    diagGrade <- paste(tbl.lggGrade$diagnosis, tbl.lggGrade$grade, sep=".")
    tbl.lggGrade <- cbind(tbl.lggGrade, diagGrade)

     as.data.frame(table(tbl.lggGrade$diagGrade))
                     Var1 Freq
           Astrocytoma.G2   57
           Astrocytoma.G3  114
      Oligoastrocytoma.G2   61
      Oligoastrocytoma.G3   53
     Oligodendroglioma.G2  100
     Oligodendroglioma.G3   74

    save(tbl.lggGrade, file="~/oncodev/hbolouri/dataPackages/RawData/TCGAlgg/Clinical_2-10-15/tbl.lggDiagnosisGrade.RData")

   --- now gbm
     cd ~/oncodev/hbolouri/dataPackages/RawData/TCGAgbm/Clinical_2-10-15
     tbl <- read.table("clinical_patient_gbm.txt", sep="\t", header=TRUE, as.is=TRUE)  #  594  39
     status: all gbm's are implicitly grade 4

   --- this task summarized
      hamid says just use grade
      2: green
      3: blue
      4: red

   ---- add this new "categorized samples" table to ~/oncogit/Oncoscape/dataPackages/TCGAbrain/inst/extdata/
     follow existing form found, eg, in tbl.glioma8
     print(load("~/oncogit/Oncoscape/dataPackages/TCGAbrain/inst/extdata/ericsEightGliomaClusters.RData"))
     head(tbl.glioma8)
                     cluster   color
        TCGA.DU.A5TT       1 darkred
        TCGA.DU.8165       1 darkred
        TCGA.E1.A7YD       1 darkred
        TCGA.HT.A4DS       1 darkred
        TCGA.02.0055       1 darkred
        TCGA.06.0130       1 darkred

    cd ~/oncogit/Oncoscape/dataPackages/TCGAbrain/inst/extdata/
    print(load("~/oncogit/Oncoscape/dataPackages/TCGAbrain/inst/extdata/ericsEightGliomaClusters.RData"))
    dim(tbl.glioma8)  [1] 704   2

    print(load("~/oncodev/hbolouri/dataPackages/RawData/TCGAlgg/Clinical_2-10-15/tbl.lggDiagnosisGrade.RData"))
    dim(tbl.lggGrade)  # [1] 459   4
    patientID <- gsub("-", ".", tbl.lggGrade$patientID, fixed=TRUE)
    tbl.lggGrade$patientID <- patientID
    length(intersect(tbl.lggGrade$patientID, rownames(tbl.glioma8)))  # [1] 402

   ---- lgg manifest.tsv shows a patient history patient count of 459
      matches dim(tbl.lggGrade)
      tbl.grade <- tbl.lggGrade[, c(1,3)]

   ---- extend tbl.grade to include all gbm tumors
     print(load("~/oncogit/Oncoscape/dataPackages/TCGAgbm/inst/extdata/verhaakGbmClustersAugmented.RData"))
     tbl.gbmGrade <- data.frame(patientID=rownames(tbl.verhaakPlus1), grade="G4")
     tbl.grade <- rbind(tbl.grade, tbl.gbmGrade)
     tbl.grade$patientID <- gsub("-", ".", tbl.grade$patientID, fixed=TRUE)
     dim(tbl.grade)  # [1] 1007    2
     table(tbl.grade$grade)
        2   3   4
      218 241 548
      greens <- which(tbl.grade$grade == "G2")
      blues <- which(tbl.grade$grade == "G3")
      reds <- which(tbl.grade$grade == "G4")

    color <- rep("", nrow(tbl.grade))
    color[greens] <- "green"
    color[blues] <- "blue"
    color[reds] <- "red"
    table(color)
       blue green   red
        241   218   548
    tbl.grade$color <- color
    rownames(tbl.grade) <- tbl.grade$patientID
    head(tbl.grade[, -1])
    tbl.grade <- tbl.grade[, -1]
    colnames(tbl.grade) <- c("cluster", "color")
    save(tbl.grade, file="~/oncodev/hbolouri/dataPackages/RawData/TCGAlgg/Clinical_2-10-15/tbl.grade.RData")
    print(load("~/oncodev/hbolouri/dataPackages/RawData/TCGAlgg/Clinical_2-10-15/tbl.grade.RData"))
    head(tbl.grade)
                   cluster color
      TCGA.CS.6290      G3  blue
      TCGA.DU.5847      G3  blue
      TCGA.DU.5849      G2 green
      TCGA.DU.5852      G3  blue
      TCGA.DU.5854      G3  blue
      TCGA.DU.5855      G3  blue

   --- problem: many lgg nodes are not in tbl.grade, or in tbl.lggGrade
     found, for example, these uncolored (subType=undefined) in the rcyjs display
     ["TCGA.E1.A7YU", "TCGA.S9.A7IS", "TCGA.HT.7610", "TCGA.E1.5322"]

   --- get list of all lgg tumors
   library(TCGAlgg)
   lgg <- TCGAlgg()
   mtx.mut.lgg <- matrices(lgg)$mtx.mut
   names.trimmed <- sub(".0[12]$", "", rownames(mtx.mut.lgg))
   rownames(mtx.mut.lgg) <- names.trimmed
   mtx.cn.lgg <- matrices(lgg)$mtx.cn
   names.trimmed <- sub(".0[12]$", "", rownames(mtx.cn.lgg))
   rownames(mtx.cn.lgg) <- names.trimmed
   lgg.tumors.from.pkg <- sort(unique(c(rownames(mtx.cn.lgg), rownames(mtx.mut.lgg))))
   length(lgg.tumors.from.pkg)  # 516
   lgg.missingInPatient <- setdiff(lgg.tumors.from.pkg, tbl.lggGrade$patientID)
   length(lgg.missingInPatient) # [1] 57

   cy.nodes().fnFilter(function(node){return typeof(node.data("subType")) === "undefined"}).length  488
   JSON.stringify(nodesNoSubType.map(function(node){return node.id()}))

   "["TCGA.E1.5319","TCGA.HT.7693","TCGA.CS.6665","TCGA.S9.A7J2","TCGA.FG.A6J3","TCGA.FG.6688","TCGA.S9.A6TX",
"TCGA.HT.A74L","TCGA.DU.A5TS","TCGA.DB.A4XA","TCGA.HT.A4DV","TCGA.TQ.A7RP","TCGA.E1.5311","TCGA.E1.A7YI",
"TCGA.E1.5305","TCGA.HT.8113","TCGA.DH.A66G","TCGA.HT.7620","TCGA.P5.A731","TCGA.HT.7480","TCGA.HT.7689",
"TCGA.HT.8109","TCGA.E1.A7YE","TCGA.S9.A7R1","TCGA.FG.A710","TCGA.S9.A7J0","TCGA.DU.A6S6","TCGA.QH.A6CU",
"TCGA.HW.7486","TCGA.FG.7634","TCGA.DU.6407","TCGA.S9.A7IX","TCGA.HT.8010","TCGA.P5.A5F1","TCGA.DU.6542",
"TCGA.FG.7638","TCGA.DH.5143","TCGA.DU.7299","TCGA.DU.7013","TCGA.DU.7011","TCGA.DB.5281","TCGA.S9.A6WI",
"TCGA.HT.7605","TCGA.E1.A7YK","TCGA.S9.A6WQ","TCGA.HT.8106","TCGA.HT.7608","TCGA.E1.A7YU","TCGA.TM.A7C5",
"TCGA.S9.A7QY","TCGA.QH.A6CW","TCGA.S9.A6WO","TCGA.IK.7675","TCGA.HT.7601","TCGA.P5.A5ET","TCGA.S9.A6U1",
"TCGA.HT.7472","TCGA.HT.7880","TCGA.E1.A7Z3","TCGA.P5.A77X","TCGA.FG.A6IZ","TCGA.HT.7873","TCGA.CS.4938",
"TCGA.KT.A74X","TCGA.P5.A5EX","TCGA.HT.7476","TCGA.DB.A75L","TCGA.HT.8563","TCGA.HT.7609","TCGA.S9.A7IS",
"TCGA.S9.A6U0","TCGA.FG.7643","TCGA.DB.5274","TCGA.TQ.A7RG","TCGA.QH.A6X5","TCGA.DU.6403","TCGA.DB.A4XG",
"TCGA.HT.7855","TCGA.DU.8166","TCGA.DH.A7UT","TCGA.DU.7015","TCGA.HT.A616","TCGA.FG.8181","TCGA.HT.7611",
"TCGA.HT.A74K","TCGA.FG.A60K","TCGA.HT.7856","TCGA.FG.5963","TCGA.DU.5851","TCGA.DU.A7T6","TCGA.S9.A6TY",
"TCGA.CS.5395","TCGA.DU.7292","TCGA.HT.A5RC","TCGA.TQ.A7RR","TCGA.DU.8162","TCGA.P5.A72W","TCGA.S9.A6TU",
"TCGA.DU.5855","TCGA.HT.7884","TCGA.TQ.A7RQ","TCGA.FG.A4MW","TCGA.IK.8125","TCGA.HT.8018","TCGA.DB.A75P",
"TCGA.QH.A6X8","TCGA.HT.A5R5","TCGA.HT.A618","TCGA.FG.6691","TCGA.HT.7467","TCGA.S9.A7R3","TCGA.QH.A6CX",
"TCGA.FG.A4MX","TCGA.HT.7681","TCGA.S9.A7IZ","TCGA.DU.A6S7","TCGA.HW.A5KM","TCGA.P5.A72Z","TCGA.HT.8114",
"TCGA.HW.8321","TCGA.TQ.A7RN","TCGA.DH.5141","TCGA.CS.6186","TCGA.EZ.7264","TCGA.P5.A5F4","TCGA.QH.A65V",
"TCGA.FG.8191","TCGA.DH.5142","TCGA.DU.A6S8","TCGA.E1.A7YW","TCGA.CS.6666","TCGA.DU.7298","TCGA.DB.A64R",
"TCGA.DU.6406","TCGA.S9.A6UA","TCGA.FG.A60L","TCGA.CS.5390","TCGA.S9.A6WP","TCGA.DU.A7TB","TCGA.DB.5280",
"TCGA.DH.A66D","TCGA.DB.5278","TCGA.S9.A6WN","TCGA.DB.A4XC","TCGA.TQ.A7RH","TCGA.E1.A7YS","TCGA.P5.A735",
"TCGA.DU.7294","TCGA.E1.A7YQ","TCGA.HT.7881","TCGA.QH.A6CS","TCGA.P5.A5EU","TCGA.DB.A64X","TCGA.S9.A6U5",
"TCGA.FG.A70Y","TCGA.E1.A7YO","TCGA.HW.7487","TCGA.HW.7491","TCGA.HT.7691","TCGA.CS.4944","TCGA.FG.A6J1",
"TCGA.S9.A7R7","TCGA.DB.A75M","TCGA.HT.7877","TCGA.DU.6399","TCGA.HT.7477","TCGA.HT.8012","TCGA.FG.5965",
"TCGA.HT.A614","TCGA.HT.7695","TCGA.QH.A6X4","TCGA.P5.A77W","TCGA.DU.7302","TCGA.DU.7012","TCGA.DU.7309",
"TCGA.E1.5307","TCGA.S9.A7QW","TCGA.DU.6402","TCGA.HT.7604","TCGA.P5.A733","TCGA.HT.7684","TCGA.HW.7495",
"TCGA.QH.A65R","TCGA.DU.A7TG","TCGA.DH.A7UV","TCGA.HW.A5KK","TCGA.CS.6669","TCGA.CS.4942","TCGA.DU.A7TC",
"TCGA.HT.7610","TCGA.S9.A6TW","TCGA.FG.A60J","TCGA.E1.5303","TCGA.QH.A6XC","TCGA.HT.7481","TCGA.FN.7833",
"TCGA.E1.A7Z4","TCGA.DU.A5TR","TCGA.FG.A4MU","TCGA.DU.7300","TCGA.HT.7473","TCGA.TM.A7C3","TCGA.S9.A7IQ",
"TCGA.DU.7008","TCGA.DB.A64O","TCGA.DU.A5TT","TCGA.S9.A6WG","TCGA.DU.8163","TCGA.DB.A75O","TCGA.HT.7688",
"TCGA.DU.7304","TCGA.HT.8019","TCGA.P5.A5EY","TCGA.S9.A6WD","TCGA.DU.A7T8","TCGA.FG.8185","TCGA.HT.7902",
"TCGA.CS.5397","TCGA.TQ.A7RU","TCGA.HT.7879","TCGA.DU.5874","TCGA.FG.7641","TCGA.FG.6690","TCGA.HW.8320",
"TCGA.HT.8104","TCGA.S9.A7R2","TCGA.R8.A6MK","TCGA.QH.A6CY","TCGA.S9.A7J1","TCGA.P5.A72X","TCGA.E1.5322",
"TCGA.P5.A5F0","TCGA.S9.A6WM","TCGA.R8.A73M","TCGA.FG.A70Z","TCGA.HT.7680","TCGA.DB.A4X9","TCGA.DU.8167",
"TCGA.HT.A74O","TCGA.FG.8188","TCGA.P5.A5F6","TCGA.DU.A6S3","TCGA.HT.8110","TCGA.DB.A4XH","TCGA.HT.7485",
"TCGA.VW.A7QS","TCGA.E1.A7YJ","TCGA.DU.A76L","TCGA.DB.A4XE","TCGA.S9.A6TS","TCGA.DB.A64S","TCGA.CS.6667",
"TCGA.E1.A7YL","TCGA.E1.A7YV","TCGA.HT.A61C","TCGA.TQ.A7RW","TCGA.DU.5849","TCGA.QH.A6CV","TCGA.HT.7468",
"TCGA.FG.6692","TCGA.TQ.A7RI","TCGA.DB.5279","TCGA.S9.A6U8","TCGA.HW.7489","TCGA.R8.A6YH","TCGA.DU.7018",
"TCGA.HT.7677","TCGA.FG.A713","TCGA.HT.7875","TCGA.TM.A7CA","TCGA.HT.7690","TCGA.CS.5393","TCGA.FG.6689",
"TCGA.DU.7007","TCGA.TQ.A7RF","TCGA.KT.A7W1","TCGA.HT.A5RA","TCGA.DB.5277","TCGA.HT.7694","TCGA.HT.8013",
"TCGA.HW.7490","TCGA.QH.A65S","TCGA.DU.A76R","TCGA.DH.5144","TCGA.CS.6188","TCGA.P5.A780","TCGA.HT.7606",
"TCGA.DU.A7TJ","TCGA.DB.A64V","TCGA.E1.5302","TCGA.HW.A5KJ","TCGA.HT.A615","TCGA.HT.8105","TCGA.DU.A5TY",
"TCGA.DU.5847","TCGA.DB.5270","TCGA.HT.7874","TCGA.HT.7471","TCGA.HT.7882","TCGA.DU.5854","TCGA.DU.6395",
"TCGA.HT.8011","TCGA.S9.A6TV","TCGA.P5.A5EW","TCGA.DB.A4XD","TCGA.DU.5852","TCGA.DU.6408","TCGA.FG.8189",
"TCGA.E1.A7YY","TCGA.FG.A4MT","TCGA.HT.A619","TCGA.P5.A72U","TCGA.HT.A5R9","TCGA.CS.4941","TCGA.DU.6404",
"TCGA.FG.5964","TCGA.CS.5396","TCGA.HT.8107","TCGA.DU.A7TA","TCGA.HW.8319","TCGA.DH.A7UR","TCGA.S9.A6TZ",
"TCGA.HT.7479","TCGA.DU.6400","TCGA.S9.A6WL","TCGA.DB.A75K","TCGA.DU.8165","TCGA.DB.A64Q","TCGA.P5.A737",
"TCGA.DB.5275","TCGA.S9.A6WH","TCGA.HT.7602","TCGA.DU.A5TU","TCGA.HT.A5RB","TCGA.E1.A7YN","TCGA.HT.7616",
"TCGA.S9.A7R8","TCGA.DU.6394","TCGA.HT.8111","TCGA.E1.A7Z2","TCGA.DU.A5TP","TCGA.S9.A7QZ","TCGA.HT.7482",
"TCGA.TQ.A7RK","TCGA.HT.7858","TCGA.HT.7475","TCGA.HT.8564","TCGA.DB.A64U","TCGA.S9.A6WE","TCGA.DB.A64W",
"TCGA.R8.A6MO","TCGA.DU.5872","TCGA.HW.8322","TCGA.CS.6668","TCGA.DU.5870","TCGA.FG.7636","TCGA.HT.7692",
"TCGA.FG.8187","TCGA.HT.7854","TCGA.R8.A6ML","TCGA.HT.7686","TCGA.DU.6410","TCGA.S9.A6U9","TCGA.CS.6290",
"TCGA.TQ.A7RO","TCGA.DU.7019","TCGA.FG.A711","TCGA.TQ.A7RM","TCGA.HT.7860","TCGA.S9.A7R4","TCGA.E1.5318",
"TCGA.HT.7676","TCGA.S9.A7J3","TCGA.DU.A6S2","TCGA.P5.A5F2","TCGA.E1.5304","TCGA.DU.7006","TCGA.HT.7469",
"TCGA.TQ.A7RS","TCGA.S9.A7QX","TCGA.CS.4943","TCGA.QH.A65Z","TCGA.DB.5276","TCGA.P5.A730","TCGA.DU.8161",
"TCGA.S9.A6UB","TCGA.E1.A7YM","TCGA.DB.5273","TCGA.TM.A7C4","TCGA.DH.A66F","TCGA.HT.7607","TCGA.DU.6393",
"TCGA.QH.A6XA","TCGA.HT.8108","TCGA.E1.A7YD","TCGA.S9.A7IY","TCGA.P5.A736","TCGA.P5.A5EV","TCGA.DU.7301",
"TCGA.HT.7470","TCGA.DU.7009","TCGA.P5.A781","TCGA.DH.5140","TCGA.FG.A4MY","TCGA.TM.A7CF","TCGA.S9.A6U6",
"TCGA.HT.8015","TCGA.DU.7010","TCGA.S9.A6U2","TCGA.DU.A76K","TCGA.DU.A7TD","TCGA.DU.6405","TCGA.DU.8168",
"TCGA.QH.A6X3","TCGA.DU.6401","TCGA.DU.6396","TCGA.E1.A7YH","TCGA.DU.7306","TCGA.HT.A74J","TCGA.HT.A74H",
"TCGA.DH.A7US","TCGA.HT.7478","TCGA.DU.7290","TCGA.DU.8164","TCGA.DB.A64L","TCGA.HT.A61B","TCGA.DH.A66B",
"TCGA.FG.8182","TCGA.HT.7603","TCGA.DU.6397","TCGA.HT.A4DS","TCGA.DU.5853","TCGA.CS.6670","TCGA.QH.A65X",
"TCGA.DB.A64P","TCGA.TQ.A7RV","TCGA.HT.A5R7","TCGA.HW.A5KL","TCGA.DU.8158","TCGA.HT.7474","TCGA.DH.A7UU",
"TCGA.QH.A6CZ","TCGA.DH.A669","TCGA.QH.A6X9","TCGA.P5.A5EZ","TCGA.DU.5871","TCGA.TQ.A7RJ","TCGA.FG.8186",
"TCGA.DB.A4XF","TCGA.HT.7483","TCGA.HT.7687","TCGA.E1.A7Z6","TCGA.CS.5394","TCGA.HT.A617","TCGA.DU.A76O",
"TCGA.DU.A5TW","TCGA.HT.7857","TCGA.FG.5962","TCGA.06.0119","TCGA.06.0151","TCGA.06.0165","TCGA.06.0209",
"TCGA.06.1806","TCGA.06.6693","TCGA.06.6694","TCGA.06.6697","TCGA.06.6699","TCGA.14.0862","TCGA.16.1048",
"TCGA.19.5953","TCGA.28.2501","TCGA.28.2510","TCGA.41.6646","TCGA.74.6575","TCGA.74.6577","TCGA.74.6578",
"TCGA.74.6584","TCGA.76.6280","TCGA.76.6283","TCGA.76.6286","TCGA.76.6656","TCGA.76.6657","TCGA.76.6660",
"TCGA.76.6661","TCGA.76.6662","TCGA.76.6663","TCGA.76.6664","TCGA.81.5911"]"

   --- lgg org_clinical_patient has 459 tumors assigned to G2 or G3
       lgg cn + mut data, from the TCGAlgg package, has 516 tumors

    --- get the cn + mut tumors
      cd ~/oncogit/Oncoscape/dataPackages/networks/TCGAbrainMarkersAndTissues/prep/
        # two matrices are loaded at top of go.R
      lgg.mut.cn.tumors <- sort(unique(c(rownames(mtx.cn.lgg), rownames(mtx.mut.lgg))))
      save(lgg.mut.cn.tumors, file="~/oncogit/Oncoscape/dataPackages/networks/TCGAbrainMarkersAndTissues/prep/lgg.mut.cn.tumors.RData")

    --- get the graded tumors
      cd ~/oncodev/hbolouri/dataPackages/RawData/TCGAlgg/Clinical_2-10-15/ ; start R
      tbl <- read.table("nationwidechildrens.org_clinical_patient_lgg.txt", sep="\t", header=TRUE, as.is=TRUE) # 461 * 69
      lgg.graded.tumors <- gsub("-", ".", tbl[, 1], fixed=TRUE)[-(1:2)]   # 459
      save(lgg.graded.tumors, file="~/oncodev/hbolouri/dataPackages/RawData/TCGAlgg/Clinical_2-10-15/lgg.graded.tumors.RData")
      print(load("~/oncodev/hbolouri/dataPackages/RawData/TCGAlgg/Clinical_2-10-15/lgg.graded.tumors.RData"))

    --- 731 tumors in the TCGAbrain network
      cy.nodes().fnFilter(function(node){return node.data("nodeType") == "patient"}).length  // 731

    --- do we have grade assignments for all?
      cy.nodes().fnFilter(function(node){return node.data("nodeType") == "patient"}).select()
      R: tumors <- getSelectedNodes(rcy)$id
         length(intersect(tumors, rownames(tbl.grade)))[1] 659
	 731-659   # 72 tumors have no grade assigned
      setdiff(tumors, rownames(tbl.grade))  # 72
       [1] "TCGA.HT.A74L" "TCGA.TQ.A7RP" "TCGA.E1.A7YI" "TCGA.E1.A7YE" "TCGA.E1.A7YK" "TCGA.E1.A7YU"
       [7] "TCGA.E1.A7Z3" "TCGA.P5.A77X" "TCGA.TQ.A7RG" "TCGA.HT.A74K" "TCGA.TQ.A7RR" "TCGA.TQ.A7RQ"
      [13] "TCGA.TQ.A7RN" "TCGA.TQ.A7RH" "TCGA.E1.A7YS" "TCGA.P5.A735" "TCGA.E1.A7YQ" "TCGA.P5.A77W"
      [19] "TCGA.E1.A7Z4" "TCGA.TQ.A7RU" "TCGA.E1.A7YJ" "TCGA.E1.A7YL" "TCGA.TQ.A7RW" "TCGA.TQ.A7RI"
      [25] "TCGA.R8.A6YH" "TCGA.TQ.A7RF" "TCGA.P5.A780" "TCGA.E1.A7YY" "TCGA.P5.A737" "TCGA.E1.A7YN"
      [31] "TCGA.E1.A7Z2" "TCGA.TQ.A7RK" "TCGA.TQ.A7RO" "TCGA.TQ.A7RM" "TCGA.TQ.A7RS" "TCGA.E1.A7YM"
      [37] "TCGA.E1.A7YD" "TCGA.P5.A736" "TCGA.P5.A781" "TCGA.E1.A7YH" "TCGA.HT.A61B" "TCGA.TQ.A7RV"
      [43] "TCGA.TQ.A7RJ" "TCGA.06.0119" "TCGA.06.0151" "TCGA.06.0165" "TCGA.06.1806" "TCGA.06.6693"
      [49] "TCGA.06.6694" "TCGA.06.6697" "TCGA.06.6699" "TCGA.14.0862" "TCGA.16.1048" "TCGA.19.5953"
      [55] "TCGA.28.2501" "TCGA.28.2510" "TCGA.41.6646" "TCGA.74.6575" "TCGA.74.6577" "TCGA.74.6578"
      [61] "TCGA.74.6584" "TCGA.76.6280" "TCGA.76.6283" "TCGA.76.6286" "TCGA.76.6656" "TCGA.76.6657"
      [67] "TCGA.76.6660" "TCGA.76.6661" "TCGA.76.6662" "TCGA.76.6663" "TCGA.76.6664" "TCGA.81.5911"

    --- for future reference and puzzling out (asked jenny to check when she has a moment)
     lgg.tumors.unassigned <- setdiff(tumors, rownames(tbl.grade))
    save(lgg.tumors.unassigned,
       file="~/oncogit/Oncoscape/dataPackages/networks/TCGAbrainMarkersAndTissues/prep/lgg.tumors.unassigned.RData")

    --- add these into tbl.grade
     print(load("~/oncogit/Oncoscape/dataPackages/networks/TCGAbrainMarkersAndTissues/prep/lgg.tumors.unassigned.RData"))
     print(load("~/oncogit/Oncoscape/dataPackages/networks/TCGAbrainMarkersAndTissues/prep/lgg.tumors.unassigned.RData"))
     length(intersect(lgg.tumors.unassigned, rownames(tbl.grade))) [1] 0
     count <- length(lgg.tumors.unassigned)
     tbl.unassigned <- data.frame(cluster=rep("NA", count), color=rep("gray", count), stringsAsFactors=FALSE)
     rownames(tbl.unassigned) <- lgg.tumors.unassigned
     tbl.grade <- rbind(tbl.grade, tbl.unassigned)
     dim(tbl.grade)  # [1] 1079    2
     table(tbl.grade$cluster)
         G2  G3  G4  NA
        218 241 548  72
     table(tbl.grade$color)
        blue  gray green   red
         241    72   218   548

    save(tbl.grade, file="~/oncogit/Oncoscape/dataPackages/TCGAbrain/inst/extdata/tumorGrade.RData")

*----------------------------------------------------------------------------------------------------
* prep for onocoscape server meeting (21 oct 2015) proposed topic: building an oncoscape farm

--- what we have

1) oncocape: an evolving webapp in which an R server is paired with a
web browser.  The server provides HTML/CSS and Javascript to the
browser at startup, after which peer-to-peer JSON websocket messages
are exchanged.  This design works best with one R process per browser
user.  Our current demo can handle a few different browser sessions, but
we should end this soon.

2) A registration, login, authentication, configuration and R lauching webapp,
currently written in node.js with some python helpers, one of which is ...

3) a very simple python script which, when given a configuration

     1) target host and port
     2) userID
     3) names of available datasets

launches an Oncoscape R process on the specified target host/port,
passing in parameters; Oncoscape then waits to be contacted by a
browser (or a simulated browser; see testing described below).

--- what we need next: the oncoscape farm

Given any number of "create oncoscape" requests (port:host, userID,
datasets) we need to start up and load oncoscape R instances, then run
clients to test them, ensuring that they

    1) start quickly
    2) run robustly
    3) provide timing and memory statistics

We can benefit from a crucial simplification: the farm can be developed, run and be
thoroughly tested without web browsers.

Farm input: a list of configurations (host:port, userID, dataset
names) generated randomly or created by hand.

Testing: a python http/websocket client (we already have one) which talks
to a farm instance, ensures that it responds properly.  Automated
browser testing of oncoscape -- simulating a user clicking in their
browser -- is a separate task I am working on now.  We can test the
farm with these later.
on.

--- what we can defer for now (for a few weeks, at least)

   1) improvements in the login/launcher webapp (lots of complexity to be
      handled here.  a minimal launcher connected to the farm will, in
      the near future, get us started)

   2) distributed secure data.  absolutely needed, but since this
      will follow the same API we currently use for R packaged data,
      we can defer this till we have more staff





*----------------------------------------------------------------------------------------------------
* prep for onocoscape server meeting (21 oct 2015) answering lisa's questions

  --- lisa proposes:

    Most of what we will discuss in that meeting tomorrow will be execution of
    code that comes after the launcher code/port manager that Ken was involved
    in.  Questions we should be prepare to answer tomorrow include:

      1. Why not use shiny server?
      2. Would R MPI help?
      3. Can we create a pool of R instances?

   I think we already can field question 3, but can you look into #1 and 2 please?

  --- shiny server
    open source edition: no authentication or ssl, single R process per application
    professional edition: 50% of 10k, 15k, 25k (20,

   --- R MPI

     MPI is for distributing ("shared nothing") tasks within a single program.
     may be useful to us when we want optimize oncoscape R algorithms

   --- can we create a pool of R processes?
     certainly.  a pool manager would handle them: starting, stopping, assigning them to incoming requests
     some latencies will remain:  there will be little known about what data and tabs the
     incoming request will specify; this configuration and loading will take at least a little time.

   --- Rserve: a protocal for sending R commands to your own dedicated R process within the server
       the protocol is, eg, RConnection.eval("some R command string")
       not so helpful to us

     Rserve is a TCP/IP server which allows other programs to use
     facilities of R (see www.r-project.org) from various languages
     without the need to initialize R or link against R library. Every
     connection has a separate workspace and working
     directory. Client-side implementations are available for popular
     languages such as C/C++, PHP and Java. Rserve supports remote
     connection, authentication and file transfer. Typical use is to
     integrate R backend for computation of statstical models, plots
     etc. in other applications.

     The following Java code illustrates the easy integration of Rserve:

        RConnection c = new RConnection();
        double d[] = c.eval("rnorm(10)").asDoubles();

    --- Rserve/RStudio contrast

      http://stackoverflow.com/questions/19500561/what-is-the-relation-between-rstudio-and-rserve

      Rserve is a client server implemenation written in pure c that
      starts a server and spawns multiple processes each with it's own
      R workspace. This is not threads but processes due to R's
      limitation on multithreading. It uses a QAP packing protocol as
      it's primary form of transport between the client and the
      server. You execute commands via the client (PHP, Java, C++) to
      the server and it returns you REXP objects that are essentially
      mappings to R's underlying SEXP data objects. Rserve also offers
      a websockets version that does will can transmit data through
      websockets but the api is not well documented. It also supports
      basic authentication through a configuration file.

      Rstudio is a C++ and gwt application that provides a web based
      front end to R. AFAIK it uses json as it's primary transport and
      supports authentication through pam. Each user has a workspace
      configured in their home directory. It runs a server very
      similar but not the same as Rserve to communicate with R using
      RCPP. It also has it's own plotting driver used to wrap the plot
      device so that it can pickup the plots to be served to the
      ui. It has much more functionality such as stepping through your
      code from the ui and viewing workspace variables.

      Functionally they are similar in that they provide a
      client/server connection to R but IMHO the comparison stops
      there.


    --- more on R MPI
     https://en.wikipedia.org/wiki/Message_Passing_Interface
     (http://www.r-bloggers.com/accelerating-r-with-multi-node-parallelism-rmpi-batchjobs-and-openlava/)

     The message passing interface (MPI) is a staple technique among HPC
     aficionados for achieving parallelism. MPI is meant to operate in a
     distributed, shared nothing environment and provides primitives for
     tasks (referred to as ranks or slaves) to share state with one
     another by efficiently passing messages. Rmpi provides an R wrapper
     to the MPI API making MPI functions accessible to R programmers.

     While Rmpi can be used with snow, in a snow environment it is
     assumed that the MPI job is the only problem running on the
     cluster. Often in academic or workgroup environments however,
     multiple users or departments are sharing a cluster and need to run
     multiple MPI jobs concurrently or mix serial and MPI
     workloads. When it comes to scaling workloads, there’s nothing like
     a workload manager.


*----------------------------------------------------------------------------------------------------
* javascript tips, jshint tips

   --- use debugger statement

        /* jshint ignore:start */
	debugger;
	/* jshint ignore:end */

*----------------------------------------------------------------------------------------------------
* github tips, git tips:  what branches are on the remote?

    git ls-remote --heads origin

      deea48347cfb8fa0fd20e1ff5a09722c56129a8f	refs/heads/Release_1.4.89
      630c8aeea9dcb7adf2700dae80b1adb19aa37ef7	refs/heads/addTestingAndTiming-MarkersModule
      e68366e92af08d5d6e63d1aae4a30f581bae2ce3	refs/heads/dataPackage
      71417f61a8d2d8535ebed684ff3ae7d356d7e3c0	refs/heads/develop
      4a35536ef0f5c649caf54225ee3a36ab0f7516a6	refs/heads/gh-pages
      0802ca22e5c76a1b62aa9bdad2de8124fde9c01b	refs/heads/master
      e86f700ec7b9d28c1edb651eae2a6a61418fa5a5	refs/heads/oncoprint

*----------------------------------------------------------------------------------------------------
* github tips, git tips:  checkout branch from remote

    git fetch
    git checkout -b addTestingAndTiming-MarkersModule

*----------------------------------------------------------------------------------------------------
* github tips, git tips:  checkout just one branch

  git clone -b develop --single-branch https://github.com/FredHutch/Oncoscape

  (9 feb 2016, eager.systemsbiology.net)   --single-branch rejected. otherwise seems fine
    /local/ehc/github/Oncoscape

*----------------------------------------------------------------------------------------------------
* git cribsheet

  git remote -v            # what's my remote?
  git branch -v            # what branch?
  git checkout develop     # switch to the (already existing) branch 'develop'
  git pull origin develop  # fetch and merge from the remote.  aborts if

     # create a new branch off the current branch
  git checkout develop    # see the branch off of which the new one will itself branch
  git checkout -b addTestingAndTiming-MarkersModule    # create the new branch
  git push origin addTestingAndTiming-MarkersModule    # put it up on the server

  git add <changed files>
  git commit -m "message"
  git push origin addTestingAndTiming-MarkersModule   # push the changed files up to the new branch



*----------------------------------------------------------------------------------------------------
* oncoscape timing

  display markers network, DEMOdz:      < 500 msecs     (08 oct 2015)
                           TCGAbrain:   15 seconds      (08 oct 2015)
                           TCGAgbm:     25 seconds      (08 oct 2015)


  getSampleCategorizationNames, runs concurrently with display markers network, thus same durations
  markersApplyTumorCategorization, TCGAbrain:  ~5 seconds  (08 oct 2015)

  --- request and apply tumor categorization (Module.markers)

    [event] OncoDev14 1.4.88 (2015-10-08 14:03:47.476): autotest@nowhere.org markersApplyTumorCategorization request
    [event] OncoDev14 1.4.88 (2015-10-08 14:03:47.609): autotest@nowhere.org markersApplyTumorCategorization data received
    [event] OncoDev14 1.4.88 (2015-10-08 14:03:55.000): autotest@nowhere.org markersApplyTumorCategorization complete


    [event] OncoDev14 1.4.88 (2015-10-08 14:24:13.611): {TCGAbrain} autotest@nowhere.org display markers network request from TCGAbrain
    [event] OncoDev14 1.4.88 (2015-10-08 14:24:13.693): {TCGAbrain} autotest@nowhere.org getSampleCategorizationNames from TCGAbrain
    [event] OncoDev14 1.4.88 (2015-10-08 14:24:31.942): {TCGAbrain} autotest@nowhere.org display markers network complete
    [event] OncoDev14 1.4.88 (2015-10-08 14:24:32.968): {TCGAbrain} autotest@nowhere.org getSampleCategorizationNames complete
    [event] OncoDev14 1.4.88 (2015-10-08 14:25:19.255): {DEMOdz} autotest@nowhere.org display markers network request from DEMOdz
    [event] OncoDev14 1.4.88 (2015-10-08 14:25:19.284): {DEMOdz} autotest@nowhere.org getSampleCategorizationNames from DEMOdz
    [event] OncoDev14 1.4.88 (2015-10-08 14:25:19.723): {DEMOdz} autotest@nowhere.org display markers network complete
    [event] OncoDev14 1.4.88 (2015-10-08 14:25:19.834): {DEMOdz} autotest@nowhere.org getSampleCategorizationNames complete
    [event] OncoDev14 1.4.88 (2015-10-08 14:25:41.417): {TCGAgbm} autotest@nowhere.org display markers network request from TCGAgbm
    [event] OncoDev14 1.4.88 (2015-10-08 14:25:41.462): {TCGAgbm} autotest@nowhere.org getSampleCategorizationNames from TCGAgbm
    [event] OncoDev14 1.4.88 (2015-10-08 14:25:48.720): {TCGAgbm} autotest@nowhere.org display markers network complete
    [event] OncoDev14 1.4.88 (2015-10-08 14:25:49.113): {TCGAgbm} autotest@nowhere.org getSampleCategorizationNames complete
    [event] OncoDev14 1.4.88 (2015-10-08 14:26:11.887): {TCGAbrain} autotest@nowhere.org display markers network request from TCGAbrain
    [event] OncoDev14 1.4.88 (2015-10-08 14:26:11.971): {TCGAbrain} autotest@nowhere.org getSampleCategorizationNames from TCGAbrain
    [event] OncoDev14 1.4.88 (2015-10-08 14:26:30.237): {TCGAbrain} autotest@nowhere.org display markers network complete
    [event] OncoDev14 1.4.88 (2015-10-08 14:26:31.238): {TCGAbrain} autotest@nowhere.org getSampleCategorizationNames complete
    [event] OncoDev14 1.4.88 (2015-10-08 14:26:57.170): {TCGAgbm} autotest@nowhere.org display markers network request from TCGAgbm
    [event] OncoDev14 1.4.88 (2015-10-08 14:26:57.246): {TCGAgbm} autotest@nowhere.org getSampleCategorizationNames from TCGAgbm
    [event] OncoDev14 1.4.88 (2015-10-08 14:27:06.850): {TCGAgbm} autotest@nowhere.org display markers network complete
    [event] OncoDev14 1.4.88 (2015-10-08 14:27:07.233): {TCGAgbm} autotest@nowhere.org getSampleCategorizationNames complete
    [event] OncoDev14 1.4.88 (2015-10-08 14:27:16.520): {DEMOdz} autotest@nowhere.org display markers network request from DEMOdz
    [event] OncoDev14 1.4.88 (2015-10-08 14:27:16.558): {DEMOdz} autotest@nowhere.org getSampleCategorizationNames from DEMOdz
    [event] OncoDev14 1.4.88 (2015-10-08 14:27:17.181): {DEMOdz} autotest@nowhere.org display markers network complete
    [event] OncoDev14 1.4.88 (2015-10-08 14:27:17.253): {DEMOdz} autotest@nowhere.org getSampleCategorizationNames complete

    [event] OncoDev14 1.4.88 (2015-10-08 16:27:36.685):       TCGAbrain autotest@nowhere.org display markers network request
    [event] OncoDev14 1.4.88 (2015-10-08 16:27:50.961):       TCGAbrain autotest@nowhere.org display markers network complete
    [event] OncoDev14 1.4.88 (2015-10-08 16:27:36.748):       TCGAbrain autotest@nowhere.org getSampleCategorizationNames
    [event] OncoDev14 1.4.88 (2015-10-08 16:27:51.799):       TCGAbrain autotest@nowhere.org getSampleCategorizationNames complete

    [event] OncoDev14 1.4.88 (2015-10-08 16:29:07.334):          DEMOdz autotest@nowhere.org display markers network request
    [event] OncoDev14 1.4.88 (2015-10-08 16:29:39.296):          DEMOdz autotest@nowhere.org display markers network complete
    [event] OncoDev14 1.4.88 (2015-10-08 16:29:07.359):          DEMOdz autotest@nowhere.org getSampleCategorizationNames
    [event] OncoDev14 1.4.88 (2015-10-08 16:29:39.319):          DEMOdz autotest@nowhere.org getSampleCategorizationNames complete




*----------------------------------------------------------------------------------------------------
* youtube views
                         6oct15  8oct15
   cbioportal/gstt:         2      4
   onocoscape/oncoprint:    8     11
   sword fern die-off:     95     97

*----------------------------------------------------------------------------------------------------
* cbioportal/oncoscape/oncoprint integrations for niki schultz (6 oct 2015)

  ~/s/docs/attachmentToNikiShultzCbioportal letter.pdf
  ~/s/docs/attachmentToNikiShultzCbioportal letter.docx

   cbioportoal oncoscape integration:   https://www.youtube.com/watch?v=8k3rKBjNMaI
   oncoprint/oncoscape demo:            https://www.youtube.com/watch?v=NPdl87V8xtQ

*----------------------------------------------------------------------------------------------------
* sttr oncoscape job candidate, dave reid (5 oct 2015)

  phone anytime: 206.371.9128
  (5 oct 2015, 230p): left message
*----------------------------------------------------------------------------------------------------
* fred hutch hr, job reclassification? (5 oct 2015)

  current position: systems analyst/programmer IV
  grace campbell, admin for lisa campbell

  --- lisa will call back by tuesday afternoon, 10/6

*----------------------------------------------------------------------------------------------------
* salishan nouns and verbs (3 oct 2015)

  from http://www-personal.umich.edu/~jlawler/Lushootseed.html

  http://linguistics.stackexchange.com/questions/11413/does-any-linguist-honestly-believe-that-nouns-and-verbs-are-not-universals

One has to be careful how the words Noun and Verb are understood, if one wants a
good answer.  Semanticists talk about Entities and Events, and leave Noun and
Verb as formal categories, dependent on criteria of usage (can it be a subject?
can it take a definite article?) instead of meaning.

Frawley (Linguistic Semantics, 1992 Ch.3 "Entities", p.62) notes that,

while it is certainly not true that nouns always refer to persons, places, or
things, it certainly is true that persons, places, and things are overwhelmingly
expressed using nouns.  This is because nouns normally refer to entities, and
verbs normally refer to events (including states).  In other words, those
definitions of noun and verb from grade school are completely backwards.

There's all kinds of linguistic evidence that most languages do distinguish
between noun and verb.  But that's not evidence that categories like Noun and
Verb can be attached to individual words.  At least not permanently; lexical
categorization is a separate issue. Pretty much any English word, for instance,
can be used as just about any open-category part of speech: noun, verb,
adjective, adverb.  But we have good tests for what a given word is being used
as -- in a given sentence. Not generally.

However, the joker in the question is that it presupposes that there are words
in a language.  Most languages do have words -- i.e, they can put word-level
constituents together into larger ones.

But there are polysynthetic languages, like Eskimo languages and Salishan
languages. In a polysynthetic language there is usually a very simple root
system with dozens of derivations and inflections that get added on to form even
the simplest utterance. And these roots are very general, and have lots of
metaphoric and idiomatic associations -- like any other language -- so their
possible forms get big very fast. Both in the sense of getting longer and
longer, and in the sense of there being almost infinite extensibility of words.

It says something about Skagit (Puget Salish; Northern Lushootseed) that over
3/4 of the nouns in the language start with the overt nominalizer s- --even the
words for 'man' and 'woman'. They're built on CVC roots, as is most of the rest
of the language. So in Skagit, while there are nouny things and verby things and
you can tell the difference in a given sentence, they don't split up the
descriptive labor the way we're used to, and the roots are normally neither
verby nor nouny, but can be made to refer to either. Plus there isn't a really
well-defined boundary between words and sentences.

So serious scholars will question the presuppositions.

shareimprove this answer
answered Feb 14 at 20:34

john lawler in exile


*----------------------------------------------------------------------------------------------------
* phytochrome papers

  Phytochrome Signaling: Time to Tighten up the Loose Ends (2014)

  The Structure of Phytochrome: A Picture Is Worth a Thousand Spectra (2006)

  A light-sensing knot revealed by the structure of the chromophore-binding domain of phytochrome (2005)

*----------------------------------------------------------------------------------------------------
* robert bringhurst, a story as sharp as a knife, the world which was lost p193 (30 sep 2015)

in a self-sustaining oral culture faith, hope and even charity are invested very differently than
in culture that are lerning or have learned the use of writing.  a shift from oral to written
culture affects the functioning of memory, the understnading of truth, and the place of voice
and language in the working of the world.  it affects not just the meaning of words but the
the meaning of language itself.  it affects the meaning of meaning.  on the northwest coast, the shift
from oral to written culture was linked to other changes just as rapid and profound. it was linked
first of all to a shift from a culture of hunting and gathering to a culture of seasonal wage
work and industrial production - from harvesting for use to harvesting for export.  in the world
that came with writing, fish and timber go to market, and food and clothing come from stores.  it
was also linked, in this case, to a catastrophic drop in population, a shift from the matrilineal
to patrilineal inheritance, and a conceptual version of the world. whole villages of relatives
and benefactors - aerial, sylvan and submarine - were displaced by God the Father above, a crucified
redeemer on the surface, and a Satan tempting sinners in the shadows and punishing their errors
underground. The Americas were invaded on many fronts at once.  But there is no such thing as
introducing writing into a world of oral poets and hunter-gatherers while holding the other factors
of culture the same.

*----------------------------------------------------------------------------------------------------
* add new tumor categorization to tcgabrain (28 sep 2015)


   --- email from hamid

     Attached are IDs for 2 groups of samples that Eric and I have identified
     as having very distinct metabolic, stemness, and immune gene expression
     profiles (see pdf image fyi).

     Per Eric's request below, please could you add these annotations to the
     Oncoscape Markers and Tissues tab?


    --- construct a data.frame
    print(load("HoBoMetabolicClustersBlue.RData"))  # [1] "samplesHi"
    length(samplesHi) # [1] 71
    print(load("HoBoMetabolicClustersRed.RData"))   # [1] "samplesLo"
    length(samplesLo) # [1] 73
    df <- data.frame(cluster=rep("low", 144), color=rep("red", 144), stringsAsFactors=FALSE)
    rownames(df) <- c(samplesLo, samplesHi)
    hiTumors <- match(samplesHi, rownames(df))
    df$cluster[hiTumors] <- "high"
    df$color[hiTumors] <- "blue"

    tbl.expression <- df
    save(tbl.expression, file="../../../TCGAbrain/inst/extdata/metabolicExpressionStemness.RData")

*----------------------------------------------------------------------------------------------------
* draft email to niki, version 2: a minimal "executive summary" (5 oct 2015)

Dear Niki,

Our demo is ready.

   http://chinookdemo6.sttrcancer.org/cbioportal

This illustrates how to extend cbioportal with a new computation and its accompanying UI tab
using the loose-coupling design principles we developed with Oncoscape.

We also have the complementary demo, extending Oncoscape with cbioportal capabilities:

   http://oncotest1.sttrcancer.org/

Here we make use of your fine javascript OnocPrint library to add new visualizations to
Oncoscape



WIn addition to this, which adds a new tab and computation to the cbioportal,
we have added your OncoPrint capability into Oncoscape

This is coming to you quite a bit later than I predicted ("ready by June 30th"
was what I promised).  Our delay is due mostly to the conflicting priorites
and schedules we have faced, rather than to any intrinsic complexity in our
approach.   We got distracted by other priorities, but with a growing sense
of unease that we might be missing a great opportunity to collaborate.
I am glad to say that we have some proofs of principle ready for you now.



*----------------------------------------------------------------------------------------------------
* draft email to niki schultz, cbio, mskcc (28 sep 2015)

Dear Niki,

Our demo illustrating our approach to extending cbioportal is now live at

   http://chinookdemo6.sttrcancer.org/cbioportal

This is coming to you quite a bit later than I predicted ("ready by June 30th"
was what I promised).  Our delay is due mostly to the conflicting priorites
and schedules we have faced, rather than to any intrinsic complexity in our
approach.   We got distracted by other priorities, but with a growing sense
of unease that we might be missing a great opportunity to collaborate.
I am glad to say that we have some proofs of principle ready for you now.

Our design, code, and engineering are all pretty simple, which is our strong
point.  The central idea is a slighly novel implementation of standard computer
science strategies using recently standardized technologies.  We emphasize the
separation of concerns, and the loose-coupling of separately developed,
separately tested components.  Websockets and JSON messages provide the
connectivity between compute and data servers on the backend and the user's
browsers.  Javascript libraries (d3, cytoscape.js, jQuery) power the browser.
Based on my roots in the Bioconductor project, we use R for data and data
analyis on the server side (though experiments with Python and Java are quite
possible as well).  In our demo we illustrate this by adding a tab and a
supporting computational service to an otherwise standard cbioportal instance.

This tab, "Oncoscape Geneset T-Test", appears along side the standard cbiportal
tabs.  It depends upon two patient (tumor) groups being identified by normal cbioportal
operations and stored as globally accessible Javascript object.  The user
can then switch to our tab, set some thresholds, then calculate a simple t-test
version of gene expression geneset enrichment across all 12,000  Broad msigdb
genesets.  Results are returned in 20 seconds are less, and may be explored
interactively.

Specifically, the demo (avaialable at http://chinookdemo6.sttrcancer.org/cbioportal)


  1) Operates on a prior calculation by cbiopotal, in which patients with and without
     alterations have been identified.  We typically use the TCGA Breast Invasion
     Carcinoma study, select 280 sequenced tumors, then request a division of tumors
     (patients) between those with and without alterations in 34 Cell Cycle Control genes.
     This is somewhat  arbitrary; our demo works with any any two non-overlapping tumor
     groups available to our Javascript in the variables your team kindly added for
     us, "xxxx" and "yyyyy"

  2) Given two groups (138 altered, 149 unaltered in the above example), Oncoscape
     Genset T-Tests analyzes TCGA breast gene expression for these two groups
     across al 12k Broad msigdb  genesets, reporting those  where gene expression is
     significantly different (using thresholds set by the
     user; we suggest a pvalue of 0.01).  Thus we identify genesets with differential
     expression correlated with mutations and copy number aberrations in the cell cycle
     control genes (discovered by the cbioportal).

  3) Each of the significant genesets is listed, and an expression heatmap showing their
     contrast can be displayed, along with the full description of the geneset from the
     Broad's GSEA website.

One computer science topic needs to be discussed explicitly here, one upon which
many attempts at collaboration have foundered:  that of semantics, ontologies and
vocabularies.

Our approach sidesteps nearly all of the thorny problems that arise in these
fields.  To add the Oncoscape Geneset T-Test capability to the cbioportal, we
needed only to obtain tumor identifiers and the name of the TCGA cancer type.
These identifiers, like HUGO gene symbols, are standard and well-known.

The specific use and interpretation of these identifiers may change from tab to
tab (from context to context), that is, the terms are "semantically flexible"
and can can be used and reused successfully in many different contexts,
interpreted differently in each one.  A gene symbol can refer to a cell in a
heatmap, to a node in a cytoscape.js network, as a key to retrieve a GeneCards
webpage or a genome browser track.  Rich and specific semantics thus apply WITHIN each
tab (within each analytical context) but flexible semantics applies BETWEEN tabs.
This allows many tabs to be separately developed and richly combined.

I title talks I give about this approach, "No More Silos: A Tiny Protocol for
Connecting Software".  In that spirit, and with the tables turned, we have
just added, to the delight of our users, an OncoPrint tab to our Oncoscape webapp.
(You can see this in action at http://oncotest1.sttrcancer.org).   Your group's decision
to make your software open source, and to carve out some of the useful pieces for
others to reuse is an exciting more. It contributes signficantly to our hope that
we can break down silos, share UI widgets and computational services, and make
faster progress in biology and cancer treatment then would otherwise be possible.








*----------------------------------------------------------------------------------------------------
* rcyjs tips: saveLayout to dated filename

  filename= paste("layout.", gsub(" ", ".", date()), sep=""); saveLayout(rcy, filename); print(filename)
*----------------------------------------------------------------------------------------------------
* plsr data.frame to list conversion (25 sep 2015)

  just one factor (of two sent) make it into calculatePLSR
  the ultimate call looks like this: (from test_PLSR.R)

   factor.age <- list(name="AgeDx", low=loAge,  high=hiAge)
   factor.survival <- list(name="Survival", low=loSurvival,  high=hiSurvival)
   x <- calculatePLSR(plsr, list(factor.age, factor.survival), goi)

   which list looks like this when printed in PLSR-class.R, method calculatePLSR:
[[1]]
[[1]]$name
[1] "AgeDx"

[[1]]$low
[1] 16435.8

[[1]]$high
[1] 24105.84


[[2]]
[[2]]$name
[1] "Survival"

[[2]]$low
[1] 1096.72

[[2]]$high
[1] 2556.68

   but when assembled from incoming JSON in wsPLSR.R
      factors.df <- msg$payload$factors
      printf("--- factors.df assigned from msg$payload$factors");
      print(factors.df)
      factors <- apply(factors.df, 1, as.list)

  it becomes

[1] --- PLSR.calculatePLSR
[1] --- factors: 2
$`1`
$`1`$high
[1] "24105.84"

$`1`$name
[1] "AgeDx"

$`1`$low
[1] "16435.80"


$`2`
$`2`$high
[1] " 2556.68"

$`2`$name
[1] "Survival"

$`2`$low
[1] " 1096.72"


   --- find the remedy
     [1] --- factors.df assigned from msg$payload$factors
           high     name      low
     1 24105.84    AgeDx 16435.80
     2  2556.68 Survival  1096.72

     [1] --- factors after apply on factors.df
     $`1`
     $`1`$high
     [1] "24105.84"

     $`1`$name
     [1] "AgeDx"

    df <- data.frame(age=c(10, 20), name=c("a", "b"), survival=c(40, 50), stringsAsFactors=FALSE)
    apply(df, 1, as.list)

*----------------------------------------------------------------------------------------------------
* github tips: what are my remotes?

   --- git remote -v
     origin	https://github.com/pshannon-bioc/Oncoscape (fetch)
     origin	https://github.com/pshannon-bioc/Oncoscape (push)
     trueOncoscapeOrigin	https://github.com/oncoscape/Oncoscape.git (fetch)
     trueOncoscapeOrigin	https://github.com/oncoscape/Oncoscape.git (push)

   --- add
     git remote add <shortName> url
     git remote add trueOncoscapeOrigin https://github.com/FredHutch/Oncoscape

   --- remove
     git remote rm trueOncoscapeOrigin

   --- git pull:  a git fetch followed by a git merge

*----------------------------------------------------------------------------------------------------
* github tips: sync a fork

   https://github.com/pshannon-bioc/Oncoscape is a fork of
   https://github.com/oncoscape/Oncoscape

   i am using the development branch of pshannon-bioc/Oncoscape, my origin
     (i forked the true oncoscape, then cloned pshannon-bioc/Oncoscape to my laptop)

   git fetch trueOncoscapeOrigin
   git push origin

*----------------------------------------------------------------------------------------------------
* github tips: fix files in conflict

   --- told of unmerged files when
     git checkout <branchName>
     git commit ...

   --- solution
     look in the reported files for 'HEAD'
     resolve the conflict
     stage them with git add <filename>
     commit the staged files:
      git commit -m "two keepAlive intervals in Module.hub: 3 and 10 seconds.  chose latter; removed duplicate code in Module.markers"



*----------------------------------------------------------------------------------------------------
* more github tips, grokking basic operations for oncoscpe (29 sep 2015)

    git branch              # list branches
    git checkout develop    # switch to the (already existing) branch 'develop'
    git checkout syncWithMyRecentChanges
    git status
    git checkout develop
    git merge --no-ff syncWithMyRecentChanges
    git status
    git commit -m "changes i unintentionally did directly to the develop branch"
    git sttaus
    git status
    git merge --no-ff syncWithMyRecentChanges
    git status
    git push
    git pull
    git pull origin develop
    git add remote https://github.com/oncoscape/Oncoscape.git
    git add remote http://github.com/oncoscape/Oncoscape.git
    git add remote remoteDevelopOrigin https://github.com/oncoscape/Oncoscape.git
    git remote add trueOncoscapeOrigin https://github.com/oncoscape/Oncoscape.git
    git branch
    git push trueOncoscapeOrigin
    git pull trueOncoscapeOrigin
    git pull trueOncoscapeOrigin develop


* github tips: my first use of lisa's git repo (25 sep 2015)

  used github gui button to fork https://github.com/oncoscape/Oncoscape to me as pshannon-bioc

  on wombat:
    cd ~/oncogit
    # fork at github
    git clone https://github.com/pshannon-bioc/Oncoscape

    cd Oncoscape
    git branch   # reports just one: master
    git status   # On branch master; Your branch is up-to-date with 'origin/master'. nothing to commit, working directory clean

    git checkout develop # Branch develop set up to track remote branch develop from origin. Switched to a new branch 'develop'
    git status   # On branch develop, Your branch is up-to-date with 'origin/develop'. nothing to commit, working directory clean


   on lopez as sttrweb:


  --- create a new branch (off of develop) in which I will incorporate my latest svn changes
    git checkout -b syncWithMyRecentChanges   # Switched to a new branch 'syncWithMyRecentChanges'
    git status  On branch syncWithMyRecentChanges, nothing to commit, working directory clean

  --- to change branches
    git branch
    git checkout <branch name>

*----------------------------------------------------------------------------------------------------
* github tips: lisa's startup instructions (25 sep 2015)

   After much delay and anticipation, the github repository exists and is ready
   for use.  A stub of a fancy page can be found here:

    http://oncoscape.github.io/Oncoscape/

   The main code is found on the normal github page:

      https://github.com/oncoscape/Oncoscape

    This has both master and develop branches, which correspond to our Release and Test pages.

    To start working from this directory:

   1. Fork the develop branch from github into your server repository  (upper right corner of webpage)
   2. Clone your server repository to folder on your local machine
      git clone https://github.com/LisaMc/Oncoscape.git
      cd Oncoscape
      git checkout develop
      git status

   When you fork/clone, both the master and develop branches will be stored in
   your server/local repositories.  Except for hot fixes, all changes should be
   made to your develop branch.  Features should be separated into specific
   branches and merged within your local develop branch when complete. Here is
   the link for our version schema:

   http://nvie.com/posts/a-successful-git-branching-model/.

   More info can also be found here:

   https://www.atlassian.com/git/tutorials/comparing-workflows/forking-workflow

   A typical workflow would then look like:

     git checkout develop
     git checkout -b myBestFeature develop
     git status
     … your changes
     git add <files>
     git commit –m “informative message”   #updates to your local machine
     git pull origin develop   #updates local develop branch using server changes (useful/necessary when collaborating)
     git checkout develop
     git merge --no–ff myBestFeature     #no fast forward groups all individual commits together
     git push                                          # this will update your server version and create a pull request within the Oncoscape master repository so myBestFeature can be included in the main Test version
     git branch –d myBestFeature     #deletes branch

    Several files should be ignored so to not track log files, etc.  I’ve
    checked in a .gitignore file that should exclude the common files.  See
    https://help.github.com/articles/ignoring-files/ for how to edit it further
    if desired.

    If you find that you were making changes to the wrong branch, you can
    rectify this by

       http://stackoverflow.com/questions/2941517/how-to-fix-committing-to-the-wrong-git-branch:

    git reset —soft HEAD^
    git checkout branch
    git commit



*----------------------------------------------------------------------------------------------------
* address chrom loc layout crowding in markers tab (23 sep 2015)

  cd ~/oncodev/hbolouri/dataPackages/networks/TCGAbrainMarkersAndTissues/prep/
  reload(); make()
  zoom in on the chr7 centromere
  select pileup of genes just below (and partly hidden by) chr7p


  subset(tbl.all, name %in% getSelectedNodes(rcy)$name)    # negative locs: genes on the revese strand
     name           map       loc chrom arm type screen.x screen.y
     EGFR          7p12  55086725     7   p gene     2800       71
    IKZF1        7p12.2  50344378     7   p gene     2800      147
   LANCL2 7q31.1-q31.33  55433141     7   q gene     2800       66
   SEC61G        7p11.2 -54819940     7   p gene     2800       75
   SEPT14        7p11.2 -55861237     7   p gene     2800       59
    VOPP1        7p11.2 -55538306     7   p gene     2800       64
   VSTM2A        7p11.2  54610019     7   p gene     2800       79
   ZNF713        7p11.2  55980331     7   p gene     2800       57
    chr7p                58054331     7   p  arm     2800       24



  tbl <- subset(tbl.all, name %in% getSelectedNodes(rcy)$name)[, c("name", "loc")]
  tbl$loc <- abs(tbl$loc)
   tbl
         name      loc
  155    EGFR 55086725
  278   IKZF1 50344378
  304  LANCL2 55433141
  539  SEC61G 54819940
  540  SEPT14 55861237
  648   VOPP1 55538306
  649  VSTM2A 54610019
  677  ZNF713 55980331
  6001  chr7p 58054331

  tbl <- tbl[order(tbl$loc, decreasing =TRUE),]
  dist <- 58054331 - tbl$loc
  tbl$dist <- dist/1000000  # re-express as megabase
  tbl$dist <- dist

          name      loc     dist
   6001  chr7p 58054331 0.000000
   677  ZNF713 55980331 2.074000
   540  SEPT14 55861237 2.193094
   648   VOPP1 55538306 2.516025
   304  LANCL2 55433141 2.621190
   155    EGFR 55086725 2.967606
   539  SEC61G 54819940 3.234391
   649  VSTM2A 54610019 3.444312
   278   IKZF1 50344378 7.709953


  --- how many pixels spanned by 1MB?
    getPosition(rcy, getSelectedNodes(rcy)$id)
          id    x     y
   1 start.1 1000  1974
   2   end.2 1300 -2397

   subset(tbl.all, name %in% c("start.1", "end.2"))
          name map       loc chrom arm           type screen.x screen.y
   546 start.1             0     1   p telomere.start     1000     1974
   571   end.2     243199373     2   q   telomere.end     1300    -2397

   243199373/ (1974 + 2397)   #  55639.3 (bases per pixel

   chr7 znf713 and sept14  begin 120k bases apart, or 2 pixels

   confirmed at ucsc
     https://genome.ucsc.edu/cgi-bin/hgTracks?db=hg19&position=chr7%3A55867900-56120862&hgsid=445801975_qWW4KOOMLJdGGIviP1vzKZUX93gB





*----------------------------------------------------------------------------------------------------
* restart chinookdemo1/2 on lopez (22 sep 2015)

  cd /home/sttrweb/lopez/github/chinook/R-server
  /home/sttrweb/lopez/github/chinook/R-server
  source ~/lopez/oncoscape/v1.4.60/.setupR
  R CMD INSTALL -l /home/sttrweb/lopez/oncoscape/v1.4.60/Rlibs/x86_64-unknown-linux-gnu-library/3.2/ Chinook/
  R CMD INSTALL -l /home/sttrweb/lopez/oncoscape/v1.4.60/Rlibs/x86_64-unknown-linux-gnu-library/3.2/ ModelMPG/
  R CMD INSTALL -l /home/sttrweb/lopez/oncoscape/v1.4.60/Rlibs/x86_64-unknown-linux-gnu-library/3.2/ ModelMPG/

  nohup  R -f runChinook.R &
  nohup  R -f runModelMPG.R &

*----------------------------------------------------------------------------------------------------
* get svn repo before lisa merges in her changes, on the occasion of moving to github (22 sep 2015)

  --- 22 sep 2015, before lisa merges in all her changes

   wombat: cd /Users/pshannon/oncodev/preGitHub
     svn co https://hedgehog.fhcrc.org/hb/devel/hbolouri/oncoDev14

   lopez:  cd /home/sttrweb/lopez/pshannonSvnCopy

     svn co https://hedgehog.fhcrc.org/hb/devel/hbolouri/oncoDev14
     svn co https://hedgehog.fhcrc.org/hb/devel/hbolouri/analysisPackages
     svn co https://hedgehog.fhcrc.org/hb/devel/hbolouri/dataPackages




*----------------------------------------------------------------------------------------------------
* eric's north ontario no datasets bug (22 sep 2015)

 --- he sees in his js console

    Consider using 'dppx' units, as in CSS 'dpi' means dots-per-CSS-inch, not
    dots-per-physical-inch, so does not correspond to the actual 'dpi' of a
    screen. In media query expression: only screen and
    (-webkit-min-device-pixel-ratio: 2), only screen and (min-resolution:
    144dpi) (index):45

    hypothesis: socket connected quickly, but not all html loaded, so menu.ready did not fire

      --- eric                                              --- me

    === Module.hub setupSocket                         (index):156 === Module.hub setupSocket
    websocket connection now open
    ==== Module.hub: 11 onDocumentReadyFunctions       (index):231 ==== Module.hub: 11 onDocumentReadyFunctions
    calling on ready function			       (index):234 calling on ready function
    ====== tabapps document ready		       (index):660 ====== tabapps document ready
    calling on ready function			       (index):234 calling on ready function
    loginRequired? false			       (index):764 loginRequired? false
    enabling datasetMenu			       (index):767  enabling datasetMenu
    calling on ready function			       (index):234 calling on ready function
    === Module.patientHistory, initializeUID	       (index):1041 === Module.patientHistory, initializeUID
    8calling on ready function			       8(index):234 calling on ready function

    cwMarkers ready				       (index):160 websocket connection now open
    cwMarkers.reset				       (index):163 calling the next sockectConnectedFunction
    --- configureLayoutsMenu			       (index):833 === datasetMenu ready, now issuing populateDataSetMenu request to server
    cyGbm ready					       (index):335 --- hub.send: 'getDataSetNames' (server)
    cyGbm.reset					       (index):163 calling the next sockectConnectedFunction
    cyPathway ready				       (index):335 --- hub.send: 'getUserId' (server)
    about to show all edges			       (index):163 calling the next sockectConnectedFunction
    after showing all edges			       (index):335 --- hub.send: 'getUserId' (server)
    cyPathway.reset				       (index):163 calling the next sockectConnectedFunction
    --- configureLayoutsMenu			       (index):335 --- hub.send: 'getUserId' (server)
						       (index):1796 cwMarkers ready
						       (index):1830 cwMarkers.reset
						       (index):1725 --- configureLayoutsMenu
						       (index):2733 cyGbm ready
						       (index):2759 cyGbm.reset
						       (index):3536 cyPathway ready
						       (index):3538 about to show all edges




 --- i see in mine

Navigated to http://chinookdemo5.sttrcancer.org/
(index):156 === Module.hub setupSocket
(index):231 ==== Module.hub: 11 onDocumentReadyFunctions
(index):234 calling on ready function
(index):660 ====== tabapps document ready
(index):234 calling on ready function
(index):764 loginRequired? false
(index):767  enabling datasetMenu
(index):234 calling on ready function
(index):1041 === Module.patientHistory, initializeUID
8(index):234 calling on ready function
(index):160 websocket connection now open
(index):163 calling the next sockectConnectedFunction
(index):833 === datasetMenu ready, now issuing populateDataSetMenu request to server
(index):335 --- hub.send: 'getDataSetNames' (server)
(index):163 calling the next sockectConnectedFunction
(index):335 --- hub.send: 'getUserId' (server)
(index):163 calling the next sockectConnectedFunction
(index):335 --- hub.send: 'getUserId' (server)
(index):163 calling the next sockectConnectedFunction
(index):335 --- hub.send: 'getUserId' (server)
(index):1796 cwMarkers ready
(index):1830 cwMarkers.reset
(index):1725 --- configureLayoutsMenu
(index):2733 cyGbm ready
(index):2759 cyGbm.reset
(index):3536 cyPathway ready
(index):3538 about to show all edges
*----------------------------------------------------------------------------------------------------
* cyjs tips:  selected node, selected edge, mark indicate with backround shading (4 dec 2015)

    {"selector":"edge:selected", style:
       {"overlay-opacity": 0.2,
        "overlay-color": "red"
        }}

*----------------------------------------------------------------------------------------------------
* cyjs tips: layout selected nodes in a grid (17 sep 2015)

  function spreadSelectedNodes(){
     var totalHeight = 0;
     var totalWidth = 0;
     centerX = 0;
     centerY = 0
     cy.nodes("node:selected").forEach(function(node){
        totalHeight += node.height();
        totalWidth  += node.width();
        centerX = node.position().x
        centerY = node.position().y
        });
     var x = centerX - (totalWidth/2);
     var y = centerY - (totalHeight/2);
     boundingBox = {x1: x, y1: y, w: totalWidth, h: totalHeight};
     //var strategy = "circle";
     var strategy = "grid";
     cy.nodes("node:selected").layout({name: strategy, boundingBox: boundingBox, columns: 3});
     }

*----------------------------------------------------------------------------------------------------
* cyjs tips:  get border-color border colors of selected nodes (22 sep 2015)

    jQuery.unique(cwMarkers.nodes("node:selected").map(function(node){return node.style("border-color")}))

*----------------------------------------------------------------------------------------------------
* cyjs tips: identify nodes (get their objects) by id/name, many at one time

   genes = cwMarkers.$("#EED")
   genes = cwMarkers.filter("node[id='EED']")
   genes = cwMarkers.nodes("[id='EED']")

   tumors = cwMarkers.filter("node[id='TCGA.02.0014']")
   tumors = cwMarkers.nodes("[id='TCGA.02.0014']")
   tumors =  cwMarkers.$("#TCGA\\.02\\.0014")

   genes.edgesWith(tumors).length  // 1
   genes.edgesWith(tumors).data("edgeType")  // "cnGain.2"

   cwMarkers.nodes().filterFn(function(node){ return (["EED"].indexOf(node.data("id") >= 0))}
   cwMarkers.nodes()[0].filterFn(node) {return ["EED"].indexOf(node.data("id")) >= 0}
   cwMarkers.nodes()[0].filterFn(function(node) {return ["EED"].indexOf(node.data("id")) >= 0;})

   cwMarkers.nodes()[0].filterFn(function(node) {return ["EDIL3"].indexOf(node.data("id")) >= 0;}).length      // 1
   cwMarkers.nodes()[0].filterFn(function(node) {return ["EED"].indexOf(node.data("id")) >= 0;}).length       // 0
   cwMarkers.nodes()[0].filterFn(function(node) {return ["EED", "EDIL3"].indexOf(node.data("id")) >= 0;}).length  // 1

   ---
     selectedNodes.map(function(node){return node.id()})            // ["TCGA.02.0014"]
     selectedNodes.neighborhood().map(function(e){return(e.id())})  // ["EED", "e71", "ELAVL2", "e72", "PTK2", "e73", "UCP2", "e74"]
     geneNodeRestriction   // ["EED", "UCP2"]
     neighbors = selectedNodes.neighborhood()
     neighbors.filterFn(function(e) {return geneNodeRestriction.indexOf(e.id()) >= 0})
     restrictedNeighbors = neighbors.filterFn(function(e) {return geneNodeRestriction.indexOf(e.id()) >= 0})

     targets = ["EED", "UCP2"]  // find only edges to these nodes
     neighbors = selectedNodes.neighborhood()
     neighbors.map(function(e) {return  e.isEdge()})  [false, true, false, true, false, true, false, true]
     neighbors.map(function(e) {if (e.isEdge()) return e.connectedNodes()})
     edges = neighbors.filterFn(function(e) {if(e.isEdge()) return e})

    function intersects(array1, array2){
      var size = array1.filter(function(n) {return array2.indexOf(n) != -1}).length;
      return(size > 0);
      }

    edges.filterFn(function(edge){
       var actual=edge.connectedNodes().map(function(node){return node.id()});
       return(intersects(actual, targets));
       }).show()


*----------------------------------------------------------------------------------------------------
* r tips: redo installation, rmove.packages (4 nov 2015)

  ip <- installed.packages()
  pkgs.to.remove <- ip[!(ip[,"Priority"] %in% c("base", "recommended")), 1]
  sapply(pkgs.to.remove, remove.packages)
  sapply(pkgs.to.remove, install.packages)

*----------------------------------------------------------------------------------------------------
* r tips build

  R CMD build --no-build-vignettes RCyjs && R CMD check --no-vignettes --no-tests RCyjs_1.1.32.tar.gz

*----------------------------------------------------------------------------------------------------
* r tips, marc's technique for learning methods, via sonali

   search()[c(2,11)]   # [1] "package:DEMOdz"          "package:SttrDataPackage"
   ls(2)   # [1] "DEMOdz" "show"
   ls(11)
     [1] "SttrDataPackage"              "data.frames"                  "entities"                     "getGeneSetGenes"
     [5] "getGeneSetNames"              "getPatientList"               "getPatientTable"              "getSampleCategorization"
     [9] "getSampleCategorizationNames" "history"                      "manifest"                     "matrices"
     [13] "networks"                     "show"

  --- also 'methods'
   dz <- DEMOdz()
   methods(class=class(dz))
    [1] coerce<-                     data.frames                  entities                     getGeneSetGenes
    [5] getGeneSetNames              getPatientList               getPatientTable              getSampleCategorization
    [9] getSampleCategorizationNames history                      manifest                     matrices
   [13] networks                     show


*----------------------------------------------------------------------------------------------------
* cyjs markers: apply tumor categorizations and colors (15 sep 2015)

   --- in Module.markers function markersApplyTumorCategorization:

     var tumorNodes = cwMarkers.nodes("[nodeType='patient']")
     var tumors = msg.payload.rownames
     var tbl = msg.payload.tbl
     //tumorNodes

   var x = tumorNodes.forEach(function(node, index){
        var id = node.id();
        var cluster = tbl[index][0];
        var color = tbl[index][1];
        if(tumors.indexOf(id) >= 0){
           console.log(id + " in cluster " + cluster + "  color: " + color);
           node.data({subType: cluster});
           } // if
        else{
          node.data({subtype: "unclassifed"));
          }
        })

      // this sets the style, removing all pre-existing styling
   //cwMarkers.style().fromString('node[tumorCluster=1] {border-color: darkred;}').update();

     // add to an existing stylesheet
   //cy.style().selector('node[tumorCluster=1]').style({'border-color': 'cyan';}).update();
   //cwMarkers.style().selector('node[tumorCluster=1]').style({'background-color': 'cyan'}).update();


*----------------------------------------------------------------------------------------------------
* localStorage, javascript (15 sep 2015)

  https://github.com/ofirdagan/cross-domain-local-storage

   Problem: As for now, standard HTML5 Web Storage (a.k.a Local Storage) doesn't now allow cross
   domain data sharing. This may be a big problem in an organization which have a lot of sub domains
   and wants to share client data between them.

   Solution: xdLocalStorage is a lightweight js library which implements LocalStorage interface and
   support cross domain storage by using iframe post message communication.



*----------------------------------------------------------------------------------------------------
* generalize tumor categories: first try, eric & TCGAbrain, from hamid (13 sep 2015)


  2.5) use a plot that colors in the diagnosis of the tumors (as an option in addition to or rather
  than the GBM subtypes) make sure gene locations are correct)

  cd ~/oncodev/hbolouri/dataPackages/networks/TCGAbrainMarkersAndTissues/prep
  cp ~/Downloads/IDsOfErics8GliomaClusters.RData .   # from email from hamid (9 sep 2013)

  perGrpIDs <- list(grp1=grp1, grp2=grp2, grp3=grp3, grp4=grp4, grp5=grp5, grp6=grp6, gr7=grp7, grp8=grp8)
    and the colors that I used (see fig 2f of the attached pdf) were:

  #  perGrpColors8 <- c("darkred","red","orange","magenta","blue","cyan","green","forestgreen")
  colors.8 <-  c("darkred","red","orange","magenta","blue","cyan","green","forestgreen")

  print(load("IDsOfErics8GliomaClusters.RData")) # [1] "perGrpIDs", a list, length, 8

  lapply(perGrpIDs, length)
  $grp1:  21
  $grp2:  22
  $grp3:  246
  $grp4:  53
  $grp5:  162
  $grp6:  42
  $gr7:  111
  $grp8:  47

  --- convert to a data.frame
    tumors <- unlist(perGrpIDs, use.names=FALSE)
    group <- unlist(lapply(names(perGrpIDs), function(name) rep(name, length(perGrpIDs[[name]]))))
    groups <- sub("grp", "", group)
    color <- unlist(lapply(1:8, function(i) rep(colors.8[i], length(perGrpIDs[[i]]))))
    tbl.categories <- data.frame(cluster=groups, color=color, stringsAsFactors=FALSE)
    rownames(tbl.categories) <- tumors
    save(tbl.categories, file="ericsEightGliomaClusters.RData")

     head(tbl.categories)
                       cluster   color
          TCGA.DU.A5TT       1 darkred
          TCGA.DU.8165       1 darkred
          TCGA.E1.A7YD       1 darkred
          TCGA.HT.A4DS       1 darkred
          TCGA.02.0055       1 darkred
          TCGA.06.0130       1 darkred

   cp ericsEightGliomaClusters.RData ../../../TCGAbrain/inst/extdata/

  --- now put the old verhaak classification into the same format, tbl.dzSubTypes.RData
     print(load("tbl.dzSubTypes.RData")) #      [1] "tbl.gbmDzSubTypes"
      head(tbl.gbmDzSubTypes)
                  gbmDzSubType  color
     TCGA.02.0010       G-CIMP purple
     TCGA.02.0028       G-CIMP purple
     TCGA.02.0102    Classical    red
     TCGA.02.0114       G-CIMP purple
     TCGA.08.0525    Classical    red
     TCGA.12.0615    Classical    red

    tbl.categories <- tbl.gbmDzSubTypes
    colnames(tbl.categories) <- c("cluster", "color")
    unassigned <- which(tbl.categories$cluster == "")
    tbl.categories$cluster[unassigned] <- NA
    save(tbl.categories, file="verhaakGbmClustersAugmented.RData")

     cp verhaakGbmClustersAugmented.RData ../../../TCGAbrain/inst/extdata/

  --- with meaningful variable names
    save(tbl.verhaakPlus1, file="verhaakGbmClustersAugmented.RData")
    save(tbl.glioma8, file="ericsEightGliomaClusters.RData")

*----------------------------------------------------------------------------------------------------
* criteria of mind, gregory bateson (10 nov 2015)

  https://en.wikipedia.org/wiki/Gregory_Bateson

   1) Mind is an aggregate of interacting parts or components.
   2) The interaction between parts of mind is triggered by difference.
   3) Mental process requires collateral energy.
   4) Mental process requires circular (or more complex) chains of determination.

   5) In mental process the effects of difference are to be regarded
      as transforms (that is, coded versions) of the difference which
      preceded them.

   6) The description and classification of these processes of
      transformation discloses a hierarchy of logical types immanent in
      the phenomena.

*----------------------------------------------------------------------------------------------------
* does photomorphogenesis exhibit bateson's six criteria of mind (10 nov 2015)

   1) an aggregate of interacting parts or components
        the phytochromes, FHY3, FAR1, FHY1, FHL   (FHY3 and FAR1 are tfs producing
        FHY1 and FHL, which serve as transporters for PHYA)

   2) interaction triggered by difference:  between red light (660 nm) and far red (730 nm)

   3) requires collateral energy: cell energetics provided by ATP derived from photosynthesis

   4) requires circular (or more complex chains of determination)
      stockpiled  transcription factors FHY3 and FAR1 transcribe transporters
        FHY1 and FHL, carrying the Pfr form into the nucleus where it
        contributes to the transcription of "sun seeking" genes.
        more phytochrome A accumulates in the nucleus, the less FHY3 and FAR1
        proteins are produced, the fewer transporters are made, PhyA
        density drops.

   5) In mental process the effects of difference are to be regarded
      as transforms (that is, coded versions) of the difference which
      preceded them.

          PhyA transport into the nucleus, and its transcriptional activity
          are transforms of the original far red light (shade) signal

   6) The description and classification of these processes of
      transformation discloses a hierarchy of logical types immanent in
      the phenomena.   huh?



  chlorophyll absorbs red light, far red passes through
  red light: 660 nm
  far red:   730
  phy synthesises in the Pr (red-sensitive) form.
  red light converts some into the Pfr form
  in some plants, Pfr translocates to the nucleus, binds to partners, either
    activates or inhibits transcription of specific genes

  Studies in Arabidopsis have shown that phytochromes primarily transduce light signals via
  interaction with PIFs (phytochrome interacting factors), a sub‐family of bHLH proteins.

  --- haiyang wang, Phytochrome Signaling Mechanism, 2002

   As sessile organisms, plants are unable to move actively towards favorable or away from unfavorable environmental
   conditions. Therefore, through their evolution, plants have adapted a high degree of developmental plasticity to
   optimize their growth and reproduction in response to their ambient environments. Light is one of the major
   environmental signals that influence plant growth and development.  Not only is light the primary energy source for
   plants, but it also provides them with positional information to modulate their developmental processes such as seed
   germination, seedling de-etiolation, gravitropism and phototropism, chloroplast movement, shade avoidance, circadian
   rhythms, and flowering time. Plants can detect almost all facets of light such as direction, duration, quantity, and
   wavelength by using three major classes of photoreceptors: the red (R)/far-red (FR) light (600-750 nm) absorbing
   phytochromes (phys), the blue (B)/UV-A (320-500 nm) absorbing cryptochromes (crys) and phototropins (phots), and the
   UV-B (282-320 nm) sensing UV-B receptors (Kendrick and Kronenberg, 1994; Briggs and Olney, 2001; Briggs et al.,
   2001). These photoreceptors perceive, interpret, and transduce light signals, via distinct intracellular signaling
   pathways, to photoresponsive nuclear genes, which modulates plant growth and development.

   --- haiyang wang, "Illuminating Study Reveals How Plants Respond to Light"
        http://www.solutions-site.org/node/295

    By conducting experiments with Arabidopsis--a small flowering plant widely used as a model organism--the researchers
    discovered that the plant prepares to respond to light while it is still in the dark, even before it is exposed to
    light.

    This preparation involves producing a pair of closely related proteins known as FHY1 and FHL in darkness. The
    researchers found that another pair of closely related proteins named FHY3 and FAR1 act as transcription factors to
    promote the production of FHY1 and FHL in darkness.

    When plants are exposed to light, the photoreceptor protein phytochrome A is activated through a change in shape
    that allows it to bind to FHY1 and FHL. The binding of FHY1 and FHL to phytochrome A helps to bring phytochrome A
    into the nucleus to regulate the activity of genes located in the cell nucleus that govern plant growth and
    development.

    Haiyang Wang, a member of the research team from Boyce Thompson Institute for Plant Research, says that the plant
    probably stockpiles these proteins (FHY3, FAR1, FHY1, FHL and phytochrome A) needed for light responses in the dark
    for the same reason that a traveler fills his car's gas tank the night before a morning journey: in order to be able
    to get going, without delay, at first light.

    Moreover, the researchers also discovered the existence of a negative feedback loop between accumulations of
    phytochrome A in the cell nucleus and the FHY3 and FAR1 proteins that prime the plant's light response system: the
    more phytochrome A accumulates in the nucleus, the less FHY3 and FAR1 proteins are produced, and so less phytochrome
    A is imported into the nucleus. "This feedback loop serves as a built-in brake that limits the flow of light
    responses," says Wang.


  --- Phytochrome photosensory signalling networks, Peter H. Quail
  --- Phytochromes, Quail:  http://www.ncbi.nlm.nih.gov/pmc/articles/PMC2954054/
  2008 Transposing phytochrome into the nucleus. Fankhauser C1, Chen M.
*----------------------------------------------------------------------------------------------------
*
  it is now fully accepted that shade avoidance reactions are all
  initiated by a single environmental signal, the reduction in the ratio
  of red (R) to far-red (ER) radiation (i.e. R:ER) that occurs within
  crowded plant communities. We use the term 'syndrome' to describe the
  multiple responses to low R:ER, in analogy to medical conditions in
  which multiple symptoms are caused by a single underlying problem.

  Phytochromes exist in two forms: PR and PFR. It is synthesised as PR, but red light triggers a conformational change,
  producing PFR. Far red light causes the phytochrome to be converted back into PR. For a given red:far red light ratio,
  there will be a dynamic equilibrium in the relative quantities of PR and PFR present. Far red enrichment causes a
  build-up of PR. If PR is present above a species-specific threshold, shade avoidance signal transduction pathways will
  be activated.


*----------------------------------------------------------------------------------------------------
* plants analyze light

  http://genesdev.cshlp.org/content/14/3/257.full
  Light: an indicator of time and place,  Michael M. Neff1,3, Christian Fankhauser1,4, and Joanne Chory1,2,5
   2000, Genes and Development

  Because they are both photosynthetic and sessile, plants have to be especially plastic in response to their light
  environment. In addition to utilizing light as a time-keeping mechanism, plants are unique in that they use light as a
  source of energy and they analyze light to control such developmental decisions as when to germinate and flower. The
  diverse responses of plants require sophisticated sensing of intensity, direction, duration, and wavelength of light.

*----------------------------------------------------------------------------------------------------
* photomorphogenesis papers

  ---- Fernando Valladares
  The Architecture of Plant Crowns: From Design Rules to Light Capture and Performance
  https://scholar.google.com/citations?user=sjUP6dsAAAAJ&hl=en&oi=sra
*----------------------------------------------------------------------------------------------------
* bateson

  it's hard to be enthusiastic about being (only) human.

  but delightful to be a critter, a mind nestled within overlapping, neighboring, somtimes containing,
    sometimes contained systems of minds.

  so that local (human) runaway is likely contained by larger more stable systems

  https://en.wikipedia.org/wiki/Plant_perception_(physiology)

ch 19 "multiple signals regulate the growth an development of plant organs an denable their adaptation
to envirnonmental conditions" p 451 of plant biochemistry.


  peter harries-jones, author of "a recursive vision"
     http://www.yorku.ca/laps/anth/faculty/emeriti/Harries-Jones_Culture_is_Nature.pdf
     discusses biosemiotics as the opposite of eo wilson's reductionism


This mistaken view has been justly labelled ‘meaning
rationalism’ and fosters a belief that the universal syntactics of human language is clearly
distinctive from all other forms of communication exhibited by non-human life – that is
non-human life has not grammaticality.
 ‘Meaning rationalism’ proposes that birds may sing, but they have no ‘grammar’ in their
singing. Moreover, says the ‘meaning rationalists,’ they cannot learn how to give a
performance in ‘bird songs’ through recursively practicing bird calls. We maintain
pragmatics trumps syntax. Here we have a specific opposition to Biolinguistics and to

   argues for and against robert bringhurst, "the tree of meaning"

 also by harries jones:
     Bioentropy, Aesthetics and Meta-dualism: The Transdisciplinary Ecology of Gregory Bateson
     ~/s/notes/book/entropy-12-02359.pdf


*----------------------------------------------------------------------------------------------------
* six words, leo's college essay

  have musical presence, want cultural presence.

  --- alternatives?
    late night jam, encounter america's curse
    play with feeling, add historical depth



*----------------------------------------------------------------------------------------------------
* centromere locations (10 sep 2015)

  library(GWASTools)
  data(centromeres.hg19)  # data.frame of the same name
  centromeres.hg19
       chrom left.base right.base
    1      1 121535434  124535434
    2      2  92326171   95326171
    3      3  90504854   93504854
    4      4  49660117   52660117
    5      5  46405641   49405641
    6      6  58830166   61830166
    7      7  58054331   61054331
    8      8  43838887   46838887
    9      9  47367679   50367679
    10    10  39254935   42254935
    11    11  51644205   54644205
    12    12  34856694   37856694
    13    13  16000000   19000000
    14    14  16000000   19000000
    15    15  17000000   20000000
    16    16  35335801   38335801
    17    17  22263006   25263006
    18    18  15460898   18460898
    19    19  24681782   27681782
    20    20  26369569   29369569
    21    21  11288129   14288129
    22    22  13000000   16000000
    X      X  58632012   61632012
    Y      Y  10104553   13104553


*----------------------------------------------------------------------------------------------------
* chromosome lengths  (17 nov 2015)

   library(TxDb.Hsapiens.UCSC.hg19.knownGene)     version 3.2.2
   tbl.seqInfo <- seqlevels(seqinfo(TxDb.Hsapiens.UCSC.hg19.knownGene))

   seqlengths(seqinfo(TxDb.Hsapiens.UCSC.hg19.knownGene))[paste("chr", c(1:22, "X", "Y"), sep="")]
   chrom.lengths <- as.list(seqlengths(seqinfo(TxDb.Hsapiens.UCSC.hg19.knownGene))[paste("chr", c(1:22, "X", "Y"), sep="")])
          chr1      chr2      chr3      chr4      chr5      chr6      chr7      chr8      chr9     chr10
     249250621 243199373 198022430 191154276 180915260 171115067 159138663 146364022 141213431 135534747
         chr11     chr12     chr13     chr14     chr15     chr16     chr17     chr18     chr19     chr20
     135006516 133851895 115169878 107349540 102531392  90354753  81195210  78077248  59128983  63025520
         chr21     chr22      chrX      chrY
      48129895  51304566 155270560  59373566

   ---- obsoloete
   tbl.seqInfo <- as.data.frame(seqinfo(TxDb.Hsapiens.UCSC.hg19.knownGene))  # 93 x 3
   tbl.seqInfo[paste("chr", c(1:22, "X", "Y"), sep=""), "seqlengths"]
    [1] 249250621 243199373 198022430 191154276 180915260 171115067 159138663 146364022 141213431 135534747 135006516
    [12] 133851895 115169878 107349540 102531392  90354753  81195210  78077248  59128983  63025520  48129895  51304566
    [23] 155270560  59373566



*----------------------------------------------------------------------------------------------------
* scaled chromosomes for eric in new MDS chrom markers tab (10 sep 2015)

  cd ~/oncodev/hbolouri/dataPackages/networks/TCGAbrainMarkersAndTissues/prep/

  --- strategy: create data.frame with coordinates for all genes, small p/q arm nodes, telomeres


  --- explore with a gene on 7q (MUC17) and one on 7p (EGFR)
    from ucsc genome browser:
       egfr  p11.2  chr7: 55,086,725 -  55,275,031 188,307 bp
       muc17 q22.1 chr7:100,663,364 - 100,702,140  38,777 bp


  --- using AnnotationDb
   genes <- c("DUX4", "TTN", "TPM3")
   genes <- c("EGFR", "MUC17")
   db <- org.Hs.eg.db
      # add CHRLOCEND to get the loc of the end of each known transcript (i think....)
   select(db, columns=c("SYMBOL", "MAP", "CHRLOC"), keytype="SYMBOL", keys=head(genes))
      SYMBOL    MAP    CHRLOC CHRLOCCHR
    1   EGFR   7p12  55086725         7
    2  MUC17 7q22.1 100663364         7



*----------------------------------------------------------------------------------------------------
* marc carlson on AnnotationDb objects (eg, org.Hs.eg.db) (successor to mget)  (9 sep 2015)

   library(org.Hs.eg.db)
   db <- org.Hs.eg.db
columns(db)
 [1] "ENTREZID"     "PFAM"         "IPI"          "PROSITE"      "ACCNUM"       "ALIAS"
 [7] "CHR"          "CHRLOC"       "CHRLOCEND"    "ENZYME"       "MAP"          "PATH"
[13] "PMID"         "REFSEQ"       "SYMBOL"       "UNIGENE"      "ENSEMBL"      "ENSEMBLPROT"
[19] "ENSEMBLTRANS" "GENENAME"     "UNIPROT"      "GO"           "EVIDENCE"     "ONTOLOGY"
[25] "GOALL"        "EVIDENCEALL"  "ONTOLOGYALL"  "OMIM"         "UCSCKG"
>

*----------------------------------------------------------------------------------------------------
* hamid's short-term solution to the brca-complex, basc-comple problem (4 sep 2015)

   In _theory_ the BASC complex and the BRCA complex could be
   connected to different sets of downstream processes (BRCA1 is
   thought to drive more cellular processes than BRCA2).

   BUT, in our current network fig, these 2 complexes currently both
   drive only 'DNA-repair'. So in our current network, these two
   meta-nodes could be combined without loss of information.

   So let's just have a single meta-node called 'BASC-BRCA' that
   contains MSH6, BRCA1, and BRCA2.


   --- my analysis, to which the above is a response

     I think I see the problem here.  In our interaction data (both
     from 03/14 and my derived version, but this is lifted directly
     from the earlier one) we have:

       BASC complex	DNA Damage Repair	activates.process	TCGA	complex	process
       BASC complex	BRCA1	contains	TCGA	complex	gene
       BASC complex	MSH6	contains	TCGA	complex	gene
       BRCA complex	DNA Damage Repair	activates.process	TCGA	complex	process
       BRCA complex	BRCA2	contains	TCGA	complex	gene
       BRCA complex	BRCA1	contains	TCGA	complex	gene

     This puts BRCA1 in two different complexes, BASC and BRCA.  That
     worked fine until I started using compound nodes.  In
     cytoscape.js, a node can be nested immediately only within one
     parent node.

     Given this restriction, how should we proceed?



*----------------------------------------------------------------------------------------------------
* deployed oncscape:

   --- from list, ports & processes (31 aug 2015)
     oncoscape.s.o (Release): port 7777 pid 18477 (running cronjob)
     oncoTest.s.o (Test): port 7788 pid 17990 (running cronjob)
     chinook3 (TCGAgbm demo): port 11003 pid 774 (running cronjob)
     chinook4 (Oncoplex uwlung): port 11004 pid 25806
     chinook5 (TCGAgbm demo): port 11005 pid 2565

  --- release
   /home/sttrweb/lopez/oncoscape/Release2015_08_14/v1.4.60/oncoDev14/Oncoscape/inst/scripts/eric

*----------------------------------------------------------------------------------------------------
* bugs reports from eric on new MDS chrom markers tab (4 sep 2015)

 one bug or error I detected this morning is that not all of the genes
 are in the right order in the markers and patients plot.
 Specifically chr7 has genes out of order. Lancl2 is actually in 7p
 and the genes in 7p are ordered backward on the plot. I haven’t gone
 through all the other chromosomes but I am worried that there may be
 other errors as well.

 the search function  is not working.  Also, the "send to" is not working.  If I select a set of
 tumors and want to send to survival or patient history or something.

  --- todo list (4 sep 2015)

    0) fix mouse-over readout (done),  fix search (done)
    1) reverse y coordinates of the MDS plot and potentially stretch out the display a bit horizontally.  See the plots that Hamid made.
    2) add telomere nodes and vertical lines to them from centromeres (and
  2.5) use a plot that colors in the diagnosis of the tumors (as an option in addition to or rather than the GBM subtypes) make sure gene locations are correct)
    3) fix selection augmentation (add a block of nodes to an existing block of selected nodes)
    4) allow user to identify, name, and restrict future network operations to an arbitrary group of genes, a group of tumors
    5) add "restore original layout" button
    6) support circular and freehand interactive selection areas


*----------------------------------------------------------------------------------------------------
* txdb tips  (with mget on org.Hs.egCHR deprecated) (3 may 2015)

   --- goal: get chrom, start, end of human gene MEF2C




   --- more elaborate steps
  library(org.Hs.eg.db)
  library("TxDb.Hsapiens.UCSC.hg38.knownGene")
  orgdb <- org.Hs.eg.db
  txdb <- TxDb.Hsapiens.UCSC.hg38.knownGene
    columns(orgdb)
     [1] "ACCNUM"       "ALIAS"        "ENSEMBL"      "ENSEMBLPROT"  "ENSEMBLTRANS" "ENTREZID"     "ENZYME"
     [8] "EVIDENCE"     "EVIDENCEALL"  "GENENAME"     "GO"           "GOALL"        "IPI"          "MAP"
    [15] "OMIM"         "ONTOLOGY"     "ONTOLOGYALL"  "PATH"         "PFAM"         "PMID"         "PROSITE"
    [22] "REFSEQ"       "SYMBOL"       "UCSCKG"       "UNIGENE"      "UNIPROT"

    columns(txdb)
     [1] "CDSCHROM"   "CDSEND"     "CDSID"      "CDSNAME"    "CDSSTART"   "CDSSTRAND"  "EXONCHROM"  "EXONEND"
     [9] "EXONID"     "EXONNAME"   "EXONRANK"   "EXONSTART"  "EXONSTRAND" "GENEID"     "TXCHROM"    "TXEND"
    [17] "TXID"       "TXNAME"     "TXSTART"    "TXSTRAND"   "TXTYPE"

   head(keys(txdb, keytype="TXNAME"))
    [1] "uc001aaa.3" "uc001aab.3" "uc010nxq.1" "uc031tlb.1" "uc001aal.1" "uc031tlc.1"


    select(orgdb, columns=c("SYMBOL", "ENSEMBLTRANS"), keytype="SYMBOL", key="MEF2C")  # 34 transcripts
    select(txdb, columns=c("TXNAME", "TXCHROM", "TXSTART", "TXSTRAND"), keytype="TXNAME", key="MEF2C")

*----------------------------------------------------------------------------------------------------
* txdb tips  (with mget on org.Hs.egCHR deprecated) (2 sep 2015)

  from here: https://www.bioconductor.org/help/workflows/annotation/annotation/

  library("TxDb.Hsapiens.UCSC.hg19.knownGene")
  txdb <- TxDb.Hsapiens.UCSC.hg19.knownGene
  --> abandoned this for now: no obvious way to chromosome arm.  maybe "band" would be avaiallable
       like org.Hs.egMAP


*----------------------------------------------------------------------------------------------------
* leo and listening (1 sep 2015)

-- draft 2


In your college essay you start with two strong points:

 1) "I have trouble feeling fully present"
 2) you regularly find, "tucked away deep in the pulsing groove
  of an Old Time fiddle tune" a remedy for this

You then go on to explore the social, political and moral complexities of
this music you love.  A lot of injustice and twisted history lies
therein, and like the Confederate Battle flag, you need to see it, understand it,
not overlook it.

A couple of years ago you wrote a startling essay, one of the finest things
I have ever read.  No kidding.

I am not sure ifyou gave it to me to read or -- more likely -- that I found it on the
living room table and read it without first asking if I could.  The
broad topic was metacognition.  You wrote about how listening to
scratchy old fiddle tunes closely enough so you could learn
to play them, to do them justice, had taught you how to listen to your
friends, and how to do them justice.  A beautiful essay.  An amazing
discovery for a 14 year-old.  Or a 62 year-old.

Maybe there's a theme here, your theme?  That careful listening is what enables you
to feel fully present?

Your attention to the easiliy overlooked complexities of "Nigger
in the Treetop" is another place where your theme seems to arise.  (Your
work with Core and GHS environmental work also.)  That you have so many
admirable, fun, often older friends is probably related.

MLK claimed "the arc of the moral universe is long, but it bends
towards justice".  To which I add (suspecting King would agree): the
first step towards achieving more justice, like the first step towards playing an old
tune, is listening very carefully.  One has to understand the
structures, the changes, the parts, the relations.

Maybe it is no accident that the music you play is music of oppressed
peoples: hillbillies, forgotten African American string bands and
banjo songsters, Irish peasants, urban black swing jazz from before the Civil
Rights era.

You have come far by listening, by playing, by working with a few good
teachers, in late night jam sessions with friends.  By doing so, and by
virtue of the sense of justice I think you were born with, you are now
encountering some complex histories.  Your music has become a key which opens
a door, putting some injustices, easily ignored, on vivid display.

To play the music honestly, and to live honestly, maybe we have to listen carefully
to the lives and histories from which they come.

College can give you the tools to listen to these histories.  And just
as listening to music contributes to your fine (and world-changing)
music (not peace-in-the-middle-east kinds of world changing, but
modest world changing, reminding people of beauty and groove), so too
can college  make you wiser and set you up -- in small ways also,
since those are alwasy the best -- to make the world a better place too.

Perhaps listening is the somewhat hidden theme of your college essay.

footnote: in his journals Thoreau mentions that there are times when
he is "out of his senses".  He was out in the woods but stuck in
his mind, not really hearing, not really seeing.  He says, "I am
wasting my time, I may as well go home".  He practiced something which
has been called "micro-visioning" in which he paid studied attention
to the finest details, of lichen on bark, of a particular ripple
moving across Walden Pond.  He was an "inspector of snowstorms".

Buddhist practice, some varieties of it, are very similar: just sit
there, wait for your thinking to (maybe eventually) quiet down, notice
that you are just a body, flesh blood and eyes, sitting in -this-
room.  This room, this place, this body, this friend, this tune.  Close attention
is an old and venerable human practice.  We never really do it enough.

 -- draft 1


In your college essay you start with two strong points:

  1) "I have trouble feeling fully present"
  2) you regularly find, "tucked away deep in the pulsing groove
   of an Old Time fiddle tune" a remedy for this

You then go on to explore the social, political, moral complexities of
this music you love.  A lot of injustice and twisted history lies
therein, and like the Confederate Battle flag, you need to address it.

A couple of years ago you wrote a startling essay.  I am not sure if
you gave it to me to read or -- more likely -- that I found it on the
living room table and read it without first asking if I could.  The
broad topic was metacognition.  You wrote about how listening to
scratchy old fiddle tunes, listening closely enough so you could learn
to play them, and to do them justice, had taught you how to listen to your
friends, how to do them justice.  A beautiful essay.  An amazing
discovery for a 14 year-old.

Maybe there's a them here?  That careful listening is what enables you
to feel full present?  It might be a prerequisite for artful speaking
and artful playing?  (see footnote on Thoreau etc. below)

Your attention to the easiliy overlooked complexities of "Nigger
in the Treetop" is another place where your theme seems to arise.  (Your
work with Core and GHS environmental work also.)

MLK claimed "the arc of the moral universe is long, but it bends
towards justice".  To which I add (suspecting King would agree): the
first step towards justice, like the first step towards playing an old
tune, is listening very carefully.  You have to understand the
structures, the changes, the parts, the relations.

Maybe it is no accident that the music you play is music of oppressed
peoples: hillbillies, forgotten African American string bands and
banjo songsters, Irish peasants, swing jazz from before the Civil
Rights era.

You have come far by listening, playing, by working with a few good
teachers, thorough late night jam sessions with friends.  By doing so, and by
virtue of the sense of justice I think you were born with, you are now
encountering some complex histories, using your music as a key which opens
a door, putting some injustices on vivid display.

To play the music honestly, and to live honestly, maybe we have to listen carefully
to the lives and histories from which they come.

College can give you the tools to listen to these histories.  And just
as listening to music contributes to your fine (and world-changing)
music (not peace-in-the-middle-east kinds of world changing, but
modest world chaning, reminding people of beauty and groove), so too
can college studies make you wiser and set you up -- in small ways,
since those are alwasy the best -- to make the world a better place too.

Maybe listening is the somewhat hidden theme of your college essay?

footnote: in his journals Thoreau mentions that there are times when
he is "out of his senses".  He was out in the woods but stuck in
his mind, not really hearing, not really seeing.  He says, "I am
wasting my time, I may as well go home".  He practiced something which
has been called "micro-visioning" in which he paid studied attention
to the finest details, of lichen on bark, of a particular ripple
moving across Walden Pond.  He was an "inspector of snowstorms".

Buddhist practice, some varieties of it, are very similar: just sit
there, wait for your thinking to (maybe eventually) quiet down, notice
that you are just a body, flesh blood and eyes, sitting in -this-
room.  This room, this place, this body, this tune.  Close attention
is an old and venerable human practice.




 — that this listening practice had
taught you some things about listening generally, and about listening
to people in particular.  (One of your mom’s books about dogs, maybe
one from the Monks of New Skete, mentions what they call one spiritual
benefit of having a dog.  “They teach you to listen till the end of
the sentence [being spoken to you].”  Learning music: same thing.



 -- draft 0

Reading your essay, and mulling it over, and reflecting on the
directions of your life, I’ve got this to offer. I am trying to avoid
seeing you through the lens of my own projects; you should be wary of
me, looking out for where I might be doing that in spite of my best
intentions.

A couple of years ago you wrote a startling essay.  I am not sure if
you gave it to me to read; more likely is that I found it on the
living room table and read it without first asking if I could.  I
think the broad topic was metacognition.  You wrote about how
listening to scratchy old fiddle tunes, listenting closely so you
could learn to play those tunes — that this listening practice had
taught you some things about listening generally, and about listening
to people in particular.  (One of your mom’s books about dogs, maybe
one from the Monks of New Skete, mentions what they call one spiritual
benefit of having a dog.  “They teach you to listen till the end of
the sentence [being spoken to you].”  Learning music: same thing.

One of your consistent traits (I’d call it a great virtue) is that
(and here I am thinking about your work with CORE, and not least of
when you took me to task about my trans colleague Natalie).  You try
to listen for the ethical and political and moral overtones in
situations.

Nigger in the Treetops, more vividly than most human creations, has
clear ethical, political and moral overtones.  Undertones.  I think
you hear, grasp and then recreate (making it new) the beauty of that
tune.  But since you listen well you are not deaf to the tune’s
complex history.  Our complex history.

According to Thoreau, most of us lead lives of quiet desperations.
Christians say we are all sinners.  The Buddha proclaimed that life is
suffering.  There is without a doubt a lot of being lost, a lot of
being unconnected in being human.  Especially now in the 21st century:
too many of us people, our appetites too big, our dogmas too strong,
our apprecitaion of simple unremarkable beauties oftne too fleeting.
This is what you are saying in your opening line?

You know how to listen.  This is a practice — just like Buddhist
practice: learning to pay attention.

Your essay, your interest in the racism of many old-time fiddlers,
your interest in the mostly hidden African American roots of the
music, your draw to (it might not be just a coincidence) the music of
several oppressed peoples (hillbillies, Irish peasants, African
American stringbands and pre-WWII, pre-Civil Rights era jazz) this
leads me to this summary:

You have a beautiful talent for paying attention, not only to the
intricacies of a tune, but to the complex interwoven forces at play in
our collective lives.  You are not blind to all of the injustice
around us.

You work hard, you listen well, and have had some fine teachers.

At a school like Hampshire you will have the time, the teachers, the
fellow students and the right setting to learn to listen deeply to
something related t the intricacies of our collective lives.  Through
your music you make the world a better place.  By acquiring



*----------------------------------------------------------------------------------------------------
* gbmPathway requests from hamid (31 aug 2015)

  minimize edges through nodes
  minimze edge crossing
  align nodes vertically and horizontally
  all processes in two rows at bottom


*----------------------------------------------------------------------------------------------------
* add cisbp to MotifDb: next up (25 aug 2015)

  [note: latest matrices available from http://cisbp-rna.ccbr.utoronto.ca/bulk_archive.php,
   downloaded entiredata_2015_08_26_2-15_pm.zip]
  cd ~/s/bioc/trunk/Rpacks/MotifDb/inst/scripts/import/cisbp/
  source("test.R")
  runTests()
  with dataDir <- "/Users/pshannon/s/data/public/TFBS";
    ~1184 matrices can be found in dataDir/cisbp/pwms
    metadata has been extracted via RMySQL query in ~/s/data/public/TFBS/cisbp/go.R
    from a database built by ~/s/data/public/TFBS/cisbp/load.sh
       (see mysql tips below in "* motifdb, finally finish adding cisdb (24 aug 2015)")

  next up:  recall how to build a proper MotifDb matrix/metadata set
            figure out if the 8 columns of metadata extracted above are adequate

               ma_id        tf_id   motif_id      species TF_Name     PMID Family_Name               DBID
      MA0116870_1.02 T025973_1.02 M0316_1.02 Mus_musculus   Nfil3 25215497        bZIP ENSMUSP00000065363

   --- the standard columns
     library(MotifDb)
     mdb <- MotifDb
     colnames(values(MotifDb))
     colnames (values (MotifDb))
       [1] "providerName"    "providerId"      "dataSource"      "geneSymbol"
       [5] "geneId"          "geneIdType"      "proteinId"       "proteinIdType"
       [9] "organism"        "sequenceCount"   "bindingSequence" "bindingDomain"
      [13] "tfFamily"        "experimentType"  "pubmedID"

   --- compare with one of the 4 human motifs for NFIL3
     t(as.data.frame(md[grep("nfil3", md$geneSymbol, ignore.case=T)[3],]))
                       [,1]                    possible mappings
       providerName    "NFIL3"                  MA0116870_1.02
       providerId      "MA0025.1"               M0316_1.02
       dataSource      "JASPAR_2014"            csipb_1.02
       geneSymbol      "NFIL3"                  Nfil3
       geneId          "4783"                   calculate, or present in db?
       geneIdType      "ENTREZ"                 entrez
       proteinId       "NP_005375"              ENSMUSP00000065363
       proteinIdType   "REFSEQ"                 whatever calculated from or present in db
       organism        "Hsapiens"               Mus_musculus -> Mmusculus
       sequenceCount   "23"                     NA
       bindingSequence NA                       NA
       bindingDomain   "Zipper-Type"            NA
       tfFamily        "Leucine Zipper"         bZip
       experimentType  "SELEX"                  NA
       pubmedID        "1620116"                25215497



    --- how a MotifDb dataset constructed?
      f <- system.file(package="MotifDb", "extdata", "hPDI.RData")
      file.exists(f)
      print(load(f))
      length(matrices); nrow(tbl.md)   # 437  437
      class(matrices); class(tbl.md)   # "list" "data.frame"

    --- create a tiny 1-entry csipb dataset, add to MotifDb, make sure it works
     tbl.md <-  data.frame(providerName="MA0116870_1.02",
                           providerId="M0316_1.02",
                           dataSource="csipb_1.02",
                           geneSymbol="Nfil3",
                           geneId=NA,
                           geneIdType=NA,
                           proteinId="ENSMUSP00000065363",
                           proteinIdType="ensembl",
                           organism="Mmusculus",
                           sequenceCount=NA,
                           bindingSequence=NA,
                           bindingDomain=NA,
                           tfFamily="bZip",
                           experimentType=NA,
                           pubmedID="25215497",
                           stringsAsFactors=FALSE)

     # expanded so that this now extracts 874 matrices with metadata from the 5099 non-empty
     # matrices in the download directory, ~/s/data/public/TFBS/cisbp/pwms
     # 1460 matrices had only colnames, but no data
     # 5099-874 parsable matrices had bad metadata.

   source("test.R"); run.tests()

*----------------------------------------------------------------------------------------------------
* install python pip on lopez as sttrweb

  cd /home/sttrweb/lopez/oncoscape/v1.4.60/utils
  curl -O  https://bootstrap.pypa.io/get-pip.py    # 1.4M

  python get-pip.py --user  --verbose
     204 Aug 24 16:51 /home/sttrweb/.local/bin/pip
  thus creates:  ~/.local/bin/pip

  installs pip to /home/sttrweb/.local/lib/python2.7/site-packages

  check:

   >>> import sys
   >>> sys.path


*----------------------------------------------------------------------------------------------------
* install python websockets on lopez

  pip must be installed (see above)


  https://pypi.python.org/pypi/websocket-client/
  python pip --user websocket-client
  pip install websocket-client


*----------------------------------------------------------------------------------------------------
* motifdb, finally finish adding cisdb (24 aug 2015)

  cd ~/s/bioc/trunk/Rpacks/MotifDb/inst/scripts/import/cisbp

  cisbp, 8 cols of metadata now figured out (29 may 2015)

  --- before resuming test, start mysql
     mysql # if client can connect, no need to
        sudo /usr/local/mysql/support-files/mysql.server start
    library (RMySQL)
    db <- dbConnect(MySQL (), dbname='cisbp')

  --- found cisdb database missing
   cd ~/s/data/public/TFBS/cisbp/
   make sure version 1.02 is still current
   http://cisbp.ccbr.utoronto.ca/bulk.php - yep.
    wc -l load.sh # 25


  --- configure mysql, create database

    bash> mysql -u root
    mysql> create user 'pshannon'@'localhost';
    mysql> grant all privileges on *.* to 'pshannon'@'localhost';
    quite
    bash> mysql -u pshannon
    mysql> create database cisbp;


  --- load some tables (are these enough?)
    based upon the sql query in ~/s/data/public/TFBS/cisbp/go.R

      select <- "select ma.ma_id, ma.tf_id, ma.motif_id, ma.species, tf.TF_Name, ms.PMID, fa.Family_Name, pr.DBID"
      from <- "from motif_all as ma, tfs as tf, motifs as mo, motif_sources as ms, tf_families as fa, proteins as pr"
      where <- paste(matrix.selector,
               "and ma.Motif_ID=mo.Motif_ID",
               "and ma.TF_ID = tf.TF_ID",
               "and ma.Evidence = 'D'",
               "and mo.MSource_ID = ms.MSource_ID",
               "and tf.Family_ID = fa.Family_ID",
               "and pr.TF_ID = tf.TF_ID"
               )

      query <- paste(select, from, where, sep=" ")
      tbl <- dbGetQuery(db, query)
      print(dim(tbl))
      print(dim(unique(tbl[, 1:8])))   # [1] 15694     8
      print(dim(unique(tbl[, 1:7])))   # [1]  6559    7
      dups <- which(duplicated(tbl[, 1:7]))
      if(length(dups) > 0)
          tbl <- tbl[-dups,]
      dim(tbl)   # 1143 x 7
      save(tbl, file="cisbp-metadata-6559-matrices.Rdata")

       > head(tbl)
                 ma_id        tf_id   motif_id                  species TF_Name     PMID Family_Name    DBID
      1 MA0000004_1.02 T000176_1.02 M0001_1.02 Saccharomyces_cerevisiae    ABF1 19111667        ABF1 YKL112W
      2 MA0000139_1.02 T000388_1.02 M0003_1.02 Saccharomyces_cerevisiae    AFT2 19111667         AFT YPL202C
      3 MA0036641_1.02 T005322_1.02 M0091_1.02 Saccharomyces_cerevisiae    MBP1 19111667       APSES YDL056W
      4 MA0036646_1.02 T005323_1.02 M0093_1.02 Saccharomyces_cerevisiae    SWI4 19111667       APSES YER111C
      5 MA0036650_1.02 T005324_1.02 M0094_1.02 Saccharomyces_cerevisiae    XBP1 19111667       APSES YIL101C
      6 MA0036656_1.02 T005325_1.02 M0096_1.02 Saccharomyces_cerevisiae    PHD1 19111667       APSES YKL043W

*----------------------------------------------------------------------------------------------------
* crontab tips, cron tips

  --- run job every 5 minutes
    */5 * * * * /usr/bin/python ~/oncodev/hbolouri/oncoDev14/utils/monitorWebAppsByLoading.py

  --- register with cron
    crontab crontab.pshannon

  --- list
    crontab -l
       */5 * * * * /usr/bin/python ~/oncodev/hbolouri/oncoDev14/utils/monitorWebAppsByLoading.py

  --- remove
     crontab -r

*----------------------------------------------------------------------------------------------------
* python email notifier, oncoscape/chinook app monitor via download of landing page (21 aug 2015)

  cd ~/oncodev/hbolouri/oncoDev14/utils/

  sudo pip install requests

import requests
r = requests.get('http://google.com')
len(r.text) # 18583


url = "http://chinookDemo1.sttrcancer.org"
len(requests.get(url).text)   # 4716

curl http://oncoscape.sttrcancer.org
curl http://oncotest1.sttrcancer.org
curl http://chinookdemo4.sttrcancer.org/
curl http://chinookdemo4.sttrcancer.org
curl http://chinookdemo1.sttrcancer.org
curl http://chinookdemo2.sttrcancer.org

   -------- file
      import requests
      import smtplib
      *---------------------------------------------------------------------------------------------------
      def mail(recipient, subject, message, sendersEmailAccount, sendersPassword):

          try:
              print 0
              s=smtplib.SMTP()
              s.connect("smtp.gmail.com", 587)
              s.starttls()
              s.ehlo()
              s.login(sendersEmailAccount, sendersPassword)
              fromAndTo = sendersEmailAccount
              msg = "Subject: %s\n\n%s" % (subject, message)
              s.sendmail(fromAndTo, recipient, msg)
          except Exception,R:
              return R

      *---------------------------------------------------------------------------------------------------
      def runTests(recipient, password):

        urls = ["http://oncoscape.sttrcancer.org",
                "http://oncotest1.sttrcancer.org",
                "http://chinookdemo4.sttrcancer.org",
                "http://bogus.boo.tv",
                "http://chinookdemo4.sttrcancer.org",
                "http://chinookdemo1.sttrcancer.org",
                "http://chinookdemo2.sttrcancer.org"];

        for url in urls:
           try:
               print "%50s: %6d" % (url, len(requests.get(url).text))
           except requests.exceptions.RequestException as e:
               title = "%s error" % url
               message = title
               mail(recipient,
                    title, message, recipient, password)

      *---------------------------------------------------------------------------------------------------
      f = open("/Users/pshannon/.gmail-identity")
      text = f.read()
      [user, password, junk] = text.split("\n")
      runTests(user, password)


*----------------------------------------------------------------------------------------------------
* cleveland high school, volunteering (21 aug 2015)

   -- email (17 aug 2015)  cmbrown@seattleschools.org

    Dear Catherine,

    I just left a voice mail inquiring whether there might be some way that I could help out at
    Cleveland during the coming school year.

   I am a software engineer by profession, a bioinformatician, sometimes sort of a computational
   biologist, and frequently a molecular map maker in my work at the Hutch (and previously at the
   Institute for Systems Biology).  I have a flexible schedule, and my current research group (STTR:
   http://www.sttrcancer.org/en.html) probably has some funding for high school interns next summer.

   Two biographical items might be worth mentioning.

   In my twenties, as a college drop out, I worked as a carpenter.  I learned the trade from a
   semi-retired contractor whose grandparents had been slaves, and whose kids went to Harvard.  A
   few years later, and for two years. I taught basic carpentry to unemployed adults, who were often
   young men of color just out of jail.

   Over the last two summers I have mentored a couple of students.  These were young men of promise,
   but in most cases - as sons of UW faculty and surgeons - their prospects were already bright.  After
   Ferguson and after Charleston, it occurred to me: maybe I could be useful to kids whose prospects
    weren’t so intrinsically bright?

   Please let me know if there is some place I could fit in and help out at Cleveland.  I would hope
   to be guided by Cleveland teachers in anything we attempted.  I have great respect for
   experienced teachers, and I suspect that an inexpert “helper” like me, working on his own, would
   not be actually much help at all.


*----------------------------------------------------------------------------------------------------
* restart chinookdemo1, chinookdemo2 (21 aug 2015)

  --- first, get in running on laptop
    cd ~/github/chinook/R-server

       R CMD install Chinook/
       R CMD install ModelMPG/
       R -f runChinook.R
       R -f runModelMPG.R


   --- now do the same on lopez.  get the code
     ssh lopez
     sudo su - sttrweb
     emacs ~nw /home/sttrweb/lopez/github
     git clone https://github.com/oncoscape/chinook
     cd chinook/R-server
     source ~/lopez/oncoscape/v1.4.60/.setupR
     cat  ~/lopez/oncoscape/v1.4.60/.setupR
        PATH=/app/R/3.2.1/bin:$PATH
        export R_LIBS=/hfindome/sttrweb/lopez/oncoscape/v1.4.60/Rlibs/3.2
          # to install packages into $R_LIBS, the full path has to be specified:
          #   R CMD INSTALL -l /home/sttrweb/lopez/oncoscape/v1.4.60/Rlibs/x86_64-unknown-linux-gnu-library/3.2/ .

   --- install both packages

*----------------------------------------------------------------------------------------------------
* python cgi example, post, form (20 aug 2015)

  cd ~/s/examples/python/simpleCgi/
  create index.cgi in subdirectory cgi-bin
  make sure that the index.cgi python script is chmod 755
  start the simple server:

    python -m CGIHTTPServer 8000

  browse to:  http://localhost:8000/cgi-bin/index.cgi
  --- index.cgi python script:
     import cgi
     import cgitb; cgitb.enable()  # for troubleshooting

     print "Content-type: text/html"
     print

     print """
     <html>

     <head><title>Sample CGI Script</title></head>

     <body>

       <h3> Sample CGI Script </h3>
     """

     form = cgi.FieldStorage()
     message = form.getvalue("message", "(no message)")

     print """

       <p>Previous message: %s</p>

       <p>form

       <form method="post" action="index.cgi">
         <p>message: <input type="text" name="message"/></p>
       </form>

     </body>

     </html>
     """ % message





*----------------------------------------------------------------------------------------------------
* reverse engineer dgidb search, for use in an iframe (20 aug 2015)


  <form action="interaction_search_results" class="form-horisontal" enctype="multipart/form-data" method="post">
  a <div class="control-group"> of which there are many

*----------------------------------------------------------------------------------------------------
* egfr: colin's suggestions (19 aug 2015)

  I don’t see BRAF or ARAF in the pathway.  Would be great to include gene names PIK3CA and PIK3R1 too.

*----------------------------------------------------------------------------------------------------
* good egfr-related pathway map (labled mitgoen-activated protien kinse, MAPK) (19 aug 2015)

  https://en.wikipedia.org/wiki/Raf_kinase#/media/File:MAPKpathway.jpg

*----------------------------------------------------------------------------------------------------
* cyjs selection, examples

   cwMarkers.$('[id="TCGA.02.0080"]')

*----------------------------------------------------------------------------------------------------
* revivify hamid's gbmPathways tab for oncoDev14 (29 aug 2015)

  cyjs tips: shrink canvas size   (hamid points out that the edge decorations are too small, fonts are 48px,
                                   a consequence of nodes being laid out on a huge canvas)

  with three nodes selected:

   JSON.stringify(cy.filter("node:selected").map(function(n){return {id: n.id(), x: n.position("x") + 500, y: n.position("y") + 500}}))

       "[{"id":"GAB1","x":1207,"y":-421},{"id":"IRS1","x":1040,"y":-587},{"id":"SRC","x":1028,"y":-271}]"

  ---  or for immediate reuse in the console, try this:

    get the current positions, add 500 to them:
       locs = cy.filter("node:selected").map(function(n){return {id: n.id(), x: n.position("x") + 500, y: n.position("y") + 500}})

    now apply those new positions:
       locs.map(function(e){var tag = "#" + e.id; cy.$(tag).position({x:e.x, y:e.y})})

  --- now try shrinking everything down, adjusting to accomodate ids with whitespace
     locs = cy.nodes().map(function(n){return {id: n.id(), x: n.position("x")/6, y: n.position("y")/6}})
     locs.map(function(e){var tag = "[id='" + e.id + "']"; cy.$(tag).position({x:e.x, y:e.y})})


  --- actual steps take with hamid's return email.  pasted this into

      ~/oncodev/hbolouri/dataPackages/networks/gbmPathways/prep/layoutHamid.json


    // two lines suitable for pasting into the javascript console,
    // created this way
    // JSON.stringify(cyGbm.nodes().map(function(n){return {id: n.id(), x: n.position("x"), y: n.position("
    //
    locs = [{"id":"ABCA1","x":-25.919956220703476,"y":829.6528564591732},{"id":"AKT family","x":-124.896714....
    locs.map(function(node){var tab="[id='" + node.id + "']"; cy.$(tab).position({x: node.x, y: node.y})});


   --- save freshly loaded layout in cyMarkers, to be restored on demand
     locs = cwMarkers.nodes().map(function(n){return {id: n.id(), x: n.position("x"), y: n.position("y")}});
     locs.map(function(node){var tab="[id='" + node.id + "']"; cwMarkers.$(tab).position({x: node.x, y: node.y})});




*----------------------------------------------------------------------------------------------------
* revivify hamid's gbmPathways tab for oncoDev14 (18 aug 2015)

  cd ~/oncodev/hbolouri/dataPackages/networks/gbmPathways/priorVersions
       309393 Nov 11  2014 curatedGBMpathways.js
         9761 Mar 27  2014 network.tsv

  [final state]:
     cd ~/oncodev/hbolouri/dataPackages/networks/gbmPathways/priorVersions
     bash> make
        writing interactions.tsv, 202 rows, 3 cols: a,b,type
        writing    nodeTypes.tsv, 169 rows, 2 cols: node,type


    the js file is loaded into oncoDev12 in
       ~/oncodev/hbolouri/oncoDev12/Oncoscape/inst/scripts/gbmPathways/widget.html:

      include(../gbmPathways/curatedGBMpathways.js)

   --- 210 edges in curatedGBMpathways.js
   --- 202 edges in networks.tsv

   but a closer look shows that the json file has but 201 edges:
     ~/oncodev/hbolouri/dataPackages/networks/gbmPathways/priorVersions/go.R

       library(jsonlite)
       f <- "curatedGBMpathways.adaptedForReadingInR"
       x <- fromJSON(f)
       names(x) #  "format_version", "generated_by", "target_cytoscapejs_version", "data", "elements"
       names(x$elements) # "nodes" "edges"
       dim(x$elements$nodes$data)  # [1] 156  12
       tbl <- x$elements$nodes$data
       colnames(tbl)
         #  [1] "id"            "mut"           "SUID"          "cnv"           "score"         "label"
         #  [7] "selected"      "canonicalName" "name"          "geneSymbol"    "nodeType"      "shared_name"
       dim(x$elements$edges$data)  # [1] 201  13
       tbl.edges <- x$elements$edges$data
       colnames(tbl.edges)
         #  [1] "id"                 "source"             "target"             "pmid"
         #  [5] "selected"           "canonicalName"      "edgeType"           "SUID"
         #  [9] "name"               "interaction"        "shared_interaction" "shared_name"
         # [13] "edgeDetail"


  --- first attempt at construction: build from tsv file

*----------------------------------------------------------------------------------------------------
* oncoplex: egfr signaling map (15 aug 2015)

   cd ../../oncodev/hbolouri/dataPackages/networks/egfr/cellSignaling
   R> reload(); make();

  --- good beginning map
   http://www.cellsignal.com/contents/science-pathway-research-tyrosine-kinase/erbb-her-signaling-pathway/pathways-erbb

   Characterization of the EGFR interactome reveals associated protein complex networks and intracellular receptor dynamics.
   PMID: 23956138

   created intersection of oncoplex genes and this geneset:

     load("~/s/examples/clustering/ttest.msigdb/msigdb.RData")
     reactome.egfr.genes <- genesets[["REACTOME_SIGNALING_BY_EGFR_IN_CANCER"]]


*----------------------------------------------------------------------------------------------------
 1) egfr signaling kras braf myc, akp1, pik3ca

 2) mtor pathway, lots of approved inhibitorsnf1 nf2

 3) cdk4,6: rb1  p16, cyclin , cdk4/6 inhibitors now approved.

 4) met


*----------------------------------------------------------------------------------------------------
*----------------------------------------------------------------------------------------------------
*----------------------------------------------------------------------------------------------------
*----------------------------------------------------------------------------------------------------
*----------------------------------------------------------------------------------------------------
*----------------------------------------------------------------------------------------------------
*----------------------------------------------------------------------------------------------------
*----------------------------------------------------------------------------------------------------
*----------------------------------------------------------------------------------------------------
* hallmarks of cancer, hoc, pi3k-akt (14 aug 2015)

*----------------------------------------------------------------------------------------------------
* UWlung and pathways (14 aug 2015)

  cd ~/oncodev/hbolouri/dataPackages/networks/UWlungHoC/prep/

  get actually implicated genes from current oncoplex app:
     JSON.stringify(cwMarkers.filter("node:selected").map(function(e){return e.data("id")}))

  edited this into ~/oncodev/hbolouri/dataPackages/networks/UWlungHoC/prep/implicatedGenes.txt   (62 genes)

  kegg search pathways: http://www.genome.jp/kegg/tool/map_pathway1.html

     ko05200 Pathways in cancer (26)
     ko04151 PI3K-Akt signaling pathway (22)
     ko05206 MicroRNAs in cancer (21)
     ...






*----------------------------------------------------------------------------------------------------
* dgidb get api (13 aug 2015)

  http://dgidb.genome.wustl.edu/api


*----------------------------------------------------------------------------------------------------
* get trimmed down and more effective interactions table from dgidb postgres database, cont. (13 aug 2015)

  select id from genes where name='TYR';         6c36cedd-8fb5-4bb9-b767-b0ba09fb7e8d
  select gene_claim_id from gene_claims_genes where gene_id='6c36cedd-8fb5-4bb9-b767-b0ba09fb7e8d';   6 rows

   --- simple inner join example, http://www.w3schools.com/sql/sql_join.asp

   select gene_claims_genes.gene_claim_id, genes.name from genes inner join gene_claims_genes on gene_claims_genes.gene_id=genes.id;
   SELECT gene_claims_genes.gene_claim_id, genes.name FROM genes INNER JOIN gene_claims_genes ON gene_claims_genes.gene_id=genes.id AND genes.name='TYR';

   save as x.sql
   \i x.sql;

   --- select * from V1;
                  gene_claim_id             |            drug_claim_id             | known_action_type |                  id
      --------------------------------------+--------------------------------------+-------------------+--------------------------------------
       445aa8ef-9a63-4262-844d-e1537b8c41c6 | fe3f2ef7-de78-4fda-9e3c-f8b85d6f2e2a | inhibitor         | 4e930939-3b1e-48d2-8be5-6b2a4b559288
       445aa8ef-9a63-4262-844d-e1537b8c41c6 | c7a0c2d8-84bd-4853-b04a-0a71192efc13 | inhibitor         | 2a75c6b6-586b-456e-8e7d-b822b9d0b2e5

    how to get from   c7a0c2d8-84bd-4853-b04a-0a71192efc13 to drug_claim_types_drug_claims.drug_claim_type
      select * from drug_claim_types;
                        id                  |      type
      --------------------------------------+----------------
       0e212a04-adaa-4fca-af4d-4607934426bc | antineoplastic
       0a0bd658-cb61-4b94-a837-b6d919788d0b | other

    egrep '(c7a0c2d8-84bd-4853-b04a-0a71192efc13|stdin)' data.sql
     COPY drug_claims (id, name, description, nomenclature, source_id, primary_name) FROM stdin;
         c7a0c2d8-84bd-4853-b04a-0a71192efc13	6827	\N	GuideToPharmacology Ligand Identifier	8d26dfa9-ca1a-48d3-98c5-9e17afdd9f28	MEQUINOL
     COPY drug_claim_aliases (id, drug_claim_id, alias, description, nomenclature) FROM stdin;
         b68539b5-e34e-4643-8c99-b0c0901605aa	c7a0c2d8-84bd-4853-b04a-0a71192efc13	178103433	\N	PubChem Substance ID
     COPY interaction_claims (id, drug_claim_id, gene_claim_id, interaction_type, description, source_id, known_action_type) FROM stdin;
         2a75c6b6-586b-456e-8e7d-b822b9d0b2e5	c7a0c2d8-84bd-4853-b04a-0a71192efc13	445aa8ef-9a63-4262-844d-e1537b8c41c6	\N	\N	8d26dfa9-ca1a-48d3-98c5-9e17afdd9f28	inhibitor




*----------------------------------------------------------------------------------------------------
* get trimmed down and more effective interactions table from dgidb postgres database (13 aug 2015)

 drug_claim_aliases
 drug_claim_attributes
 drug_claim_types
 drug_claim_types_drug_claims
 drug_claims
 drug_claims_drugs
 drugs
 gene_claim_aliases
 gene_claim_attributes
 gene_claim_categories
 gene_claim_categories_gene_claims
 gene_claims
 gene_claims_genes
 gene_gene_interaction_claim_attributes
 gene_gene_interaction_claims
 genes
 interaction_claim_attributes
 interaction_claim_types
 interaction_claim_types_interaction_claims
 interaction_claims
 schema_migrations
 source_trust_levels
 source_types
 sources

  --- test case: tyr
    mutant in patient 067

   *  TABLE genes:  select * from genes where name='TYR';
                       id                  | name |                long_name
     --------------------------------------+------+-----------------------------------------
      6c36cedd-8fb5-4bb9-b767-b0ba09fb7e8d | TYR  | tyrosinase (oculocutaneous albinism IA)

   *  TABLE gene_claims_gene

      select * from gene_claims_genes where gene_id='6c36cedd-8fb5-4bb9-b767-b0ba09fb7e8d';
                     gene_id                |            gene_claim_id
      --------------------------------------+--------------------------------------
       6c36cedd-8fb5-4bb9-b767-b0ba09fb7e8d | df0fc146-4e84-4970-8cd6-b0eaf4d9d2d8
       6c36cedd-8fb5-4bb9-b767-b0ba09fb7e8d | 4029dd52-ecc7-460e-bab8-80cb1f7cdbdd
       6c36cedd-8fb5-4bb9-b767-b0ba09fb7e8d | 6019ab93-4f72-4762-91e4-905fd6bc947d
       6c36cedd-8fb5-4bb9-b767-b0ba09fb7e8d | a306ff25-b4c6-45f8-a67c-a82012b4b487
       6c36cedd-8fb5-4bb9-b767-b0ba09fb7e8d | d6269aaf-75f0-4d27-b59b-3a3d78cfeb57
       6c36cedd-8fb5-4bb9-b767-b0ba09fb7e8d | 445aa8ef-9a63-4262-844d-e1537b8c41c6




*----------------------------------------------------------------------------------------------------
* access dgidb tables in postgres as pshannon, prepare for R access (13 aug 2015)

   --- explore as postgres user, password = sttr
     sudo date   # in order to avoid confusing password prompt in the next command. sudo pw?  postgres pw?
     sudo -u postgres /Library/PostgreSQL/9.4/bin/psql dgidb

   --- reset the pshannon password
     alter user pshannon with password 'tril0byt';

   --- try that out
     sudo date
     sudo -u pshannon /Library/PostgreSQL/9.4/bin/psql dgidb prompts for password

   --- better yet, with no sudo

     /Library/PostgreSQL/9.4/bin/psql -U pshannon -d dgidb

     \dt   # sows 24 dgidb tables
      select * from genes limit 3;
                        id                  |     name      |                   long_name
      --------------------------------------+---------------+------------------------------------------------
       9cc08f1c-9d82-4242-a9ae-1ddfaf7905d8 | IRX2          | iroquois homeobox 2
       3d7cbdca-3623-483d-907f-e81a8725b263 | LOC643792     | contactin associated protein-like 3 pseudogene
       a5bbe4dc-743b-430a-b2c5-d3de3f9027d1 | DKFZP434E1119 | uncharacterized DKFZp434E1119


   --- specify dgidb database on the command line
     sudo -u pshannon /Library/PostgreSQL/9.4/bin/psql dgidb   # prompts for password, old animal

   --- list tables
     \dt

*----------------------------------------------------------------------------------------------------
* install postgres on wombat for dgi (13 aug 2015)

 9.4.4-3 in a dmg
  installs to /Library/PostgreSQL/
  superuser: postgres   pw: sttr
  server listens on port 5433


  --- is it running?
    ps aux | grep postgres

  --- stackoverflow suggestions

    alias postgres.server="sudo -u postgres pg_ctl -D /Library/PostgreSQL/9.2/data"

   /Library/PostgreSQL/9.4/bin/initdb

  --- password not known or not correct
   sudo su postgres -c /Library/PostgreSQL/9.4/bin/psql
   ALTER USER postgres with password 'sttr';

   try it out:    /Library/PostgreSQL/9.4/bin/psql -U postgres   prompts for password, sttr does the trick

   ---- restore the dump
     cd ~/s/data/public/drug-gene-interactions/dgidb
     create database dgidb;
     get schema file:
        https://raw.githubusercontent.com/genome/dgi-db/master/db/structure.sql

   /Library/PostgreSQL/9.4/bin/psql -U postgres dgidb < structure.sql
   /Library/PostgreSQL/9.4/bin/psql -U postgres dgidb < data.sql

   --- simple postgres administration
      sudo su postgres -c /Library/PostgreSQL/9.4/bin/psql
      \list     # shows all dtabases
      \connect dgidb
      \dt
                                 List of relations
       Schema |                    Name                    | Type  |  Owner
      --------+--------------------------------------------+-------+----------
       public | drug_claim_aliases                         | table | postgres
       public | drug_claim_attributes                      | table | postgres
       public | drug_claim_types                           | table | postgres
       public | drug_claim_types_drug_claims               | table | postgres
       public | drug_claims                                | table | postgres
       public | drug_claims_drugs                          | table | postgres
       public | drugs                                      | table | postgres
       public | gene_claim_aliases                         | table | postgres
       public | gene_claim_attributes                      | table | postgres
       public | gene_claim_categories                      | table | postgres
       public | gene_claim_categories_gene_claims          | table | postgres
       public | gene_claims                                | table | postgres
       public | gene_claims_genes                          | table | postgres
       public | gene_gene_interaction_claim_attributes     | table | postgres
       public | gene_gene_interaction_claims               | table | postgres
       public | genes                                      | table | postgres
       public | interaction_claim_attributes               | table | postgres
       public | interaction_claim_types                    | table | postgres
       public | interaction_claim_types_interaction_claims | table | postgres
       public | interaction_claims                         | table | postgres

       \du
                                   List of roles
       Role name |                   Attributes                   | Member of
      -----------+------------------------------------------------+-----------
       labkey    | Superuser, Create role, Create DB              | {}
       postgres  | Superuser, Create role, Create DB, Replication | {}
       pshannon  | Superuser, Create role, Create DB              | {}


   ---- connect to it with R
      http://www.r-bloggers.com/r-and-postgresql-using-rpostgresql-and-sqldf/


   psql -d public

*----------------------------------------------------------------------------------------------------
* dgi, drug/gene interactions (12 aug 2015)

  --- for 24 jul demo
    wsDatasets.getDrugGeneInteractions()

    file <- system.file(package="DGI", "extdata", "tbl.dgi.RData")
    load(file, envir=.GlobalEnv);
    dim(tbl.dgi) 35361     5

    tbl.sub <- unique(subset(tbl.dgi, gene %in% genes))
    genes.out <- unique(tbl.sub[,1])
    payload <- list(colnames=colnames(tbl.sub), tbl=as.matrix(tbl.sub))
    return.msg <- list(cmd=msg$callback, status="success", callback="", payload=payload)


 --- refine the table, keeping only cancer-related drugs?  finding links to detail?  from meeting:

   a) add linkout column.  when clicked, a popup window displays the source database's full info
   b) add "date acquired" column
   c) sort and filter in all columns
   d) look for a good shared (simple) schema, include "drug class" if possible
   e) add more of the six sources David suggested


  --- need more information that that proficvide in this simple 5-column table

   look around in http://dgidb.genome.wustl.edu/downloads

   http://dgidb.genome.wustl.edu/downloads/druggable_gene_tsvs.tar.gz
   cd ~/s/data/public/drug-gene-interactions/dgidb


   tar tf druggable_gene_tsvs.tar
      BaderLabWASHU.tsv
      ./._CancerCommons_WashU_INTERACTIONS.tsv
      CancerCommons_WashU_INTERACTIONS.tsv
      ClearityFoundationClinicalTrials_WashU_INTERACTIONS.tsv
      ./._ClearityFoundation_WashU_INTERACTIONS.tsv
      ClearityFoundation_WashU_INTERACTIONS.tsv
      DrugBank_WashU_DRUGS.tsv
      DrugBank_WashU_INTERACTIONS.tsv
      DrugBank_WashU_TARGETS.tsv
      Ensembl_WashU_TARGETS.tsv
      Entrez_WashU_TARGETS.tsv
      GO_WashU_TARGETS.tsv
      HopkinsGroom_WashU_TARGETS.tsv
      MyCancerGenomeClinicalTrials_WashU_INTERACTIONS.tsv
      ./._MyCancerGenome_WashU_INTERACTIONS.tsv
      MyCancerGenome_WashU_INTERACTIONS.tsv
      RussLampel_WashU_TARGETS.tsv
      ./._TALC_WashU_INTERACTIONS.tsv
      TALC_WashU_INTERACTIONS.tsv
      TTD_WashU_INTERACTIONS.tsv
      dGene_WashU_TARGETS.tsv

*----------------------------------------------------------------------------------------------------
* simplify graph (igraph, R)

   http://blog.revolutionanalytics.com/2015/08/contracting-and-simplifying-a-network-graph.html

*----------------------------------------------------------------------------------------------------
* chrome tips

  -- create a log file

    start chrome from the command line:
       /Applications/Google\ Chrome.app/Contents/MacOS/Google\ Chrome --enable-logging --v=1

    find the log:

       ~/Library/Application Support/Google/Chrome/chrome_debug.log

*----------------------------------------------------------------------------------------------------
* oncoscape timings (12 aug 2015)
                                               wombat                    lopez 4G             lopez 8G
                                         user  system elapsed      user  system elapsed      user   system  elapsed
    system.time(library(TCGAbrain))      3.023   0.083   3.447      4.317   0.121   5.514   4.246    0.104   4.751
    system.time(dz <- TCGAbrain())      22.509   0.425  24.252 	   31.748   1.134  36.454  30.822    0.666  32.403

   about 50% longer


  --- load networks, once data package is loaded (on wombat, my laptop)
    cd ~/oncodev/hbolouri/oncoDev14/Oncoscape/inst/scripts/eric/
    make
     OncoDev14 loading:         datasets[['DEMOdz']] <- DEMOdz()    0.38 seconds
     OncoDev14 loading:       datasets[['TCGAgbm']] <- TCGAgbm()   15.93 seconds
     OncoDev14 loading:   datasets[['TCGAbrain']] <- TCGAbrain()   23.81 seconds

   with TCGAgbm already loaded, network display takes about 5 seconds
   with TCGAbrain already loaded, network display takes about 23 seconds


  --- graph size and transmission times:
    TCGAgbm is 1254650, transmits on laptop in about 5 seconds.   879 nodes, 4204 edges
    TCGA brain is  4990458, 323 seconds, 1376 nodes, 10601 edges



*----------------------------------------------------------------------------------------------------
* jquery tip, dialog dynamic dialog, radio buttons

  var content = "<form action=''>";
  var borderColors =  $.unique(cwMarkers.nodes("node:selected").map(function(node){return node.style("border-color")}));
  for(i=0; i < borderColors.length; i++){
     var color = borderColors[i];
     var e = "<input type='checkbox' name='" + color + "' value='" + color + "'> " + color + "<br>";
     content = content + e
     }
  content = content + "</form>";
  var d =  $('<div/>').html(content).dialog();


*----------------------------------------------------------------------------------------------------
* jquery tip, simple dialog dynamic dialog

    x = $('<div />').html('hello there').dialog();

*----------------------------------------------------------------------------------------------------
* jquery tips, demo, dynamically add and remove tabs, with 'x' to delete (11 aug 2015)

   js console simple add of new tab to running oncoscape

   tabs = $("#oncoscapeTabs").tabs()
   tabTemplate = "<li><a href='#{href}'>#{label}</a> <span class='ui-icon ui-icon-close' role='presentation'>Remove Tab</span></li>"
   tabCounter = 4
   var label = "Tab " + tabCounter
   li = $(tabTemplate.replace(/#\{href\}/g, "#" + id).replace(/#\{label\}/g, label))
   tabContentHtml = "Tab " + tabCounter + " content.";
   tabs.find(".ui-tabs-nav").append(li);
   tabs.append("<div id='" + id + "'><p>" + tabContentHtml + "</p></div>");
   tabs.tabs("refresh");
   tabCounter++;

*----------------------------------------------------------------------------------------------------
* jquery tips, demo, dynamically add and remove tabs, with 'x' to delete


<!-- Revised from demo code on http://jqueryui.com/ -->
<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<title>jQuery UI Tabs - Simple manipulation</title>
<script type="text/javascript" src="http://ajax.googleapis.com/ajax/libs/jquery/1.11.1/jquery.min.js"></script>
<script type="text/javascript" src="http://ajax.googleapis.com/ajax/libs/jqueryui/1.10.4/jquery-ui.min.js"></script>
<link type="text/css" href="http://ajax.googleapis.com/ajax/libs/jqueryui/1.10.4/themes/smoothness/jquery-ui.css" rel="stylesheet" />
<!--from ww w . jav a2  s. co m-->
<style>
#dialog label, #dialog input { display:block; }
#dialog label { margin-top: 0.5em; }
#dialog input, #dialog textarea { width: 95%; }
#tabs { margin-top: 1em; }
#tabs li .ui-icon-close { float: left; margin: 0.4em 0.2em 0 0; cursor: pointer; }
#add_tab { cursor: pointer; }
</style>
<script>
$(function() {
var tabTitle = $( "#tab_title" ),
tabContent = $( "#tab_content" ),
tabTemplate = "<li><a href='#{href}'>#{label}</a> <span class='ui-icon ui-icon-close' role='presentation'>Remove Tab</span></li>",
tabCounter = 2;

var tabs = $( "#tabs" ).tabs();

// modal dialog init: custom buttons and a "close" callback resetting the form inside
var dialog = $( "#dialog" ).dialog({
autoOpen: false,
modal: true,
buttons: {
Add: function() {
addTab();
$( this ).dialog( "close" );
},
Cancel: function() {
$( this ).dialog( "close" );
}
},
close: function() {
form[ 0 ].reset();
}
});

// addTab form: calls addTab function on submit and closes the dialog
var form = dialog.find( "form" ).submit(function( event ) {
addTab();
dialog.dialog( "close" );
event.preventDefault();
});

// actual addTab function: adds new tab using the input from the form above
function addTab() {
var label = tabTitle.val() || "Tab " + tabCounter,
id = "tabs-" + tabCounter,
li = $( tabTemplate.replace( /#\{href\}/g, "#" + id ).replace( /#\{label\}/g, label ) ),
tabContentHtml = tabContent.val() || "Tab " + tabCounter + " content.";

tabs.find( ".ui-tabs-nav" ).append( li );
tabs.append( "<div id='" + id + "'><p>" + tabContentHtml + "</p></div>" );
tabs.tabs( "refresh" );
tabCounter++;
}

// addTab button: just opens the dialog
$( "#add_tab" )
.button()
.click(function() {
dialog.dialog( "open" );
});

// close icon: removing the tab on click
tabs.delegate( "span.ui-icon-close", "click", function() {
var panelId = $( this ).closest( "li" ).remove().attr( "aria-controls" );
$( "#" + panelId ).remove();
tabs.tabs( "refresh" );
});

tabs.bind( "keyup", function( event ) {
if ( event.altKey && event.keyCode === $.ui.keyCode.BACKSPACE ) {
var panelId = tabs.find( ".ui-tabs-active" ).remove().attr( "aria-controls" );
$( "#" + panelId ).remove();
tabs.tabs( "refresh" );
}
});
});
</script>
</head>
<body>

<div id="dialog" title="Tab data">
<form>
<fieldset class="ui-helper-reset">
<label for="tab_title">Title</label>
<input type="text" name="tab_title" id="tab_title" value="" class="ui-widget-content ui-corner-all" />
<label for="tab_content">Content</label>
<textarea name="tab_content" id="tab_content" class="ui-widget-content ui-corner-all"></textarea>
</fieldset>
</form>
</div>

<button id="add_tab">Add Tab</button>

<div id="tabs">
<ul>
<li><a href="#tabs-1">Nunc tincidunt</a> <span class="ui-icon ui-icon-close" role="presentation">Remove Tab</span></li>
</ul>
<div id="tabs-1">
<p>Proin elit arcu, rutrum commodo, vehicula tempus, commodo a, risus. Curabitur nec arcu. Donec sollicitudin mi sit amet mauris. Nam elementum quam ullamcorper ante. Etiam aliquet massa et lorem. Mauris dapibus lacus auctor risus. Aenean tempor ullamcorper leo. Vivamus sed magna quis ligula eleifend adipiscing. Duis orci. Aliquam sodales tortor vitae ipsum. Aliquam nulla. Duis aliquam molestie erat. Ut et mauris vel pede varius sollicitudin. Sed ut dolor nec orci tincidunt interdum. Phasellus ipsum. Nunc tristique tempus lectus.</p>
</div>
</div>

<div class="demo-description">
<p>Simple tabs adding and removing.</p>
</div>
</body>
</html>
*----------------------------------------------------------------------------------------------------
* jquery tips, dynamically add tabs

   http://stackoverflow.com/questions/14702631/in-jquery-ui-1-9-how-do-you-create-new-tabs-dynamically

   $(document).ready(function() {
       $("div#tabs").tabs();
       $("button#add-tab").click(function() {
           var num_tabs = $("div#tabs ul li").length + 1;
           $("div#tabs ul").append("<li><a href='#tab" + num_tabs + "'>#" + num_tabs + "</a></li>");
           $("div#tabs").append("<div id='tab" + num_tabs + "'>#" + num_tabs + "</div>");
           $("div#tabs").tabs("refresh");
           }); // click
       }); // ready

*----------------------------------------------------------------------------------------------------
* myra hird,  The Origins of Sociable Life: Evolution After Science Studies

  Myra J. Hird
  The Origins of Sociable Life: Evolution After Science Studies
  Hardcover (260 pages)

  ISBN	9780230202139
  Publication Date	June 2009
  Formats	Hardcover Ebook (PDF)
  Publisher	Palgrave Macmillan

  This ambitious, agenda-setting study considers the origins of sociable life from a
  microontological perspective. More specifically, it suggests ways of engaging with bacteria in
  other-than pathogen characterization. We know much more about living organisms "big-like-us" than
  we do about those organisms which originated life on Earth and sustain the biosphere through
  complex symbiotic and recycling relationships. This book details scientific research on bacterial
  capabilities such as perception, communication, community organization and symbiosis. It
  critically analyzes evolutionary theories about the development of the species (including
  neo-Darwinism, epigenetics and symbiogenesis). It also draws on bio-philosophical discussions of
  sexual difference, identity, environmentalism and ethics, providing a transdisciplinary framework
  with which to engage the social and natural sciences together to recognise bacterial liveliness in
  structuring social relations.


*----------------------------------------------------------------------------------------------------
* social ontologies

  http://www.ncbi.nlm.nih.gov/pmc/articles/PMC2606704/

  Neuroscientists study the brain to throw light on human capabilities, sometimes glossed as
  mind. Archaeologists study objects to understand past human collectivities, sometimes glossed as
  society. Both mind and society are abstract entities, somewhat hard to bring into contact due to
  their ghostliness. Rather than now concentrating on these two ghosts, mind and society, both
  neuroscientists and archaeologists are emphasizing material aspects of the brain in its body on
  the one hand and the physical properties of objects as they affect the body on the other. The
  triangle of brain–body–world is the point at which neuroscience and archaeology meet. What is
  needed to make this meeting most productive is a series of ideas that allow us to think about
  brains, bodies and material things in combination. In the first part of this article, I set out
  what I hope will be some bridging concepts between the two disciplines, before sketching out how
  these might be worked through in an empirical case

*----------------------------------------------------------------------------------------------------
* double calls in eric test


(index):5328 display dataset manifest for DEMOdz
(index):870 dataset 'DEMOdz'
(index):920 === requestDataSetSummary
(index):335 --- hub.send: 'getDataManifest' (server)
(index):5334  new mutobs target: datasetsStatusDiv
(index):5361 observing datasetsStatusDiv
(index):296 hub.dispatchMessage(displayDataManifest): 2
(index):837 ==== Module.datasets handleWindowResize
(index):839   window: 1227
(index):5342 datasetsStatusDiv status changed: manifest table displayed
(index):5350 dispalyDataSetManifest test complete, now calling loadDataSet

(index):621  tabsApp/code.js:activate
(index):629    skipping! - adjusting user data store table
(index):5368 testLoadDataSet: DEMOdz
(index):988 Module.datasets 'Use Dataset' button clicked, specifyCurrentDataset: DEMOdz
(index):335 --- hub.send: 'specifyCurrentDataset' (server)
(index):5375  new mutobs target: pcaStatusDiv
(index):5395 observing pcaStatusDiv
(index):621  tabsApp/code.js:activate
(index):629    skipping! - adjusting user data store table

(index):5342 datasetsStatusDiv status changed: manifest table displayed   # why does this get called again?
(index):5350 dispalyDataSetManifest test complete, now calling loadDataSet
(index):621  tabsApp/code.js:activate

*----------------------------------------------------------------------------------------------------
* mary douglas, genesis of discursive form, how institutions think (6 aug 2015)

  mentioned in conlusion to delanda's 1000 years of nonlinear history, to explain
  why people think (the ontologies they hold?) as they do

*----------------------------------------------------------------------------------------------------
* leo's credit union info (6 aug 2015)
  account login: 251242, pw: last 4 of social  leo.paul with famous guitar snp?
  new login: leo.shannon

*----------------------------------------------------------------------------------------------------
* jquery tips, promise + qunit testing (10 aug 2015)

  status: not useful unless an explicit animation runs on the target element
          use MutationObserver instead

  https://api.jquery.com/promise/

     "Using .promise() on a collection with no active animation returns a resolved Promise:"

  but fwiw, from a now-abandoned eric/Test.js qunit test:

      $("#datasetsManifestTable").promise().done(function(){
         console.log("datasetsManifestTable, starting done");
         assert.equal($("#datasetMenu").val(), datasetName);  done1();
         assert.ok($("#datasetsManifestTable tr").length >= 10); done2();
         var firstRowTitle = $("#datasetsManifestTable tbody tr td")[0].innerHTML;
         var expectedTitles = ["mRNA expression", "mutations", "copy number", "history",
                               "protein abundance", "methylation", "geneset", "network"];
         assert.ok(jQuery.inArray(firstRowTitle, expectedTitles) >= 0); done3()
         console.log("datasetsManifestTable, ending done");
         });



*----------------------------------------------------------------------------------------------------
* jquery tips, MutationObserver + qunit testing

  --- better example, with setTimeout simulating a long-running task


     //----------------------------------------------------------------------------------------------------
     function testStatus()
     {
        QUnit.test("statusDiv", function(assert){
          var msg = $("#statusDiv").text();
          assert.ok(msg === "complete");
          });

     } // testStatus
     //----------------------------------------------------------------------------------------------------
     function test(){

       var target = document.querySelector("#statusDiv");
       var observer = new MutationObserver(function(mutations) {
       mutations.forEach(function(mutation) {
          console.log(mutation.target.id + " is complete");
          if(mutation.target.id === "statusDiv")
             testStatus();
          });
         });

       var config = {attributes: true, childList: true, characterData: true};
       observer.observe(target, config);

         // simulate some long-running tasks which concludes by setting
         // status div to "complete"
       setTimeout(function(){
          $("#statusDiv").text("complete");
          }, 2000);

     } // test
     //--------------------------------------------------------------------------------


  --- first success, an okay example

    ~/s/examples/js/jquery/promise/withMutationObserver/

   some lessons learned:

     var target = document.querySelector("#animationStatusDiv");
     var observer = new MutationObserver(function(mutations) {
        mutations.forEach(function(mutation) {
          console.log(mutation.target.id + " is complete");
           });
        });

    var config = {attributes: true, childList: true, characterData: true};
    observer.observe(target, config);

    --- suggested usage:
      wrap this code in a funcion (e.g., testAnimation)
      at the completion of an animation, the status div is modified
      this triggers the mutation observer
      which then inspects the associated element, tests whether or not it has the expected contents
*----------------------------------------------------------------------------------------------------
* jquery tip, promise tip

  ~/s/examples/js/jquery/promise/animationDemo/animationDemo.html

  see combination with junit in
   ~/s/examples/js/jquery/promise/withQunit/testWhenDone.html

  see another good approach:

     http://stackoverflow.com/questions/3900151/is-there-a-jquery-event-that-fires-when-a-new-node-is-inserted-into-the-dom

  this mentions MutationObserver as the modern efficient way to detect dom insertions


   var target = document.querySelector('#some-id');

   // create an observer instance
   var observer = new MutationObserver(function(mutations) {
     mutations.forEach(function(mutation) {
     console.log(mutation.type);
     });
   });

// configuration of the observer:
var config = { attributes: true, childList: true, characterData: true };

// pass in the target node, as well as the observer options
observer.observe(target, config);

// later, you can stop observing
observer.disconnect();

*----------------------------------------------------------------------------------------------------
* oncoplex conference call (05 aug 2015)

  colin, eric, tina (david away)

1) markers & patients tab
  layout selected nodes, zoom into this selection, save this layout for later reuse,
  restore original layout on demand
    a) for example: select KRAS
    b) Network operations menu ("netOpsMenu"):  show edges from selected nodes
    c) netOpsMenu: select all connected nodes
    d) currently possible: zoom out, drag all selected nodes to a blank region, arrange
       layout by hand, save layout (see menu towards top right)
    e) new operation requested: layout selected nodes in blank area of the screen,
       optionally zoom in on that freshly-laid out selection

2) drug/gene interactions
   a) add linkout column.  when clicked, a popup window displays the source database's full info
   b) add "date acquired" column
   c) sort and filter in all columns
   d) look for a good shared (simple) schema, include "drug class" if possible
   e) add more of the six sources David suggested

3) markers & patients
   a) add gene fustions to the gene nodes
   b) as a new type of edge, "fusion" with fusion partner named as an edge label when known

       patient ---------> ALK
                 (EML4)

   c) as a new kind of gene node, "ALK-EML4", different shape and border color
   d) These are currently reported:
        ALK fusions (including ALK-EML4, ALK-KIF5B, ALK-TFG, ALK-C2orf44)
        ROS1 fusions
        RET fusions
        NTRK1 fusions
        BRAF fusions
        DNAJB1- PRKACA fusions
        PML-RARA
        BCR-ABL (common p190 and p210 fusions only)
        MLL rearrangements

  --- fusions found in jenny's latest (3 aug 2015) updates)
Prepraring for another demo (maybe this Friday?) I have just extracted the updated mutations extracted by Kara in NYC from the text of the UWlung patient records:

EML-ALK
EPHB1-FGFR2
EZR-ROS1
RET-FRMD4A
RET-KIF5B
ROS1-CD74

Rearranged for consistency

ALK-EML
EPHB1-FGFR2
RET-FRMD4A
RET-KIF5B
ROS1-EZR
ROS1-CD74

Does it make sense to all of you that these six fusions might be all reported in the 104 patients so far extracted?

- Paul


*----------------------------------------------------------------------------------------------------
* fix DEMOdz:  mtx.mrna.ueArray (20x64) has all 20 patients, mtx.mrna.bc has (!) just 2 (5 aug 2015)

   library(DEMOdz)
   demoDz <- DEMOdz()
   mrna.datasets <- sort(grep("mtx.mrna", manifest(demoDz)$variable, value=TRUE))
   mtx.mrna.ueArray <- matrices(demoDz)$mtx.mrna.ueArray
   mtx.mrna.bc <- matrices(demoDz)$mtx.mrna.bc

   length(intersect(rownames(mtx.mrna.bc), rownames(tbl.pt)))      #   2
   length(intersect(rownames(mtx.mrna.ueArray), rownames(tbl.pt))) #  20
     # arbitrary assignment, preserving array dimensions, completely fabricated rownames
   rownames(mtx.mrna.bc)[1:20] <- rownames(mtx.mrna.ueArray)
   length(intersect(rownames(mtx.mrna.bc), rownames(tbl.pt))) # [1] 20
   save(mtx.mrna.bc, file="~/oncodev/hbolouri/dataPackages/DEMOdz/inst/extdata/mtx.mrna.bc.RData")

*----------------------------------------------------------------------------------------------------
* plsr bug, with DEMOdz, when tab ui translates to and from days (in R) and years (in js) (5 aug 2015)

  --- get factor (AgeDx, Survival) ranges
[1] "summarizePLSRPatientAttributes"

$callback
[1] "handleAgeAtDxAndSurvivalRanges"

$status
[1] "request"

$payload
[1] "AgeDx"    "Survival"

[1] "------------ myplsr"
[1] "------------ summary returned"
$AgeDx
[1] 18571 18571 19114 19657 19657

$Survival
[1] 82 82 82 82 82




  --- the failed calculation

[1] === calculate_plsr
$cmd
[1] "calculatePLSR"

$callback
[1] "handlePlsrResults"

$status
[1] "request"

$payload
$payload$genes
[1] "random.40"

$payload$factorCount
[1] 2

$payload$factors
      name      low     high
1    AgeDx 18627.24 19357.72
2 Survival     0.00   365.24


[1] gene count for calculatePLSR (1)
[1] genes for calculatePLSR after possible lookup(40)
[1] "------------ myplsr before calculate"
Function: calculatePLSR (package PLSR)
obj="PLSR"

description       class        mode        text      opened    can read   can write
   "stdout"  "terminal"         "w"      "text"    "opened"        "no"       "yes"
[1] --- factors: 2
[1] --- genes: 40
[1] OncoDev14.R 1.4.71 dispatchMessage detected error
[1] --- msg.full: OncoDev14 (version 1.4.71) exception!  Error in pls::mvr(mtx.classify ~ mtx.mrna, ncomp = 2, scale = TRUE, validation = "none", : Invalid number of components, ncomp\n. incoming msg: calculatePLSR;  handlePlsrResults;  request;  list(genes = "random.40", factorCount = 2, factors = list(name = c("AgeDx", "Survival"), low = c(18627.24, 0), high = c(19357.72, 365.24)))



*----------------------------------------------------------------------------------------------------
* ensure that TCGAbrain can be recreated at will via 'make' (3 aug 2015)

  see "recover eric's tcgabrain layout..." below on how layout was freshly obtained from
    - an old july email message (this is apparently tcgagbm, not enough nodes)
    - from the current chinookdemo5.sttrcancer.org

   --- need the style as well

*----------------------------------------------------------------------------------------------------
* recover eric's tcgabrain layout from his mail message (3 aug 2015)

   cd ~/oncodev/hbolouri/dataPackages/networks/TCGAbrainMarkersAndTissues/prep/

  --- obtained this way in his javascript console
    JSON.stringify(cwMarkers.nodes().map(function(node) {return ({id:node.data("id"), pos: node.position()})}))
    tbl.rough <- fromJSON(x, simplifyDataFrame=TRUE)
    colnames(tbl.rough) #  "id" "pos"
    length(tbl.rough$id)  # [1] 1958
    dim(tbl.rough$pos)    # [1] 1958    2

    tbl.layout <- cbind(tbl.rough$id, tbl.rough$pos)
    colnames(tbl.layout) <- c("id", "x", "y")

      # bug in rcyjs.html setLayout means that setPosition(rcy, tbl.layout) fails
      # but one node at a time works:
    for(i in 1:nrow(tbl.layout)) setPosition(rcy, tbl.layout[i,])

  ---  saved
   as ~/oncodev/hbolouri/dataPackages/networks/TCGAbrainMarkersAndTissues/ericsLayout-2015-jul-06.json-mail-message
   copy into an emacs buffer, remove enclosing double quotes, see "scan" below

  --- fresh creation of tcgabrain network, using "createBaseGraph" then
    httpAddGraph(rcy, g.chrom)
    httpAddGraph(rcy, g.mut)  # lgg
    httpAddGraph(rcy, g.mut)  # gbm
    httpAddGraph(rcy, g.cn)
    httpAddGraph(rcy, g.cn)

  --- get layout information from json mail message
    f <- "ericsLayout-2015-jul-06.json"
    f <- "layout.raw"
    x <- scan(f, what=character(0), sep="\n")
    tbl.rough <- fromJSON(x, simplifyDataFrame=TRUE)
    colnames(tbl.rough) #  "id" "pos"
    length(tbl.rough$id)  # [1] 1958
    dim(tbl.rough$pos)    # [1] 1958    2

    tbl.layout <- cbind(tbl.rough$id, tbl.rough$pos)
    colnames(tbl.layout) <- c("id", "x", "y")

      # bug in rcyjs.html setLayout means that setPosition(rcy, tbl.layout) fails
      # but one node at a time works:
    for(i in 1:nrow(tbl.layout)) setPosition(rcy, tbl.layout[i,])




   --- problem:  the current TCGAbrain demo has 1958 nodes, but this email from eric has only 879
       motiviating a fresh start, getting layout from that current TCGAbrain demo

     browse to chinookdemo5.sttrcancer.org.  choose TCGAbrain, wait a LONG time. see network

      JSON.stringify(cwMarkers.nodes().map(function(node) {return ({label:node.data(), pos: node.position()})}))
      copy all into emacs buffer, remove above command, and quotes, save as layout.raw

      tbl.layout <- fromJSON("layout.raw", simplifyDataFrame=TRUE)
      dim(tbl.layout$pos)  # [1] 1958    2
      head(tbl.layout$label)
         name   nodeType dzSubType label   id degree
       1 chr1 chromosome            chr1 chr1     67
       2 chr2 chromosome            chr2 chr2     37

    tbl.layout <- cbind(tbl.layout$label$id, tbl.layout$pos)
    colnames(tbl.layout) <- c("id", "x", "y")
    setPosition(rcy, tbl.layout)   # takes a few minutes, not sure why
    fitContent(rcy)
    setZoom(rcy, 0.8 * getZoom(rcy))
    saveLayout(rcy, "layout-2015aug03.RData")

   ---


*----------------------------------------------------------------------------------------------------
* cyjs qtip demos (3 aug 2015)

  cd ~/s/examples/cyjs/qtip

*----------------------------------------------------------------------------------------------------
* initial forays into fund raising for sword fern die-off (31 jul 2015)

   --- sent email, erin (leaving for seattle parks foundation) offered to support my approach
   lisa@wecprotect.org  lisa remlinger
   People For Puget Sound Program  Washington Environmental Council, 1402 Third Ave, Suite 1400
   (206) 631-2615
   erin miller seattle parks foundation erin@seattleparksfoundation.org

   --- lisa younger at the nature conservanccy
     admin asst also added supporting email

   --- rei: lots of runaround, don't expect a response
      stewardship@rei.com

*----------------------------------------------------------------------------------------------------
* rei foundation, sword fern die-off proposal

  253 395 3780

*----------------------------------------------------------------------------------------------------
* new materialism: interview and cartographies (27 jul 2015)

 Rick Dolphijn & Iris van der Tuin
 interviews with barad, delanda,  Rosi Braidotti, Quentin Meillassoux

 saved to ~/books/new-materialism-interviews-cartographies.pdf

*----------------------------------------------------------------------------------------------------
* drug-gene interactions for UWlung, first look (23 jul 2015)

  cd ~/oncodev/hbolouri/dataPackages/networks/UWlungMarkersAndTissues/prep/


*----------------------------------------------------------------------------------------------------
* create, install, load R packages from  a project/version-specific directory (23 jul 2015)

  --- install as if via biocLite
    pkg <- "AnnotationDbi"
    mylib <- "/home/sttrweb/lopez/oncoscape/v1.4.60/Rlibs/x86_64-unknown-linux-gnu-library/3.2"
    install.packages(pkg, lib=mylib, repos=biocinstallRepos())

  --- install one of our packages
    R CMD INSTALL -l ../Rlibs/x86_64-unknown-linux-gnu-library/3.2/ DEMOdz
    with install dir explicit:
    R CMD INSTALL -l ~/lopez/oncoscape/v1.4.60/Rlibs/x86_64-unknown-linux-gnu-library/3.2/ <package>

  --- or all
    R CMD INSTALL -l ../Rlibs/x86_64-unknown-linux-gnu-library/3.2/ PatientHistory SttrDataPackage DEMOdz TCGAbrain TCGAgbm TCGAlgg UWlung

   .libPaths(c("/app/R/3.2.1/lib/R/library", "~/lopez/oncoscape/v1.4.60/Rlibs/x86_64-unknown-linux-gnu-library/3.2"))

  --- use these in runAsServer.R
   .libPaths(c("/app/R/3.2.1/lib/R/library",
             "~/lopez/oncoscape/v1.4.60/Rlibs/x86_64-unknown-linux-gnu-library/3.2"))
   library(OncoDev14)
   scriptDir <- "tabsApp"
   stopifnot(nchar(Sys.getenv("ONCOSCAPE_USER_DATA_STORE")) > 0)
   userID <- "test@nowhere.org"
   current.datasets <- c("DEMOdz;TCGAgbm;TCGAbrain")
   port <- 11004
   onco <- OncoDev14(port=port, scriptDir=scriptDir, userID=userID, datasetNames=current.datasets)
   if(Sys.info()[["nodename"]] != "lopez")
     browseURL(sprintf("http://localhost:%d", port))
   run(onco)

*----------------------------------------------------------------------------------------------------
* fosp addresses

Janis   Medley  	4609 Somerset Dr SE 	Bellevue  	Washington  	98006  	jpmedey@mac.com
John  	Thorpe  	17614 Rouse Rd., KP S 	Longbranch  	Washington  	98351  	jwthorpe@sbc global.net
Karen  	O'Brien  	9840 Rainier Ave 	Seattle  	Washington  	98118  	slalom4lyf@aol.com

*----------------------------------------------------------------------------------------------------
* sword fern die-off documents and reports (22 jul 2015)

  ~/s/notes/fosp/swordFernDieOff/reportsAndDocs/
    olaf-2015jun23
*----------------------------------------------------------------------------------------------------
* how does TCGAgbm lose its style?

  Module.markers, function displayMarkersNetwork(msg)


     XXX = msg.payload;
     XXX.slice(0,50)  // "{"elements":{"nodes":[{"data":{"name":"TCGA.06.074" ...
     xxx = JSON.parse(XXX);
     JSON.stringify(xxx["style"][0])

  --- for DEMOdz
   JSON.stringify(xxx["style"][0])
    "{"selector":"node","css":{"text-valign":"center","text-halign":"center",
      "content":"data(label)", "background-color":"rgb(240,240,240)",
      "border-color":"black","border-width":"1px",
      "width":"mapData(degree,0.0,100.0,20.0,300.0)",
      "height":"mapData(degree,0.0,100.0,20.0,300.0)","font-size":"12px"}}"

   JSON.stringify(cy.style().json()[0])
      "{"selector":"node","css":{"text-valign":"center","text-halign":"center",
        "content":"data(label)","background-color":"rgb(240,240,240)",
        "border-color":"black","border-width":"1px",
        "width":"mapData(degree,0.0,100.0,20.0,300.0)",
        "height":"mapData(degree,0.0,100.0,20.0,300.0)","font-size":"12px"}}"


   --- for TCGAgbm
     XXX.slice(0,50)   // "{"elements":{"nodes":[{"data":{"name":"ZMYM2","nod"
     xxx = JSON.parse(XXX);
     JSON.stringify(xxx["style"][0])

       "{"selector":"node","style":{"text-valign":"center","text-halign":"center",
         "background-color":"rgb(240, 240, 240)","border-color":"black",
         "border-width":"1px",
         "width":"mapData(degree,0.0,20.0, 20.0, 70.0)",
         "height":"mapData(degree,0.0,20.0, 20.0, 70.0)"}}"


*----------------------------------------------------------------------------------------------------
* new bioc package, from bioc2015 developer day (20 jul 2015)
  mocluster: clustering on multiple omics data
   mogsa: gene set analysis on multiple omics data
*----------------------------------------------------------------------------------------------------
* bioc 2015 project updates (17 jul 2015)

   https://github.com/Bioconductor/BioC2015DDay/blob/master/vignettes/ProjectUpdates.Rmd

*----------------------------------------------------------------------------------------------------
* leo & portland state university (psu) office of sustainability (17 jul 2015)

  tanya called back regarding my question:  would this be a good fit for leo?
   503.725.9940
  suggested jacob sherman as a good contact: jsherman@pdx.edu, 971.570.7167
  he coor

   --- left msg with jacob (24 sep 2015)
    asked for call or email if honors college/sustainability curriculum seemed likely

*----------------------------------------------------------------------------------------------------
* fresh clean TCGAgbm network (17 jul 2015)

  cd ~/oncodev/hbolouri/dataPackages/networks/TCGAgbmMarkersAndTissues/prep/
  steals liberally from
    ~/s/data/hamid/repo/hbolouri/oncoDev/prep/tcgaMarkersAndTissues/markers/go.R (20 apr 2015)
  uses genes and patients from nodes.json, extracted using javascript console and the
  markers & tissues network in oncotest1.sttrcancer.org

  --- next up
   with g.base (no edges, 879 nodes - genes, patients, chromsomes) in browser
     table(as.character(nodeData(g.base, attr="nodeType")))
      chromosome       gene    patient
              24        551        304
   do successive calls to
          httpAddGraph(rcy, g.chrom/mut/cn)
   to add edges


*----------------------------------------------------------------------------------------------------
* oncoplex genes as of (16 jul 2015)

  from david wu:

The following genes are sequenced on an Illumina instrument to detect single nucleotide variants,
small insertions and deletions, gene amplifications, and selected translocations:

ABCB1*, ABCC4*, ABCG2*, ABL1, ABL2, AKT1, AKT2, AKT3, ALK**, APC, AR,
ASXL1, ATM, ATRX (NEW), AURKA, AURKB, AXL (NEW), BAK1, BAP1, BARD1
(NEW), BCL2, BCL2L11, BCOR, BCR*, BRAF**, BRCA1, BRCA2, BRIP1 (NEW),
CALR (NEW), CBL, CBLB, CCND1, CCNE1, CDH1, CDK4, CDK6, CDK8, CDKN1A
(NEW), CDKN2A, CEBPA, CHD1 (NEW), CHEK1, CHEK2, CREBBP, CRLF2, CSF1R,
CTNNB1, CYP1B1*, CYP2C19*, CYP2C8*, CYP2D6*, CYP3A4*, CYP3A5*, DAXX
(NEW), DDR2, DEPDC5 (NEW), DNAJB1 (NEW), DNMT3A, DOCK7 (NEW), DPYD,
EGFR, EIF3A, EML4*, EPHA3, EPHA5, EPHB2, EPHB6, ERBB2, ERBB3, ERBB4,
ERCC2*, ESR1*, ESR2*, ETV6, EZH2, FAM175A (NEW), FBXW7, FCGR1A,
FCGR2A, FCGR3A*, FGFR1, FGFR2, FGFR3, FGFR4, FLT1, FLT3, FLT4, FOXA1,
GAB2, GATA1, GATA2, GATA3, GLI1 (NEW), GNA11, GNAQ, GNAS, GRIN2A,
GRM3, GSTP1*, H3F3A (NEW), HDAC4, HIF1A, HNF1A, HRAS, HSPH1*, IDH1,
IDH2, IGF1R, IKZF1, IL7R, ITPA*, JAK1, JAK2, JAK3, KDM6A, (UTX), KDR,
KIF5B*, KIT, KRAS, LRP2*, MAN1B1*, MAP2K1, MAP2K2, MAP2K4, MAPK1,
MC1R, MCL1, MDM2, , MDM4, MED12, MEN1, MET, MIOS (NEW), MITF, MLH1**,
MLH3 (NEW), MLL (KMT2A)**, MPL, MRE11A, MSH2**, MSH6**, MTAP (NEW),
MTHFR*, MUTYH, MYC, MYCL1, MYCN, NBN (NEW), NF1, NF2, NKX2-1, NOTCH1,
NOTCH2, NPM1, NPRL2 (NEW), NPRL3 (NEW), NQO1*, NRAS, NRP2*, NTRK1
(NEW), PAK1 (NEW), PALB2 (NEW), PAX5, PBRM1, PDGFRA, PDGFRB, PHF6
(NEW), PIK3CA, PIK3R1, PLK1 (NEW), PLK2 (NEW), PLK3 (NEW), PLK4 (NEW),
PML*, PMS2, POLD1 (NEW), POLE (NEW), PRPF40B, PTCH1, PTEN, PTPN11,
PTPRD, RAD51C (NEW), RAD51D (NEW), RAF1, RARA**, RB1, RET, RICTOR,
ROS1**, RPS14, RUNX1, SF1, SF3B1, SHH (NEW), SLC19A1*, SLC22A2*,
SLCO1B3*, SMAD2, SMAD3, SMAD4, SMARCA4, SMARCB1, SMO, SOD2*, SPOP,
SPRY4, SRC, SRSF2, STK11, SUFU (NEW), SULT1A1*, SUZ12, TACC3 (NEW),
TACSTD2 (NEW), TET2, TFG*, TGFBR2, TMPRSS2*, TP53, TPMT*, TRRAP, TSC1,
TSC2, TYMS*, TYR, U2AF1, (U2AF35), U2AF2, (U2AF65), UGT1A1*, UMPS*,
VHL, WT1, ZBTB16 (NEW), and ZRSR2.




*----------------------------------------------------------------------------------------------------
* notes and todos from oncoplex meeting (10 jul 2015)

1) very helpful if we get real survival dates.  All patients in UWlung show status=alive
so the
pseudo-survival times are acutally diagnosis to present day.  These data are from 2013; they surmise
that death dates can be obtained for some.

2) all durations are represented in days.   Years would be better.

3) gene fusions are common in lung cancer.  They can be extracted from the results field, and
displayed as separate “virtual gene” nodes in the markers & patient network.

4) optional tooltips, so that hovering over a node or edge displays transient popup of information:
a summary of patient data, a summary of alterations in a gene.

5) Though probably encountering an IRB obstacle, clicking through from a de-identified patient
record or node to see the chart from which their data was extracted, will be very important at some
point.

6) One possibly not-so-controversial solution (but maybe still too controversial to actually
implement) is to give Colin & co. the de-identification key, or even (with proper secure login in
place) to display the original patient ID in oncoscape.  They could then copy this real ID into
their own secure UW EMR application, and view the original data.

7) Sharing layouts and selections within their group is a high priority, and a modest task for me.
Also requested by Eric.

8) Robust logins needed right away, so that they can explore the program and their data at will.

9) The current markers & patients layout is adhoc, force-directed, and will not scale well.  Custom
layouts (a la Eric) will help.  Well-known pathways will help also.

*----------------------------------------------------------------------------------------------------
* TCGAgbm, repair broken style in markers.json (15 jul 2015)

  improvements in the markers & patients/tissues graph generation, attributes and style,
  for TCGAbrain and UWlung causes (at least) broken edge styles, apparently node shapes also

  this code can be found here:

    ~/oncodev/hbolouri/dataPackages/networks/
       TCGAbrainMarkersAndTissues/prep/go.R  (24 jun 2015)
       UWlungMarkersAndTissues/prep/go.R     (9 jul 2015)

   --- related: Eric's latest brain (or just gbm?) layout
  ~/oncodev/hbolouri/dataPackages/networks/TCGAbrainMarkersAndTissues/ericsLayout-2015a-jul-06.json-mail-message
      (jul6, 260k)

   --- the current status of TCGAgbm markers network
     ~/oncodev/hbolouri/dataPackages/TCGAgbm/inst/extdata/markers.json  (11 jun, 2.4M)
     ~/oncodev/hbolouri/dataPackages/TCGAgbm/inst/extdata/markers.json.RData  (5 jun, 153k)  (out of date!)

   --- quick strategy:
     replace edge and node attribute names in the 11 jun markers.json to match those now used,
     see if that resurrects a usuable style for TCGAgbm.

     need better single-copy & centralized curation of the markers style.js.
     in latest design, the style is included in markers.json of the data package
     but markersAndPatients/Module.js has some things hard-coded: edgeType, for example

     let's try using the TCGAbrain network-construction
     cp -p ~/oncodev/hbolouri/dataPackages/TCGAbrain/inst/import/networks/markers/style.js markersAndTissues-style.js

     now: ~/oncodev/hbolouri/dataPackages/networks/markersAndTissues-style.js
     this is ready for use, when constructing a network:

        httpSetStyle(rcy, "~/oncodev/hbolouri/dataPackages/networks/markersAndTissues-style.js")


      new style: (from ~/oncodev/hbolouri/dataPackages/networks/markersAndTissues-style.js)

    {selector: 'edge[edgeType="cnGain.1"]',   css:{"line-color": "rgb(0,128,0)", "width": 1, "line-style": "dotted"}},
    {selector: 'edge[edgeType="cnGain.2"]',   css:{"line-color": "rgb(0,64,0)", "width": 5, "line-style": "dotted"}},
    {selector: 'edge[edgeType="cnLoss.1"]',   css:{"line-color": "red",   "width": 1, "line-style": "dotted"}},
    {selector: 'edge[edgeType="cnLoss.2"]',   css:{"line-color": "red",   "width": 5, "line-style": "dotted"}},
    {selector: 'edge[edgeType="chromosome"]',

     old


*----------------------------------------------------------------------------------------------------
* jsfiddle tips: get the source (13 jul 2015)

the full fiddle: http://jsfiddle.net/5WsEt/
just the result: http://jsfiddle.net/5WsEt/embedded/result
get the source of the results frame:  right-click on the displayed table, choose "view frame source"

---------------------------------------------------------------------------------------------------
* seward park ford ad filming incident (11 jul 2015) saturday

  --- valancy blackwell, mayor's staff, dug up by cheryl brush  (14 sep 2015) 684.8817
    valancy probably not the one to actually do the work, but will find someone who is
    call her at the mayor's office if i hear nothing by, say, wed 9/16
      684.5034

  --- (6 oct 2015)
    no word (from carlos?) to whom I was referred by valancy blackwell


  --- city contacts
     Rockwell, Susanne K. 	206-733-9702  	susanne.rockwell@seattle.gov
       (18 sep 2015): phone call.  very receptive.

     susan golub: Policy Unit Manager at Seattle Parks and Recreation
     susan golub  684-7046 [spoke with her 24 aug, she promised to contact kate becker and keep me in the loop]
                  (28 aug 2015) left voice message, begging for an update.
                  (31 aug 2015) left voice message again, suggesting expanding "neighbor" to include parks. and me.
                  (08 sep 2015) phone call.  said 72-hour-neighbor policy extended to forest stewards not possible
                                but she will ask peggy pullen, who is notified, to contact me
                                says restitution will happen.  i asked if she could request a date certain for that.
                  (17 sep 2015) told her of joey's problem, and re permit: no deposit, no inspection
                  (18 sep 2015) left friendly voicemail proposing that i should no longer pester her, asked for response

     peggy pullen 386-1916.  gave her rundown.  hasn't this already been "processed"?  she'll nudge some people,
                             promises to call me back.



  -- 18 jul 2015: was it a crime?

   http://seattlish.com/post/92850740931/no-the-parks-city-attorney-is-not-out-to-get

   Earlier this year Kurt Zwar was charged in Seattle Municipal Court with one count of Removal/Destruction of Parks
   Property pursuant to Seattle Municipal Code18.12.070(B). The criminal charge reads:

   Commit the crime of removing, destroying, mutilating or defacing any structure, lawn, monument, statue, vase,
   fountain, wall, fence, railing, vehicle, bench, shrub, tree, geological formation, plant, flower, lighting system,
   sprinkling system, gate, barricade or lock or other property lawfully in any park, or removing sand, soil, or sod
   from any park. Contrary to Seattle Municipal Code Section(s): 18.12.070(B)

   ---  https://www.municode.com/library/wa/seattle/codes/municipal_code?nodeId=TIT18PARE_CH18.12PACO

     B. It is unlawful for any person except a duly authorized Department of Parks and Recreation or other City employee in
     the performance of his or her duties, or other person duly authorized, to remove, destroy, mutilate or deface any
     structure, lawn, monument, statue, planter, vase, fountain, wall, fence, railing, vehicle, bench, shrub, tree,
     geological formation, plant, flower, lighting system, sprinkling system, gate, barricade or lock or other property
     lawfully in any park, or to remove sand, soil, sod, or water from any park.

     C. Every offense defined by this section or conduct made unlawful hereby shall constitute a crime subject to the
     provisions of Chapters 12A.02 and 12A.04 of this Code (Seattle Criminal Code) and any person convicted of such
     crime may be punished by a fine not to exceed $5,000 or by imprisonment for a term not to exceed one year, or by
     both such fine and imprisonment.


erin
lisa@wecprotect.org  lisa remlinger
lisa younger



talked to south precinct desk sergeant, eric zerr, who asked me to text him at 206-779-4620.
failed to accomplish that.  he's ready to consider this when he is back at work sunday evening.

officer who urged me to leave the park, claimed it was closed
j. bernal   badge number 1937
said "they hired us"  (the film company)

--- email exchange with eric.zerr
Officer J, Bernal
Badge # 1937
Seattle? King?  I forgot to note that down, sorry. Dark blue uniform.
Could you let me know that you received this? Many thanks!

Got it......I'll get back to you soon

Sgt. Eric Zerr #5310
South Pct Patrol
dsk   206-386-1868
cl    206-779-4620

--- left message with sam of seattle office of film and music (8:10, monday 13 july)
233-3948, sam mouser
(14 jul) left message, describing violotaion
Kate Becker, Director: 206-684-5030
chris swenson (sam's boss)  206-733-9245, 930a, voice mailbox ful
julie borden: film & music assistant, left message (15 jul 2015)

  --- thurs 17 sep 2015
    left message with kate regarding 2nd paragraph of permit:
    and again with chris swenson

  in addition, the company named above agrees to pay a
  $500.00/$1000.00 deposit, refundable upon final inspection of the
  film location and verification that all obligations to the City
  incurred as a result of this activity are satisfied. The company
  agrees that the City Staff time and materials required to restore
  the location to its previous condition will be deducted from the
  deposit. The company further agrees to pay the City of Seattle for
  restoration costs in excess of the deposit amount. In addition, the
  company named above agrees to secure and maintain in full force and
  effect during the full term of the permit, comprehensive general
  liability insurance as described in the Seattle Film Manual and
  Instructions, which by this reference are incorporated herein.


--- wed 15 jul
many, many voice mails left, kafka-esque mailboxes full, vacations long past announced.
finally called danielle hursh, executive assistnat in the oed, the parent organization.
said kate will call me toeday

---- oed
Brian K. Surratt, DIRECTOR	206-684-8090 , brian.surratt@seattle.gov
Kevin Burrell, DEPUTY DIRECTOR	206-684-3348, kevin.burrell@seattle.gov
Danielle Hursh, EXECUTIVE ASSISTANT, 206-733-9254 danielle.hursh@seattle.gov



kate called, great fan of seward, ardent environmentalist, horrified about what happened


--- left message with kyle griggs, park use permits (8am, monday 13 july)    684-4080
   sent the event permit.
   (21 sep 2015): asked for stats on monitoring and assessment of event permits

--- youtube
ford damage 1: https://www.youtube.com/watch?v=Z7NYGeDPlIM&feature=youtu.be
ford damage 2: https://www.youtube.com/watch?v=swUo7DPAro8&feature=youtu.be

--- delayed message to lisa

For completeness, I add this following detail.  This is probably more than you want to know, but since it paints an uncomplimentary portraint of me, and you may hear of it, I lay it out here.

At my request on Sunday, SPD South Precinct Sergeant Eric Zerr tracked down the off-duty officer who ushered me out of the woods and threatened me with a parks exclusionary order.  That officer, J. Bernal, now asserts that I had to be removed because I was making “physical contact” with film crew.  That terms suggests touching, pushing, shoving or striking.  I did none of those things (but note an inconsequential exception described below).  If I had been bellicose, that would justify the officer’s action.  I believe that is why he fabricated this claim.  He similarly (but less damagingly to me) fabricated the claim that the park filming site was officially closed to the public.  The permit specifies that public access is preservered, except for brief times when filming is actually in progress.  I think that the good officer Bernal, an off-duty policemen (but in full official uniform) answering to the production chief, was charged with getting me out of there, stopping my awkward questions, and to do so before the crew’s violations of the permit came to light.   Officer Bernal succeeded, by threat, by falsehoods, and by making after the fact false claims against me.

I think we can prevent situations like this, and do so collaboratively.  We can establish better notification and compliance monitoring procedures.

- Paul

Regarding Bernal’s claim that I was making physical contact with the crew:  I mention this for completeless.  After Bernal had escorted me beyond the bollards to the upper loop road, and after he had threatened me with an exclusionary order, I started walking to my car.  I passed by a crew member and lightly tapped her on the shoulder.  My intention was to follow up on our prior friendly conversation, in which she (the crew member) explained that she was using our mulch pile to dress up the forest floor.  I wished to ask her to please take care with off-trail travel, and to get the word out to her fellow crew members.  My approach — my tap on the shoulder as an invitation to talk — was, as it turned out, unwelcome, and she did not respond.  I suspect that the crew chief had labeled me persona non grata because of the questions I was asking, and the caution I promoted.   I was embarrassed at her lack of response, felt awkward, and I immediately proceeded to my car and drove away.   This light tap on the shoulder, and possibly shaking hands with the crew chief when I first arrived, were my only physical contacts during my time in the forest on Saturday.

--- suggested by mike carter (seattle times reporter)
call spd opa, pierce murphy, 684-8485  (left message 14 jul 2015)
meeting with opa's sgt
2015opa-1071 runolfson

--- called ford customer service (17 jul 2015)
  got case# cas7548263

--- http://aerofilm.tv/

  --- email from pierce (20 aug 2015)

    1) With respect to your complaint regarding your contact with
    Officer Bernal on July 11 at Seward Park (OPA2015-1071), following
    our preliminary investigation and review the case was assigned to
    his chain of command to handle. His supervisor will be required to
    discuss the matter with him and conduct whatever counseling for
    improvement is necessary. I believe a letter from OPA was emailed
    to you yesterday under separate cover. You will be hearing back
    from the officer's supervisor, either to obtain more information
    or to let you know what action was taken. If you have not heard
    back from someone within the next two weeks, please let me know.

    2) Regarding you dissatisfaction with how Sgt. Runolfson behaved
    during your interview, his supervisor and I both listened to the
    recording of the interview in light of the concerns you
    raised. His supervisor also interviewed Sgt. Runolfson and
    obtained his perspective and thoughts on the encounter. In my
    opinion, Sgt. Runolfson could have handled the interaction and
    interview better. I have asked his supervisor to meet with the
    Captain of OPA who is my direct report and put together a plan for
    helping Sgt. Runolfson learn and improve from this feedback. When
    the Captain returns from his annual leave next week, I will expect
    him and the supervisor to implement that plan and document the
    action in Sgt. Runolfson's performance appraisal.


   --- follow up with opa (15 sep 2015)
     206.684.8797
     interviewed with sgt. runolfson (16 may 2015)
     blandishments and voice mail offered.
     i requested real contact from someone involved by friday 3pm (it is now tuesday 3pm)
       or i would trouble pierce murphy with a phone call.


*----------------------------------------------------------------------------------------------------
* 4 successful sttr oncoscape grant proposals (10 jul 2015)

cd ~/s/papers/sttrOncoscape2015

*----------------------------------------------------------------------------------------------------
* ben puts up an odbc/mysql instance on lopez (8 jul 2015)

I created a DSN and tested a connection against MySQL successfully.

Here is the DSN example:

[mysql_local]
DRIVER = myodbc
DESCRIPTION = MySQL ODBC Driver
SERVER = localhost
UID = root
DATABASE = mysql

The keys here are that the driver is 'myodbc' as that is the exact way it is defined in /etc/odbcinst.ini, which manages the driver. I believe the DESCRIPTION field is free-form however.

To test and get an ODBC-based commandline, I am using 'isql' which is supplied with the msodbcsql driver package. It is invoked: isql [DSN] [UID] [PASS] and passing in '-v' is useful when you have connection issues.

I have not used ODBC drivers in R, but I know my team has some good R experience, and we are happy to help out if necessary.

This DSN is typically put into the file .odbc.ini in your home directory. It should work in the home directory of sttrweb, if that is the user your code is running as. If you need it available globally, we can add that DSN to /etc/odbc.ini, which should make it available for all users. Furthermore, if you add a 'PASSWORD' definition to the DSN, you should be able to connect w/o entering a password (note however, that in order to specify a password on the command line with isql, you will need to specify the UID as well as the parameters are positional, sadly).

Scientific Computing Wiki: http://scicomp.fhcrc.org


*----------------------------------------------------------------------------------------------------
* revise UWlung patient history data:   7 patients missing survival, ageDx, status, 1stP (7 jul 2015)

28, 31, 49, 76, 82, 87, 102

cd ~/oncodev/hbolouri/dataPackages/UWlung/inst/unitTests/
dp <- UWlung();
checkTrue("history" %in% manifest(dp)$variable)
ptHistory <- history(dp)
checkTrue(is(ptHistory, "PatientHistoryClass"))

tbl.events <- getTable(ptHistory)


t(tbl.events["UW.LU.0028",])   # just 5 columns, everything else NA
UW.LU.0028
ptID                                   "UW.LU.0028"
ptNum                                  "28"
study                                  "UWlung"
Birth.date                             "03/29/1937"
Birth.gender                           "female"
Birth.ethnicity                        NA
...

same for 102

--- remedy: remove these from the network, then (following procedure below) from the table
deleters <- rownames(tbl.events)[which(is.na(tbl.events$Survival))]
[1] "UW.LU.0028" "UW.LU.0031" "UW.LU.0049" "UW.LU.0076" "UW.LU.0082" "UW.LU.0087" "UW.LU.0102"


print(load("../extdata/history.RData"))  [1] "history"
class(history)   #  "list"
x <- lapply(history, function(event) event$PatientID %in% deleters)
which(unlist(x))   # 26 29 42 62 67 70 82
length(history)   # 1699
length(history[-which(unlist(x))])   # 1692
history <- history[-which(unlist(x))]
save(history, file="../extdata/history.RData")

/Users/pshannon/oncodev/hbolouri/dataPackages/UWlung/inst/extdata:
-rw-r--r--  1 pshannon  staff  33471 Jul  8 09:54 history.RData
-rw-r--r--  1 pshannon  staff  33571 Jul  7 16:46 history.RData-1699-events
-rw-r--r--  1 pshannon  staff  42240 Jul  7 11:19 history.RData-2175-events
-rw-r--r--  1 pshannon  staff  72046 Jun 24 14:22 history.RData-orig

rebuild package, view in uwLung oncocape app -- reset in patient history now recovers all rows


--- bring more patient history columns in
dim(tbl.events)  # 76 x 759
x <- apply(tbl.events, 2, function(col) length(which(!is.na(col))))
fivenum(as.integer(x)) # [1]  0  0  2 15 76





*----------------------------------------------------------------------------------------------------
* revise UWlung patient history data:   use only patients in the mutation table (7 jul 2015)

cd ~/oncodev/hbolouri/dataPackages/UWlung/inst/unitTests/
print(load("../extdata/history.RData"))        # history
print(load("../extdata/markers.json.RData"))   # "g.markers.json"

in ~/oncodev/hbolouri/dataPackages/networks/UWlungMarkersAndTissues/prep/

reload(0)
length(grep("^UW", nodes(g.mut), v=TRUE)) [1] 83

# get the overly large history list from the UWlung package

print(load("../../../UWlung/inst/extdata/history.RData"))  # [1] "history"
pts <- grep("^UW", nodes(g.mut), v=TRUE)    # length 83

x <- as.logical(lapply(history, function(e) e$PatientID %in% pts))
length(x)  #  2175
length(history[x]) # [1] 1699
history <- history[x]



*----------------------------------------------------------------------------------------------------
* revise UWlung patient history data:   found negative first progression dates (7 jul 2015)
asked jenny to check

cd ~/oncodev/hbolouri/dataPackages/UWlung/inst/unitTests/
t(tbl.events["UW.LU.0004",])   time to first: -30 days

Here are a few relevant fields from the UWlung data package tbl.events for 0004.

Is “06/03/2013” a typo?

Thanks!

- Paul

Diagnosis.date                         "07/03/2013"
Diagnosis.disease                      "Lung Cancer"
Diagnosis.siteCode                     "STD"
Status.date                            "09/21/2013"
Status.status                          "Alive"
Progression.date                       "06/03/2013"
Progression.event                      "Metastatic Disease"
Progression.number                     "1"
Progression.date.2                     "08/13/2013"
Progression.event.2                    "Metastatic Disease"
Progression.number.2                   "2"
Progression.date.3                     "08/28/2013"
Progression.event.3                    "1"
Progression.number.3                   "3"
Progression.date.4                     "09/17/2013"
Progression.event.4                    "2"
Progression.number.4                   "4"
Radiation.date1                        "08/28/2013"
Radiation.date2                        "09/09/2013"

*----------------------------------------------------------------------------------------------------
* build uwlung webapp

cd ~/oncodev/hbolouri/dataPackages/networks/UWlungMarkersAndTissues/prep
reload("redo")


*----------------------------------------------------------------------------------------------------
* cyjs tips: get eric's latest markers & tissues TCGAbrain layout from him, save, make available (6 jul 2015)

  JSON.stringify(cwMarkers.nodes().map(function(node) {return ({label:node.data(), pos: node.position()})}))

  saved in ~/oncodev/hbolouri/dataPackages/networks/TCGAbrainMarkersAndTissues as
   ericsLayout-2015-jul-06.json-mail-message

*----------------------------------------------------------------------------------------------------
* cyjs tip: get all node names from the tcgagbm markers & patients network (16 jul 2015)

   JSON.stringify(cwMarkers.nodes().map(function(node) {return (node.data("label"))}))

*----------------------------------------------------------------------------------------------------
* i2TCGAbrain: RSQLite experiment for this SttrDataPackage (3 jul 2015)

cd  ~/oncodev/hbolouri/dataPackages/i2TCGAbrain/inst/unitTests/


--- load time for direct data:
system.time(library(TCGAbrain)) # 0.1 second
system.time(dz <- TCGAbrain())  # 21.3 seconds

no time needed to get data (though substantial time to transmit to browser)

system.time(print(dim(matrices(dz)$mtx.mrna.bc)))   # [1]   654 18641
user  system elapsed
0.000   0.000   0.001

--- load time for RSQLite data
system.time(library(i2TCGAbrain))   # 2.620 seconds
system.time(dz <- i2TCGAbrain(list(user="oncotest", password="password"))) # 2.5 seconds
system.time(mtx <- getData(dz, "mtx.mrna"))  # 35 seconds,   681 x  20457
system.time(mtx <- getData(dz, "mtx.mrna", entities=soi, features=goi)) # 2.4 seconds


--- email to lisa, hamid, ken

I just ran an experiment.  I converted TCGAbrain (with matrices &
etc stored as RData objects within the package) to i2TCGAbrain (with
the data stored in an SQLite database in the package).

For most of our expected uses, this brought a 3-fold speed
improvment.  There’s more detail below, but briefly:

library(TCGAbrain)                     # 0.1 second
dz <- TCGAbrain()                      # 21 seconds (all data loaded, including methylation)
mtx.mrna <- matrices(dz)$mtx.mrna.bc   # 0.001 seconds, matrix is 654 x 18641

library(i2TCGAbrain)                   # 2.6 seconds
dz <- i2TCGAbrain(credentials)         # 2.6 seconds (no data loaded, but database connected and ready)
mtx.mrna <- getData(dz, entities=samples.500, features=genes.1000) # 2.4 seconds, matrix is 500 x 1000

Anticipating that most of our use of large matrices will be on ones
with dimension < 1000 x 1000, the database (RSQLite) approach is a
big improvement.  SQLite is an “embedded database” — which means
that is runs in the same process as R.  I predict that traditional
database servers (MySQL and SQL Server, coming soon on lopez and
castle respectively) will give us a speedup similar to SQLite, and
our long delays with Oncoscape startup should be reduced by half,
two-thirds or more.


*----------------------------------------------------------------------------------------------------
* i2DEMOdz:  RSQLite experiment for an SttrDataPackage class (3 jul 2015)

cd ~/oncodev/hbolouri/dataPackages/i2DEMOdz/
unit tests on expression data, working out the new getData method:

soi <- c("TCGA.06.0413", "TCGA.06.0201", "bogus", "TCGA.08.0344", "TCGA.02.0114")
goi <- c("EDIL3", "EED", "EEF2", "bogus")

mtx <- getData(dz, "mtx.mrna", entities=soi, features=goi)

setMethod("getData", "i2DEMOdzClass",

function (obj, signature, entities=NA, features=NA) {
# cannot have "." in column name in sql table
signature <- gsub(".", "_", signature, fixed=TRUE) # which matrix to get from
column.specifier <- "*"
if(!all(is.na(features))){
table.colnames <- colnames(dbGetQuery(obj@db, sprintf("select * from %s limit 0", signature)))
known.features <- intersect(table.colnames, features)
if(length(known.features) == 0)
return(NA)
column.specifier <- paste(c("row_names", known.features), collapse=",")
}
row.specifier <- ""
if(!all(is.na(entities))){
entity.set <- paste(paste0("'", c("row_names", entities), "'"), collapse=",")
row.specifier <- sprintf("where row_names in (%s)", entity.set)
}
full.query <- sprintf("select %s from %s %s", column.specifier, signature, row.specifier);
#printf("full.query: %s", full.query)
df <- dbGetQuery(obj@db, full.query)
rownames(df) <- df$row_names
as.matrix(df[,-1])
})




*----------------------------------------------------------------------------------------------------
* install cbioportal.war on lopez (2 jul 2015)

[following "* cbio deployed with database (10 feb 2015)"]

on wombat, cd ~/cbio
scp cbioportal.war lopez:cbio/                  # 64M, 1 seconds

on lopez, cd ~/cbio
cp /home/jzhang23/cbio_BR_0702.sql .            # 2.4G, breast cancer studies only

--- load cbio brca
mysql --host=localhost --user=cbio --password=cbio -D cgds_public < cgds_public_dump_20150116.sql


--- make sure that cbio user has been created and is usable
mysql --user=root --password=root
show databases;
use mysql;
select Host,User,Password from user;

+-----------+------------------+-------------------------------------------+
| localhost | root             | *81F5E21E35407D884A6CD4A731AEBFB6AF209E1B |
| lopez     | root             | *81F5E21E35407D884A6CD4A731AEBFB6AF209E1B |
| 127.0.0.1 | root             | *81F5E21E35407D884A6CD4A731AEBFB6AF209E1B |
| ::1       | root             | *81F5E21E35407D884A6CD4A731AEBFB6AF209E1B |
| localhost | debian-sys-maint | *816586F56A997BD56637226E2A8108059C2F8828 |
| localhost | pshannon         | *F95AEEDC9F848A22E5DFBA20CC556B4145707FF8 |
| localhost | cbio             | *B7184D8BA93F3658BB4B5F6E39446F1AE80CB08F |
+--------------------------------------------------------------------------+

prior art:
mysql --host=localhost --user=cbio --password=cbio -D cgds_public < cgds_public_dump_20150116.sql

mysql --user=cbio --password=cbio
show databases;
+--------------------+
| information_schema |
| cbioportal         |
| cgds_public        |
| mysql              |
| performance_schema |
| pshannon           |
+--------------------+

--- try load of brca data
ensure fresh start:
drop database cgds_public;

mysql --host=localhost --user=cbio --password=cbio -D cgds_public < cbio_BR_0702.sql

this fails with incomplete last line

--- try to get a fresh copy of this file
https://github.com/cBioPortal/cbioportal/wiki/Downloads
failed.  asked jenny to get me a good file.



*----------------------------------------------------------------------------------------------------
* install RODBC, brew, unix

installed brew:
ruby -e "$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/master/install)"
brew install wget
brew update && brew install unixODBC && \
wget "http://cran.r-project.org/src/contrib/RODBC_1.3-10.tar.gz" && \
R CMD INSTALL RODBC_1.3-10.tar.gz

could not find that cran package, but the install unixODBC seemed to help so that now
biocLite("RODBC") works -- it failed before on a couple of header files



*----------------------------------------------------------------------------------------------------
* install odbc for mysql on lopez ubuntu (01 jul 2015)

ssh -X lopez
sudo apt-get install iodbc
sudo apt-get install libmyodbc

iodbcadm-gtk

Switch to the "ODBC Drivers" tab, click "Add a driver". Type in a description of the driver
(i.e., "MySQL").
For "Driver file name" choose /usr/lib/odbc/libmyodbc.so.
on lopez:  /usr/lib/x86_64-linux-gnu/odbc/libmyodbc.so

For "Setup file name" choose /usr/lib/odbc/libodbcmyS.so.
on lopez: /usr/lib/x86_64-linux-gnu/odbc/libodbcmyS.so

add dsn ("data source name") -- personal only, though tried to do system wide
configure dsn:
database: mysql
password: pshannon
user: pshannon
server: lopez

--- this creates ~/.odbc.ini:
[ODBC Data Sources]
userDSN = ODBC

[userDSN]
Driver      = /usr/lib/x86_64-linux-gnu/odbc/libmyodbc.so
Description = pshannon's DSN
database    = mysql
password    = pshannon
server      = lopez
user        = pshannon

--- and ~/.odbcinst.ini
ODBC Drivers]
ODBC = Installed

[ODBC]
Driver = /usr/lib/x86_64-linux-gnu/odbc/libmyodbc.so
Setup  = /usr/lib/x86_64-linux-gnu/odbc/libodbcmyS.so

--- test if successfully installed
odbcinst -q -s    # looks at ? ~/.odbc.ini
[userDSN]

odbcinst -q -d   # looks at /etc/odbcinst.ini
[ODBC Driver 11 for SQL Server]
[ODBC Drivers]

--- make sure mysql is running, that i can login
mysql -u pshannon --password="leo.paul"

---- test if you can connect to your MySQL database via ODBC:
isql -v userDSN pshannon "leo.paul"  --failed
[S1000][unixODBC][MySQL][ODBC 5.1 Driver]Can't connect to MySQL server on 'lopez' (111)

maybe restart?


*----------------------------------------------------------------------------------------------------
* try mysql/odbc on wombat, macos yosemite

see below "install mysql on wombat (30 jun 2015)" for installation

trying to avoid lisa's limited-use odbc driver ("actual"?)
trying this instead, from oracle:
https://dev.mysql.com/downloads/file.php?id=415005

mysql-connector-odbc-5.1.13-osx10.7-x86-64bit.dmg

*----------------------------------------------------------------------------------------------------
* install tomcat7 on lopez for jenny's cbio demo (1 jul 2015)

info from https://help.ubuntu.com/lts/serverguide/tomcat.html#tomcat-webapps

[either i or ben installed tomcat7 base already.  now add other tomcat7 pkgs, create a little
hello world demo jsp app]

ssh lopez
as me:

sudo apt-get install tomcat7-docs
sudo apt-get install tomcat7-admin
sudo apt-get install tomcat7-user

--- create a devel user-specific directory (as me)

cd
mkdir tomcat
cd tomcat
tomcat7-instance-create my-instance
cd my-instance
find .
./conf
./conf/server.xml
./conf/catalina.properties
./conf/tomcat-users.xml
./conf/context.xml
./conf/web.xml
./conf/logging.properties
./logs
./webapps
./work
./temp
./bin
./bin/setenv.sh
./bin/startup.sh
./bin/shutdown.sh


--- modify ports in conf/server.xml

looks like conf/server.xml specifies port 8080: changed to 8090
<Connector port="8090" protocol="HTTP/1.1"
connectionTimeout="20000"
URIEncoding="UTF-8"
redirectPort="8453" />
also 8005 to 8015:
<Server port="8015" shutdown="SHUTDOWN">


http://lopez:8090   -- this works, but just an empty page


--- create and install minimal servlet
wombat:
cd ~/s/examples/java/servlets/helloEarth
scp * lopez:tomcat/my-instance/webapps/earth/

lopez:

http://lopez:8090/earth/hello

runs the servlet found here

~/tomcat/my-instance/webapps/earth/WEB-INF/

<?xml version="1.0" encoding="UTF-8"?>
<web-app>
<servlet>
<servlet-name>HelloEarth</servlet-name>
<servlet-class>HelloEarth</servlet-class>
</servlet>
<servlet-mapping>
<servlet-name>HelloEarth</servlet-name>
<url-pattern>/hello</url-pattern>
</servlet-mapping>
</web-app>

running code found here

~/tomcat/my-instance/webapps/earth/WEB-INF/classes/
HelloEarth.class
HelloEarth.java



*----------------------------------------------------------------------------------------------------
* nik holland: hamid's gbm map in cy3 (1 jul 2015)

  cd ~/s/rcy/nik/hamidsGlioblastomaNetwork

*----------------------------------------------------------------------------------------------------
* install mysql on lopez (30 jun 2015)

--- remove old installation
sudo apt-get remove --purge mysql*
sudo apt-get autoremove
sudo apt-get autoclean


--- install fresh

as pshannon:
sudo apt-get install mysql-server   # root password:  "root"

--- gets started automatically at end of install:
mysql start/running, process 19551
Setting up mysql-server (5.5.43-0ubuntu0.14.04.1) ...
lopez.~> ps aux	| grep mysql
mysql    19551  0.1  1.1 564200 45364 ?        Ssl  12:50   0:00 /usr/sbin/mysqld

--- client tools
/usr/bin/mysql*

--- create account for me: login as root, using password created just above
mysql -u root --password    # then prompted to supply password
create user pshannon@localhost identified by 'leo.paul'
grant all privileges on * . * to pshannon@localhost;

show databases;   # information_schema, performance_schema, pshannon

--- find registered users
show databases;
use mysql;
show tables;
show columns from user;

select Host, User, Password  from user;
+-----------+------------------+-------------------------------------------+
| Host      | User             | Password                                  |
+-----------+------------------+-------------------------------------------+
| localhost | root             | *81F5E21E35407D884A6CD4A731AEBFB6AF209E1B |
| lopez     | root             | *81F5E21E35407D884A6CD4A731AEBFB6AF209E1B |
| 127.0.0.1 | root             | *81F5E21E35407D884A6CD4A731AEBFB6AF209E1B |
| ::1       | root             | *81F5E21E35407D884A6CD4A731AEBFB6AF209E1B |
| localhost | debian-sys-maint | *816586F56A997BD56637226E2A8108059C2F8828 |
| localhost | pshannon         | *F95AEEDC9F848A22E5DFBA20CC556B4145707FF8 |
| localhost | cbio             | *B7184D8BA93F3658BB4B5F6E39446F1AE80CB08F |
+-----------+------------------+-------------------------------------------+


--- ensure that mysql is available to user tomcat7
sudo su - tomcat7
mysql -u cbio --password    # type 'cbio' when prompted

*----------------------------------------------------------------------------------------------------
* install mysql on wombat (30 jun 2015)

macos yosemite 10.10.3
MySQL 5.6.24 "community"

--- start it, as root
sudo /usr/local/mysql/support-files/mysql.server start

--- test it out
show databases;     +--------------------+
| Database           |
+--------------------+
| information_schema |
| test               |
+--------------------+

*----------------------------------------------------------------------------------------------------
* oncoscape launcher

cd ~/oncodev/hbolouri/oncoDev14/launcher
mongod --dbpath /Users/pshannon/mongo/data/db &   # if needed
python oncoPortMgr.py

*----------------------------------------------------------------------------------------------------
* install mysql on lopez (30 jun 2015)
sudo apt-get install mysql-server
sudo /usr/sbin/mysqld

--- client tools
/usr/bin/mysql*

*----------------------------------------------------------------------------------------------------
* python tips, figure out where modules are imported from

  import imp
  imp.find_module('websocket')
     (None, '/home/klatoza/.local/lib/python2.7/site-packages/websocket', ('', '', 5))

*----------------------------------------------------------------------------------------------------
* python tips, PYTHONPATH for macos python3.4 websockets packages

export PYTHONPATH=/Library/Frameworks/Python.framework/Versions/3.4/lib/python3.4/site-packages
python3
import websockets

---- get latest python and pip to install latest websockets module

pip3 install --upgrade pip

*----------------------------------------------------------------------------------------------------
* mysql/cmake install/build options
When you run cmake, you might want to add options to the
command line. Here are some examples:

* -DBUILD_CONFIG=mysql_release: Configure the source with
the same build options used by Oracle to produce binary
distributions for official MySQL releases.

* -DCMAKE_INSTALL_PREFIX=dir_name: Configure the
distribution for installation under a particular
location.

* -DCPACK_MONOLITHIC_INSTALL=1: Cause make package to
generate a single installation file rather than multiple
files.

* -DWITH_DEBUG=1: Build the distribution with debugging
support.
*----------------------------------------------------------------------------------------------------
* install mysql from source on lopez (23 jun 2015)

cd ~/lopez/mysql/mysql-cluster-gpl-7.4.6/
mkdir bld; cd bld
~/local/bin/cmake  .. -DBUILD_CONFIG=mysql_release  -DCMAKE_INSTALL_PREFIX=/home/sttrweb/local/ -DIGNORE_AIO_CHECK


*----------------------------------------------------------------------------------------------------
* install cmake on lopez (23 jun 2015)   needed to build mysql from source

cd /home/sttrweb/tmp/cmake-3.3.0-rc2
./bootstrap --prefix=/home/sttrweb/local/
make
make install


*----------------------------------------------------------------------------------------------------
* install cmake on wombat as prep for doing so on lopez (23 jun 2015)

cd ~/tmp/cmake/cmake-3.3.0-rc2
bash ./bootstrap
make


-- now mysql
cd ~/tmp/mysql/mysql-cluster-gpl-7.4.6
mkdir bld; cd bld
~/local/bin/cmake  .. -DBUILD_CONFIG=mysql_release

*----------------------------------------------------------------------------------------------------
* install mysql on lopez (23 jun 2015)

[status: abandoned.  instead build from source, use cmake, sepcify prefix=~/local]

got generic linux binary from

http://dev.mysql.com/downloads/file.php?id=457136

467,778,137 Jun 23 17:02 mysql-cluster-gpl-7.3.9-linux-glibc2.5-i686.tar.gz

on lopez,  /home/sttrweb/lopez/mysql:
tar xzvf mysql-cluster-gpl-7.3.9-linux-glibc2.5-i686.tar.gz

ln -s mysql-cluster-gpl-7.3.9-linux-glibc2.5-i686 current

bin/mysqld_safe --user=mysql &


*----------------------------------------------------------------------------------------------------
* jquery datatables column filtering:  apparently builtin  (23 jun 2015)

https://datatables.net/examples/api/multi_filter.html

*----------------------------------------------------------------------------------------------------
* jquery datatables column filtering: yadcf (23 jun 2015)

not used

--- has sliders, selection pulldown, possibly promisin
https://github.com/vedmack/yadcf/releases

*----------------------------------------------------------------------------------------------------
* psicquic & geneMANIA, at Mark Grimes request (15 jun 2015)

the psicuic web page examples seems to work:
http://www.ebi.ac.uk/Tools/webservices/psicquic/registry/registry?action=STATUS
http://webservice.baderlab.org:8380/psi-gm/webservices/current/search/query/*?firstResult=0&maxResults=10

now use our pkg to see what url is emitted

x <- interactions(p, "FLT3",provider="BIND", quiet=FALSE)
http://webservice.baderlab.org:8480/psicquic-ws/webservices/current/search/query/identifier:FLT3 result: 5 15

http://webservice.baderlab.org:8380/psi-gm/webservices/current/search/query/identifier:FLT3 result: 5 15

-- email to gary bader, mark grimes cc'd

Mark reminded me of his need for GeneMANIA rich intereactions, which he’d like to get from from
our Bioconductor PSICQUIC package, for easy use with the new RCy3 package a few of us are
wrapping up.  I realized I had not followed up with more tests, and his reminder got me into
action.

I am pretty sure I see the same problem we saw last fall.  We must :} allow for my errors of
course.

The “first 10” general query we find on the PSCIQUIC stauts page works fine:

http://webservice.baderlab.org:8380/psi-gm/webservices/current/search/query/*?firstResult=0&maxResults=10

But the id-specified search does not seem to:

http://webservice.baderlab.org:8380/psi-gm/webservices/current/search/query/identifier:FLT3

For what it’s worth, the related BIND url works great:

http://webservice.baderlab.org:8480/psicquic-ws/webservices/current/search/query/identifier:FLT3

Any guidance for us?



*----------------------------------------------------------------------------------------------------
* deploy chinook demos (14 jun 2015) chinookDemo

lopez, cd /home/sttrweb/lopez/oncoscape/githubDemos:
chinookDemo1-6 -> lopez:11001-11006


*----------------------------------------------------------------------------------------------------
* ahhi, AMLdemo, now create full graph (13 jun 2015)

cd ~/s/data/sage/abhi/aml/chinook/AMLdemo/inst/prep/network/

network structure is created via go.R

vizmap set via style.js

httpSetStyle(rcy, "style.js")   # a new RCyjs method, assumes python -m SimpleHTTPServer

    uses port 8000


*----------------------------------------------------------------------------------------------------
* abhi, AMLdemo, helsinki (12 jun 2015)

cd ~/s/data/sage/abhi/aml/chinook/
in one buffer:  R CMD install AMLdemo
in an R session:  source("launch.R")


*----------------------------------------------------------------------------------------------------
* seattle weather history (12 jun 2015)

http://w2.weather.gov/climate/xmacis.php?wfo=sew

jan     feb     mar     apr     may     jun     jul     aug     sep     oct     nov     dec     annual
2000	3.77	5.25	2.82	1.48	3.27	1.61	0.23	0.33	1.12	3.00	3.27	2.51	28.66
2001	2.70	2.07	2.73	3.16	1.39	3.05	1.03	2.32	0.83	3.13	9.26	5.89	37.56
2002	5.98	4.17	2.82	4.29	1.11	1.73	0.64	0.04	0.42	0.67	3.51	5.98	31.36
2003	8.39	1.76	6.34	2.74	1.16	0.51	0.06	0.32	0.89	8.96	6.77	3.88	41.78
2004	6.36	2.44	2.14	0.65	2.51	0.71	0.16	3.00	2.80	2.80	3.16	4.37	31.10
2005	4.44	1.20	3.71	3.68	3.32	1.63	1.03	0.29	0.75	3.02	5.52	6.85	35.44
2006	11.65	2.55	2.18	2.73	1.65	1.67	0.06	0.02	1.43	1.55	15.63	7.30	48.42
2007	6.22	3.38	4.42	0.69	1.46	1.34	1.44	0.73	3.16	3.32	3.71	9.08	38.95
2008	4.26	1.47	3.65	1.90	0.89	1.64	0.48	2.87	0.78	2.17	6.52	4.10	30.73
2009	5.40	1.51	4.16	3.36	3.61	0.18	0.06	1.16	1.75	5.54	8.96	2.75	38.44
2010	6.17	3.52	3.76	3.49	2.83	2.49	0.31	0.64	4.80	5.24	5.05	8.69	46.99
2011	4.99	3.05	6.29	4.47	3.20	1.42	0.70	0.13	1.29	3.45	5.16	2.24	36.39
2012	6.83	3.63	7.20	2.68	2.05	2.96	1.04	T	0.03	6.71	8.28	6.85	48.26
2013	4.16	1.58	2.74	5.89	2.38	1.30	T	1.35	6.17	1.54	3.79	1.66	32.56
2014	3.70	6.11	9.44	4.18	3.15	0.73	0.77	1.81	2.23	6.75	4.84	4.79	48.50
2015	3.66	5.27	4.47	2.03	0.58	M	M	M	M	M	M	M	M
Mean	5.54	3.06	4.30	2.96	2.16	1.53	0.53	1.00	1.90	3.86	6.23	5.13	38.34




*----------------------------------------------------------------------------------------------------
* extra ports, chinook ports, provided by ben mcgough (7 apr 2015)

chinookDemo1-6 -> lopez:11001-11006

*----------------------------------------------------------------------------------------------------
* summary of (8 jun 2015) tour of sword fern die-off

--- permanent versioned file kept here
~/s/notes/fosp/swordFernDieOff/notes.txt

On Monday June 8th seven of us visited the sword fern die-off area, on
the Hatchery Trail at Seward Park:

Dr. Olaf Riebeiro, plant pathologist
Barbara DeCaro, Natural Resource Conservation Coordinator for Seattle Parks
Lisa Cieko, Plant Ecologist for Seattle Parks
Paul Talbert, President of the Friends of Seward Park
Joseph Manson, Director of Seward Park Audubon
Paul Shanon, Friends of Seward Park, GSP forest steward
Flip (last name needed): Audubon volunteer, naturalist

During the hour we spent at the site, Olaf led an examination of roots
and fronds, and collected soil samples for subsequent analysis.

The following informal observations were made and hypotheses discussed:

1) There are no obvious pathogens or insects responsible for the
die-off.  Small or as yet undetected pathogenic effects may combine
with environmental conditions (see below) to cause the die-off.

2) There are no Douglas Firs in the north-facing "ground zero" slope.
A few down trunks can be found on its periphery.  Many 100 year-old
cedars and a few hemlocks are found.  Ground zero itself (about 6-10k
sq ft) has no trees.  Large spreading canopies of nearby bigleaf
maples provide cover.

3) Laminated root rot was postulated as cause for the absence of live
doug fir.  It was suggested that this disease had swept through the
region decades ago.

4) Olaf found hollow roots in one of the fern samples he dug up, and
speculated that these may harbor insect egggs - which he will test
for.  I do not recall this phenomenon being reported in the four
samples examined prior to our visit (two by Olaf in May, two by Jenny
Glass in November 2014).

5) We had substantial discussion of a "drought hypothesis": that
recent years of reduced rainfall at a site with reduced canopy cover
led to unusually dry soil, fern stress and death.  Experimental
remedies were discussed, including the possible installation of a
cistern and drip irrigation at the top of the ground zero bowl.

6) Monitoring strategies were informally discussed, concluding with
(as yet) no specific plan of action.  Reconvening was discussed, but
no details set, once Olaf's reports are in.

Next steps: I meet with Joy Woods of Kelsey Ketcheson of Restoration
Analytics and Design (RAD) at the site this Friday (June 12th).  We
will discuss possible steps towards a methodical monitoring plan which
would be able to illuminate the drought/canopy hypothesis described
above.  (Crucial in this will be measures to reduce the risk of the
"post hoc fallacy" -- that is, the promotion of plausible-sounding
possible factors into presumed causes, which then become the basis for
future action or inaction.)

Comparisons and controls are needed, perhaps primarily with other
sites at Seward Park, or elsewhere in Seattle.  Some undescribed
combination of factors are apparently unique to this site.
Discovering these will require field work, data collection and data
analysis.

Funding was briefly discussed.  We have thus far relied upon small
contributions from the Friends of Seward Park and the generous pro
bono efforts of Dr. Ribeiro.

$55 will be needed very soon to pay for the soil analysis Olaf is
arranging for.  Any future work by Olaf will need renumeration.
Monitoring may require some funding as well.

I will send out a report of the Friday meeting on site with
Restoration Analytics and Design.





*----------------------------------------------------------------------------------------------------
* old obsolete websocket package (8 jun 2015)

needed to build 1.2.28 of Oncoscape
dir ~/s/src/websockets/
drwxr-xr-x  12 pshannon  staff     408 Jul  1  2014 websockets/
-rw-r--r--   1 pshannon  staff  215894 Jul  1  2014 websockets_1.1.7.tar.gz
-rw-r--r--@  1 pshannon  staff  271515 Jul  2  2014 websockets_1.1.7.zip

*----------------------------------------------------------------------------------------------------
* abhi's aml data, second look (6 jun 2015)

15 patients, 4 with multiple mrna measurements
cd ~/s/data/sage/abhi/aml
subset(as.data.frame(table(tbl.mrna$patient_id)), Freq > 1)
Var1 Freq
1  FHRB.1064   2
10  FHRB.252    8
11  FHRB.560    4
12  FHRB.600    2
14  FHRB.784    2
>


*----------------------------------------------------------------------------------------------------
* add old oncotest1 json network to TCGAgbm inst/extdata (5 jun 2015)

http://oncotest1.sttrcancer.org/
cwMarkers.nodes().length  // 879
cwMarkers.edges().length // 4205

*----------------------------------------------------------------------------------------------------
* with lgg/gbm markers network loading well, layout genes a la eric (5 jun 2015)

cd ~/oncodev/hbolouri/dataPackages/TCGAbrain/inst/import/networks/markers/
currently:  1958 nodes, 19k edges
dir ~/oncodev/hbolouri/dataPackages/networks/TCGAbrainMarkersAndTissues/prep-old/cwMarkers-layout.json

this file apparently current as of 24 apr 2015
cp ~/oncodev/hbolouri/dataPackages/networks/TCGAbrainMarkersAndTissues/prep-old/cwMarkers-layout.json layoutEric-2015apr24.json

--- how to apply these coordinates to current genes?
the old file looks like this:
layout = [{"label":"Y","pos":{"x":1617.1904587862193,"y":2153.788086012285}},
{"label":"X","pos":{"x":1617.1904587862193,"y":2153.788086012285}},
{"label":"9","pos":{"x":-1414.245902212248,"y":865.743450822403}},
{"label":"8","pos":{"x":585.1446430507284,"y":1024.2557831514835}},
{"label":"7","pos":{"x":2349.3202846049976,"y":-156.61755679105173}},
...

--- strategy:
try just the chromosome nodes, which begin with "chr" in the current graph, just a number in old file
this worked, using the following steps

tbl.eric <- fromJSON("layoutEric-chromosomes-only.json")
id <- tbl.eric$label
x <- tbl.eric$pos$x
y <- tbl.eric$pos$y
tbl.eric2 <- data.frame(id=id, x=x, y=y, stringsAsFactors=FALSE)
setPosition(rcy, tbl.eric2)

--- now with all genes and chromosomes (TCGA entries deleted)
tbl.eric3 <- fromJSON("layoutEric-2015apr24-noPatients.json")
id <- tbl.eric3$label
x <- tbl.eric3$pos$x
y <- tbl.eric3$pos$y
tbl.eric4 <- data.frame(id=id, x=x, y=y, stringsAsFactors=FALSE)


*----------------------------------------------------------------------------------------------------
* gbm/lgg common gene list: 834   (4 jun 2015)

cd ~/oncodev/hbolouri/dataPackages/networks/TCGAbrainMarkersAndTissues/prep-old/
go.R shows calculation
starts with class gbm 545 markers
cp'd ~/oncodev/hbolouri/dataPackages/networks/TCGAbrainMarkersAndTissues/prep-old/goi545.RData
cp'd ~/oncodev/hbolouri/dataPackages/networks/TCGAbrainMarkersAndTissues/prep-old/allLists.RData

which has these parts
"goi.all"      "list.cat"     "list.chrom"   "list.cnL.gbm" "list.cnG.gbm" "list.cnL.lgg" "list.cnG.lgg" "list.mut.gbm" "list.mut.lgg"
with goi.all now 834 genes long, with all 545 gbm genes

now using these in ~/oncodev/hbolouri/dataPackages/TCGAbrain/inst/import/networks/markers/go.R


*----------------------------------------------------------------------------------------------------
* seattle parks supplemental use guidelines for natural areas (4 jun 2015)

left message for  David Takami, 206-684-8020
*----------------------------------------------------------------------------------------------------
* re: sword fern die-off (4 jun 2015)

We will tour the sword fern die-off area on the Hatchery Trail at Seward Park, 1 pm on Monday June
8th, organized by the Friends of Seward Park.  We are grateful to those who have offered to attend.

More then 10,000 sq. ft. of previously lush hemlock/fir old growth climax understory is now bare
ground.  The die-off area is growing steadily larger.  No cause has been determined.

The die-off was first reported by Catherine Alexander in the Spring of 2014.  Two plant pathology
laboratory studies have been done, neither of them conclusive (details below).  The die-off may
eventually turn out to be self-limiting.  It could spread far and wide: throughout Seward Park, into
other Seattle parks and throughout the Puget lowland.

A rigorous monitoring program is needed, which is the primary purpose of our meeting.

Some of those attending:

Dr. Olaf Ribeiro,  Bainbridge island plant pathologist (author of "Phytophthora Diseases Worldwide")
Joy Wood, Restoration Analytics and Design
Jon Jainga, Seattle Parks Project Manager
Lisa Ciecko, Seattle Parks Plant Ecologist
Catherine Alexander, naturalist
Paul Talbert, president of the Friends of Seward Park, Fred Hutch molecular biologist




details of which, along with the photos, a video,
and an informal history may be found below.  No conclusive cause of this dramatic die-off has
emerged from these studies.  The effected area appears to be growing steadily larger.

The goal on Monday is to devise a monitoring plan

*----------------------------------------------------------------------------------------------------
* rcy tips: saveLayout, restoreLayout with timestamp (3 jun 2015)

saveLayout(rcy, filename=sprintf("layout.%s", as.numeric(Sys.time())))
restoreLayout(rcy, tail(sort(grep("layout", dir(), value=TRUE)),n=1))

*----------------------------------------------------------------------------------------------------
* markers network for TCGAbrain (3 jun 2015)

draw upon, refine, centralize ~/oncodev/hbolouri/dataPackages/DEMOdz/inst/import/networks/mut/go.R

cd ~/oncodev/hbolouri/dataPackages/TCGA/inst

cd ~/oncodev/hbolouri/dataPackages/TCGAbrain/inst/import/networks/markers

*----------------------------------------------------------------------------------------------------
* abhi's aml data, first look (3 jun 2015)

cd ~/s/data/sage/abhi/aml
---- go.R
tbl.mut <- read.table("mutations.tsv", sep="\t", header=TRUE, as.is=TRUE)
length(unique(tbl.mut$Patient)) # [1] 17
length(unique(tbl.mut$Gene_Name)) # [1] 15504
tbl.dist.effect <- as.data.frame(table(tbl.mut$Effect))   # 866 2
tbl.dist.effect <- tbl.dist.effect[order(tbl.dist.effect$Freq, decreasing=TRUE),]
fivenum(tbl.dist.effect$Freq)   # [1]     1     1     2     4 52065

subset(tbl.dist.effect, Freq > 100)
#                              Var1  Freq
# 354                      missense 52065
# 6           NON_SYNONYMOUS_CODING 22551
# 657                   stop-gained  4832
# 10                    STOP_GAINED  2192
# 724                         utr-3  2113
# 595          missense-near-splice  1382
# 619                      splice-3   997
# 634                      splice-5   894
# 807                         utr-5   760
# 7            SPLICE_SITE_ACCEPTOR   731
# 237               intron,missense   590
# 362               missense,intron   581
# 5                     FRAME_SHIFT   520
# 84  coding-synonymous-near-splice   319
# 8               SPLICE_SITE_DONOR   309
# 394      missense,intron,missense   163
# 191        intron,intron,missense   134
# 238        intron,missense,intron   132
# 752                utr-3,missense   127
# 413      missense,missense,intron   113
# 263      intron,missense,missense   102

tbl.drug <- read.table("drugProcess.tsv", sep="\t", header=TRUE, as.is=TRUE)  # 26 435
length(unique(tbl.drug$SampleID))  # [1] 17
tbl.mrna <- read.table("mRNA_exp.tsv", sep="\t", header=TRUE, as.is=TRUE)  #    28 26904

length(unique(tbl.mrna$patient_id)) #  15

*----------------------------------------------------------------------------------------------------
* rcyjs, create big complex network (5 jun 2015) TCGAbrain markers

~/oncodev/hbolouri/dataPackages/TCGAbrain/inst/import/networks/markers/go.R

*----------------------------------------------------------------------------------------------------
* DEMOdz: here's how to create a dz-specific markers & samples network for oncoscape (3 jun 2015)

cd ~/oncodev/hbolouri/dataPackages/DEMOdz/inst/import/networks/mut/
reload(); rcy <- demo()
start python http server in this directory:
python -m SimpleHTTPServer
--- in browser:
rcy.loadStyle("style.js")
--- in R
showAllEdges(rcy)   # a different rcy!
hideAllEdges(rcy)
showEdges(rcy, "mutation")
g.markers.json <- getJSON(rcy)
nchar(g.markers.json) # [1] 23771
save(g.markers.json, file="../../../extdata/markers.json.RData")
R CMD build DEMOdz

--- view in oncoscape
cd ~/oncodev/hbolouri/oncoDev14/Oncoscape/inst/scripts/markersAndSamples/
make tabs


*----------------------------------------------------------------------------------------------------
* frequently mutated genes from SttrDataPackage/TCGA data sets(1 jun 2015)

# get 10 frequently mutated genes in gbm
library(TCGAgbm)
gbm <- TCGAgbm()
mtx.mut.gbm <- matrices(gbm)$mtx.mut
names.trimmed <- sub(".0[12]$", "", rownames(mtx.mut.gbm))
rownames(mtx.mut.gbm) <- names.trimmed

gene.mutation.counts <- apply(mtx.mut.gbm, 2, function(column) length(which(column != "")))
genes <- names(tail(sort(gene.mutation.counts), n=10))
genes # [1] "FLG" "PIK3CA" "NF1" "SPTA1"  "PIK3R1" "MUC16"  "TTN"    "TP53"   "EGFR"   "PTEN"


*----------------------------------------------------------------------------------------------------
* load and apply hand-edited json style for markers & samples (1 jun 2014)

--- start python webserver
cd ~/oncodev/hbolouri/oncoDev14/Oncoscape/inst/scripts/markersAndSamples/
cd ~/oncodev/hbolouri/dataPackages/DEMOdz/inst/import/networks/mut/
python -m SimpleHTTPServer
dir style.js    # 3399 bytes
source function loadStyle into browser
now
loadStyle("style.js")


function loadStyle(filename){
s = "http://localhost:8000/" + filename;
console.log("=== about to getScript on " + s);

$.getScript(s)
.done(function(script, textStatus) {
console.log(textStatus);
//console.log("style elements " + layout.length);
cy.style(vizmap);
})
.fail(function( jqxhr, settings, exception ) {
console.log("getScript error trying to read " + filename);
});
}

*----------------------------------------------------------------------------------------------------
* add chromosome nodes to DEMOdz markers&samples graph (1 jun 2015)

cd ~/oncodev/hbolouri/dataPackages/DEMOdz/inst/import/networks/mut/

*----------------------------------------------------------------------------------------------------
* summary DEMOdz mutation graph: create in rcyjs, save as json (1 jun 2015)
add to DEMOdz package, display in markers (1 jun 2015)

cd ~/oncodev/hbolouri/dataPackages/DEMOdz/inst/import/networks/mut/

reload(); runTests(); rcy <- run()
g.markers.json <- getJSON(rcy)
nchar(g.markers.json) # [1] 23771
save(g.markers.json, file="../../../extdata/markers.json.RData")

---- test it out in oncodev14, markers & tissues tab
cd ~/oncodev/hbolouri/oncoDev14/Oncoscape/inst/scripts/markersAndSamples/
make tabs
choose DEMOdz, use dataset, view Markers & Patients tab.
crucial lines in Module.markers:

function displayMarkersNetwork(msg) {
console.log("--- Module.markers: displayMarkersNetwork");
console.log(msg);
if(msg.status == "success"){
var json = JSON.parse(msg.payload);
cwMarkers.add(json.elements);
cwMarkers.style(json.style);
}
else{
console.log("displayMarkersNetwork error: " + msg.payload);
}
} // displayMarkersNetwork


*----------------------------------------------------------------------------------------------------
* DEMOdz mutation graph: create in rcyjs, save as json, add to DEMOdz package, display in markers (1 jun 2015)

cd ~/oncodev/hbolouri/dataPackages/DEMOdz/inst/import/networks/mut/
reload(); runTests(); rcy <- run()
g.markers.json <- getJSON(rcy)
nchar(g.markers.json) # [1] 23771
save(g.markers.json, file="../../../extdata/markers.json.RData")


--- remove orphan nodes and all but one pair (ELN -> TCGA.06.0140) to give a really simple test
cy.filter("node:selected").remove()   // in 3 steps
JSON.stringify(cy.json)
format for readability:  paste console text into
http://www.bodurov.com/JsonFormatter/
pasted this 233 lines into a text file "2nodes1edge.json"
g.markers.json <- paste(scan(file="2nodes1edge.json", what=character(), sep="\n"), collapse="")
nchar(g.markers.json)  #  5730
g.markers.json <- gsub(" ", "", g.markers.json)  # [1] 2703 chars
save(g.markers.json, file="../../../extdata/markers.json.RData")
install DEMOdz afresh


*----------------------------------------------------------------------------------------------------
* cyjs tips: calculate and assign node degree dynamically (2 jun 2015)

cy.nodes().map(function(node){return (node.degree())})
cy.nodes().map(function(node){node.data({degree: node.degree()})});

"width"   : "mapData(degree, 0.0, 100.0, 20.0, 100.0)",
"height"  : "mapData(degree, 0.0, 100.0, 20.0, 100.0)",


*----------------------------------------------------------------------------------------------------
* rcyjs tips: export network, layout, style (31 may 2015)

  --- get the id and position of one node
    cy = cwMarkers
    cy.filter("node:selected").data().id
    cy.filter("node:selected").position()

  --- test: get the positions of just the selected nodes
    cy = cwMarkers
    JSON.stringify(cy.filter("node:selected").map(function(node){return ({name: node.data().name, pos: node.position()})}))
    x = [copy and paste into gbmprep js console]
    x.length  // 14
    for(var i=0; i < x.length; i++){
      name = x[i].name
      pos = x[i].pos
      //console.log(name + ": " + pos.x + ", " + pos.y);
      filterString = "node[name='" + name + "']";
      cy.filter(filterString).position({x: pos.x, y: pos.y});
      }


  --- test: set the positions of those selected nodes after manual rearrangement
    xx = cy.filter("node:selected").map(function(node){return ({name: node.data().name, pos: node.position()})})

    cy.nodes().positions(function(i, node){return{x: xx[i].pos.x, y: xx[i].pos.y};});
    for(var i=0; i < xx.length; i++){
       name = xx[i].name;
       x = xx[i].pos.x;
       y = xx[i].pos.y;
       filterString =  "node[name='" + name + "']";
       cy.filter(filterString)
       } // for i


    cy.nodes().positions(function(i, node){return{x: layout[i].pos.x, y:layout[i].pos.y};});

  --- create a single string with all node positions
   JSON.stringify(cy.nodes().map(function(node){return ({name: node.data().name, pos: node.position()})}))




  --- separately, create quoted strings from JSON:

   JSON.stringify(cy.nodes().map(function(node) {return ({id: node.data().id, pos: node.position()})}))
   layoutJSON =  JSON.stringify(cy.nodes().map(function(node) {return ({label: node.data().label, pos: node.position()})}))
   styleJSON = JSON.stringify(cy.json().style)
    networkJSON = JSON.stringify(cy.json().elements)

   --- all in one
    JSON.stringify(cy.json())

   --- save as file
     primitively:  copy and paste from javascript console, as variable assignment
     network = {"elements":
     {"nodes":[
        {"data":{"name":"TCGA.06.0747","nodeType":"patient","label":"TCGA.06.0747","id":"TCGA.06.0747"},...


   --- load it (experimentally, using python http server, to be replaced in time by a websocket message
     plan of action, stealing ideas and code from RCyjs addGraph
     paste contents of ~/oncodev/hbolouri/dataPackages/DEMOdz/inst/import/networks/mut/cyMut.json into console
     cy.remove(cy.elements())
     cy.add(network.elements)
     obj = cy.add(network.elements)   # layout is in network data structure, is replicated here.
     cy.style(network.style)


*----------------------------------------------------------------------------------------------------
* DEMOdz, oncoscape, put networks into data package (30 may 2015)

--- mutations in DEMOdz, using RCyjs
cd ~/oncodev/hbolouri/dataPackages/DEMOdz/inst/import/networks/mut/
reload(); runTests(); run()

uses assisted grid layout described below:
* cyjs typs: manual layout, assisted layout, of  selected nodes into a grid  (javascript)

box = {x1: 1200, y1:180, w: 500, h: 800}
box = {x1: 1200, y1:180, w: 800, h: 800}

cy.filter("node:selected").layout({ name: 'grid', rows: 5, columns: 3, boundingBox: box });
cy.filter("node:selected").layout({ name: 'grid', boundingBox: box });


*----------------------------------------------------------------------------------------------------
* motifdb, add cisbp, 8 cols of metadata now figured out (29 may 2015)

  cd ~/s/bioc/trunk/Rpacks/MotifDb/inst/scripts/import/cisbp
  cp ~/s/data/public/TFBS/cisbp/cisbp-metadata-6559-matrices.Rdata

*----------------------------------------------------------------------------------------------------
* motifdb, cisbp, 8 columns of metadata for each of the 6559 matrices (29 may 2015)

~/s/data/public/TFBS/cisbp/

go.R

library (RMySQL)
db <- dbConnect(MySQL (), dbname='cisbp')
#====================================================================================================
# current best  (friday 29 may)
#====================================================================================================
matrix.names <- list.files("pwms")#[1:53]
matrix.names <- sub(".txt", "", matrix.names, fixed=TRUE)
printf("matrix names: %d", length(matrix.names))
s <- paste(matrix.names, collapse="','")
formatted.matrix.names.as.group <- sprintf("'%s'", s)
matrix.selector <- sprintf("where ma.Motif_ID in (%s)", formatted.matrix.names.as.group)

select <- "select ma.ma_id, ma.tf_id, ma.motif_id, ma.species, tf.TF_Name, ms.PMID, fa.Family_Name, pr.DBID"
from <- "from motif_all as ma, tfs as tf, motifs as mo, motif_sources as ms, tf_families as fa, proteins as pr"
where <- paste(matrix.selector,
"and ma.Motif_ID=mo.Motif_ID",
"and ma.TF_ID = tf.TF_ID",
"and ma.Evidence = 'D'",
"and mo.MSource_ID = ms.MSource_ID",
"and tf.Family_ID = fa.Family_ID",
"and pr.TF_ID = tf.TF_ID"
)

query <- paste(select, from, where, sep=" ")
tbl <- dbGetQuery(db, query)
print(dim(tbl))
print(dim(unique(tbl[, 1:8])))   # [1] 15694     8
print(dim(unique(tbl[, 1:7])))   # [1]  6559    7
dups <- which(duplicated(tbl[, 1:7]))
if(length(dups) > 0)
tbl <- tbl[-dups,]
dim(tbl)
save(tbl, file="cisbp-metadata-6559-matrices.Rdata")

*----------------------------------------------------------------------------------------------------
* motifdb, cisbp, RMySQL: the case of the missing matrix (lacks easy metadata) (29 may 2015)

cd ~/s/data/public/TFBS/cisbp/go.R

# there are 6559 matrix names
list.files("pwms")
# there are 5929 metadata rows, for 3202 unique Motif_IDs
tbl <- dbGetQuery(db, paste(select, from, where, sep=" "))
length(tbl$Motif_ID) # [1] 5929
length(unique(tbl$Motif_ID)) # [1] 3202
length(setdiff(matrix.names, unique(tbl$Motif_ID))) # [1] 3357

Thus 3357 matrices fail this query:
select mb.Motif_ID, tf.TF_Name, Species, PMID, Family_Name, pr.DBID
from  motif_best as mb, tfs as tf, motifs as mo, motif_sources as ms, tf_families as fa, proteins as pr
where mb.Motif_ID in ('M0052_1.02','M0053_1.02') and
mb.Motif_ID=mo.Motif_ID and
mb.TF_ID = tf.TF_ID and
mb.Evidence = 'D' and
mo.MSource_ID = ms.MSource_ID and
tf.Family_ID = fa.Family_ID and
pr.TF_ID = tf.TF_ID"

cherry picking the problem: tow pfalc motifs, one which responds to the general query, one does not

M0052_1.02 PF11_0442 Plasmodium_falciparum 21060817         AP2 PF11_0442


*----------------------------------------------------------------------------------------------------
* rcy3 rebuild gbm/lgg markers & patients graph (27 may 2015)

cd ~/oncodev/hbolouri/dataPackages/networks/TCGAbrainMarkersAndTissues/prep-rcy3/

*----------------------------------------------------------------------------------------------------
* oncoscape big build & test (27 may 2015)

problem:  I test and build with oncoscape packages already in my libPaths.
solution: remove them all before starting

.libPaths() points to  "/Library/Frameworks/R.framework/Versions/3.1/Resources/library"
bash> dir /Library/Frameworks/R.framework/Versions/3.1/Resources/library | grep pshannon

remove.packages(c("Chinook", "DEMOdz", "ModelMPG", "OncoDev", "OncoDev14",
"PLSR", "PatientHistory", "SttrDataPackage", "SttrDataSet",
"TCGAbrain", "TCGAgbm", "TCGAlgg", "TCGAluad", "iDEMOdz"))


came up with this simple script: ~/oncodev/hbolouri/oncoDev14/removeInstalledOncoscapePackages.R

pkgs <- c("DEMOdz", "OncoDev", "OncoDev14",
"PLSR", "PatientHistory", "SttrDataPackage", "SttrDataSet",
"TCGAbrain", "TCGAgbm", "TCGAlgg", "TCGAluad", "iDEMOdz")
pkgs.paths <- file.path(.libPaths(), pkgs)
deleters <- which(file.exists(pkgs.paths))
printf("oncoscape-related packages to remove before testing: %d", length(deleters))
if(length(deleters) > 0){
pkgs.to.remove <- pkgs[deleters];
print(paste("removing package ", paste(pkgs.to.remove, collapse=",")))
remove.packages(pkgs.to.remove, .libPaths())
}



*----------------------------------------------------------------------------------------------------
* fill and test instructions for the small expression dataset in iDEMOdz (26 may 2015)

start mysql: sudo /usr/local/mysql/support-files/mysql.server start

~/oncodev/hbolouri/dataPackages/iDEMOdz/inst/import/expression/
library(RMySQL)
print(load("../../extdata/mrna.RData"))
tbl <- cbind(rownames(mtx.mrna), as.data.frame(mtx.mrna), stringsAsFactors=FALSE)
write.table(tbl, file="mrna.tsv", row.names=FALSE, col.names=FALSE, quote=FALSE, sep="\t")

# for convenience, create here the schema specifying command for this table in sql

s <- sprintf("create table mrna(sample char(30), %s)", noquote(paste(paste(colnames(mtx.mrna), "float"), collapse=", ")))

# sql commands looks like this.  paste it into an sql session
# create databasee DEMOdz;
# use DEMOdz;
#
# create table mrna(sample char(30), EDIL3 float, EED float, EEF2 float, EFEMP2 float, EGFR float, EHD2 float, EIF4A2 float, ELAVL1 float, ELAVL2 float, ELF4 float, ELK4 float, ELL float, ELN float, ELOVL2 float, EML4 float, EMP3 float, PIGP float, PIK3C2B float, PIK3C2G float, PIK3CA float, PIK3CB float, PIK3CD float, PIK3CG float, PIK3R1 float, PIK3R2 float, PIM1 float, PIPOX float, PLA2G5 float, PLAG1 float, PLAU float, PLAUR float, PRPSAP2 float, PRR4 float, PRRX1 float, PSIP1 float, PTBP1 float, PTCH1 float, PTEN float, PTGER4 float, PTK2 float, PTPN11 float, PTPN14 float, PTPN22 float, PTPN6 float, PTPRA float, PTPRC float, TTC28 float, TTC3 float, TTN float, TTPA float, TTYH1 float, TYK2 float, U2AF1 float, UAP1 float, UBN1 float, UBR5 float, UCP2 float, UGT8 float, UNC45A float, UPF1 float, UROS float, USH2A float, USP33 float, USP6 float);
# unfortunately, file path must be explicit and absolute
# load data infile "/Users/pshannon/oncodev/hbolouri/dataPackages/iDEMOdz/inst/import/expression/mrna.tsv" into table mrna fields terminated by "\t";
# test:
#    select * from mrna limit 3;
#
# grant privileges to a sample test user
#  mysql --user=root --password=root
#   GRANT SELECT ON DEMOdz.mrna TO 'oncotest'@'localhost';
#
# now the unit tests should run.



*----------------------------------------------------------------------------------------------------
* add security to a mysql database (26 may 2015)

mysql --user=root --password=root
mysql> REVOKE ALL PRIVILEGES, GRANT OPTION FROM 'oncotest'@'localhost';

where user "oncotest" has password "password"

--- try this out
mysql --user=oncotest --password=password
use DEMOdz; # ERROR 1044 (42000): Access denied for user 'oncotest'@'localhost' to database 'demodz'

--- now make it possible
mysql --user=root --password=root
GRANT SELECT ON DEMOdz.mrna TO 'oncotest'@'localhost';

mysql --user=oncotest --password=password
use DEMOdz;
select * from mrna;  # works!

--- in R, before grant select
db <- iDEMOdz(list(user="oncotest", password="password"))
Error in .local(drv, ...) :
Failed to connect to database: Error: Access denied for user 'oncotest'@'localhost' to database 'demodz'

--- in R, without restarting session
db <- iDEMOdz(list(user="oncotest", password="password"))
x <- matrices(db)
length(x)  # 1
dim(x[[1]])  # [1] 20 65


*----------------------------------------------------------------------------------------------------
* make sure iDEMOdz demo heeds user and password protection (26 may 2015)

db <- dbConnect(MySQL(), user = "root", password = "root", dbname = "DEMOdz")
dbListTables(db)  # [1] "mrna"

db <- dbConnect(MySQL(), user = "joe", password = "blow", dbname = "DEMOdz")
Failed to connect to database: Error: Access denied for user 'joe'@'localhost' (using password: YES)

R> library(iDEMOdz); db <- iDEMOdz(list(user="oncotest", password="password"))
Failed to connect to database: Error: Access denied for user 'oncotest'@'localhost' to database 'demodz'

*----------------------------------------------------------------------------------------------------
* retrieve expression matrix from mysql, for iDEMOdz (26 may 2015)

library (RMySQL)
db <- dbConnect(MySQL (), dbname='DEMOdz')
select <- "select *"
from <- "from mrna"
where <- "";

tbl <- dbGetQuery(db, paste(select, from, sep=" "))


*----------------------------------------------------------------------------------------------------
* store expression matrix as table in mysql, for iDEMOdz (26 may 2015)

--- create a proper file
load("~/oncodev/hbolouri/dataPackages/iDEMOdz/inst/extdata/mtx.mrna.RData")
x <- cbind(rownames(mtx.mrna), as.data.frame(mtx.mrna), stringsAsFactors=FALSE)
write.table(x[, 1:4], file="x.tsv", row.names=FALSE, col.names=FALSE, quote=FALSE, sep="\t")

create database DEMOdz;
use DEMOdz;

in R:  noquote(paste(paste(colnames(mtx.mrna)[1:3], "float"), collapse=", "))
-->  EDIL3 float, EED float, EEF2 float

drop table mrna;
create table mrna (sample char(30), EDIL3 float, EED float, EEF2 float);
data infile "/tmp/x.tsv" into table mrna fields terminated by "\t";
select * from mrna limit 3;
+--------------+-----------+-----------+---------+
| sample       | EDIL3     | EED       | EEF2    |
+--------------+-----------+-----------+---------+
| TCGA.02.0014 |  -1.22294 |   5.87099 | 2.43987 |
| TCGA.02.0021 |  -1.01189 | -0.138074 | 2.26708 |
| TCGA.02.0028 | -0.456194 |  0.967821 | 1.44131 |
+--------------+-----------+-----------+---------+

--- now try again with the full (though still small) DEMOdz mtx.mrna

noquote(paste(paste(colnames(mtx.mrna), "float"), collapse=", "))
EDIL3 float, EED float, EEF2 float, EFEMP2 float, EGFR float, EHD2 float, EIF4A2 float, ELAVL1 float, ELAVL2 float, ELF4 float, ELK4 float, ELL float, ELN float, ELOVL2 float, EML4 float, EMP3 float, PIGP float, PIK3C2B float, PIK3C2G float, PIK3CA float, PIK3CB float, PIK3CD float, PIK3CG float, PIK3R1 float, PIK3R2 float, PIM1 float, PIPOX float, PLA2G5 float, PLAG1 float, PLAU float, PLAUR float, PRPSAP2 float, PRR4 float, PRRX1 float, PSIP1 float, PTBP1 float, PTCH1 float, PTEN float, PTGER4 float, PTK2 float, PTPN11 float, PTPN14 float, PTPN22 float, PTPN6 float, PTPRA float, PTPRC float, TTC28 float, TTC3 float, TTN float, TTPA float, TTYH1 float, TYK2 float, U2AF1 float, UAP1 float, UBN1 float, UBR5 float, UCP2 float, UGT8 float, UNC45A float, UPF1 float, UROS float, USH2A float, USP33 float, USP6 float
drop table mrna;
create table mrna (sample char(30), EDIL3 float, EED float, EEF2 float, EFEMP2 float, EGFR float, EHD2 float, EIF4A2 float, ELAVL1 float, ELAVL2 float, ELF4 float, ELK4 float, ELL float, ELN float, ELOVL2 float, EML4 float, EMP3 float, PIGP float, PIK3C2B float, PIK3C2G float, PIK3CA float, PIK3CB float, PIK3CD float, PIK3CG float, PIK3R1 float, PIK3R2 float, PIM1 float, PIPOX float, PLA2G5 float, PLAG1 float, PLAU float, PLAUR float, PRPSAP2 float, PRR4 float, PRRX1 float, PSIP1 float, PTBP1 float, PTCH1 float, PTEN float, PTGER4 float, PTK2 float, PTPN11 float, PTPN14 float, PTPN22 float, PTPN6 float, PTPRA float, PTPRC float, TTC28 float, TTC3 float, TTN float, TTPA float, TTYH1 float, TYK2 float, U2AF1 float, UAP1 float, UBN1 float, UBR5 float, UCP2 float, UGT8 float, UNC45A float, UPF1 float, UROS float, USH2A float, USP33 float, USP6 float);
load("~/oncodev/hbolouri/dataPackages/iDEMOdz/inst/extdata/mtx.mrna.RData")
x <- cbind(rownames(mtx.mrna), as.data.frame(mtx.mrna), stringsAsFactors=FALSE)
write.table(x, file="x.tsv", row.names=FALSE, col.names=FALSE, quote=FALSE, sep="\t")
load data infile "/tmp/x.tsv" into table mrna fields terminated by "\t";
select * from mrna limit 3;


--- status
successful
mysql on wombat, database DEMOdz, table "mrna"
next up (see above):   remote access from iDEMOdz package



*----------------------------------------------------------------------------------------------------
* store expression matrix as blob in mysql, for iDEMOdz (26 may 2015)

- make sure mysql is started
/usr/local/mysql/bin/mysql -V
- start if need be
sudo /usr/local/mysql/support-files/mysql.server start

mysql> show databases;
create database oncoscapeExperiments;
use oncoscapeExperiments;
create table expression (id integer auto_increment, matrx blob, primary key (id));

show columns from expression;
+-------+---------+------+-----+---------+----------------+
| Field | Type    | Null | Key | Default | Extra          |
+-------+---------+------+-----+---------+----------------+
| id    | int(11) | NO   | PRI | NULL    | auto_increment |
| matrx | blob    | YES  |     | NULL    |                |
+-------+---------+------+-----+---------+----------------+

make sure you can read it:
select length(LOAD_FILE('/Users/pshannon/oncodev/hbolouri/dataPackages/iDEMOdz/inst/extdata/mrna.RData'));
+----------------------------------------------------------------------------------------------------+
| length(LOAD_FILE('/Users/pshannon/oncodev/hbolouri/dataPackages/iDEMOdz/inst/extdata/mrna.RData')) |
+----------------------------------------------------------------------------------------------------+
|                                                                                              10444 |
+----------------------------------------------------------------------------------------------------+

select LOAD_FILE('/Users/pshannon/oncodev/hbolouri/dataPackages/iDEMOdz/inst/extdata/mrna.RData');
insert into expression values(2, load_file('/Users/pshannon/oncodev/hbolouri/dataPackages/iDEMOdz/inst/extdata/mtx.mrna.RData'));

--- get blob sizes
SELECT OCTET_LENGTH(matrx) FROM expression;
+---------------------+
| OCTET_LENGTH(matrx) |
+---------------------+
|               10444 |
|               10444 |
+---------------------+
2 rows in set (0.00 sec)


--- get it back, as file
select matrx into dumpfile "/tmp/mrna2.RData" from expression where id=1;

--- status
perhaps not so attractive after all, in that
- no row/column selection seems available
- extracted blob would be written to a file on the server, leaving unsolved
the problem of transmission, & secure transmission, to the client
see above: load each file, row by row, using "load data infile"

--- remove table, remove blob table
drop table expression;

*----------------------------------------------------------------------------------------------------
* jefferson hort center, doug critchfield (26 may 2015)

684-4111

friendly person on phone (doug's admin?): doug is out today, back tomorrow, she will send me
a calendar invite.

sent email to that friendly person:  necka kapesi
necka.kapesi@seattle.gov
11:44am, 28 may 2015, titled: touring the sword fern die-off at Seward Park

also invited joy wood and kelsey ketcheson of  Restoration Analytics and Design.
wood.joyk@gmail.com   kelsey.soup@gmail.com
*----------------------------------------------------------------------------------------------------
* two stories (sputnik & quetzocoatulus in the garden) sent to davis 12/31/2013

--- part 1, the basic epistemological/historical claim, and ground rules with which to explore it

I want to make a claim, for another era, akin to Virginia Wolf's about modernism:

On or about December 1910, human character changed. I am not saying that one went out, as one
might into a garden, and there saw that a rose had flowered, or that a hen had laid an egg. The
change was not sudden and definite like that. But a change there was, nevertheless; and, since one
must be arbitrary, let us date it about the year 1910.

My version runs something like, "In and around the first decade of the 17th century, the world
became a different place."

--- part 2, ground rules (how to proceed)

As for ground rules, I want them to keep me safe from pomposity, and free of that dreadful tension
I feel whenever I proclaim, or hear someone else proclaim, that such and such is a fact, is the
truth, or NEEDS to be recognized.

I would rather say: maybe the modern atomistic world view would be richer if it had some
alternative worlds (world views) to keep it company.  If you think "maybe so", then here are some
stories you might enjoy, stories about how it came to be, which might provide some openings for
other sensibilities.  None of these stories is TRUE. Some of them might be useful.


Two quotations-from-authority for that:

Dell Hymes in his introduction to "Now I Know Only So Far: Essays in Ethnopoetics":

Let me say again how much there is still to be learned.  It is for that
reason that I adopt as the title a line with which Victoria Howard sometimes
ended what she told in Clackamas: Now I know only this far.

She (and he) went that far.  I want to go further,  in that same direction, as (I hope these quotations don't drive you crazy) Carol Feldman found when studying "teacher talk".  As Jerome Bruner tells it:

let me give an example of stance in teacher talk, one drawn from carol feldman's work. she was
interested in the extent to which teachers' stances toward their subject indicate some sense of the
hypothetical nature of knowledge, its uncertainty, its invitation to further thought. she chose as
an index the use of modal auxiliary markers in teachers' talk to students and in their talk to each
other in the staff room, distinguishing between expressions that contained modals of uncertainty and
probability (like might, could, and so on) and expressions not so marked.  modals expressing a
stance of uncertainty or doubt in teacher to to teachers far outnumber their occurence in teacher
talk to students.  the world that the teachers were presenting to their students was a far more
settled, far less hypothetical, far less negotiatory world than the one they were offering to their
colleagues.

To summarize: I want to find a non-dogmatic stance, easygoing and exploratory, and fill both my own
mind and the mind of any readers I might attract, with some stories that give me pleasure, and that
help me navigate this life.


--- message 2

clifford geertz writes:

"Believing, with Max Weber, that man is an animal suspended in webs
of significance he himself has spun, I take culture to be those
webs, and the analysis of it to be therefore not an experimental
science in search of law but an interpretative one in search of meaning.


or: we swim in a sea of stories -- which overlap, collide, mix
and dissolve.  we are mightily tempted to think we see, know and
manipulate the world as it actually is, but in fact we do all of those things
only indirectly through the stories we inhabit, be they scientific theories, religions,
national histories,  political committments, or folk realisms of any sort.

our stories, the bigger ones at least, depict entire worlds.
self-consistent worlds.  the stories tell us what the important
objects in the worlds are, how they relate to and affect each other.
who has power, what to be afraid of, what goals are worth pursuing.
such a story, once analyzed, once well understood, specifies and
illuminates an entire metaphysics, its ontology, its values.

a large amount of human travail can be traced to ascribing Truth to a
story, and predictably enough, to feeling intolerant of other stories.
Far better that that travail, and possibly leading to some increase in
liberation and happiness - to some greater skill at being human -- may come
from discerning instead only some small "t" truths in stories: understanding how stories
work,  getting good at telling and using a variety of (conflicting) stories, each in its
own time and place, and in flexible and apt combinations.

here are two stories.  they suggest some of the uneasy seas in which I
myself have swum, some of silken threads out of which the web of my own
live has been constructed.

these stories adumbrate world views -- they suggest worlds.  I aspire to
to navigate these worlds, and do so deftly.


story 1: sputnik in the skies over oklahoma

one of my earliest memories is easy to trace to a specific date: the
first week of October 1958.  I was not quite six years old.  I stood
with my parents, my brother and neighbors on a quiet street in the
officer's residential section of Fort Sill Oklahoma, at night, away
from the street lights. overhead, in the great plains fall night sky,
an adult neighbor  located and pointed out a moving dot to all of us there
assembled: Sputnik.

My father was then a career army officer, West Point graduate, a
mid-level manager of missile programs.  After WWII he had worked in
the general vicinity of the German rocket scientist Werner von Braun,
creator of the V-2 rockets which had terrorized England, and later the
architect of the Saturn V rocket which landed men on the moon.  Though
reviled as a Nazi, he had been acquired as a valuable prize to the US
during the cold war space race.   Engineering, missiles, nuclear and
conventional warfare, career advancement: these dominated my father's life.

The suprise success of Sputnik sounded an alarm to my father, to his
colleagues, the US defense community, politicians and the country as a
whole.  That alarm rang down through the next American decade, changed
public school curricula, research budgets and our national sense of
self.  Fallout shelters and nuclear attack drills.

I was a kid who had, or managed to acquire, a knack for math and
science, which were highly valued in the age of "the American Sputnik
crisis, began the Space Age and triggered the Space Race, a part of
the larger Cold War. The launch ushered in new political, military,
technological, and scientific developments."  I pursued and polished
those skills.  I grew up in a world shaped by physics, engineering,
nationalism and fear.

story 2: Quetzalcoatlus in my back garden.

Fourteen years later, I dropped out of college when the viet nam
war era draft ended.  no longer a math & science guy, I had drifted
towards philosophy and literature.  I worked as a gardener, learned
some carpentry, did odd jobs, read widely.  I planted a garden.

i dreamed one night, during that rather unorganized period of my life,
that while digging in that small backyard garden, getting ready to
plant a spring crop, that the blade of my shovel encountered something
soft.  Puzzled and looking closer, i saw that i had sliced through a
large undeveloped egg, maybe 16 inches long.  now digging more
carefully, i unearthed two additional eggs, one of which started to
crack open after I laid it on the grass: whatever was inside that egg
was pecking to get out. a wet sticky winged creature emerged and
unfurled itself, and grew rapidly to its full height.  A very
considerable full height.  i recognized this creature as a
Quetzacoatulus, a flying dinosaur, among the largest flying creatures
to ever inhabit the earth.  It had a 35 foot wingspan.  It could fly
transcontinental distances, "up to 80 miles an hour for 7 to 10 days
at altitudes of 15,000 feet".

this creature instructed me to climb on its back. how it communicated I can no longer recall.
I was told to shinny forward, grab hold, and take a seat
at the base of his long neck.  Which I did.  The creature took off,
and we flew through the university, Thomas Jefferson's University of
Virginia, where I had studied fitfully for a couple of years; where I
had recently worked much more happily as a gardener and laborer in gardens
designed by Jefferson, enclosed by serpentine brick walls; past the
Biology department where I was auditing a class (again, fitfully) on plant
morphogenesis; to the university's medical center.  reaching
that last location, the creature by now clearly aggravated by my anxious
grasping at its neck, and by my nervous plucking at its feather-like
coat, told me in a way I instantly knew had broad, full-life
ramifications:  I should just for pete's sake RELAX!

This creature's time on the planet had long since past.  It's entire
order was extinct, vanished suddenly in the massive
Cretaceous-Triassic extinction.  Whose individual return, here on this
spring day in central Virginia, did not likely presage a return of its
species to a flourishing life.  Whatever the mechanism and duration of
this visit, I got the message: the long flow of life -- its flow full of
extinction, of occasional horrors, of life frequently beautiful and endlessly
prolific, everything transient, that this life was at present producing me, and I was
squandering the opportunity by worrying about things.  my visitor had
sharp words for me: you fool!  stop fussing.  do whatever work you are
called to do.  but do -enjoy- the ride.


*----------------------------------------------------------------------------------------------------
* testing strategies for jQuery DataTable (25 may 2015)

tableRef.settings()[0]._iDisplayLength  // 10
tableRef.settings()[0]._iRecordsTotal   // 32

$("#browserTable").DataTable().page.info()
{page: 3,
pages: 4,
start: 30,
end: 32,
length: 10…}

$("#browserTable").DataTable().settings()[0]._iRecordsTotal // 32


-- programmatically click a row, selection happens since that event connection is registered:

$('#browserTable tbody').on( 'click', 'tr', function (){
var rowName = $('td', this).eq(0).text();
if($(this).hasClass("selected")){  // remove selection
$(this).removeClass('selected');
var whichRow = currentlySelectedRows.indexOf(rowName);
if(whichRow >= 0)
currentlySelectedRows.splice(whichRow, 1);
} // if row was already selected
else{ // add selection
$(this).addClass('selected');
currentlySelectedRows.push(rowName);
}
selectedRowCountReadout.val(currentlySelectedRows.length);
});


$('#browserTable tbody tr')[4].click()
$('#browserTable tbody tr')[5].click()

$("#browserTable_first").click()
$("#browserTable_last").click()

-- table tools: promising, but not yet expedient
<script src="//cdn.datatables.net/tabletools/2.2.4/js/dataTables.tableTools.min.js"></script>
<link rel="stylesheet" href="//cdn.datatables.net/tabletools/2.2.4/css/dataTables.tableTools.css">

oTT = TableTools.fnGetInstance('browserTable');
oTT.fnSelect( $('#browserTable tbody tr')[3] );

-- programmatically click a row

*----------------------------------------------------------------------------------------------------
* jQuery DataTable() vs dataTable()

The former returns a DataTables API instance, while the latter returns a jQuery object.
http://datatables.net/reference/api/

can't get DataTable to work so I posted to stack overflow:
https://stackoverflow.com/questions/31015372/example-datatable-returns-empty-array

*----------------------------------------------------------------------------------------------------
*

I talked to your mom last night.  she said
she had been ragging on you. please
forgive her: she gets anxious.

But don't YOU get anxious!  a late
assignment, a B or a C now and then:
this only shows you are not a machine.
we each have our own kinds of genius;
you have a full complement.  4.0 grades,
stanford and etc - that particular
genius is not yours - a relief to me, 3x
college dropout that I am!

Please forgive yourself your imperfections, and pay not much attention to things that don't go right.

Like a tall doug fir, like a
mountain, like a whale at sea:
you -belong- here, you have
your particular great gifts,
you have good and important
work that is particularly
yours to do - work you have
already begun.

It is one of the great
pleasures of my life to know
you, to see the life (the
different lives) you invent
for yourself, to see (and
experience) the kindness you
show to people.  you make us
proud.








*----------------------------------------------------------------------------------------------------
* finalizer, from martin (21 may 2015)

e = new.env()
?reg.finalizer
e[["foo"]] = "goodbye hal"
reg.finalizer(e, function(self) { cat("say goodbye\n", self[["foo"]], "\n") })
NULL
rm(e)
gc()
say goodbye
goodbye hal


*----------------------------------------------------------------------------------------------------
* motifdb, cisbp, RMySQL join example (20 may 2015)

[from work-in-progress, ~/s/bioc/trunk/Rpacks/MotifDb/inst/scripts/import/cisbp/import.R
createMetadataTable = function (dataDir, motifIDs)

[also in ~/s/data/public/TFBS/cisbp/go.R]

library (RMySQL)
db <- dbConnect(MySQL (), dbname='cisbp')
matrix.names <- list.files("pwms")
matrix.names <- sub(".txt", "", matrix.names, fixed=TRUE)

printf("matrix names: %d", length(matrix.names))

s <- paste(matrix.names, collapse="','")
formatted.matrix.names.as.group <- sprintf("'%s'", s)


select <- "select mb.Motif_ID, tf.TF_Name, Species, PMID, Family_Name, pr.DBID"
from <- "from  motif_best as mb, tfs as tf, motifs as mo, motif_sources as ms, tf_families as fa, proteins as pr"
matrix.selector <- sprintf("where mb.Motif_ID in (%s) and ", formatted.matrix.names.as.group)

where <- paste(matrix.selector,
"mb.Motif_ID=mo.Motif_ID and",
"mb.TF_ID = tf.TF_ID and",
"mb.Evidence = 'D' and",
"mo.MSource_ID = ms.MSource_ID and",
"tf.Family_ID = fa.Family_ID and",
"pr.TF_ID = tf.TF_ID")

tbl <- dbGetQuery(db, paste(select, from, where, sep=" "))
printf("metadata tbl rows before removing dups: %d", nrow(tbl))
dups <- which(duplicated(tbl[, -(grep("DBID", colnames(tbl)))]))
if(length(dups) > 0)
tbl <- tbl[-dups,]

printf("metadata tbl after before removing dups: %d", nrow(tbl))

--- results
[1] matrix names: 6559
[1] metadata tbl rows before removing dups: 5929
[1] metadata tbl after before removing dups: 3202

head(as.list((sort(table(tbl$Species), decreasing=TRUE))), n=20)

Homo_sapiens: 731
Mus_musculus: 502
Drosophila_melanogaster: 329
Arabidopsis_thaliana: 313
Saccharomyces_cerevisiae: 223
Caenorhabditis_elegans: 195
Neurospora_crassa: 119
Oryza_sativa: 52
Dictyostelium_discoideum: 37
PBM_CONSTRUCTS: 33
Zea_mays: 30
Nicotiana_tabacum: 25
Physcomitrella_patens: 25
Ostreococcus_tauri: 24
Rattus_norvegicus: 24
Petunia_x_hybrida: 23
Nematostella_vectensis: 22
Solanum_lycopersicum: 22
Plasmodium_falciparum: 20
Cannabis_sativa: 19

*----------------------------------------------------------------------------------------------------
* motifdb: add arabidopsis (18 may 2015)

Determination and Inference of Eukaryotic Transcription Factor Sequence Specificity
Weirauch et al, Cell sep 2014
pmid 25215497

CIS-BP Database: Catalog of Inferred Sequence Binding Preferences
http://cisbp.ccbr.utoronto.ca/

cd ~/s/bioc/trunk/Rpacks/MotifDb/inst/scripts/import/cis-bp
get sql tables

cd ~/s/data/public/TFBS/cisbp
http://cisbp.ccbr.utoronto.ca/data/1.02/DataFiles/SQLDumps/SQLArchive_cisbp_1.02.zip (111M)
unzip *.zip
use tmp script to unzip all of the sql files

--- try to load all of these tables into a fresh cisbp mysql database
mysql version
create database cisbp;
use cisbp;
source cisbp_1.02.db_links.sql;

found error message in the text at bottom of very long neighbors file.
sent message via cisbp website

ERROR 1064 (42000) at line 6016722: You have an error in your SQL
syntax; check the manual that corresponds to your MySQL server
version for the right syntax to use near '<br />

<b>Fatal error</b>: Maximum execution time of 300 seconds exceeded

--- check quality of load by getting row counts
need to know schema name
select distinct table_schema from information_schema.tables;
+--------------------+
| table_schema       |
+--------------------+
| information_schema |
| cgds_public        |
| cgds_test          |
| cisbp              |
| datatable          |
| ebookshop          |
| mysql              |
| performance_schema |
| uniprobe           |
+--------------------+


now get the row counts
select table_name, table_rows from information_schema.tables where table_schema = "cisbp";
+--------------------+------------+
| table_name         | table_rows |
+--------------------+------------+
| db_links           |         67 |
| domains            |         88 |
| motif_all          |    1087799 |
| motif_best         |      59976 |
| motif_best_8mer    |      46232 |
| motif_features     |      10717 |
| motif_sources      |         29 |
| motifs             |       6559 |
| neighbors          |    1287841 |
| prot_features      |     523085 |
| proteins           |     190334 |
| search_ids         |    1115519 |
| stats_by_data_type |         13 |
| stats_by_dbd       |         90 |
| stats_by_species   |        340 |
| stats_by_study     |         29 |
| tf_families        |        263 |
| tf_neighbors       |    6009408 |
| tf_sources         |         95 |
| tfs                |     167081 |
| version            |         14 |
+--------------------+------------+

--- explore using these tables by recalling how MotifDb is used
library(MotifDb)
mdb <- MotifDb
indices = grep ('egr1', values (mdb)$geneSymbol, ignore.case=TRUE)
organism.rows = grep ('hsapiens', values (mdb)$organism, ignore.case=TRUE)
egr1.human <- intersect(indices, organism.rows)   # 2190 2301 2302
names(as.list (mdb [egr1.human]))
"Hsapiens-JASPAR_2014-EGR1-MA0162.2"
"Hsapiens-jolma2013-EGR1"
"Hsapiens-jolma2013-EGR1-2"

seqLogo(mdb[[egr1.human[1]]])

1         2          3          4          5         6 7          8          9         10         11        12         13        14
A 0.08958877 0.1228786 0.09464752 0.10892624 0.01901110 0.2375163 0 0.00000000 0.00000000 0.29797650 0.00000000 0.1932115 0.00000000 0.2468995
C 0.46736292 0.5586651 0.49355418 0.85109334 0.94435379 0.0000000 1 0.96703655 0.82849217 0.68219648 0.97519582 0.0000000 0.80360640 0.4565111
G 0.25155026 0.1108845 0.18358355 0.00000000 0.00000000 0.5580940 0 0.00000000 0.04985313 0.00000000 0.00000000 0.5384302 0.11586162 0.1560868
T 0.19149804 0.2075718 0.22821475 0.03998042 0.03663512 0.2043897 0 0.03296345 0.12165470 0.01982702 0.02480418 0.2683584 0.08053198 0.1405026

seqLogo(mdb[[egr1.human[1]]])
consensusString(mdb[[egr1.human[1]]])  #  "?C?CCGCCCCCGC?"

--- try with ELK4, identified in the cisbp paper:

a recent study implicated rs554219 in estrogen-receptor-positive breast cancer tumors and used a
series of experiments to predict and eventually establish that this SNP causes the differential
binding of two Ets family TFs, ELK4 and GABPA

indices = grep ('elk4', values (MotifDb)$geneSymbol, ignore.case=TRUE)  # 3, all human

consensusString(as.list(mdb[indices])[[1]])  [1]   "ACCGGAAGT"
consensusString(as.list(mdb[indices])[[2]])  [1]    "?CACTTCCGG?"
consensusString(as.list(mdb[indices])[[3]])  [1]   "ACCGGAAGT?"

--- now look for this in the cisbp database
intially clueless, did grep -i elk4 *.sql
found this:

--- cisbp_1.02.motifs.sql  (5 total)

| Motif_ID   | TF_ID        | MSource_ID |   DBID  | Motif_Type | Motif_Sequence                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              | IUPAC       | IUPAC_REV   |
('M0703_1.02', 'T078280_1.02', 'MS27_1.02', 'Elk4', 'PBM', 'MDSAITLWQFLLQLLQEPQNEHMICWTSNNGEFKLLQAEEVARLWGIRKNKPNMNYDKLSRALRYYYVKNIIKKVNGQKFVYKFVSYPEILKMDPLTVGRIEGDCEALNSIETSSSKDVEYGGKERPPQPGAKTSSRNDYIHSGLYSSFTLNSLNTSNKKLFKSIKIENPAEKLAEKKAQEPTPSVIKFVTTPAKKPPIEPVAAAFATSPSLSPSSEETIQALETLVSPTLPSLETPASISILATTFNPTPPVPSTPLPLKEPPRTPSPPLSSNPDIDTDIESVASQPMELPENLSLEPKNEDSALPEKDKTNNSSRSKKPKGLELTPALVVTGSDPSPLGILSPSLPTASLTPALFSQTPILLTPSPLLSSIHFWSTLSPFAPLSPARLQGANTLFQFPSVLNSHGPFTLSGLDGPSTPGPFSPDLQKT', 'NNVCGGAWRH', 'DYWTCCGBNN'),
('M4522_1.02', 'T078000_1.02', 'MS13_1.02', 'HEK293b_ELK4_UCD', 'ChIP-seq', 'NULL', 'CCGGAAGYNV', 'BNRCTTCCGG'),
('M4539_1.02', 'T078000_1.02', 'MS13_1.02', 'HeLa-S3_ELK4_UCD', 'ChIP-seq', 'NULL', 'NVCCGGAAGYN', 'NRCTTCCGGBN'),
('M5385_1.02', 'T078000_1.02', 'MS20_1.02', 'ELK4_1', 'SELEX', 'NULL', 'ACCGGAARYN', 'NRYTTCCGGT'),
('M6209_1.02', 'T078000_1.02', 'MS18_1.02', 'ELK4_f1', 'HocoMoco', 'NULL', 'VACCGGAWGYV', 'BRCWTCCGGTB'),

--- cisbp_1.02.search_ids.sql  (58 total)
| Search_ID          | Text | TF_IDs       |
('I0382929_1.02', 'ELK4-001', 'T078000_1.02'),
('I0382930_1.02', 'Elk4-001', 'T078280_1.02'),
('I0382931_1.02', 'ELK4-002', 'T078000_1.02'),
('I0382932_1.02', 'Elk4-002', 'T078280_1.02'),
('I0382933_1.02', 'ELK4-003', 'T078000_1.02'),

--- cisbp_1.02.tfs.sql   (31 total)
TF_ID        | Family_ID | TSource_ID | DBID        | TF_Name    | TF_Species            | TF_Status |
('T077950_1.02', 'F153_1.02', 'TS19_1.02', 'ENSETEG00000013109', 'ELK4', 'Echinops_telfairi', 'I'),
('T077969_1.02', 'F153_1.02', 'TS19_1.02', 'ENSFCAG00000006723', 'ELK4', 'Felis_catus', 'I'),
('T078000_1.02', 'F153_1.02', 'TS19_1.02', 'ENSG00000158711', 'ELK4', 'Homo_sapiens', 'D'),
('T078021_1.02', 'F153_1.02', 'TS19_1.02', 'ENSGACG00000010970', 'ELK4', 'Gasterosteus_aculeatus', 'I'),



select * from search_ids where Text="ELK4";          # 38 rows
select * from search_ids where Text like "%ELK4%";   # 58 rows

+---------------+------+--------------+
| Search_ID     | Text | TF_IDs       |
+---------------+------+--------------+
| I0382947_1.02 | ELK4 | T077649_1.02 |
| I0382948_1.02 | ELK4 | T077662_1.02 |
| I0382949_1.02 | ELK4 | T077700_1.02 |
...


--- what does the metadata for elk4 look like in motifdb?
indices = grep ('elk4', values (MotifDb)$geneSymbol, ignore.case=TRUE)  # 1316 2191 2390
t(as.matrix(mcols(mdb)[indices,]))
[,1]                      [,2]                      [,3]
providerName    "ELK4"                    "ELK4"                    "Hsapiens-jolma2013-ELK4"
providerId      "MA0076.1"                "MA0076.2"                "ELK4"
dataSource      "JASPAR_CORE"             "JASPAR_2014"             "jolma2013"
geneSymbol      "ELK4"                    "ELK4"                    "ELK4"
geneId          "2005"                    "2005"                    "2005"
geneIdType      "ENTREZ"                  "ENTREZ"                  "ENTREZ"
proteinId       "P28324"                  "P28324"                  NA
proteinIdType   "UNIPROT"                 "UNIPROT"                 NA
organism        "Hsapiens"                "Hsapiens"                "Hsapiens"
sequenceCount   "20"                      "3427"                    "33786"
bindingSequence NA                        NA                        "ACCGGAARTN"
bindingDomain   "Winged Helix-Turn-Helix" "Winged Helix-Turn-Helix" NA
tfFamily        "Ets"                     "Ets"                     "ETS"
experimentType  "SELEX"                   "ChIP-seq"                "SELEX"
pubmedID        "8524663"                 "8524663"                 "23332764"


--- figure out cross-referencing ids through the cisbp data tables
db_links
domains:   try motifs.TF_ID -> motfis.Domain_ID -> domains.Domain_ID
mysql>  select * from domains limit 3;
+-----------+-------------+-----------+-----------+------------+-------------+
| Domain_ID | Domain_Name | Pfam_Name | Pfam_DBID | Inter_DBID | Domain_Type |
+-----------+-------------+-----------+-----------+------------+-------------+
| D01_1.02  | ABF1        | BAF1_ABF1 | PF04684   | IPR006774  | DBD         |
| D02_1.02  | AFT         | AFT       | PF08731   | IPR014842  | DBD         |
| D03_1.02  | AP2         | AP2       | PF00847   | IPR001471  | DBD         |
+-----------+-------------+-----------+-----------+------------+-------------+


motif_all
mysql>  select * from motif_all where TF_ID = 'T078000_1.02';   # 89 rows
+----------------+--------------+------------+----------+--------------+
| MA_ID          | TF_ID        | Motif_ID   | Evidence | Species      |
+----------------+--------------+------------+----------+--------------+
| MA0241503_1.02 | T078000_1.02 | M0689_1.02 | I        | Homo_sapiens |
| MA0241504_1.02 | T078000_1.02 | M0690_1.02 | I        | Homo_sapiens |
| MA0241505_1.02 | T078000_1.02 | M0692_1.02 | I        | Homo_sapiens |
....

motif_best
mysql>  select * from motif_best where TF_ID = 'T078000_1.02';
+--------------+--------------+------------+----------+--------------+
| MB_ID        | TF_ID        | Motif_ID   | Evidence | Species      |
+--------------+--------------+------------+----------+--------------+
| MB25189_1.02 | T078000_1.02 | M1903_1.02 | D        | Homo_sapiens |
+--------------+--------------+------------+----------+--------------+

motif_best_8mer
mysql>  select * from motif_best_8mer where TF_ID = 'T07
+---------------+--------------+------------+----------+
| MBE_ID        | TF_ID        | Motif_ID   | Evidence |
+---------------+--------------+------------+----------+
| MBE17364_1.02 | T078000_1.02 | M1903_1.02 | D        |
+---------------+--------------+------------+----------+

motif_features
mysql>  select * from motif_features where Motif_ID = "M1903_1.02";
+-------------+------------+-----------+---------------+-------------+--------------------------------------------------------------------------------------+
| MFeature_ID | Motif_ID   | Domain_ID | Motif_FromPos | Motif_ToPos | MotifFeature_Sequence                                                                |
+-------------+------------+-----------+---------------+-------------+--------------------------------------------------------------------------------------+
| MF02611_1.0 | M1903_1.02 | D31_1.02  |             4 |          87 | AITLWQFLLQLLQKPQNKHMICWTSNDGQFKLLQAEEVARLWGIRKNKPNMNYDKLSRALRYYYVKNIIKKVNGQKFVYKFVSY |
+-------------+------------+-----------+---------------+-------------+--------------------------------------------------------------------------------------+
motif_sources
select * from motif_sources where MSource_ID = "MS19_1.02";
+------------+--------------------+--------------+----------------+--------------+----------+-----------------+
| MSource_ID | MSource_Identifier | MSource_Type | MSource_Author | MSource_Year | PMID     | MSource_Version |
+------------+--------------------+--------------+----------------+--------------+----------+-----------------+
| MS19_1.02  | JASPAR             | JASPAR       | Mathelier      |         2014 | 24194598 | August 201      |
+------------+--------------------+--------------+----------------+--------------+----------+-----------------+




motifs
select * from motifs where  TF_ID = 'T078000_1.02';
+------------+--------------+------------+------------------+------------+----------------+-------------+-------------+
| Motif_ID   | TF_ID        | MSource_ID | DBID             | Motif_Type | Motif_Sequence | IUPAC       | IUPAC_REV   |
+------------+--------------+------------+------------------+------------+----------------+-------------+-------------+
| M1903_1.02 | T078000_1.02 | MS19_1.02  | MA0076.2         | ChIP-seq   | NULL           | VCCGGAAGYVV | BBRCTTCCGGB |
| M3858_1.02 | T078000_1.02 | MS26_1.02  | V$SAP1A_01       | Transfac   | NULL           | NULL        | NULL        |
| M3859_1.02 | T078000_1.02 | MS26_1.02  | V$SAP1A_Q6       | Transfac   | NULL           | NULL        | NULL        |
| M4522_1.02 | T078000_1.02 | MS13_1.02  | HEK293b_ELK4_UCD | ChIP-seq   | NULL           | CCGGAAGYNV  | BNRCTTCCGG  |
| M4539_1.02 | T078000_1.02 | MS13_1.02  | HeLa-S3_ELK4_UCD | ChIP-seq   | NULL           | NVCCGGAAGYN | NRCTTCCGGBN |
| M5385_1.02 | T078000_1.02 | MS20_1.02  | ELK4_1           | SELEX      | NULL           | ACCGGAARYN  | NRYTTCCGGT  |
| M6209_1.02 | T078000_1.02 | MS18_1.02  | ELK4_f1          | HocoMoco   | NULL           | VACCGGAWGYV | BRCWTCCGGTB |
+------------+--------------+------------+------------------+------------+----------------+-------------+-------------+




neighbors
prot_features
mysql>  select * from prot_features limit 3;
+---------------+--------------+-----------+---------------------+-------------------+------------------------
| PFeature_ID   | Protein_ID   | Domain_ID | ProtFeature_FromPos | ProtFeature_ToPos | ProtFeature_Sequence
+---------------+--------------+-----------+---------------------+-------------------+------------------------
| PF000001_1.02 | P000001_1.02 | D01_1.02  |                 733 |               854 | TGKPQIEGMLVKKGALALAKAKS
| PF000002_1.02 | P000001_1.02 | D06_1.02  |                1948 |              2039 | LHRWGPSAKELSAIKKYLATQSI
| PF000003_1.02 | P000002_1.02 | D01_1.02  |                 226 |               336 | PGSMQMPTPDALSLALPMAAVAA
+---------------+--------------+-----------+---------------------+-------------------+------------------------
proteins:   select * from proteins where  TF_ID = 'T078000_1.02';
+--------------+--------------+-----------------+--------------+--------------------
| Protein_ID   | TF_ID        | DBID            | Protein_Type | Protein_Sequence
+--------------+--------------+-----------------+--------------+--------------------
| P091134_1.02 | T078000_1.02 | ENSP00000289703 | Genome       | MDSAITLWQFLLQLLQKPQ
| P091135_1.02 | T078000_1.02 | ENSP00000350681 | Genome       | MDSAITLWQFLLQLLQKPQ
+--------------+--------------+-----------------+--------------+--------------------       | Protein_ID   | TF_ID        | DBID         | Protein_Type | Protein_Sequence

---- search_ids   128 entries for T078000_1.02
| Search_ID     | Text                  | TF_IDs       |
stats_by_data_type
stats_by_dbd
stats_by_species
stats_by_study
---- tf_families
| Family_ID | Family_Name      | DBDs                | DBD_Count | Cutoff |
tf_neighbors
tf_sources

--- tfs        | TF_ID        | Family_ID | TSource_ID | DBID            | TF_Name | TF_Species   | TF_Status |
+--------------+-----------+------------+-----------------+---------+--------------+-----------+
| T078000_1.02 | F153_1.02 | TS19_1.02  | ENSG00000158711 | ELK4    | Homo_sapiens | D         |
version



---- cat pwms/M1903_1.02.txt  6558 matrices total!

Pos	A	C	G	T
1	0.354829296761018	0.194922672891739	0.365625911876278	0.0846221184709655
2	0.0242194339072068	0.829588561423984	0.146192004668809	0.0
3	0.14940180916253	0.85059819083747	0.0	0.0
4	0.0	0.0	1.0	0.0
5	0.0	0.0	1.0	0.0
6	1.0	0.0	0.0	0.0
7	0.997665596731835	0.0	0.0	0.00233440326816459
8	0.21097169536037	0.0046688065363292	0.784359498103301	0.0
9	0.0612780857893204	0.302888824044352	0.0423110592354833	0.593522030930844
10	0.16370002918004	0.16632623285673	0.55587977823169	0.11409395973154
11	0.22906332068865	0.25853516194923	0.42544499562299	0.08695652173913



---- for each Motif_ID, try to build out a record
sample Motif_IDs from one of ELK4's TF_ids: select Motif_ID from motifs where  TF_ID = 'T078000_1.02';
M1903_1.02, M3858_1.02, M3859_1.02, M4522_1.02, M4539_1.02, M5385_1.02, M6209_1.02
each of these is a tsv file: /Users/pshannon/s/data/public/TFBS/cisbp/pwms/M1903_1.02.txt 572 Apr 16 19:16
create a row like these (which have been transposed)

providerName    "ELK4"                    "ELK4"                    "Hsapiens-jolma2013-ELK4"
providerId      "MA0076.1"                "MA0076.2"                "ELK4"
dataSource      "JASPAR_CORE"             "JASPAR_2014"             "jolma2013"
geneSymbol      "ELK4"                    "ELK4"                    "ELK4"
geneId          "2005"                    "2005"                    "2005"
geneIdType      "ENTREZ"                  "ENTREZ"                  "ENTREZ"
proteinId       "P28324"                  "P28324"                  NA
proteinIdType   "UNIPROT"                 "UNIPROT"                 NA
organism        "Hsapiens"                "Hsapiens"                "Hsapiens"
sequenceCount   "20"                      "3427"                    "33786"
bindingSequence NA                        NA                        "ACCGGAARTN"
bindingDomain   "Winged Helix-Turn-Helix" "Winged Helix-Turn-Helix" NA
tfFamily        "Ets"                     "Ets"                     "ETS"
experimentType  "SELEX"                   "ChIP-seq"                "SELEX"
pubmedID        "8524663"                 "8524663"                 "23332764"

1) from Motif_ID, get TF_ID
select TF_ID from motif_best where Motif_ID = 'M1903_1.02';  # 10 rows
2) from TF_ID, get TF_Species:
select TF_Species from tfs where TF_ID = 'T077756_1.02';


# example join:   select * from db.gene AS dbg, genePheno as g where dbg.gene_id=g.id
# example join:  select t.a,t.b from t,s where t.a=s.a and t.b between 50000 and 50020;

3) select * from motif_best as mb, tfs where mb.Motif_ID='M1903_1.02' and mb.TF_ID = tfs.TF_ID;
select mb.Motif_ID, tfs.TF_ID, Species from motif_best as mb, tfs as tfs where mb.Motif_ID='M1903_1.02' and mb.TF_ID = tfs.TF_ID;
select mb.Motif_ID, MSource_ID, tfs.TF_ID, tfs.TF_Name, Species from motif_best as mb, tfs as tfs, motifs where mb.Motif_ID='M1903_1.02' and mb.Motif_ID=motifs.Motif_ID and  mb.TF_ID = tfs.TF_ID;



select mb.Motif_ID, tf.TF_Name, Species, PMID
from   motif_best as mb, tfs as tf, motifs as mo, motif_sources as ms
where  mb.Motif_ID='M1903_1.02' and mb.Motif_ID=mo.Motif_ID and mb.TF_ID = tf.TF_ID and mo.MSource_ID=ms.MSource_ID;


+------------+--------------------+--------------------+----------+
| Motif_ID   | TF_Name            | Species            | PMID     |
+------------+--------------------+--------------------+----------+
| M1903_1.02 | LOC100412449       | Callithrix_jacchus | 24194598 |
| M1903_1.02 | LOC100050315       | Equus_caballus     | 24194598 |
| M1903_1.02 | ELK4               | Homo_sapiens       | 24194598 |
| M1903_1.02 | A1YF01_9PRIM       | Gorilla_gorilla    | 24194598 |
| M1903_1.02 | A2D689_MACMU       | Macaca_mulatta     | 24194598 |
| M1903_1.02 | ELK4               | Ochotona_princeps  | 24194598 |
| M1903_1.02 | ENSPPYG00000000302 | Pongo_pygmaeus     | 24194598 |
| M1903_1.02 | A2T746_PANTR       | Pan_troglodytes    | 24194598 |
| M1903_1.02 | ELK4               | Sorex_araneus      | 24194598 |
| M1903_1.02 | ELK4               | Tarsius_syrichta   | 24194598 |
+------------+--------------------+--------------------+----------+

select mb.Motif_ID, tf.TF_Name, Species, PMID, Family_Name
from   motif_best as mb, tfs as tf, motifs as mo, motif_sources as ms, tf_families as fa
where  mb.Motif_ID='M1903_1.02' and
mb.Motif_ID=mo.Motif_ID and
mb.TF_ID = tf.TF_ID and
mo.MSource_ID=ms.MSource_ID and
tf.Family_ID=fa.Family_ID
;

+------------+--------------------+--------------------+----------+-------------+
| Motif_ID   | TF_Name            | Species            | PMID     | Family_Name |
+------------+--------------------+--------------------+----------+-------------+
| M1903_1.02 | LOC100412449       | Callithrix_jacchus | 24194598 | Ets         |
| M1903_1.02 | LOC100050315       | Equus_caballus     | 24194598 | Ets         |
| M1903_1.02 | ELK4               | Homo_sapiens       | 24194598 | Ets         |
| M1903_1.02 | A1YF01_9PRIM       | Gorilla_gorilla    | 24194598 | Ets         |
| M1903_1.02 | A2D689_MACMU       | Macaca_mulatta     | 24194598 | Ets         |
| M1903_1.02 | ELK4               | Ochotona_princeps  | 24194598 | Ets         |
| M1903_1.02 | ENSPPYG00000000302 | Pongo_pygmaeus     | 24194598 | Ets         |
| M1903_1.02 | A2T746_PANTR       | Pan_troglodytes    | 24194598 | Ets         |
| M1903_1.02 | ELK4               | Sorex_araneus      | 24194598 | Ets         |
| M1903_1.02 | ELK4               | Tarsius_syrichta   | 24194598 | Ets         |
+------------+--------------------+--------------------+----------+-------------+


select mb.Motif_ID, tf.TF_Name, Species, PMID, Family_Name, pr.DBID
from   motif_best as mb, tfs as tf, motifs as mo, motif_sources as ms, tf_families as fa, proteins as pr
where  mb.Motif_ID='M1903_1.02' and
mb.Motif_ID=mo.Motif_ID and
mb.TF_ID = tf.TF_ID and
mo.MSource_ID = ms.MSource_ID and
tf.Family_ID = fa.Family_ID and
pr.TF_ID = tf.TF_ID
;

+------------+--------------------+--------------------+----------+-------------+--------------------+
| Motif_ID   | TF_Name            | Species            | PMID     | Family_Name | DBID               |
+------------+--------------------+--------------------+----------+-------------+--------------------+
| M1903_1.02 | LOC100412449       | Callithrix_jacchus | 24194598 | Ets         | ENSCJAP00000020178 |
| M1903_1.02 | LOC100050315       | Equus_caballus     | 24194598 | Ets         | ENSECAP00000004780 |
| M1903_1.02 | ELK4               | Homo_sapiens       | 24194598 | Ets         | ENSP00000289703    |
| M1903_1.02 | ELK4               | Homo_sapiens       | 24194598 | Ets         | ENSP00000350681    |  dup
| M1903_1.02 | A1YF01_9PRIM       | Gorilla_gorilla    | 24194598 | Ets         | ENSGGOP00000004278 |
| M1903_1.02 | A1YF01_9PRIM       | Gorilla_gorilla    | 24194598 | Ets         | ENSGGOP00000019701 |  dup
| M1903_1.02 | A1YF01_9PRIM       | Gorilla_gorilla    | 24194598 | Ets         | ENSGGOP00000020386 |  dup
| M1903_1.02 | A2D689_MACMU       | Macaca_mulatta     | 24194598 | Ets         | ENSMMUP00000005500 |
| M1903_1.02 | A2D689_MACMU       | Macaca_mulatta     | 24194598 | Ets         | ENSMMUP00000038169 |  dup
| M1903_1.02 | ELK4               | Ochotona_princeps  | 24194598 | Ets         | ENSOPRP00000005814 |
| M1903_1.02 | ENSPPYG00000000302 | Pongo_pygmaeus     | 24194598 | Ets         | ENSPPYP00000000322 |
| M1903_1.02 | A2T746_PANTR       | Pan_troglodytes    | 24194598 | Ets         | ENSPTRP00000003186 |
| M1903_1.02 | A2T746_PANTR       | Pan_troglodytes    | 24194598 | Ets         | ENSPTRP00000003187 |  dup
| M1903_1.02 | ELK4               | Sorex_araneus      | 24194598 | Ets         | ENSSARP00000013128 |
| M1903_1.02 | ELK4               | Tarsius_syrichta   | 24194598 | Ets         | ENSTSYP00000011580 |
+------------+--------------------+--------------------+----------+-------------+--------------------+



*----------------------------------------------------------------------------------------------------
* design for secure oncoscape data

Design goals:

1) All datasets, no matter how stored, and no matter what security they require, present
the same application programmer interface.

2) Security is complex and rapidly evolving.  Access to data is provided to those with the
correct credentials; "correct" will mean different things depending upon context.  Thus
an abstract software base class will be used, supporting a simple uniform API, and supporting
any required future implementation complexity.

3) The current SttrDataPackage API needs a few more methods (see below).

Design and Implementation notes:

A new abstract base class is needed:  DataAccessCredentials
An open-ended variety of concrete derived classes will evolve, providing many different
levels and kinds of security.   The degenerate case is currently used for public data.

The SttrDataSet API:

SttrDataPackage class (and R package) renamed to SttrDataSet, with public methods:

manifest
matrices
history
entities         # new
features         # new
getPatientList
getPatientTable
getGeneSetNames
getGeneSetGenes
dimensions       # new
getData          # new
credentials      # new

SttrDataSets are of two types (of which only the first now exists):

a) direct: data directly in the installed R package

b) indirect:  the subclass implements  the Facade design pattern, with data
retrieved from remote sources, often with credentials required.  Note
that the API for access to a secure indirect dataset is identical to
that of a public direct dataset.

Each concrete SttrDataSet subclass constructor can accept (or require) a credentials parameter.

Examples.  For our current public direct datasets, with no credentials needed:

dataset <- TCGAgbm(credentials=NA)

for a modestly-secured dataset:

credentials <- Level_1_Credentials(userName, encryptedPassword)
dataset.2 <- aConfidentialPatientStudy(credentials)

for a dataset needing extreme security
credentials <- Level_10_Credentials(userName, encryptedPassword, publicKey,
proofOfSecureBrowser, proofOfSecureConnection)





*----------------------------------------------------------------------------------------------------
* move query processing function to BrowserTable-class.R (17 may 2015)

--- new ajax source specified (this names the port used for the websocket server
source("test_BrowserTable.R"); Sys.sleep(1); app <- BrowserTable(port=8000:8010);Sys.sleep(1); display(app, mtcars)

ajax:{url: "http://127.0.0.1:8000"},
//ajax:{url: "http://127.0.0.1:7777"},
//ajax:{url: "http://127.0.0.1/~pshannon/dataTableServerSide/Demo.php"},


--- revised ctor in ~/s/bioc/trunk/RpacksTesting/BrowserTable/R/BrowserTable-class.R
.BrowserTable(BrowserViz(portRange, host, title, quiet, browserFile=browserTableBrowserFile,
httpQueryProcessingFunction=myQP))

--- queryProcessor added
myQP <- function(queryString) {
args <- strsplit(queryString, "&")[[1]]
printf("length of args: %d", length(args))
return(sample.json())
} # myQP
sample.json <- function(){
s <- list(sEcho=0, iTotalRecords=57, iTotalDisplayRecords=3,
aaData=list(
c("Trident","Internet Explorer 4.0","Win 95+","4","X"),
c("Trident","Internet Explorer 5.0","Win 95+","5","C"),
c("Trident","Internet Explorer 5.5","Win 95+","5.5","A")
))

# not using live data.frame yet
x <- cbind(name=rownames(mtcars), mtcars, stringsAsFactors=FALSE)
rownames(x) <- NULL
#s$aaData <- x[1:3, 1:5]
s2 <- as.character(toJSON(s, auto_unbox=TRUE))
printf("--- about to return:")
print(s2)
s2
} # sample.json



myQP <- function(queryString){

list(status=200L, headers = list('Content-Type' = 'text/html'), body="hello from dt.myQP")
} # myQP


*----------------------------------------------------------------------------------------------------
* moving ajax responder into the BrowserViz base class (17 may 2015)

~/s/bioc/trunk/Rpacks/BrowserViz/R/BrowserViz-class.R

global file scope:  func.env <- new.env(parent=emptyenv())
ctor:   func.env[["httpQueryProcessingFunction"]] <- httpQueryProcessingFunction

--- modify the httpuv setup

.setupWebSocketHandlers <- function(wsCon, browserFile) {
wsCon$open <- FALSE
#wsCon$wsID <- NULL
wsCon$ws <- NULL
wsCon$result <- NULL
# process http requests
wsCon$call = function(req) {
print("=== wsCon$call")
print(req$HTTP_HOST)
print(req$SERVER_NAME)
print(paste(ls(req), collapse=", "))
print(req$QUERY_STRING)
qs <- req$QUERY_STRING
if(nchar(qs) > 0){
#return(.processQuery(qs))
printf("bv$call, about to call dynamically assigned queryProcessor");
queryProcessorFunction <- func.env[["httpQueryProcessingFunction"]]
if(!is.null(queryProcessorFunction))
return(queryProcessorFunction(qs))
else
return(list(status=200L, headers = list('Content-Type' = 'text/html'),
body="no query processor registered"))
} # the request had a query string
wsUrl = paste(sep='', '"', "ws://",
ifelse(is.null(req$HTTP_HOST), req$SERVER_NAME, req$HTTP_HOST),
'"')

*----------------------------------------------------------------------------------------------------
* ajax BrowserTable, datatable working minimally from R (15 may 2015)

--- start a simple R httpuv webserver, completely separate from the websocket server
cd ~/s/examples/R/webserver/simpleGet/
simpleServer.R
starts httpuv sever on 7777:  demo
sample.json <- function(){
s <- list(sEcho=0, iTotalRecords=57, iTotalDisplayRecords=3,
aaData=list(
c("Trident","Internet Explorer 4.0","Win 95+","4","X"),
c("Trident","Internet Explorer 5.0","Win 95+","5","C"),
c("Trident","Internet Explorer 5.5","Win 95+","5.5","A")
))

s2 <- as.character(toJSON(s, auto_unbox=TRUE))
print(s2)
s2
} # sample.json



detects query string, returns json in format expected to web page with this javascript

~/s/bioc/trunk/RpacksTesting/BrowserTable/inst/scripts/ajaxTable.html

tableRef = tableElement.DataTable({
"processing": true,
"serverSide": true,
"sPaginationType": "full_numbers",
"iDisplayLength": 10,
"paging": true,
"bPaginate": true,
ajax:{url: "http://127.0.0.1:7777"},
//ajax:{url: "http://127.0.0.1/~pshannon/dataTableServerSide/Demo.php"},
"columns": [
{ "title": "Engine" },
{ "title": "Browser" },
{ "title": "Platform" },
{ "title": "Version", "class": "center" },
{ "title": "Grade", "class": "center" }
]
});


*----------------------------------------------------------------------------------------------------
* r/github

library(devtools)
install_github("armstrtw/rzmq")

resolves to https://github.com/jeroenooms/webutils
*----------------------------------------------------------------------------------------------------
* oncoscape meeting with eric (14 may 2015) todo

1) clicking on bare canvas no longer moves whole network around.  just a big spot appears. restore
previous behavior.
2) node size reflects degree (number of connections)
3) add in lgg genes from april 1st demo
4) chromosome names always visible
5) do not display tumor names ever!
6) try out tooltips for hovering names (tumors too)
7) on node selection: change to bright gold/orange thickened border, node names in small font
8) "frozen" selection, by example:
- select idh1, draw mutation edges
- select all connected nodes
- too many nodes are now selected
- switch to new mode: now selection means freeze (ie, turn permanent green) all the
already-selected nodes in this group.
- repeat this until only the desired subset of the original selection is permanently
green
- exit from mode
- all greens stay green till otherwise undone (de-greened)
- the normal select operations are restored: click on background removes all selections

*----------------------------------------------------------------------------------------------------
* table css tips tables

--- horizontal scrolling, but all visible content cleanly contained on the screen

http://jsfiddle.net/5WsEt/

---  my local trimmed and formatted version

~/s/examples/js/jquery/dataTables/horizontalScrollingCleanNoJQuery/index.html

--- successful scrolling explained

The overflow property specifies what happens if content overflows an element's box.
values: visible|hidden|scroll|auto|initial|inherit;


--- used in the demo

.search-table-outer{
overflow-x: scroll;
margin: 20px;
}






*----------------------------------------------------------------------------------------------------
* css tips: hide ul list bullets

#testTabButtonList{
list-style-type: none;
padding-left: 0px;
}

<ul id="testTabButtonList"></ul>


*----------------------------------------------------------------------------------------------------
* css tips: flexbox

  http://bocoup.com/weblog/dive-into-flexbox/

*----------------------------------------------------------------------------------------------------
* jerome bruner

These series of experiments issued in what some called the 'New Look' psychology, which challenged
psychologists to study not just an organism's response to a stimulus, but also its internal
interpretation.[2] After these experiments on perception, Bruner turned his attention to the
actual cognitions that he had indirectly studied in his perception studies.


*----------------------------------------------------------------------------------------------------
*----------------------------------------------------------------------------------------------------
*----------------------------------------------------------------------------------------------------
*----------------------------------------------------------------------------------------------------
*----------------------------------------------------------------------------------------------------
*----------------------------------------------------------------------------------------------------
*----------------------------------------------------------------------------------------------------
* create sample genesets for DEMOdz (10 may 2015)

library(DEMOdz)
dz <- DEMOdz()
set.seed(31); x <- sample(colnames(matrices(dz)$mtx.mrna), size=64)
random.40 <- x[1:40]
random.24 <- x[41:64]
genesets <- list(random.40=random.40, random.24=random.24)
save(genesets, file="../../../DEMOdz/inst/extdata/genesets.RData")


*----------------------------------------------------------------------------------------------------
* for friday (8 may 2015)

continue with wsWrapper and pythong tests in

~/oncodev/hbolouri/analysisPackages/PLSR/inst/ws/

*----------------------------------------------------------------------------------------------------
* redoing plsr as a package for oncodev14 (6 may 2015):  Invalid number of components, ncomp

cd ~/oncodev/hbolouri/analysisPackages/PLSR/inst/unitTests/
source("test_PLSR.R")
ncomp.bug()

fit <- plsr(mtx.classify ~ mrna, ncomp = 6, scale = TRUE, validation = "none")
Error in pls::mvr(mtx.classify ~ mrna, ncomp = 6, scale = TRUE, validation = "none",  :

sent demo to hamid, hoping for help

*----------------------------------------------------------------------------------------------------
* what jquery datatables sends to server side (5 may 2015) ajax data source

cd ~/dataTableServerSide

- make sure mysql is started
/usr/local/mysql/bin/mysql -V

- start if need be
sudo /usr/local/mysql/support-files/mysql.server start

- make sure apache is running
http://localhost/~pshannon/    # should show directory of ~/Sites/


--- see what gets returned when the php script "Demo.php" is run:
open http://localhost/~pshannon/dataTableServerSide/Demo.php
[json which begins like this, just what DataTable dynamic data reader needs
{"sEcho":0,"iTotalRecords":"57","iTotalDisplayRecords":"57",
"aaData":[["Trident","Internet Explorer 4.0", ...}

-- php datatable server and html/js client
~/Sites/dataTableServerSide/Demo.php
turn on the chrome cors extension
browse to:
file:///Users/pshannon/s/examples/js/jquery/ajax/jsonFromPhpSql/index.html
or
open  ~/s/examples/js/jquery/ajax/jsonFromPhpSql/index.html



http://127.0.0.1/~pshannon/dataTableServerSide/Demo.php?draw=1&columns%5B0%5D%5Bdata%5D=0&
columns%5B0%5D%5Bname%5D=&
columns%5B0%5D%5Bsearchable%5D=true&
columns%5B0%5D%5Borderable%5D=true&
columns%5B0%5D%5Bsearch%5D%5Bvalue%5D=&
columns%5B0%5D%5Bsearch%5D%5Bregex%5D=false&
columns%5B1%5D%5Bdata%5D=1&
columns%5B1%5D%5Bname%5D=&
columns%5B1%5D%5Bsearchable%5D=true&
columns%5B1%5D%5Borderable%5D=true&
columns%5B1%5D%5Bsearch%5D%5Bvalue%5D=&
columns%5B1%5D%5Bsearch%5D%5Bregex%5D=false&
columns%5B2%5D%5Bdata%5D=2&
columns%5B2%5D%5Bname%5D=&
columns%5B2%5D%5Bsearchable%5D=true&
columns%5B2%5D%5Borderable%5D=true&
columns%5B2%5D%5Bsearch%5D%5Bvalue%5D=&
columns%5B2%5D%5Bsearch%5D%5Bregex%5D=false&
columns%5B3%5D%5Bdata%5D=3&
columns%5B3%5D%5Bname%5D=&
columns%5B3%5D%5Bsearchable%5D=true&
columns%5B3%5D%5Borderable%5D=true&
columns%5B3%5D%5Bsearch%5D%5Bvalue%5D=&
columns%5B3%5D%5Bsearch%5D%5Bregex%5D=false&
columns%5B4%5D%5Bdata%5D=4&
columns%5B4%5D%5Bname%5D=&
columns%5B4%5D%5Bsearchable%5D=true&
columns%5B4%5D%5Borderable%5D=true&
columns%5B4%5D%5Bsearch%5D%5Bvalue%5D=&
columns%5B4%5D%5Bsearch%5D%5Bregex%5D=false&
order%5B0%5D%5Bcolumn%5D=0&
order%5B0%5D%5Bdir%5D=asc&
start=0&
length=5&
search%5Bvalue%5D=&
search%5Bregex%5D=false&
_=1430862899973


--- what php sends back
{"sEcho":0,"iTotalRecords":"57","iTotalDisplayRecords":"57",
"aaData":
[["Trident","Internet Explorer 4.0","Win 95+","4","X"],
["Trident","Internet Explorer 5.0","Win 95+","5","C"],
["Trident","Internet Explorer 5.5","Win 95+","5.5","A"],
["Trident","Internet Explorer 6","Win 98+","6","A"],
["Trident","Internet Explorer 7","Win XP SP2+","7","A"],
["Trident","AOL browser (AOL desktop)","Win XP","6","A"],
["Gecko","Firefox 1.0","Win 98+ \/ OSX.2+","1.7","A"],
["Gecko","Firefox 1.5","Win 98+ \/ OSX.2+","1.8","A"],
["Gecko","Firefox 2.0","Win 98+ \/ OSX.2+","1.8","A"],
["Gecko","Firefox 3.0","Win 2k+ \/ OSX.3+","1.9","A"],
["Gecko","Camino 1.0","OSX.2+","1.8","A"],
["Gecko","Camino 1.5","OSX.3+","1.8","A"],
["Gecko","Netscape 7.2","Win 95+ \/ Mac OS 8.6-9.2","1.7","A"],
["Gecko","Netscape Browser 8","Win 98SE+","1.7","A"],
["Gecko","Netscape Navigator 9","Win 98+ \/ OSX.2+","1.8","A"],
["Gecko","Mozilla 1.0","Win 95+ \/ OSX.1+","1","A"],
["Gecko","Mozilla 1.1","Win 95+ \/ OSX.1+","1.1","A"],
["Gecko","Mozilla 1.2","Win 95+ \/ OSX.1+","1.2","A"],
["Gecko","Mozilla 1.3","Win 95+ \/ OSX.1+","1.3","A"],
["Gecko","Mozilla 1.4","Win 95+ \/ OSX.1+","1.4","A"],
["Gecko","Mozilla 1.5","Win 95+ \/ OSX.1+","1.5","A"],
["Gecko","Mozilla 1.6","Win 95+ \/ OSX.1+","1.6","A"],
["Gecko","Mozilla 1.7","Win 98+ \/ OSX.1+","1.7","A"],
["Gecko","Mozilla 1.8","Win 98+ \/ OSX.1+","1.8","A"],
["Gecko","Seamonkey 1.1","Win 98+ \/ OSX.2+","1.8","A"],
["Gecko","Epiphany 2.20","Gnome","1.8","A"],
["Webkit","Safari 1.2","OSX.3","125.5","A"],
["Webkit","Safari 1.3","OSX.3","312.8","A"],
["Webkit","Safari 2.0","OSX.4+","419.3","A"],
["Webkit","Safari 3.0","OSX.4+","522.1","A"],
["Webkit","OmniWeb 5.5","OSX.4+","420","A"],
["Webkit","iPod Touch \/ iPhone","iPod","420.1","A"],
["Webkit","S60","S60","413","A"],
["Presto","Opera 7.0","Win 95+ \/ OSX.1+","-","A"],
["Presto","Opera 7.5","Win 95+ \/ OSX.2+","-","A"],
["Presto","Opera 8.0","Win 95+ \/ OSX.2+","-","A"],
["Presto","Opera 8.5","Win 95+ \/ OSX.2+","-","A"],
["Presto","Opera 9.0","Win 95+ \/ OSX.3+","-","A"],
["Presto","Opera 9.2","Win 88+ \/ OSX.3+","-","A"],
["Presto","Opera 9.5","Win 88+ \/ OSX.3+","-","A"],
["Presto","Opera for Wii","Wii","-","A"],
["Presto","Nokia N800","N800","-","A"],
["Presto","Nintendo DS browser","Nintendo DS","8.5","C\/A<sup>1<\/sup>"],
["KHTML","Konqureror 3.1","KDE 3.1","3.1","C"],
["KHTML","Konqureror 3.3","KDE 3.3","3.3","A"],
["KHTML","Konqureror 3.5","KDE 3.5","3.5","A"],
["Tasman","Internet Explorer 4.5","Mac OS 8-9","-","X"],
["Tasman","Internet Explorer 5.1","Mac OS 7.6-9","1","C"],
["Tasman","Internet Explorer 5.2","Mac OS 8-X","1","C"],
["Misc","NetFront 3.1","Embedded devices","-","C"],
["Misc","NetFront 3.4","Embedded devices","-","A"],
["Misc","Dillo 0.8","Embedded devices","-","X"],
["Misc","Links","Text only","-","X"],
["Misc","Lynx","Text only","-","X"],
["Misc","IE Mobile","Windows Mobile 6","-","C"],
["Misc","PSP browser","PSP","-","C"],
["Other browsers","All others","-","-","U"]]}

*----------------------------------------------------------------------------------------------------
* ajax datatables server-side script for php and mysql (5 may 2015)  [prep for R version]

server:   cd ~/Sites/dataTableServerSide
web page client: ~/s/examples/js/jquery/ajax/jsonFromPhpSql/index.html

https://datatables.net/development/server-side/php_mysql
installed as: ~/Sites/dataTableServerSide/Demo.php

seems to need the web browser 5-column dataset we already have in ~/Sites/data/browser.json
but stored as a table named "ajax" in MySQL

-- mysql schema and insert statements here: https://datatables.net/development/server-side/sql

mysql> create database datatable;
exit
bash> mysql < schema.sql
bash> mysql < loadData.sql

use datatable;
CREATE TABLE `ajax` (
`id` int(10) NOT NULL auto_increment,
`engine` varchar(255) NOT NULL default '',
`browser` varchar(255) NOT NULL default '',
`platform` varchar(255) NOT NULL default '',
`version` float NOT NULL default '0',
`grade` varchar(20) NOT NULL default '',
PRIMARY KEY  (`id`)
);

--- test
mysql --user cbio --password
use datatable;
select * from ajax;

*----------------------------------------------------------------------------------------------------
* datatables json server-side json response (5 may 2015)

http://www.sitepoint.com/working-jquery-datatables/

And the json response from server may look something like:

{
"iTotalRecords": 50,
"iTotalDisplayRecords": 10,
"sEcho":10,
"aaData": [
{"name": "Sitepoint", "url": "http://sitepoint.com", "editor" :{ "name" : "John Doe", "phone" : ["9191919", "1212121"], "email":[]}},
{"name": "Flippa", "url": "http://flippa.com",  "editor": { "name": "Adam Smith", "email" : ["adam.smith@domain.com"], "phone":[] }}
]
}

--- old style datatable server side
http://legacy.datatables.net/usage/server-side

--- the manual!
http://datatables.net/manual/server-side

*----------------------------------------------------------------------------------------------------
* jquery datatables ajax: access to simple static file (4 may 2015)

--- note xhr cross origin access problems can arise:

XMLHttpRequest cannot load http://localhost/~pshannon/data/browsers.json?_=1430852646427. No
'Access-Control-Allow-Origin' header is present on the requested resource. Origin 'null' is
therefore not allowed access.

cause:  index.html is
file:///Users/pshannon/s/examples/js/jquery/ajax/simpleDirectJSONtext/index.html
json is
"http://localhost/~pshannon/data/browsers.json"

some strategies:
use cors plugin on chrome (might need to reload a couple of times :})
maybe serve up index.html from localhost/~pshannon/...

--- workiung code
~/s/examples/js/jquery/ajax/simpleDirectJSONtext: the salaries demo, with data served up via
my apache server by replacing internal javascritp "data" array of arrays with "ajax" url
columns are specified in the "columns" field of the initializer
be sure to use double quotes in the json text: single quotes are invalid
//        "data": dataSet,
"ajax": "http://localhost/~pshannon/data/browsers.json",
note that the json must use double quotes, not single
validate at http://jsonlint.com/

$(document).ready(function() {
console.log("document ready");
$('#demo').html('<table cellpadding="0" cellspacing="0" border="0" class="display" id="example"></table>');
$('#example').dataTable( {
//        "data": dataSet,
"ajax": "http://localhost/~pshannon/data/browsers.json",
"columns": [
{ "title": "Engine" },
{ "title": "Browser" },
{ "title": "Platform" },
{ "title": "Version", "class": "center" },
{ "title": "Grade", "class": "center" }
]
}); // #example.dataTable
});  // document.ready




*----------------------------------------------------------------------------------------------------
* setup apache on yosemite (4 may 2015)

/usr/sbin/apachectl

apparently possible to have a bunch of apaches running:
ps aux | grep httpd    # kill any you don't want, probably all of them

as root, in /etc/apache2/httpd.conf, enable (uncomment) this line:

LoadModule php5_module libexec/apache2/libphp5.so

then sudo /usr/sbin/apachectl restart


--- setup up per-user directories

in /etc/apache2/httpd.conf:

LoadModule userdir_module libexec/apache2/mod_userdir.so
Include /private/etc/apache2/extra/httpd-userdir.conf

in /etc/apache2/extra/httpd-userdir.conf, uncomment this line:
Include /private/etc/apache2/users/*.conf

created /etc/apache2/users/pshannon.conf, with these contents:

Directory "/Users/pshannon/Sites/">
Options +Indexes +MultiViews +FollowSymLinks +SymLinksIfOwnerMatch +ExecCGI
AllowOverride All
Require local
Order allow,deny
Allow from all
</Directory>

sudo /usr/sbin/apachectl restart

browse to http://localhost/~pshannon/
see ~/Sites/index.html

--- test out php
renamed ~/Sites/index.html to -hidden
create ~/Sites/phpinfo.php with just this one line
<?php phpinfo(); ?>


--- now setup MySQL
sudo /usr/local/mysql/support-files/mysql.server start
/usr/local/mysql/bin/mysql -V  # Server version: 5.5.24 MySQL Community Server (GPL)


*----------------------------------------------------------------------------------------------------
* jquery datatables ajax demo (4 may 2015)

cd ~s/examples/js/jquery/ajax/try0
maybe use simple example in\
~/github/chinook/R-server/ModelMPG/inst/js/twoTabsSelfContained?
or ~/s/bioc/trunk/RpacksTesting/BrowserTable?

--- php example, looks promising (simple-ish, complete?)
http://coderexample.com/datatable-demo-server-side-in-phpmysql-and-ajax/
*----------------------------------------------------------------------------------------------------
* bioc first challenge: map chrom log to gene (3 may 2015)

cd ~/s/examples/bioc/challenges/mapChromLocToGene
build cnv snp file from https://tcga-data.nci.nih.gov/tcga
used sample tcga.02.0001
generated file, downloaded, looked (without really knowing what was what) for a good example, found this:

head CNV_SNP_Array/BI__Genome_Wide_SNP_6/Level_3/TRIBE_p_TCGAaffx_B1_2_GBM_Nsp_GenomeWideSNP_6_A01_155716.nocnv_hg19.seg.txt
Sample	Chromosome	Start	End	Num_Probes	Segment_Mean
TRIBE_p_TCGAaffx_B1_2_GBM_Nsp_GenomeWideSNP_6_A01_155716	1	3218610	3586250	166	0.1112
TRIBE_p_TCGAaffx_B1_2_GBM_Nsp_GenomeWideSNP_6_A01_155716	1	3586450	3589709	3	-1.2062
TRIBE_p_TCGAaffx_B1_2_GBM_Nsp_GenomeWideSNP_6_A01_155716	1	3590070	74911597	40303	0.1086
TRIBE_p_TCGAaffx_B1_2_GBM_Nsp_GenomeWideSNP_6_A01_155716	1	74916565	75377480	271	-0.3065


*----------------------------------------------------------------------------------------------------
* jquery tips:  get the text (the name) of every element in a <select> widget, all the pulldown entries
  jquery tips filter array

jquery this
jquery map


   --- filter array

   ~/oncodev/hbolouri/oncoDev14/Oncoscape/inst/scripts/tests/Module.js
   dzNames = $("#datasetMenu option").map(function(opt){return this.value})  // ["", "DEMOdz", "TCGAgbm"]
   dzNames.filter(function(e) {return e})  // ["DEMOdz", "TCGAgbm"]

   filter() calls a provided callback function once for each element
   in an array, and constructs a new array of all the values for which
   callback returns a true value or a value that coerces to true.


   function isBigEnough(value) {  return value >= 10; }
   var filtered = [12, 5, 8, 130, 44].filter(isBigEnough); //  [12, 130, 44]

   also see -? jQuery grep


--- remove option from select widget
$("#markersEdgeTypeSelector option[value='mutation']").remove();
$("#markersEdgeTypeSelector option[value!='mutation']").remove();

--- trigger a refresh, an update
$("#markersEdgeTypeSelector").trigger("chosen:updated");

*----------------------------------------------------------------------------------------------------
* new oncodev14 markers & samples network, review recent progress (6 may 2015)

--- two directories:

deploy here:  ~/oncodev/hbolouri/oncoDev14/Oncoscape/inst/scripts/markersAndSamples/
prepare here: ~/oncodev/hbolouri/dataPackages/networks/TCGAbrainMarkersAndTissues/prep

--- most recent strategy
widget.html begins with these three includes:
include(../markersAndSamples/mutCopyNumberChromNetwork.js)     15167 lines (1.3M)
include(../markersAndSamples/layoutNew.js)                      1547 lines
include(../markersAndSamples/style.js)                            83


mutCopyNumberChromNetwork.js file generated in prep on 4/27, 1325

--- gistic +/- 2 edges look like this, 2 nodes first, then the edge
{data:{name:"TCGA.02.0266",nodeType:"patient",label:"TCGA.02.0266",id:"TCGA.02.0266"}},
{data:{name:"ABCA1",nodeType:"gene",label:"ABCA1",id:"ABCA1"}},
{data:{source:"TCGA.02.0266",target:"ABCA1",edgeType:"cnGain-2","gistic":2,id:"e0"}},

--- now add gistic +/- 1 edges
cd ~/oncodev/hbolouri/dataPackages/networks/TCGAbrainMarkersAndTissues/prep/


*----------------------------------------------------------------------------------------------------
* cyjs typs: manual layout, assisted layout, of  selected nodes into a grid  (javascript)

cy.filter("node:selected").length  // 16
// put one node in the top left corner, then get its coords
pos = cy.filter("node:selected")[0].position()

box = {x1: 1200, y1:180, w: 500, h: 800}
box = {x1: 1200, y1:180, w: 800, h: 800}

cy.filter("node:selected").layout({ name: 'grid', rows: 5, columns: 3, boundingBox: box });
cy.filter("node:selected").layout({ name: 'grid', boundingBox: box });

get all non-TCGA nodes
selectNodes(rcy, nodes(g)[which(nchar(nodes(g)) < 12)])
*----------------------------------------------------------------------------------------------------
* rcyjs make sure that layout x,y are applied to nodes by label rather than by order (27 apr)

the order of nodes will reliably differ across networks
layout is obtained from the source network:

JSON.stringify(cwMarkers.nodes('[label ^= "chr"]').map(function(node) {return ({label: node.data().label, pos: node.position()})}))
layout = [{"label":"chr1","pos":{"x":-971.6949462890625,"y":849.0050659179688}},
{"label":"chr10","pos":{"x":1879.923828125,"y":-179.4615936279297}},
{"label":"chr11","pos":{"x":1954.7183837890625,"y":1124.1976318359375}},
{"label":"chr12","pos":{"x":1823.7652587890625,"y":359.4603271484375}},
{"label":"chr13","pos":{"x":1076.4320068359375,"y":-1183.5975341796875}},
{"label":"chr14","pos":{"x":-288.4932556152344,"y":-1576.884521484375}},
{"label":"chr15","pos":{"x":-877.2595825195312,"y":386.1282958984375}},
{"label":"chr16","pos":{"x":-294.668212890625,"y":579.3158569335938}},
{"label":"chr17","pos":{"x":-857.8323974609375,"y":-1495.5223388671875}},
{"label":"chr18","pos":{"x":649.6647338867188,"y":1458.806640625}},
{"label":"chr19","pos":{"x":282.6548767089844,"y":1154.9901123046875}},
{"label":"chr2","pos":{"x":-485.12420654296875,"y":1161.943359375}},
{"label":"chr20","pos":{"x":1060.0203857421875,"y":1419.244873046875}},
{"label":"chr21","pos":{"x":891.3468017578125,"y":679.511474609375}},
{"label":"chr22","pos":{"x":1325.4498291015625,"y":218.5226287841797}},
{"label":"chr3","pos":{"x":-158.1291046142578,"y":-599.4402465820312}},
{"label":"chr4","pos":{"x":11.975418090820312,"y":97.98661041259766}},
{"label":"chr5","pos":{"x":355.03472900390625,"y":540.0452270507812}},
{"label":"chr6","pos":{"x":773.085205078125,"y":239.60576629638672}},
{"label":"chr7","pos":{"x":1708.71142578125,"y":-1111.0909423828125}},
{"label":"chr8","pos":{"x":948.5714721679688,"y":-298.0948486328125}},
{"label":"chr9","pos":{"x":-1088.906982421875,"y":-78.65689659118652}},
{"label":"chrX","pos":{"x":1316.9232177734375,"y":950.81201171875}},
{"label":"chrY","pos":{"x":-1109.79052734375,"y":2405.0447998046875}}];


# this works

layout.map(function(nodeInfo) {
var label = nodeInfo.label;
var x = nodeInfo.pos.x;
var y=nodeInfo.pos.y;
console.log("--- using node " + label + " position: " + x + ", " + y);
var selectorString = "[label='" + label + "']";
var node = cwMarkers.nodes(selectorString)[0];
if(typeof(node) != "undefined"){
node.position({x: x, y: y});
console.log(node.data().label);
}
});


does it work?  all chr nodes should be in the middle, surrounded by genes

cwMarkers.nodes('[label ^= "chr"]').length
cwMarkers.nodes('[label ^= "chr"]').select()   # they are indeed in the middle

--- now get all node positions from the right version:
layout = [{"label":"ABCA1","pos":{"x":-931.72119140625,"y":-85.06956481933594}},{"label":"ABCA13","pos":{"x":4385.876994519074,"y":2685.4749624919054}},{"label":"ABCB1","pos":{"x":3265.8769945190743,"y":2965.4749624919054}},{"label":"ABCC9","pos":{"x":3745.8769945190743,"y":2725.4749624919054}},{"label":"ABCG2","pos":{"x":553.9146728515625,"y":-1203.6005859375}},{"label":"ABI1","pos":{"x":1815.0128173828125,"y":-405.23779296875}},{"label":"ABL1","pos":{"x":-907.18017578125,"y":-213.02330017089844}},{"label":"ACKR3","pos":{"x":-454.84417724609375,"y":1099.6439208984375}},{"label":"ACSL3","pos":{"x":-370.6884460449219,"y":1285.84130859375}},{"label":"ACSL6","pos":{"x":380.8532409667969,"y":583.8826904296875}},{"label":"ADAM29","pos":{"x":3905.8769945190743,"y":2965.4749624919054}},{"label":"ADAM6","pos":{"x":3505.8769945190743,"y":3005.4749624919054}},{"label":"ADAMTS12","pos":{"x":3585.8769945190743,"y":3005.4749624919054}},{"label":"ADAMTS16","pos":{"x":3265.8769945190743,"y":2725.4749624919054}},{"label":"ADCY5","pos":{"x":3825.8769945190743,"y":3005.4749624919054}},{"label":"AFF2","pos":{"x":3105.8769945190743,"y":2805.4749624919054}},{"label":"AFF3","pos":{"x":-547.122314453125,"y":1125.78515625}},{"label":"AFF4","pos":{"x":376.9432067871094,"y":601.5036010742188}},{"label":"AFM","pos":{"x":4225.876994519074,"y":3045.4749624919054}},{"label":"AGAP2","pos":{"x":1729.2628173828125,"y":281.5459289550781}},{"label":"AHNAK","pos":{"x":4385.876994519074,"y":2765.4749624919054}},{"label":"AHNAK2","pos":{"x":-185.9772186279297,"y":-1359.7794189453125}},{"label":"AKAP9","pos":{"x":1511.5361328125,"y":-1608.406494140625}},{"label":"AKT1","pos":{"x":-129.68496704101562,"y":-1340.3680419921875}},{"label":"AKT1S1","pos":{"x":230.6480712890625,"y":1243.78759765625}},{"label":"AKT2","pos":{"x":257.8584289550781,"y":1046.80126953125}},{"label":"AKT3","pos":{"x":-982.7129516601562,"y":728.8900146484375}},{"label":"ALDH2","pos":{"x":1921.643798828125,"y":316.4891357421875}},{"label":"ALK","pos":{"x":-537.056396484375,"y":1254.79052734375}},{"label":"ALMS1","pos":{"x":4065.8769945190743,"y":2805.4749624919054}},{"label":"ANKRD30A","pos":{"x":3665.8769945190743,"y":3045.4749624919054}},{"label":"APOB","pos":{"x":3585.8769945190743,"y":2685.4749624919054}},{"label":"ARAF","pos":{"x":1265.5025634765625,"y":1129.2525634765625}},{"label":"ARHGAP26","pos":{"x":375.0772399902344,"y":622.4798583984375}},{"label":"ARHGEF12","pos":{"x":1909.4534912109375,"y":1304.56884765625}},{"label":"ARID1A","pos":{"x":4145.876994519074,"y":2765.4749624919054}},{"label":"ARID1B","pos":{"x":4385.876994519074,"y":2725.4749624919054}},{"label":"ARID2","pos":{"x":1916.87060546875,"y":366.0520324707031}},{"label":"ARPC1A","pos":{"x":1507.092041015625,"y":-1466.1468505859375}},{"label":"ASNS","pos":{"x":1509.5003662109375,"y":-1403.038330078125}},{"label":"ASPSCR1","pos":{"x":-779.7630004882812,"y":-1227.252197265625}},{"label":"ATAD1","pos":{"x":3185.8769945190743,"y":3165.4749624919054}},{"label":"ATF1","pos":{"x":1754.9732666015625,"y":719.9781494140625}},{"label":"ATIC","pos":{"x":-341.2698974609375,"y":1107.9305419921875}},{"label":"ATM","pos":{"x":1944.4468994140625,"y":1182.9031982421875}},{"label":"ATP1A1","pos":{"x":-907.9666748046875,"y":851.2255249023438}},{"label":"ATP2B3","pos":{"x":1275.4345703125,"y":899.2613525390625}},{"label":"ATRX","pos":{"x":1414.8448486328125,"y":935.8837280273438}},{"label":"AURKC","pos":{"x":3585.8769945190743,"y":2925.4749624919054}},{"label":"AXIN1","pos":{"x":-358.017333984375,"y":642.0504760742188}},{"label":"BAGE","pos":{"x":1004.4303894042969,"y":728.6436157226562}},{"label":"BAGE2","pos":{"x":931.7241821289062,"y":792.7554931640625}},{"label":"BAGE3","pos":{"x":1013.3816223144531,"y":806.1246337890625}},{"label":"BAGE4","pos":{"x":988.870361328125,"y":773.8555297851562}},{"label":"BAGE5","pos":{"x":1017.53759765625,"y":-1095.55322265625}},{"label":"BCL10","pos":{"x":-1030.4871826171875,"y":953.025634765625}},{"label":"BCL11A","pos":{"x":550.88916015625,"y":-886.211669921875}},{"label":"BCL11B","pos":{"x":-238.36862182617188,"y":-1387.4510498046875}},{"label":"BCL2","pos":{"x":585.06396484375,"y":1508.1727294921875}},{"label":"BCL3","pos":{"x":300.461669921875,"y":1048.9432373046875}},{"label":"BCL6","pos":{"x":-239.142578125,"y":-696.7393798828125}},{"label":"BCL7A","pos":{"x":1763.0361328125,"y":618.606201171875}},{"label":"BCL9","pos":{"x":-846.5357666015625,"y":978.2361450195312}},{"label":"BCOR","pos":{"x":1193.697021484375,"y":948.1656494140625}},{"label":"BCR","pos":{"x":1378.5823974609375,"y":109.04563522338867}},{"label":"BIRC3","pos":{"x":1913.3514404296875,"y":1331.68701171875}},{"label":"BMI1","pos":{"x":1805.5308837890625,"y":-502.50677490234375}},{"label":"BMPR1A","pos":{"x":1767.1121826171875,"y":-218.48805236816406}},{"label":"BRAF","pos":{"x":1507.176513671875,"y":-885.0337524414062}},{"label":"BRCA1","pos":{"x":-827.8251342773438,"y":-1440.9796142578125}},{"label":"BRCA2","pos":{"x":1048.2203369140625,"y":-1002.740966796875}},{"label":"BRD3","pos":{"x":-1007.8413391113281,"y":10.040132999420166}},{"label":"BRD4","pos":{"x":147.26544570922852,"y":1188.900146484375}},{"label":"BRIP1","pos":{"x":-947.7297973632812,"y":-1421.6104736328125}},{"label":"BRSK1","pos":{"x":4305.876994519074,"y":2885.4749624919054}},{"label":"BTG1","pos":{"x":1916.53515625,"y":350.0342102050781}},{"label":"BUB1B","pos":{"x":-799.9751586914062,"y":396.8772888183594}},{"label":"C2ORF44","pos":{"x":-464.205322265625,"y":1329.9512939453125}},{"label":"C3","pos":{"x":3105.8769945190743,"y":3165.4749624919054}},{"label":"CACNA1D","pos":{"x":540.3726806640625,"y":-1315.584228515625}},{"label":"CACNA1E","pos":{"x":3585.8769945190743,"y":3125.4749624919054}},{"label":"CALR","pos":{"x":179.20303344726562,"y":1122.9444580078125}},{"label":"CALY","pos":{"x":4385.876994519074,"y":3085.4749624919054}},{"label":"CAMTA1","pos":{"x":552.3961791992188,"y":-1055.098388671875}},{"label":"CANT1","pos":{"x":-762.8009033203125,"y":-1181.167724609375}},{"label":"CARD11","pos":{"x":1499.4661865234375,"y":-1817.7593994140625}},{"label":"CARD6","pos":{"x":3665.8769945190743,"y":2605.4749624919054}},{"label":"CARS","pos":{"x":1998.50537109375,"y":871.5466918945312}},{"label":"CASC5","pos":{"x":-753.2598266601562,"y":301.6665344238281}},{"label":"CASP8","pos":{"x":-378.740966796875,"y":1214.231201171875}},{"label":"CBFA2T3","pos":{"x":-336.7298278808594,"y":533.858154296875}},{"label":"CBL","pos":{"x":1951.8408203125,"y":1235.1585693359375}},{"label":"CBLB","pos":{"x":-247.609619140625,"y":-788.0061645507812}},{"label":"CBLC","pos":{"x":305.3228454589844,"y":1027.5354919433594}},{"label":"CBX4","pos":{"x":-912.6300048828125,"y":-1429.5958251953125}},{"label":"CCDC106","pos":{"x":3505.8769945190743,"y":3045.4749624919054}},{"label":"CCDC6","pos":{"x":1879.74658203125,"y":-93.13188171386719}},{"label":"CCNB1IP1","pos":{"x":-122.02240371704102,"y":-1432.1607666015625}},{"label":"CCND1","pos":{"x":1858.5267333984375,"y":1093.3968505859375}},{"label":"CCND2","pos":{"x":1765.66845703125,"y":564.86572265625}},{"label":"CCND3","pos":{"x":772.3219604492188,"y":367.544677734375}},{"label":"CCNE1","pos":{"x":209.71397399902344,"y":1078.85791015625}},{"label":"CD274","pos":{"x":-1079.1866455078125,"y":102.21296691894531}},{"label":"CD44","pos":{"x":1879.4810791015625,"y":1137.04052734375}},{"label":"CD74","pos":{"x":378.833740234375,"y":660.7734375}},{"label":"CD79B","pos":{"x":-792.229248046875,"y":-1291.2509765625}},{"label":"CDC27","pos":{"x":3985.8769945190743,"y":2565.4749624919054}},{"label":"CDH11","pos":{"x":-282.95111083984375,"y":527.541015625}},{"label":"CDH18","pos":{"x":3665.8769945190743,"y":2645.4749624919054}},{"label":"CDK2","pos":{"x":1912.450439453125,"y":420.4009704589844}},{"label":"CDK4","pos":{"x":1716.5313720703125,"y":302.6104736328125}},{"label":"CDK6","pos":{"x":1510.98779296875,"y":-1637.1072998046875}},{"label":"CDKN1A","pos":{"x":657.1746826171875,"y":15.24995732307434}},{"label":"CDKN1B","pos":{"x":1761.6617431640625,"y":638.5263671875}},{"label":"CDKN2A","pos":{"x":-1102.1163330078125,"y":-439.8862609863281}},{"label":"CDKN2A-AS1","pos":{"x":3105.8769945190743,"y":2685.4749624919054}},{"label":"CDKN2B","pos":{"x":-1102.504638671875,"y":-340.55743408203125}},{"label":"CDKN2B-AS1","pos":{"x":3665.8769945190743,"y":3005.4749624919054}},{"label":"CDKN2C","pos":{"x":-437.5690612792969,"y":1479.3828125}},{"label":"CDX2","pos":{"x":1026.8975830078125,"y":-1295.298095703125}},{"label":"CEBPA","pos":{"x":166.96804809570312,"y":1177.914306640625}},{"label":"CFL1P1","pos":{"x":3425.8769945190743,"y":2645.4749624919054}},{"label":"CHD5","pos":{"x":4145.876994519074,"y":2845.4749624919054}},{"label":"CHD8","pos":{"x":3425.8769945190743,"y":3125.4749624919054}},{"label":"CHD9","pos":{"x":3585.8769945190743,"y":2645.4749624919054}},{"label":"CHEK2","pos":{"x":3905.8769945190743,"y":2765.4749624919054}},{"label":"CHI3L1","pos":{"x":-1037.6301574707031,"y":939.177490234375}},{"label":"CHIC2","pos":{"x":18.805571794509888,"y":-38.68374729156494}},{"label":"CHN1","pos":{"x":-368.7831115722656,"y":1191.1759033203125}},{"label":"CIC","pos":{"x":3905.8769945190743,"y":3165.4749624919054}},{"label":"CIITA","pos":{"x":544.4305419921875,"y":-923.008544921875}},{"label":"CLP1","pos":{"x":1816.2142333984375,"y":1126.0679931640625}},{"label":"CLTC","pos":{"x":-785.3345336914062,"y":-1268.71630859375}},{"label":"CLTCL1","pos":{"x":1378.57958984375,"y":139.09667587280273}},{"label":"CNBP","pos":{"x":-406.97235107421875,"y":-518.7218780517578}},{"label":"CNOT3","pos":{"x":241.15341186523438,"y":1317.8414306640625}},{"label":"CNTNAP2","pos":{"x":4305.876994519074,"y":2965.4749624919054}},{"label":"CNTRL","pos":{"x":-872.6996459960938,"y":-119.24895095825195}},{"label":"COL1A1","pos":{"x":550.4764404296875,"y":-1094.4208984375}},{"label":"COL1A2","pos":{"x":3905.8769945190743,"y":2925.4749624919054}},{"label":"COL6A3","pos":{"x":3265.8769945190743,"y":2565.4749624919054}},{"label":"COX6B2","pos":{"x":4145.876994519074,"y":3125.4749624919054}},{"label":"CREB1","pos":{"x":-376.1436462402344,"y":1202.7373046875}},{"label":"CREB3L1","pos":{"x":1957.788818359375,"y":1064.890869140625}},{"label":"CREB3L2","pos":{"x":1513.4072265625,"y":-1019.8544616699219}},{"label":"CREBBP","pos":{"x":-279.4216003417969,"y":490.4935302734375}},{"label":"CRIPAK","pos":{"x":3505.8769945190743,"y":2685.4749624919054}},{"label":"CRLF2","pos":{"x":1242.7742919921875,"y":1047.530029296875}},{"label":"CSMD3","pos":{"x":4225.876994519074,"y":2565.4749624919054}},{"label":"CUL1","pos":{"x":1509.9942626953125,"y":-1099.5762939453125}},{"label":"CXORF22","pos":{"x":3505.8769945190743,"y":2765.4749624919054}},{"label":"CYP2E1","pos":{"x":4225.876994519074,"y":2765.4749624919054}},{"label":"DAXX","pos":{"x":549.4591674804688,"y":-821.5382690429688}},{"label":"DCAF12L2","pos":{"x":4385.876994519074,"y":3165.4749624919054}},{"label":"DDIT3","pos":{"x":1794.0546875,"y":265.80750274658203}},{"label":"DDX10","pos":{"x":1890.0001220703125,"y":1217.6226806640625}},{"label":"DDX5","pos":{"x":-805.6114501953125,"y":-1411.7274169921875}},{"label":"DDX6","pos":{"x":1894.3663330078125,"y":1352.48291015625}},{"label":"DEPTOR","pos":{"x":1063.8248291015625,"y":-347.8768005371094}},{"label":"DICER1","pos":{"x":-334.61297607421875,"y":-1536.2000732421875}},{"label":"DMD","pos":{"x":4145.876994519074,"y":2685.4749624919054}},{"label":"DMRTA1","pos":{"x":-1101.90576171875,"y":-252.62885284423828}},{"label":"DNAH11","pos":{"x":4305.876994519074,"y":2685.4749624919054}},{"label":"DNAH2","pos":{"x":4225.876994519074,"y":2685.4749624919054}},{"label":"DNAH3","pos":{"x":3265.8769945190743,"y":2845.4749624919054}},{"label":"DNAH5","pos":{"x":532.3814697265625,"y":-1731.53662109375}},{"label":"DNAH8","pos":{"x":4385.876994519074,"y":2605.4749624919054}},{"label":"DNAH9","pos":{"x":4385.876994519074,"y":3205.4749624919054}},{"label":"DNM2","pos":{"x":212.30172729492188,"y":1154.553955078125}},{"label":"DNMT3A","pos":{"x":-504.43585205078125,"y":1276.204345703125}},{"label":"DOCK5","pos":{"x":923.112548828125,"y":-383.2278747558594}},{"label":"DOCK8","pos":{"x":4305.876994519074,"y":2765.4749624919054}},{"label":"DPP10","pos":{"x":3105.8769945190743,"y":2565.4749624919054}},{"label":"DRD5","pos":{"x":3185.8769945190743,"y":3205.4749624919054}},{"label":"DSG3","pos":{"x":3185.8769945190743,"y":2965.4749624919054}},{"label":"DSP","pos":{"x":3505.8769945190743,"y":2805.4749624919054}},{"label":"DUSP22","pos":{"x":753.8104248046875,"y":275.12569427490234}},{"label":"DUX4","pos":{"x":-96.29071807861328,"y":121.86444091796875}},{"label":"DUX4L7","pos":{"x":4065.8769945190743,"y":2725.4749624919054}},{"label":"DUXA","pos":{"x":3185.8769945190743,"y":2685.4749624919054}},{"label":"E2F1","pos":{"x":1130.694091796875,"y":1407.846923828125}},{"label":"EBF1","pos":{"x":376.75286865234375,"y":639.1382446289062}},{"label":"ECHS1","pos":{"x":3745.8769945190743,"y":2685.4749624919054}},{"label":"ECT2L","pos":{"x":713.4051513671875,"y":181.12039184570312}},{"label":"EED","pos":{"x":1759.0728759765625,"y":1049.0361328125}},{"label":"EGFR","pos":{"x":1691.6165771484375,"y":-1890.6138916015625}},{"label":"EIF4A2","pos":{"x":-218.7584228515625,"y":-817.4121704101562}},{"label":"ELAVL2","pos":{"x":-1096.640869140625,"y":-155.998291015625}},{"label":"ELF4","pos":{"x":1417.424560546875,"y":964.9790649414062}},{"label":"ELK4","pos":{"x":-905.5593872070312,"y":771.0067138671875}},{"label":"ELN","pos":{"x":1512.273193359375,"y":-1571.96826171875}},{"label":"EP300","pos":{"x":1293.4256591796875,"y":53.978445053100586}},{"label":"EPN1","pos":{"x":3825.8769945190743,"y":2765.4749624919054}},{"label":"EPPK1","pos":{"x":3265.8769945190743,"y":3205.4749624919054}},{"label":"EPS8L1","pos":{"x":3825.8769945190743,"y":2605.4749624919054}},{"label":"ERBB2","pos":{"x":559.1168212890625,"y":-1128.8145751953125}},{"label":"ERBB3","pos":{"x":1915.1497802734375,"y":402.8706970214844}},{"label":"ERC1","pos":{"x":1759.0697021484375,"y":735.0674438476562}},{"label":"ERCC2","pos":{"x":237.08157348632812,"y":1339.04931640625}},{"label":"ERCC5","pos":{"x":988.0997314453125,"y":-1180.9403076171875}},{"label":"ERRFI1","pos":{"x":-1014.939697265625,"y":972.2261962890625}},{"label":"ESPNP","pos":{"x":3425.8769945190743,"y":2765.4749624919054}},{"label":"ETV1","pos":{"x":1870.9078369140625,"y":-1475.394775390625}},{"label":"ETV5","pos":{"x":-238.2353515625,"y":-677.6506958007812}},{"label":"ETV6","pos":{"x":1765.22265625,"y":585.5676879882812}},{"label":"EXT1","pos":{"x":1066.8179931640625,"y":-380.7359313964844}},{"label":"EXT2","pos":{"x":1965.832763671875,"y":1041.2049865722656}},{"label":"EZH2","pos":{"x":1510.1588134765625,"y":-1075.398681640625}},{"label":"EZR","pos":{"x":720.5547485351562,"y":195.7284698486328}},{"label":"F8","pos":{"x":4305.876994519074,"y":3205.4749624919054}},{"label":"FAM46C","pos":{"x":-879.7511596679688,"y":866.097900390625}},{"label":"FAM47C","pos":{"x":4065.8769945190743,"y":3165.4749624919054}},{"label":"FAM71E2","pos":{"x":3985.8769945190743,"y":2885.4749624919054}},{"label":"FANCA","pos":{"x":-304.77117919921875,"y":527.541015625}},{"label":"FANCC","pos":{"x":-914.9263916015625,"y":-65.715087890625}},{"label":"FANCD2","pos":{"x":-254.03235626220703,"y":-486.7278747558594}},{"label":"FANCG","pos":{"x":-838.66650390625,"y":-190.58067321777344}},{"label":"FANK1","pos":{"x":1807.153564453125,"y":-268.0581970214844}},{"label":"FAS","pos":{"x":1704.9166259765625,"y":-239.40897369384766}},{"label":"FAT2","pos":{"x":3745.8769945190743,"y":3165.4749624919054}},{"label":"FBN2","pos":{"x":3505.8769945190743,"y":2885.4749624919054}},{"label":"FBN3","pos":{"x":4145.876994519074,"y":2605.4749624919054}},{"label":"FBXW7","pos":{"x":-119.29682922363281,"y":93.43751525878906}},{"label":"FCAR","pos":{"x":3105.8769945190743,"y":2885.4749624919054}},{"label":"FCGBP","pos":{"x":3825.8769945190743,"y":3045.4749624919054}},{"label":"FCGR2B","pos":{"x":-967.2861938476562,"y":1002.9871826171875}},{"label":"FCRL4","pos":{"x":-1021.5813903808594,"y":1064.652587890625}},{"label":"FEV","pos":{"x":-367.4886474609375,"y":1302.8031005859375}},{"label":"FGD5","pos":{"x":4065.8769945190743,"y":2645.4749624919054}},{"label":"FGFR1OP","pos":{"x":691.3446044921875,"y":104.83041381835938}},{"label":"FGFR2","pos":{"x":1884.0616455078125,"y":-282.1362609863281}},{"label":"FGFR3","pos":{"x":77.78090858459473,"y":75.91678810119629}},{"label":"FH","pos":{"x":-1038.3035888671875,"y":768.1301879882812}},{"label":"FIP1L1","pos":{"x":11.963803768157959,"y":-228.13446044921875}},{"label":"FIZ1","pos":{"x":4385.876994519074,"y":2925.4749624919054}},{"label":"FKBP9P1","pos":{"x":4065.8769945190743,"y":2605.4749624919054}},{"label":"FLG","pos":{"x":523.956298828125,"y":-1666.345703125}},{"label":"FLG2","pos":{"x":3505.8769945190743,"y":2965.4749624919054}},{"label":"FLI1","pos":{"x":1847.3720703125,"y":1421.4493408203125}},{"label":"FLT3","pos":{"x":1027.075927734375,"y":-1264.3712158203125}},{"label":"FN1","pos":{"x":-362.8121337890625,"y":1325.0299072265625}},{"label":"FNBP1","pos":{"x":-922.78271484375,"y":-124.23294067382812}},{"label":"FOXA1","pos":{"x":-308.01263427734375,"y":-1683.7423095703125}},{"label":"FOXL2","pos":{"x":-345.2223205566406,"y":-611.1615600585938}},{"label":"FOXO1","pos":{"x":1104.7835693359375,"y":-1062.994384765625}},{"label":"FOXO3","pos":{"x":674.146484375,"y":77.2525806427002}},{"label":"FOXO4","pos":{"x":1408.05908203125,"y":896.84619140625}},{"label":"FRAS1","pos":{"x":3505.8769945190743,"y":2845.4749624919054}},{"label":"FRG1","pos":{"x":-77.73994255065918,"y":146.9414939880371}},{"label":"FRG1B","pos":{"x":1185.8402099609375,"y":1415.688720703125}},{"label":"FRG2B","pos":{"x":3105.8769945190743,"y":2845.4749624919054}},{"label":"FRYL","pos":{"x":4385.876994519074,"y":3045.4749624919054}},{"label":"FSTL3","pos":{"x":215.87875366210938,"y":1131.9478759765625}},{"label":"FUBP1","pos":{"x":-983.6988525390625,"y":979.578369140625}},{"label":"FUOM","pos":{"x":3345.8769945190743,"y":2565.4749624919054}},{"label":"FUS","pos":{"x":-152.61175537109375,"y":574.2881469726562}},{"label":"FZD1","pos":{"x":1508.8988037109375,"y":-1334.621826171875}},{"label":"GABRA6","pos":{"x":3345.8769945190743,"y":2925.4749624919054}},{"label":"GALP","pos":{"x":3185.8769945190743,"y":2925.4749624919054}},{"label":"GAS7","pos":{"x":-983.231689453125,"y":-1525.44921875}},{"label":"GATA1","pos":{"x":1238.043212890625,"y":991.9341430664062}},{"label":"GATA2","pos":{"x":-390.8974304199219,"y":-528.4986572265625}},{"label":"GATA3","pos":{"x":1834.4078369140625,"y":-236.5064697265625}},{"label":"GBAS","pos":{"x":4225.876994519074,"y":2805.4749624919054}},{"label":"GDF2","pos":{"x":1886.97265625,"y":-240.60369873046875}},{"label":"GIMAP8","pos":{"x":1508.928466796875,"y":-1124.96826171875}},{"label":"GLI1","pos":{"x":1773.5277099609375,"y":282.9311828613281}},{"label":"GMPS","pos":{"x":-330.86944580078125,"y":-626.4019165039062}},{"label":"GNA11","pos":{"x":237.03738403320312,"y":1053.2310791015625}},{"label":"GNAQ","pos":{"x":-1195.7601318359375,"y":30.836909294128418}},{"label":"GOLGA5","pos":{"x":-68.0075511932373,"y":-1316.0426025390625}},{"label":"GOPC","pos":{"x":679.6749267578125,"y":94.23799896240234}},{"label":"GP6","pos":{"x":4385.876994519074,"y":2805.4749624919054}},{"label":"GPC3","pos":{"x":1428.72314453125,"y":1001.1474609375}},{"label":"GPHN","pos":{"x":-419.41326904296875,"y":-1620.377197265625}},{"label":"GPR98","pos":{"x":3105.8769945190743,"y":2965.4749624919054}},{"label":"GRB2","pos":{"x":-804.0224609375,"y":-1394.6844482421875}},{"label":"GRIN2A","pos":{"x":4305.876994519074,"y":2805.4749624919054}},{"label":"GRM3","pos":{"x":4225.876994519074,"y":2965.4749624919054}},{"label":"GUSB","pos":{"x":1507.2899169921875,"y":-1714.0274658203125}},{"label":"GYS1","pos":{"x":237.28143310546875,"y":1300.6666259765625}},{"label":"H3F3A","pos":{"x":-1077.3582763671875,"y":787.1475830078125}},{"label":"H3F3B","pos":{"x":-745.9300537109375,"y":-1137.587158203125}},{"label":"HCN1","pos":{"x":4305.876994519074,"y":3045.4749624919054}},{"label":"HEATR4","pos":{"x":-5.654273986816406,"y":-1284.6900634765625}},{"label":"HERPUD1","pos":{"x":-321.55426025390625,"y":528.6043701171875}},{"label":"HGF","pos":{"x":1511.6993408203125,"y":-1588.8787841796875}},{"label":"HIF1A","pos":{"x":-40.65189838409424,"y":-1325.500732421875}},{"label":"HIP1","pos":{"x":1515.9207763671875,"y":-1555.4710693359375}},{"label":"HIST1H3B","pos":{"x":709.4923706054688,"y":262.7120361328125}},{"label":"HIVEP3","pos":{"x":3825.8769945190743,"y":2805.4749624919054}},{"label":"HLA-J","pos":{"x":4385.876994519074,"y":2645.4749624919054}},{"label":"HMCN1","pos":{"x":533.8253173828125,"y":-1625.6478271484375}},{"label":"HMGA2","pos":{"x":1768.5513916015625,"y":535.43408203125}},{"label":"HMGN2P46","pos":{"x":-780.4367065429688,"y":369.27801513671875}},{"label":"HNF1A","pos":{"x":1757.9781494140625,"y":608.0585327148438}},{"label":"HNRNPA2B1","pos":{"x":1887.1759033203125,"y":-1297.19189453125}},{"label":"HOOK3","pos":{"x":540.9690551757812,"y":-958.1390380859375}},{"label":"HOXA11","pos":{"x":1889.0701904296875,"y":-1181.7847900390625}},{"label":"HOXA13","pos":{"x":1887.7791748046875,"y":-1213.5784912109375}},{"label":"HOXA4","pos":{"x":1885.9542236328125,"y":-1365.155517578125}},{"label":"HOXA5","pos":{"x":1885.16796875,"y":-1331.042236328125}},{"label":"HOXA7","pos":{"x":1887.4166259765625,"y":-1268.2197265625}},{"label":"HOXA9","pos":{"x":1889.5390625,"y":-1241.7421875}},{"label":"HOXC11","pos":{"x":1867.5802001953125,"y":496.90638732910156}},{"label":"HOXC13","pos":{"x":1909.4012451171875,"y":471.5838623046875}},{"label":"HOXD11","pos":{"x":-384.4039611816406,"y":1248.2822265625}},{"label":"HOXD13","pos":{"x":-353.70770263671875,"y":1161.3504638671875}},{"label":"HPVC1","pos":{"x":3665.8769945190743,"y":2805.4749624919054}},{"label":"HRAS","pos":{"x":1986.3719482421875,"y":984.7245483398438}},{"label":"HRNR","pos":{"x":4065.8769945190743,"y":2925.4749624919054}},{"label":"HSD17B7P2","pos":{"x":4305.876994519074,"y":3085.4749624919054}},{"label":"HSP90AA1","pos":{"x":-34.902581214904785,"y":-1298.965576171875}},{"label":"HSP90AB1","pos":{"x":770.543212890625,"y":413.7149963378906}},{"label":"HSPBP1","pos":{"x":4225.876994519074,"y":3125.4749624919054}},{"label":"HSPG2","pos":{"x":3505.8769945190743,"y":3085.4749624919054}},{"label":"IDH1","pos":{"x":-435.4776611328125,"y":1444.6566162109375}},{"label":"IDH2","pos":{"x":4305.876994519074,"y":2925.4749624919054}},{"label":"IFNA1","pos":{"x":-1106.444091796875,"y":-735.8721923828125}},{"label":"IFNA10","pos":{"x":4225.876994519074,"y":2925.4749624919054}},{"label":"IFNA13","pos":{"x":3905.8769945190743,"y":2565.4749624919054}},{"label":"IFNA14","pos":{"x":-1109.8404541015625,"y":-853.213134765625}},{"label":"IFNA16","pos":{"x":4145.876994519074,"y":2565.4749624919054}},{"label":"IFNA17","pos":{"x":4225.876994519074,"y":2845.4749624919054}},{"label":"IFNA2","pos":{"x":-1104.8524169921875,"y":-674.259765625}},{"label":"IFNA22P","pos":{"x":3985.8769945190743,"y":2645.4749624919054}},{"label":"IFNA4","pos":{"x":-1114.75146484375,"y":-1009.0436706542969}},{"label":"IFNA5","pos":{"x":3185.8769945190743,"y":2805.4749624919054}},{"label":"IFNA6","pos":{"x":-1105.6265869140625,"y":-794.808349609375}},{"label":"IFNA7","pos":{"x":-1114.289306640625,"y":-906.2196655273438}},{"label":"IFNA8","pos":{"x":-1105.87890625,"y":-611.5733032226562}},{"label":"IFNB1","pos":{"x":-1112.7891845703125,"y":-1070.104248046875}},{"label":"IFNE","pos":{"x":3345.8769945190743,"y":3045.4749624919054}},{"label":"IFNW1","pos":{"x":-1116.5189208984375,"y":-959.2161254882812}},{"label":"IGF1R","pos":{"x":536.5831298828125,"y":-999.4329833984375}},{"label":"IKZF1","pos":{"x":1874.95703125,"y":-1529.219970703125}},{"label":"IL11","pos":{"x":3905.8769945190743,"y":3085.4749624919054}},{"label":"IL21R","pos":{"x":-184.59539794921875,"y":511.91131591796875}},{"label":"IL32","pos":{"x":3185.8769945190743,"y":2845.4749624919054}},{"label":"IRF4","pos":{"x":754.2063598632812,"y":292.96441650390625}},{"label":"IRS1","pos":{"x":-366.0813293457031,"y":1178.1412353515625}},{"label":"ISOC2","pos":{"x":3585.8769945190743,"y":2725.4749624919054}},{"label":"ITGAM","pos":{"x":3985.8769945190743,"y":3085.4749624919054}},{"label":"ITGAX","pos":{"x":3425.8769945190743,"y":2565.4749624919054}},{"label":"ITK","pos":{"x":373.73126220703125,"y":688.65234375}},{"label":"JAK1","pos":{"x":-1073.120361328125,"y":893.0106811523438}},{"label":"JAK2","pos":{"x":-1080.49755859375,"y":-0.38529014587402344}},{"label":"JAZF1","pos":{"x":1510.369384765625,"y":-1900.46826171875}},{"label":"JUN","pos":{"x":-1084.021728515625,"y":885.6098022460938}},{"label":"KAT6B","pos":{"x":4145.876994519074,"y":3085.4749624919054}},{"label":"KCNJ5","pos":{"x":1936.9759521484375,"y":1296.664794921875}},{"label":"KDM5A","pos":{"x":1754.41943359375,"y":474.383056640625}},{"label":"KDM5C","pos":{"x":1237.998291015625,"y":933.1438598632812}},{"label":"KDM6A","pos":{"x":1242.9775390625,"y":1007.9673767089844}},{"label":"KDR","pos":{"x":14.608638763427734,"y":-161.81724548339844}},{"label":"KEL","pos":{"x":1510.1982421875,"y":-958.1900634765625}},{"label":"KIAA1549","pos":{"x":1511.9407958984375,"y":-1046.176513671875}},{"label":"KIF13A","pos":{"x":3425.8769945190743,"y":3205.4749624919054}},{"label":"KIF2B","pos":{"x":3745.8769945190743,"y":3205.4749624919054}},{"label":"KIT","pos":{"x":15.309579133987427,"y":-95.02448272705078}},{"label":"KLF4","pos":{"x":-942.7037353515625,"y":-43.9535436630249}},{"label":"KLF6","pos":{"x":1833.2083740234375,"y":-267.7413330078125}},{"label":"KLHL9","pos":{"x":3905.8769945190743,"y":2845.4749624919054}},{"label":"KLK2","pos":{"x":230.1559600830078,"y":1197.3570556640625}},{"label":"KLLN","pos":{"x":3505.8769945190743,"y":2925.4749624919054}},{"label":"KMT2A","pos":{"x":1872.9368896484375,"y":1397.255615234375}},{"label":"KMT2C","pos":{"x":1509.8895263671875,"y":-1181.3614501953125}},{"label":"KMT2D","pos":{"x":537.6090698242188,"y":-1406.728271484375}},{"label":"KRAS","pos":{"x":1763.9686279296875,"y":486.83990478515625}},{"label":"KRTAP1-5","pos":{"x":3985.8769945190743,"y":2805.4749624919054}},{"label":"KTN1","pos":{"x":6.298272609710693,"y":-1256.1971435546875}},{"label":"LAMA2","pos":{"x":3425.8769945190743,"y":3085.4749624919054}},{"label":"LAMA3","pos":{"x":3585.8769945190743,"y":3205.4749624919054}},{"label":"LANCL2","pos":{"x":1688.3056640625,"y":-1745.3330078125}},{"label":"LCP1","pos":{"x":1079.36181640625,"y":-1076.2576904296875}},{"label":"LDLR","pos":{"x":199.90306091308594,"y":1178.612060546875}},{"label":"LHFP","pos":{"x":1127.052734375,"y":-1050.682373046875}},{"label":"LILRA1","pos":{"x":3665.8769945190743,"y":2845.4749624919054}},{"label":"LILRB1","pos":{"x":3825.8769945190743,"y":3085.4749624919054}},{"label":"LMO1","pos":{"x":1990.60595703125,"y":925.9468383789062}},{"label":"LMO2","pos":{"x":1901.3336181640625,"y":1252.4072265625}},{"label":"LPA","pos":{"x":706.6915283203125,"y":163.1662139892578}},{"label":"LPP","pos":{"x":-75.82916831970215,"y":-659.880126953125}},{"label":"LRFN5","pos":{"x":3665.8769945190743,"y":2885.4749624919054}},{"label":"LRIG3","pos":{"x":1811.314697265625,"y":210.06439208984375}},{"label":"LRP1","pos":{"x":4305.876994519074,"y":2845.4749624919054}},{"label":"LRP2","pos":{"x":-529.3905487060547,"y":1109.1849365234375}},{"label":"LRRC55","pos":{"x":3985.8769945190743,"y":3165.4749624919054}},{"label":"LYL1","pos":{"x":196.16781616210938,"y":1088.879638671875}},{"label":"LZTR1","pos":{"x":3425.8769945190743,"y":2725.4749624919054}},{"label":"MACF1","pos":{"x":3345.8769945190743,"y":2685.4749624919054}},{"label":"MAFB","pos":{"x":945.8655395507812,"y":1359.2935791015625}},{"label":"MALAT1","pos":{"x":1937.1363525390625,"y":1253.1602783203125}},{"label":"MALT1","pos":{"x":548.1737670898438,"y":-1243.8919677734375}},{"label":"MAML2","pos":{"x":1856.4388427734375,"y":1163.5433349609375}},{"label":"MAP2K2","pos":{"x":222.884033203125,"y":1067.7030029296875}},{"label":"MAP2K4","pos":{"x":-995.7246704101562,"y":-1487.34326171875}},{"label":"MAPK1","pos":{"x":1378.2724609375,"y":170.3138427734375}},{"label":"MAPK3","pos":{"x":-152.21414184570312,"y":612.0833740234375}},{"label":"MAX","pos":{"x":-442.4814147949219,"y":-1633.2659912109375}},{"label":"MDM2","pos":{"x":1798.8768310546875,"y":190.29318237304688}},{"label":"MDM4","pos":{"x":-833.0067749023438,"y":862.1566162109375}},{"label":"MECOM","pos":{"x":-231.17149353027344,"y":-716.9869384765625}},{"label":"MED12","pos":{"x":1322.0660400390625,"y":890.3395385742188}},{"label":"MEN1","pos":{"x":1939.013671875,"y":1218.2674560546875}},{"label":"MESP2","pos":{"x":3345.8769945190743,"y":2845.4749624919054}},{"label":"MET","pos":{"x":1512.0137939453125,"y":-1250.835693359375}},{"label":"MGAM","pos":{"x":1508.165283203125,"y":-918.97802734375}},{"label":"MGMT","pos":{"x":1899.6175537109375,"y":-344.6187438964844}},{"label":"MIMT1","pos":{"x":3505.8769945190743,"y":2565.4749624919054}},{"label":"MIR-31/31","pos":{"x":3985.8769945190743,"y":2765.4749624919054}},{"label":"MIR-31/31*","pos":{"x":4145.876994519074,"y":2965.4749624919054}},{"label":"MIR200C","pos":{"x":1752.754638671875,"y":519.1319122314453}},{"label":"MIR31","pos":{"x":4385.876994519074,"y":3005.4749624919054}},{"label":"MIR31HG","pos":{"x":3745.8769945190743,"y":3125.4749624919054}},{"label":"MIR3944","pos":{"x":3185.8769945190743,"y":2765.4749624919054}},{"label":"MKL1","pos":{"x":1316.92724609375,"y":50.04744625091553}},{"label":"MLF1","pos":{"x":-225.9068145751953,"y":-731.7863159179688}},{"label":"MLIP","pos":{"x":852.1859130859375,"y":170.48060607910156}},{"label":"MLLT1","pos":{"x":276.5060729980469,"y":1065.0606689453125}},{"label":"MLLT10","pos":{"x":1809.5045166015625,"y":-478.8963928222656}},{"label":"MLLT3","pos":{"x":-1111.5506591796875,"y":-1153.6170654296875}},{"label":"MLLT4","pos":{"x":869.1060180664062,"y":184.96414184570312}},{"label":"MLLT6","pos":{"x":540.462646484375,"y":-1450.7408447265625}},{"label":"MLST8","pos":{"x":-356.6343994140625,"y":668.452880859375}},{"label":"MNX1","pos":{"x":1513.0545654296875,"y":-1280.6893310546875}},{"label":"MROH2B","pos":{"x":3265.8769945190743,"y":3125.4749624919054}},{"label":"MRPS17","pos":{"x":3985.8769945190743,"y":2845.4749624919054}},{"label":"MSH6","pos":{"x":548.0504760742188,"y":-864.803466796875}},{"label":"MSI2","pos":{"x":-754.187255859375,"y":-1161.3599853515625}},{"label":"MST1L","pos":{"x":3185.8769945190743,"y":2645.4749624919054}},{"label":"MTAP","pos":{"x":-1101.130126953125,"y":-528.4954681396484}},{"label":"MTCP1","pos":{"x":1264.527587890625,"y":922.1893920898438}},{"label":"MTG1","pos":{"x":3425.8769945190743,"y":2965.4749624919054}},{"label":"MTOR","pos":{"x":545.1968383789062,"y":-783.8020629882812}},{"label":"MUC1","pos":{"x":-1057.2918701171875,"y":1099.4473876953125}},{"label":"MUC16","pos":{"x":195.22833251953125,"y":1156.32861328125}},{"label":"MUC17","pos":{"x":1511.7415771484375,"y":-1530.3966064453125}},{"label":"MUC2","pos":{"x":3265.8769945190743,"y":3165.4749624919054}},{"label":"MUC20","pos":{"x":-52.89361572265625,"y":-629.0512084960938}},{"label":"MUC4","pos":{"x":4065.8769945190743,"y":2845.4749624919054}},{"label":"MUC5B","pos":{"x":3585.8769945190743,"y":2605.4749624919054}},{"label":"MUC7","pos":{"x":4385.876994519074,"y":2845.4749624919054}},{"label":"MXRA5","pos":{"x":4385.876994519074,"y":3125.4749624919054}},{"label":"MYB","pos":{"x":696.8779907226562,"y":128.8123321533203}},{"label":"MYC","pos":{"x":1059.28076171875,"y":-307.25885009765625}},{"label":"MYCL","pos":{"x":-1084.1553955078125,"y":816.0003662109375}},{"label":"MYCN","pos":{"x":-574.19580078125,"y":1204.841796875}},{"label":"MYH11","pos":{"x":531.5238647460938,"y":-1545.8001708984375}},{"label":"MYH13","pos":{"x":3425.8769945190743,"y":3165.4749624919054}},{"label":"MYH2","pos":{"x":3585.8769945190743,"y":2765.4749624919054}},{"label":"MYH4","pos":{"x":3505.8769945190743,"y":3125.4749624919054}},{"label":"MYH8","pos":{"x":4145.876994519074,"y":2805.4749624919054}},{"label":"MYH9","pos":{"x":558.737060546875,"y":-716.5760498046875}},{"label":"MYO15A","pos":{"x":3745.8769945190743,"y":2805.4749624919054}},{"label":"MYO3A","pos":{"x":4065.8769945190743,"y":2685.4749624919054}},{"label":"NACA","pos":{"x":1738.162109375,"y":470.9620361328125}},{"label":"NAT14","pos":{"x":3745.8769945190743,"y":3085.4749624919054}},{"label":"NBPF1","pos":{"x":3425.8769945190743,"y":2885.4749624919054}},{"label":"NBPF10","pos":{"x":4225.876994519074,"y":3005.4749624919054}},{"label":"NCKIPSD","pos":{"x":-185.6373748779297,"y":-838.1697387695312}},{"label":"NCOA1","pos":{"x":-552.8646240234375,"y":1233.7958984375}},{"label":"NCOA4","pos":{"x":1912.988525390625,"y":-226.31814575195312}},{"label":"NCR1","pos":{"x":4305.876994519074,"y":2725.4749624919054}},{"label":"NDRG1","pos":{"x":1054.96044921875,"y":-279.48223876953125}},{"label":"NEB","pos":{"x":4145.876994519074,"y":3205.4749624919054}},{"label":"NF1","pos":{"x":-857.8353271484375,"y":-1622.02197265625}},{"label":"NFE2L2","pos":{"x":-342.842529296875,"y":1127.1849365234375}},{"label":"NFIB","pos":{"x":-1225.5523681640625,"y":-46.08333492279053}},{"label":"NFKB1","pos":{"x":-8.050090789794922,"y":143.43789672851562}},{"label":"NFKB2","pos":{"x":1746.27392578125,"y":-150.8605194091797}},{"label":"NIN","pos":{"x":-254.6302490234375,"y":-1682.4066162109375}},{"label":"NIPBL","pos":{"x":3585.8769945190743,"y":3045.4749624919054}},{"label":"NLRP11","pos":{"x":3105.8769945190743,"y":2605.4749624919054}},{"label":"NLRP12","pos":{"x":3905.8769945190743,"y":2685.4749624919054}},{"label":"NLRP13","pos":{"x":4305.876994519074,"y":2645.4749624919054}},{"label":"NLRP2","pos":{"x":229.49534606933594,"y":1234.515625}},{"label":"NLRP4","pos":{"x":3425.8769945190743,"y":2605.4749624919054}},{"label":"NLRP5","pos":{"x":3585.8769945190743,"y":2805.4749624919054}},{"label":"NLRP7","pos":{"x":3185.8769945190743,"y":3085.4749624919054}},{"label":"NLRP8","pos":{"x":4385.876994519074,"y":2565.4749624919054}},{"label":"NLRP9","pos":{"x":4145.876994519074,"y":2925.4749624919054}},{"label":"NONO","pos":{"x":1411.0770263671875,"y":917.4642944335938}},{"label":"NOTCH1","pos":{"x":-949.7824096679688,"y":-57.257612228393555}},{"label":"NOTCH2","pos":{"x":-889.9387817382812,"y":961.7032470703125}},{"label":"NOTCH2NL","pos":{"x":-868.1536254882812,"y":911.5387573242188}},{"label":"NPAP1","pos":{"x":3745.8769945190743,"y":2765.4749624919054}},{"label":"NPM1","pos":{"x":451.6867370605469,"y":505.62322998046875}},{"label":"NR1H2","pos":{"x":232.9431915283203,"y":1258.490478515625}},{"label":"NR2E1","pos":{"x":753.3524780273438,"y":300.2871398925781}},{"label":"NR4A3","pos":{"x":-1006.5301208496094,"y":-28.03672695159912}},{"label":"NRAS","pos":{"x":-1103.78076171875,"y":829.5138549804688}},{"label":"NRCAM","pos":{"x":1510.4468994140625,"y":-1656.844482421875}},{"label":"NRXN3","pos":{"x":-98.31080627441406,"y":-1328.76123046875}},{"label":"NSD1","pos":{"x":374.6021423339844,"y":492.99505615234375}},{"label":"NT5C2","pos":{"x":1765.759765625,"y":-283.3273620605469}},{"label":"NTRK1","pos":{"x":-875.9464721679688,"y":974.6962890625}},{"label":"NTRK3","pos":{"x":-735.951904296875,"y":356.42547607421875}},{"label":"NUDT11","pos":{"x":4145.876994519074,"y":2645.4749624919054}},{"label":"NUMA1","pos":{"x":1858.5341796875,"y":1385.29443359375}},{"label":"NUP210L","pos":{"x":3345.8769945190743,"y":2645.4749624919054}},{"label":"NUP214","pos":{"x":-978.1495361328125,"y":-47.39120388031006}},{"label":"NUP98","pos":{"x":1989.462646484375,"y":954.52490234375}},{"label":"NUTM1","pos":{"x":-806.4032592773438,"y":345.6898498535156}},{"label":"NUTM2A","pos":{"x":1719.8157958984375,"y":-195.06787109375}},{"label":"OBSCN","pos":{"x":-968.7816162109375,"y":719.483642578125}},{"label":"OLIG2","pos":{"x":553.7562255859375,"y":-675.1814575195312}},{"label":"OR2Z1","pos":{"x":358.9183044433594,"y":1098.4334716796875}},{"label":"OR4K1","pos":{"x":-130.73821640014648,"y":-1680.87060546875}},{"label":"OR4K2","pos":{"x":-129.85643005371094,"y":-1610.2119140625}},{"label":"OR4K5","pos":{"x":-133.61016464233398,"y":-1560.3853759765625}},{"label":"OR4M1","pos":{"x":-157.18295288085938,"y":-1736.9859619140625}},{"label":"OR4Q3","pos":{"x":-127.28615951538086,"y":-1505.6766357421875}},{"label":"OR52N5","pos":{"x":1992.7933349609375,"y":903.2210693359375}},{"label":"OR8K3","pos":{"x":3825.8769945190743,"y":2885.4749624919054}},{"label":"P2RY8","pos":{"x":1194.6112060546875,"y":963.1585083007812}},{"label":"PAFAH1B2","pos":{"x":1925.4403076171875,"y":1241.343017578125}},{"label":"PALB2","pos":{"x":-174.76220703125,"y":540.6853637695312}},{"label":"PAN3","pos":{"x":4065.8769945190743,"y":2965.4749624919054}},{"label":"PAOX","pos":{"x":4145.876994519074,"y":2885.4749624919054}},{"label":"PATZ1","pos":{"x":1298.7769775390625,"y":123.06341934204102}},{"label":"PAX3","pos":{"x":-369.3697204589844,"y":1266.2001953125}},{"label":"PAX5","pos":{"x":536.71240234375,"y":-1357.158203125}},{"label":"PAX7","pos":{"x":-884.1363525390625,"y":781.0033569335938}},{"label":"PBX1","pos":{"x":-986.3497924804688,"y":1029.31494140625}},{"label":"PCDH11X","pos":{"x":4225.876994519074,"y":2605.4749624919054}},{"label":"PCDH11Y","pos":{"x":3185.8769945190743,"y":2885.4749624919054}},{"label":"PCDH19","pos":{"x":3745.8769945190743,"y":2565.4749624919054}},{"label":"PCDHA1","pos":{"x":4145.876994519074,"y":3045.4749624919054}},{"label":"PCDHA3","pos":{"x":3985.8769945190743,"y":2965.4749624919054}},{"label":"PCDHAC2","pos":{"x":3905.8769945190743,"y":2805.4749624919054}},{"label":"PCDHGC5","pos":{"x":3825.8769945190743,"y":2725.4749624919054}},{"label":"PCLO","pos":{"x":1507.095947265625,"y":-1367.748046875}},{"label":"PCM1","pos":{"x":920.998046875,"y":-344.83251953125}},{"label":"PCSK7","pos":{"x":1884.663330078125,"y":1313.3626708984375}},{"label":"PDCD1LG2","pos":{"x":-1150.80322265625,"y":114.55673599243164}},{"label":"PDE4DIP","pos":{"x":-880.2106323242188,"y":901.1173706054688}},{"label":"PDGFA","pos":{"x":1503.6781005859375,"y":-1873.4500732421875}},{"label":"PDGFRA","pos":{"x":13.854980707168579,"y":13.469215154647827}},{"label":"PDGFRB","pos":{"x":376.2137145996094,"y":709.2533569335938}},{"label":"PDPK1","pos":{"x":-303.1800537109375,"y":476.6910705566406}},{"label":"PDPR","pos":{"x":550.4548950195312,"y":-1160.1956787109375}},{"label":"PEG3","pos":{"x":3905.8769945190743,"y":3045.4749624919054}},{"label":"PER1","pos":{"x":-818.9000244140625,"y":-1425.468505859375}},{"label":"PHF21A","pos":{"x":1970.163330078125,"y":1014.835693359375}},{"label":"PHF6","pos":{"x":1423.122314453125,"y":983.446533203125}},{"label":"PHOX2B","pos":{"x":-37.156715393066406,"y":180.45648193359375}},{"label":"PICALM","pos":{"x":1783.11865234375,"y":1063.6934814453125}},{"label":"PIK3C2B","pos":{"x":-830.2660522460938,"y":823.365966796875}},{"label":"PIK3C2G","pos":{"x":1751.8746337890625,"y":501.47833251953125}},{"label":"PIK3CA","pos":{"x":-242.37957763671875,"y":-653.9910888671875}},{"label":"PIK3CB","pos":{"x":-364.28167724609375,"y":-597.2984008789062}},{"label":"PIK3CD","pos":{"x":-865.729736328125,"y":848.114501953125}},{"label":"PIK3CG","pos":{"x":1513.924560546875,"y":-1211.49658203125}},{"label":"PIK3R1","pos":{"x":532.0463256835938,"y":-1780.8719482421875}},{"label":"PIK3R2","pos":{"x":639.8404541015625,"y":1523.462646484375}},{"label":"PIM1","pos":{"x":673.3607788085938,"y":56.353933334350586}},{"label":"PKD1L1","pos":{"x":3745.8769945190743,"y":2605.4749624919054}},{"label":"PKD1L2","pos":{"x":3825.8769945190743,"y":2565.4749624919054}},{"label":"PKHD1","pos":{"x":645.3896484375,"y":-11.58248519897461}},{"label":"PKM","pos":{"x":-958.5071411132812,"y":429.8068542480469}},{"label":"PLEKHG4B","pos":{"x":3665.8769945190743,"y":2565.4749624919054}},{"label":"PLXNA3","pos":{"x":3425.8769945190743,"y":2925.4749624919054}},{"label":"PMEL","pos":{"x":1908.5931396484375,"y":445.46624755859375}},{"label":"PMS1","pos":{"x":-349.91424560546875,"y":1143.9317626953125}},{"label":"PMS2","pos":{"x":1498.5355224609375,"y":-1844.2452392578125}},{"label":"POT1","pos":{"x":1511.6690673828125,"y":-1308.7742919921875}},{"label":"POTEB","pos":{"x":-941.41748046875,"y":335.0189208984375}},{"label":"POTED","pos":{"x":960.1907958984375,"y":751.9766235351562}},{"label":"POU2AF1","pos":{"x":1856.96630859375,"y":1412.6763916015625}},{"label":"POU4F2","pos":{"x":3105.8769945190743,"y":3085.4749624919054}},{"label":"PPARG","pos":{"x":-265.07898712158203,"y":-500.3688507080078}},{"label":"PPP1R12C","pos":{"x":3665.8769945190743,"y":2925.4749624919054}},{"label":"PPP2R1A","pos":{"x":234.23648071289062,"y":1273.1552734375}},{"label":"PPP6R1","pos":{"x":4305.876994519074,"y":2565.4749624919054}},{"label":"PRAP1","pos":{"x":3345.8769945190743,"y":2885.4749624919054}},{"label":"PRB2","pos":{"x":4145.876994519074,"y":2725.4749624919054}},{"label":"PRCC","pos":{"x":-974.17626953125,"y":1028.6084899902344}},{"label":"PRDM16","pos":{"x":-1121.1104736328125,"y":847.5693359375}},{"label":"PRDM9","pos":{"x":4065.8769945190743,"y":3005.4749624919054}},{"label":"PRF1","pos":{"x":1916.229248046875,"y":-268.0865173339844}},{"label":"PRH1","pos":{"x":1753.456298828125,"y":684.9639282226562}},{"label":"PRKAR1A","pos":{"x":-781.2473754882812,"y":-1248.2677001953125}},{"label":"PRKCA","pos":{"x":-794.63720703125,"y":-1314.9576416015625}},{"label":"PRKCB","pos":{"x":-157.2660369873047,"y":633.1369018554688}},{"label":"PRKCD","pos":{"x":-15.834866523742676,"y":-545.4625244140625}},{"label":"PRKCG","pos":{"x":234.51121520996094,"y":1288.0838623046875}},{"label":"PRKCH","pos":{"x":-159.39932250976562,"y":-1346.033935546875}},{"label":"PRKCI","pos":{"x":-223.17303466796875,"y":-748.5750122070312}},{"label":"PRKCQ","pos":{"x":1799.9234619140625,"y":-559.7306518554688}},{"label":"PRKCZ","pos":{"x":-1060.041015625,"y":780.628173828125}},{"label":"PRR4","pos":{"x":1754.3636474609375,"y":705.2802734375}},{"label":"PRRX1","pos":{"x":-1002.7631225585938,"y":1036.0611877441406}},{"label":"PSIP1","pos":{"x":-1073.9754638671875,"y":58.44526481628418}},{"label":"PSPH","pos":{"x":4065.8769945190743,"y":3125.4749624919054}},{"label":"PTCH1","pos":{"x":-980.1238403320312,"y":-25.30580759048462}},{"label":"PTEN","pos":{"x":1733.81591796875,"y":-77.61258697509766}},{"label":"PTPN11","pos":{"x":1760.2459716796875,"y":661.62451171875}},{"label":"PTPN18","pos":{"x":3505.8769945190743,"y":3205.4749624919054}},{"label":"PTPRC","pos":{"x":543.4306030273438,"y":-1287.859375}},{"label":"PTPRH","pos":{"x":4385.876994519074,"y":2965.4749624919054}},{"label":"PTPRT","pos":{"x":3665.8769945190743,"y":2725.4749624919054}},{"label":"RABEP1","pos":{"x":-984.1148681640625,"y":-1548.1414794921875}},{"label":"RAC1","pos":{"x":1872.314208984375,"y":-1446.789794921875}},{"label":"RAD21","pos":{"x":1077.5560302734375,"y":-402.4044494628906}},{"label":"RAD51B","pos":{"x":-466.668212890625,"y":-1646.74267578125}},{"label":"RAF1","pos":{"x":-283.7528381347656,"y":-513.0999145507812}},{"label":"RALGDS","pos":{"x":-924.0670776367188,"y":-162.94189453125}},{"label":"RANBP17","pos":{"x":418.24884033203125,"y":472.68701171875}},{"label":"RASA3","pos":{"x":990.3870239257812,"y":-1159.4644775390625}},{"label":"RB1","pos":{"x":1047.7373046875,"y":-1082.474609375}},{"label":"RBM15","pos":{"x":-845.5850830078125,"y":990.7291870117188}},{"label":"RBM47","pos":{"x":3345.8769945190743,"y":3205.4749624919054}},{"label":"RDH13","pos":{"x":4065.8769945190743,"y":3085.4749624919054}},{"label":"RECQL4","pos":{"x":1018.9934997558594,"y":-249.11831665039062}},{"label":"RELA","pos":{"x":1868.976318359375,"y":1314.2581787109375}},{"label":"RELN","pos":{"x":3345.8769945190743,"y":2805.4749624919054}},{"label":"RFPL4A","pos":{"x":3585.8769945190743,"y":3085.4749624919054}},{"label":"RFPL4AL1","pos":{"x":3265.8769945190743,"y":2925.4749624919054}},{"label":"RHOH","pos":{"x":-27.01006269454956,"y":28.38716459274292}},{"label":"RIMBP2","pos":{"x":3905.8769945190743,"y":3205.4749624919054}},{"label":"RIMS2","pos":{"x":3825.8769945190743,"y":3205.4749624919054}},{"label":"RNF213","pos":{"x":-742.642578125,"y":-1113.9185791015625}},{"label":"RNF43","pos":{"x":-967.0264892578125,"y":-1443.966064453125}},{"label":"RNLS","pos":{"x":3345.8769945190743,"y":2605.4749624919054}},{"label":"ROS1","pos":{"x":710.9526977539062,"y":291.3377380371094}},{"label":"RP1","pos":{"x":3665.8769945190743,"y":3205.4749624919054}},{"label":"RPL10","pos":{"x":1282.6639404296875,"y":882.5198974609375}},{"label":"RPL22","pos":{"x":-1059.7720947265625,"y":909.791015625}},{"label":"RPL28","pos":{"x":3265.8769945190743,"y":2685.4749624919054}},{"label":"RPL5","pos":{"x":-1035.934814453125,"y":735.6913452148438}},{"label":"RPN1","pos":{"x":-402.8089599609375,"y":-564.1061401367188}},{"label":"RPS6KA4","pos":{"x":1871.9862060546875,"y":1361.8212890625}},{"label":"RPS6KA5","pos":{"x":-264.70935821533203,"y":-1408.406005859375}},{"label":"RPS6KB1","pos":{"x":-772.3952026367188,"y":-1203.044189453125}},{"label":"RYR1","pos":{"x":4065.8769945190743,"y":3205.4749624919054}},{"label":"RYR2","pos":{"x":-1003.693603515625,"y":748.4183349609375}},{"label":"RYR3","pos":{"x":-774.7279052734375,"y":326.5525817871094}},{"label":"SACS","pos":{"x":4385.876994519074,"y":2885.4749624919054}},{"label":"SAMD9L","pos":{"x":3505.8769945190743,"y":3165.4749624919054}},{"label":"SBDS","pos":{"x":1507.96240234375,"y":-1687.8173828125}},{"label":"SBK2","pos":{"x":3825.8769945190743,"y":2645.4749624919054}},{"label":"SBK3","pos":{"x":4225.876994519074,"y":2645.4749624919054}},{"label":"SCN10A","pos":{"x":3345.8769945190743,"y":3165.4749624919054}},{"label":"SCN9A","pos":{"x":4225.876994519074,"y":2885.4749624919054}},{"label":"SDC4","pos":{"x":1078.807373046875,"y":1361.4423828125}},{"label":"SDHAP2","pos":{"x":3185.8769945190743,"y":3005.4749624919054}},{"label":"SDHC","pos":{"x":-1012.3401794433594,"y":1049.031005859375}},{"label":"SDHD","pos":{"x":1914.58984375,"y":1282.6661376953125}},{"label":"SDK1","pos":{"x":4065.8769945190743,"y":2765.4749624919054}},{"label":"SEC22B","pos":{"x":-903.632080078125,"y":960.2876586914062}},{"label":"SEC61G","pos":{"x":1688.57177734375,"y":-1810.005859375}},{"label":"SEMA3C","pos":{"x":4305.876994519074,"y":3125.4749624919054}},{"label":"SEMG1","pos":{"x":3425.8769945190743,"y":2805.4749624919054}},{"label":"SEPT14","pos":{"x":1690.255615234375,"y":-1585.79736328125}},{"label":"SEPT5","pos":{"x":1379.4044189453125,"y":82.78191184997559}},{"label":"SEPT9","pos":{"x":-795.4776611328125,"y":-1341.02490234375}},{"label":"SERPINE1","pos":{"x":1509.8829345703125,"y":-1499.6217041015625}},{"label":"SET","pos":{"x":-895.576416015625,"y":-144.68820190429688}},{"label":"SETBP1","pos":{"x":639.8364868164062,"y":1394.5545654296875}},{"label":"SETD2","pos":{"x":524.5107879638672,"y":-1835.6375732421875}},{"label":"SF3B1","pos":{"x":-381.8628845214844,"y":1230.1800537109375}},{"label":"SF3B6","pos":{"x":-476.27423095703125,"y":1305.4910888671875}},{"label":"SH2B3","pos":{"x":1921.9906005859375,"y":334.3782043457031}},{"label":"SH3GL1","pos":{"x":366.125244140625,"y":1141.722900390625}},{"label":"SHH","pos":{"x":1505.96142578125,"y":-839.31494140625}},{"label":"SHISA7","pos":{"x":3105.8769945190743,"y":3045.4749624919054}},{"label":"SIRPB1","pos":{"x":1032.3380126953125,"y":1365.5919189453125}},{"label":"SLC1A6","pos":{"x":3985.8769945190743,"y":3125.4749624919054}},{"label":"SLC34A2","pos":{"x":-24.706834077835083,"y":199.89913940429688}},{"label":"SLC45A3","pos":{"x":-1010.8416442871094,"y":717.9074096679688}},{"label":"SLC6A3","pos":{"x":3265.8769945190743,"y":2605.4749624919054}},{"label":"SLCO6A1","pos":{"x":3985.8769945190743,"y":2605.4749624919054}},{"label":"SLIT3","pos":{"x":3985.8769945190743,"y":3005.4749624919054}},{"label":"SMARCA4","pos":{"x":364.3513488769531,"y":1116.7413330078125}},{"label":"SMIM17","pos":{"x":3425.8769945190743,"y":2845.4749624919054}},{"label":"SMO","pos":{"x":1510.5687255859375,"y":-1154.66357421875}},{"label":"SOX2","pos":{"x":-204.11131286621094,"y":-840.0778198242188}},{"label":"SPAG17","pos":{"x":3985.8769945190743,"y":3205.4749624919054}},{"label":"SPECC1","pos":{"x":-847.28955078125,"y":-1457.953369140625}},{"label":"SPRN","pos":{"x":3985.8769945190743,"y":2685.4749624919054}},{"label":"SPRNP1","pos":{"x":3425.8769945190743,"y":3045.4749624919054}},{"label":"SPRY2","pos":{"x":988.571533203125,"y":-1134.2547607421875}},{"label":"SPTA1","pos":{"x":-1036.44189453125,"y":1083.014892578125}},{"label":"SPTBN5","pos":{"x":3105.8769945190743,"y":2765.4749624919054}},{"label":"SREBF2","pos":{"x":1337.87060546875,"y":45.55864906311035}},{"label":"SRGAP3","pos":{"x":-189.20033264160156,"y":-483.4100646972656}},{"label":"SRSF2","pos":{"x":-796.4059448242188,"y":-1365.136474609375}},{"label":"SRSF3","pos":{"x":665.4493408203125,"y":35.65590715408325}},{"label":"SS18","pos":{"x":615.12646484375,"y":1413.14306640625}},{"label":"SSC5D","pos":{"x":4225.876994519074,"y":2725.4749624919054}},{"label":"SSX1","pos":{"x":1993.3841552734375,"y":1086.644775390625}},{"label":"SSX2","pos":{"x":1257.022216796875,"y":1106.1717529296875}},{"label":"SSX4","pos":{"x":1257.8138427734375,"y":1085.9920654296875}},{"label":"STAG2","pos":{"x":1378.904296875,"y":891.8446044921875}},{"label":"STIL","pos":{"x":-863.1502075195312,"y":788.419921875}},{"label":"STK11","pos":{"x":237.39227294921875,"y":1110.6451416015625}},{"label":"STK19","pos":{"x":4305.876994519074,"y":2605.4749624919054}},{"label":"STL","pos":{"x":835.3440551757812,"y":185.58473205566406}},{"label":"SUFU","pos":{"x":1741.7186279296875,"y":-257.46566009521484}},{"label":"SUV420H2","pos":{"x":3265.8769945190743,"y":2885.4749624919054}},{"label":"SYCE1","pos":{"x":3265.8769945190743,"y":2805.4749624919054}},{"label":"SYK","pos":{"x":-1213.0289306640625,"y":0.8744544982910156}},{"label":"SYNE1","pos":{"x":3505.8769945190743,"y":2645.4749624919054}},{"label":"TAF15","pos":{"x":-928.5904541015625,"y":-1596.3238525390625}},{"label":"TAF1L","pos":{"x":3745.8769945190743,"y":2885.4749624919054}},{"label":"TAL1","pos":{"x":-1099.8079833984375,"y":862.5792846679688}},{"label":"TAL2","pos":{"x":-840.1040649414062,"y":-151.3382110595703}},{"label":"TARP","pos":{"x":1882.4825439453125,"y":-1408.542236328125}},{"label":"TBL1XR1","pos":{"x":-227.00091552734375,"y":-765.2854614257812}},{"label":"TCF12","pos":{"x":-902.069580078125,"y":329.2181396484375}},{"label":"TCF3","pos":{"x":246.72927856445312,"y":1095.6668701171875}},{"label":"TCF7L2","pos":{"x":1941.0537109375,"y":-249.11739349365234}},{"label":"TCGA.02.0001","pos":{"x":3008,"y":-1578}},{"label":"TCGA.02.0003","pos":{"x":-2503.3662109375,"y":1260.3365478515625}},{"label":"TCGA.02.0004","pos":{"x":-3620.75,"y":-1241.390869140625}},{"label":"TCGA.02.0006","pos":{"x":-3439.079345703125,"y":-1130.9217529296875}},{"label":"TCGA.02.0007","pos":{"x":-87.40349578857422,"y":2444.087890625}},{"label":"TCGA.02.0009","pos":{"x":3982.18212890625,"y":-1723.2857666015625}},{"label":"TCGA.02.0010","pos":{"x":-2968.54248046875,"y":2414.20166015625}},{"label":"TCGA.02.0011","pos":{"x":-3462.23095703125,"y":1282.11865234375}},{"label":"TCGA.02.0014","pos":{"x":-2237.279052734375,"y":2460.76123046875}},{"label":"TCGA.02.0015","pos":{"x":4226.52001953125,"y":-1431.519775390625}},{"label":"TCGA.02.0016","pos":{"x":1416.554443359375,"y":2715.512939453125}},{"label":"TCGA.02.0021","pos":{"x":1439.11279296875,"y":2638.5224609375}},{"label":"TCGA.02.0023","pos":{"x":4306.52001953125,"y":-1431.519775390625}},{"label":"TCGA.02.0024","pos":{"x":2030.043701171875,"y":2507.7802734375}},{"label":"TCGA.02.0025","pos":{"x":1440.285888671875,"y":2305.414306640625}},{"label":"TCGA.02.0026","pos":{"x":-2940.551513671875,"y":2478.842041015625}},{"label":"TCGA.02.0027","pos":{"x":2709.200439453125,"y":-1640.5355224609375}},{"label":"TCGA.02.0028","pos":{"x":-2049.9033203125,"y":2319.111328125}},{"label":"TCGA.02.0033","pos":{"x":-2844.3271484375,"y":-801.25341796875}},{"label":"TCGA.02.0034","pos":{"x":-2823,"y":-1553}},{"label":"TCGA.02.0037","pos":{"x":2586.27490234375,"y":-1975.177978515625}},{"label":"TCGA.02.0038","pos":{"x":4377.44287109375,"y":-1826.9813232421875}},{"label":"TCGA.02.0039","pos":{"x":-3448.231201171875,"y":-1195.538818359375}},{"label":"TCGA.02.0043","pos":{"x":4297.44287109375,"y":-1826.9813232421875}},{"label":"TCGA.02.0046","pos":{"x":-2532.5869140625,"y":1302.0697021484375}},{"label":"TCGA.02.0047","pos":{"x":-3512.334228515625,"y":129.05566024780273}},{"label":"TCGA.02.0048","pos":{"x":-2679.197265625,"y":854.2131958007812}},{"label":"TCGA.02.0051","pos":{"x":-4168.455078125,"y":-766.1422729492188}},{"label":"TCGA.02.0052","pos":{"x":2923.8583984375,"y":836.1168212890625}},{"label":"TCGA.02.0054","pos":{"x":-3511.822509765625,"y":-1798.9639892578125}},{"label":"TCGA.02.0055","pos":{"x":-2843.929443359375,"y":-734.4210815429688}},{"label":"TCGA.02.0057","pos":{"x":3390.242919921875,"y":738.9629516601562}},{"label":"TCGA.02.0058","pos":{"x":-3411.773193359375,"y":2382.868408203125}},{"label":"TCGA.02.0059","pos":{"x":-3143,"y":-1073}},{"label":"TCGA.02.0060","pos":{"x":-3919.532470703125,"y":1078.36474609375}},{"label":"TCGA.02.0064","pos":{"x":-2429.005126953125,"y":-1407.5242919921875}},{"label":"TCGA.02.0068","pos":{"x":249.9683609008789,"y":2804.94677734375}},{"label":"TCGA.02.0069","pos":{"x":5439.991131005361,"y":609.4123089881991}},{"label":"TCGA.02.0070","pos":{"x":3328,"y":-1258}},{"label":"TCGA.02.0071","pos":{"x":5439.991131005361,"y":649.4123089881991}},{"label":"TCGA.02.0074","pos":{"x":-3059.6201171875,"y":197.67539978027344}},{"label":"TCGA.02.0075","pos":{"x":-3223,"y":-1553}},{"label":"TCGA.02.0079","pos":{"x":-2645.070068359375,"y":-952.1046752929688}},{"label":"TCGA.02.0080","pos":{"x":-2040.8759765625,"y":2457.608642578125}},{"label":"TCGA.02.0083","pos":{"x":-129.12818908691406,"y":2551.089111328125}},{"label":"TCGA.02.0084","pos":{"x":-3347.532958984375,"y":2489.142578125}},{"label":"TCGA.02.0085","pos":{"x":2033.1826782226562,"y":2294.1845703125}},{"label":"TCGA.02.0086","pos":{"x":-3143,"y":-1393}},{"label":"TCGA.02.0087","pos":{"x":-3712.19921875,"y":2346.21337890625}},{"label":"TCGA.02.0089","pos":{"x":3704.23779296875,"y":883.4386596679688}},{"label":"TCGA.02.0099","pos":{"x":-3437.2998046875,"y":-988.4024047851562}},{"label":"TCGA.02.0102","pos":{"x":293.4603271484375,"y":2566.303955078125}},{"label":"TCGA.02.0104","pos":{"x":-2393.577880859375,"y":2467.279296875}},{"label":"TCGA.02.0106","pos":{"x":-1618.7481689453125,"y":-1400.9610595703125}},{"label":"TCGA.02.0107","pos":{"x":-3435.155029296875,"y":-953.9212036132812}},{"label":"TCGA.02.0111","pos":{"x":-96.19023132324219,"y":2276.65673828125}},{"label":"TCGA.02.0113","pos":{"x":3643.849609375,"y":2126.727294921875}},{"label":"TCGA.02.0114","pos":{"x":-1945.5260009765625,"y":2318.023193359375}},{"label":"TCGA.02.0115","pos":{"x":2990.242919921875,"y":897.9629516601562}},{"label":"TCGA.02.0116","pos":{"x":1890.916259765625,"y":2264.532958984375}},{"label":"TCGA.02.0258","pos":{"x":-3289.205810546875,"y":2431.375244140625}},{"label":"TCGA.02.0260","pos":{"x":4306.52001953125,"y":-1511.519775390625}},{"label":"TCGA.02.0266","pos":{"x":3217.445068359375,"y":-1745.476806640625}},{"label":"TCGA.02.0269","pos":{"x":4142.18212890625,"y":-1563.2857666015625}},{"label":"TCGA.02.0271","pos":{"x":2869.200439453125,"y":-1480.5355224609375}},{"label":"TCGA.02.0281","pos":{"x":-2669.58349609375,"y":139.0397071838379}},{"label":"TCGA.02.0285","pos":{"x":3328,"y":-1498}},{"label":"TCGA.02.0289","pos":{"x":3986.52001953125,"y":-1511.519775390625}},{"label":"TCGA.02.0290","pos":{"x":4401.1533203125,"y":-1176.5240478515625}},{"label":"TCGA.02.0317","pos":{"x":4066.52001953125,"y":-1511.519775390625}},{"label":"TCGA.02.0321","pos":{"x":-2736.012939453125,"y":996.657958984375}},{"label":"TCGA.02.0324","pos":{"x":5999.991131005361,"y":249.41230898819907}},{"label":"TCGA.02.0325","pos":{"x":-2889.02001953125,"y":1054.7861328125}},{"label":"TCGA.02.0326","pos":{"x":-3303,"y":-1233}},{"label":"TCGA.02.0330","pos":{"x":-3448.7705078125,"y":-1434.385498046875}},{"label":"TCGA.02.0332","pos":{"x":371.17681884765625,"y":2285.37158203125}},{"label":"TCGA.02.0333","pos":{"x":4151.25927734375,"y":-1487.8243408203125}},{"label":"TCGA.02.0337","pos":{"x":305.84326171875,"y":2304.366943359375}},{"label":"TCGA.02.0338","pos":{"x":-3376.843994140625,"y":1577.2684326171875}},{"label":"TCGA.02.0339","pos":{"x":-3657.1982421875,"y":317.2064208984375}},{"label":"TCGA.02.0422","pos":{"x":3897.443115234375,"y":-1666.9813232421875}},{"label":"TCGA.02.0430","pos":{"x":3906.52001953125,"y":-1511.519775390625}},{"label":"TCGA.02.0432","pos":{"x":-2513.283203125,"y":2334.712646484375}},{"label":"TCGA.02.0439","pos":{"x":-3955.371337890625,"y":750.5101318359375}},{"label":"TCGA.02.0440","pos":{"x":-2840.853515625,"y":153.66114807128906}},{"label":"TCGA.02.0446","pos":{"x":-2842.009521484375,"y":78.96692848205566}},{"label":"TCGA.02.0451","pos":{"x":3944.23779296875,"y":1043.4386291503906}},{"label":"TCGA.02.0456","pos":{"x":-3634.989501953125,"y":-1442.0693359375}},{"label":"TCGA.02.2466","pos":{"x":5519.991131005361,"y":169.41230898819907}},{"label":"TCGA.02.2470","pos":{"x":5519.991131005361,"y":609.4123089881991}},{"label":"TCGA.02.2483","pos":{"x":5599.991131005361,"y":49.41230898819907}},{"label":"TCGA.02.2485","pos":{"x":4959.991131005361,"y":569.4123089881991}},{"label":"TCGA.02.2486","pos":{"x":5119.991131005361,"y":649.4123089881991}},{"label":"TCGA.06.0119","pos":{"x":5039.991131005361,"y":609.4123089881991}},{"label":"TCGA.06.0121","pos":{"x":5279.991131005361,"y":209.41230898819907}},{"label":"TCGA.06.0122","pos":{"x":-2058.8812866210938,"y":-1491.0596923828125}},{"label":"TCGA.06.0124","pos":{"x":-2220.193603515625,"y":-1513.6129150390625}},{"label":"TCGA.06.0125","pos":{"x":2026.3961181640625,"y":2618.0439453125}},{"label":"TCGA.06.0126","pos":{"x":4297.6435546875,"y":-1727.8243408203125}},{"label":"TCGA.06.0127","pos":{"x":3746.52001953125,"y":-1271.519775390625}},{"label":"TCGA.06.0128","pos":{"x":-2884.6845703125,"y":2380.112548828125}},{"label":"TCGA.06.0129","pos":{"x":-2792.27978515625,"y":2421.93115234375}},{"label":"TCGA.06.0130","pos":{"x":-3307.53857421875,"y":-1397.5384521484375}},{"label":"TCGA.06.0132","pos":{"x":361.8851623535156,"y":2487.51708984375}},{"label":"TCGA.06.0133","pos":{"x":4184.23779296875,"y":803.4386596679688}},{"label":"TCGA.06.0137","pos":{"x":342.71588134765625,"y":2819.572509765625}},{"label":"TCGA.06.0138","pos":{"x":-180.08734130859375,"y":2517.921875}},{"label":"TCGA.06.0139","pos":{"x":-3620.75,"y":-1481.390869140625}},{"label":"TCGA.06.0140","pos":{"x":-2855.08251953125,"y":-681.989501953125}},{"label":"TCGA.06.0141","pos":{"x":-2742.79931640625,"y":-1453.843017578125}},{"label":"TCGA.06.0142","pos":{"x":3776.8037109375,"y":1967.8094482421875}},{"label":"TCGA.06.0143","pos":{"x":-2299.081787109375,"y":-1954.9873046875}},{"label":"TCGA.06.0145","pos":{"x":4080.4415283203125,"y":-322.6611022949219}},{"label":"TCGA.06.0146","pos":{"x":-3303.98095703125,"y":2370.2353515625}},{"label":"TCGA.06.0147","pos":{"x":-4038.817138671875,"y":-606.3299560546875}},{"label":"TCGA.06.0148","pos":{"x":4208.48779296875,"y":-1795.0738525390625}},{"label":"TCGA.06.0149","pos":{"x":-3143,"y":-1153}},{"label":"TCGA.06.0150","pos":{"x":5119.991131005361,"y":609.4123089881991}},{"label":"TCGA.06.0151","pos":{"x":4879.991131005361,"y":89.41230898819907}},{"label":"TCGA.06.0152","pos":{"x":-2461.5537109375,"y":-1782.3695068359375}},{"label":"TCGA.06.0154","pos":{"x":-2232.697265625,"y":-1313.9088134765625}},{"label":"TCGA.06.0155","pos":{"x":-2225.376953125,"y":-1950.1824951171875}},{"label":"TCGA.06.0156","pos":{"x":-3796.10595703125,"y":1339.5699462890625}},{"label":"TCGA.06.0157","pos":{"x":4083.0802001953125,"y":-383.7158203125}},{"label":"TCGA.06.0158","pos":{"x":3972.904541015625,"y":-1671.519775390625}},{"label":"TCGA.06.0159","pos":{"x":4959.991131005361,"y":49.41230898819907}},{"label":"TCGA.06.0160","pos":{"x":3070.242919921875,"y":977.9629516601562}},{"label":"TCGA.06.0162","pos":{"x":4048.000732421875,"y":1093.140380859375}},{"label":"TCGA.06.0164","pos":{"x":1969.489013671875,"y":2264.752197265625}},{"label":"TCGA.06.0165","pos":{"x":5679.991131005361,"y":249.41230898819907}},{"label":"TCGA.06.0166","pos":{"x":-3507.0283203125,"y":229.80404663085938}},{"label":"TCGA.06.0167","pos":{"x":3883.849609375,"y":2126.727294921875}},{"label":"TCGA.06.0168","pos":{"x":-3290.496337890625,"y":-1311.8577880859375}},{"label":"TCGA.06.0169","pos":{"x":-2953.6064453125,"y":-1374.4202880859375}},{"label":"TCGA.06.0171","pos":{"x":3578.626708984375,"y":1588.9974365234375}},{"label":"TCGA.06.0173","pos":{"x":3772.05029296875,"y":1588.2886962890625}},{"label":"TCGA.06.0174","pos":{"x":-2689.0400390625,"y":633.1346435546875}},{"label":"TCGA.06.0175","pos":{"x":-2652.569580078125,"y":-1105.7225341796875}},{"label":"TCGA.06.0176","pos":{"x":-4152.50146484375,"y":-522.9683227539062}},{"label":"TCGA.06.0177","pos":{"x":-3065.607177734375,"y":262.2327880859375}},{"label":"TCGA.06.0178","pos":{"x":1430.0875244140625,"y":2487.03515625}},{"label":"TCGA.06.0179","pos":{"x":3864.23779296875,"y":1043.4386291503906}},{"label":"TCGA.06.0182","pos":{"x":3797.853271484375,"y":1061.592529296875}},{"label":"TCGA.06.0184","pos":{"x":1397.065185546875,"y":2397.217041015625}},{"label":"TCGA.06.0185","pos":{"x":3693.63427734375,"y":1964.5987548828125}},{"label":"TCGA.06.0187","pos":{"x":295.76702880859375,"y":2616.227294921875}},{"label":"TCGA.06.0188","pos":{"x":2020.977294921875,"y":2422.454345703125}},{"label":"TCGA.06.0189","pos":{"x":-2347.651611328125,"y":-1326.1707763671875}},{"label":"TCGA.06.0190","pos":{"x":-2969.384521484375,"y":-1267.615234375}},{"label":"TCGA.06.0192","pos":{"x":853.509521484375,"y":2258.091552734375}},{"label":"TCGA.06.0194","pos":{"x":-1949.005126953125,"y":-1327.5242919921875}},{"label":"TCGA.06.0195","pos":{"x":3486.8330078125,"y":1599.7669677734375}},{"label":"TCGA.06.0197","pos":{"x":-4241.09912109375,"y":-717.9005737304688}},{"label":"TCGA.06.0201","pos":{"x":-2963.946044921875,"y":-716.9136962890625}},{"label":"TCGA.06.0206","pos":{"x":5599.991131005361,"y":289.4123089881991}},{"label":"TCGA.06.0208","pos":{"x":3864.23779296875,"y":803.4386596679688}},{"label":"TCGA.06.0209","pos":{"x":5999.991131005361,"y":529.4123089881991}},{"label":"TCGA.06.0210","pos":{"x":-2612.53759765625,"y":-990.7682495117188}},{"label":"TCGA.06.0211","pos":{"x":4211.2802734375,"y":-1674.270263671875}},{"label":"TCGA.06.0213","pos":{"x":5919.991131005361,"y":649.4123089881991}},{"label":"TCGA.06.0214","pos":{"x":3813.073974609375,"y":1550.60302734375}},{"label":"TCGA.06.0216","pos":{"x":-154.1309356689453,"y":2367.982666015625}},{"label":"TCGA.06.0219","pos":{"x":3846.85693359375,"y":1958.375}},{"label":"TCGA.06.0221","pos":{"x":3393.369873046875,"y":1594.0750732421875}},{"label":"TCGA.06.0237","pos":{"x":3978.613525390625,"y":1500.3486328125}},{"label":"TCGA.06.0238","pos":{"x":-3287.00927734375,"y":1270.4375}},{"label":"TCGA.06.0240","pos":{"x":3543.43212890625,"y":1229.061767578125}},{"label":"TCGA.06.0241","pos":{"x":1945.2034912109375,"y":2525.2880859375}},{"label":"TCGA.06.0394","pos":{"x":3826.52001953125,"y":-1511.519775390625}},{"label":"TCGA.06.0397","pos":{"x":-2823,"y":-1393}},{"label":"TCGA.06.0402","pos":{"x":4080.8564453125,"y":-624.8701782226562}},{"label":"TCGA.06.0409","pos":{"x":1378.7568359375,"y":2288.677490234375}},{"label":"TCGA.06.0410","pos":{"x":-2670.775390625,"y":82.268798828125}},{"label":"TCGA.06.0412","pos":{"x":-1949.005126953125,"y":-1407.5242919921875}},{"label":"TCGA.06.0413","pos":{"x":-2695.9169921875,"y":559.65087890625}},{"label":"TCGA.06.0414","pos":{"x":914.1412963867188,"y":2462.406494140625}},{"label":"TCGA.06.0644","pos":{"x":-2987.53857421875,"y":-997.5384521484375}},{"label":"TCGA.06.0645","pos":{"x":-1645.25439453125,"y":-1517.4609375}},{"label":"TCGA.06.0646","pos":{"x":-2139.593017578125,"y":1145.0692138671875}},{"label":"TCGA.06.0648","pos":{"x":-3294.92138671875,"y":1319.41748046875}},{"label":"TCGA.06.0649","pos":{"x":3499.084716796875,"y":1977.6455078125}},{"label":"TCGA.06.0650","pos":{"x":5359.991131005361,"y":409.4123089881991}},{"label":"TCGA.06.0686","pos":{"x":-2522.2744140625,"y":1143.9019775390625}},{"label":"TCGA.06.0743","pos":{"x":368.86041259765625,"y":2651.6357421875}},{"label":"TCGA.06.0744","pos":{"x":2002.777587890625,"y":2681.706298828125}},{"label":"TCGA.06.0745","pos":{"x":-2132.00048828125,"y":1291.6051025390625}},{"label":"TCGA.06.0747","pos":{"x":4092.7724609375,"y":-438.2275390625}},{"label":"TCGA.06.0749","pos":{"x":3592.16748046875,"y":1971.7718505859375}},{"label":"TCGA.06.0750","pos":{"x":-2843.608154296875,"y":-571.9186401367188}},{"label":"TCGA.06.0875","pos":{"x":-3218.529296875,"y":1560.2349853515625}},{"label":"TCGA.06.0876","pos":{"x":4396.57470703125,"y":-1465.3291015625}},{"label":"TCGA.06.0877","pos":{"x":3737.643798828125,"y":-1887.8243408203125}},{"label":"TCGA.06.0878","pos":{"x":-2113.543701171875,"y":-932.062744140625}},{"label":"TCGA.06.0879","pos":{"x":917.6472778320312,"y":2592.5654296875}},{"label":"TCGA.06.0881","pos":{"x":-1873.5435791015625,"y":-1012.062744140625}},{"label":"TCGA.06.0882","pos":{"x":3347.08642578125,"y":1707.558837890625}},{"label":"TCGA.06.0939","pos":{"x":5679.991131005361,"y":329.4123089881991}},{"label":"TCGA.06.1084","pos":{"x":-169.66664123535156,"y":2285.396240234375}},{"label":"TCGA.06.1086","pos":{"x":-3223,"y":-1713}},{"label":"TCGA.06.1087","pos":{"x":-2514.330078125,"y":997.289794921875}},{"label":"TCGA.06.1800","pos":{"x":5359.991131005361,"y":489.4123089881991}},{"label":"TCGA.06.1801","pos":{"x":5759.991131005361,"y":569.4123089881991}},{"label":"TCGA.06.1802","pos":{"x":5599.991131005361,"y":129.41230898819907}},{"label":"TCGA.06.1804","pos":{"x":4879.991131005361,"y":529.4123089881991}},{"label":"TCGA.06.1805","pos":{"x":5839.991131005361,"y":209.41230898819907}},{"label":"TCGA.06.1806","pos":{"x":5679.991131005361,"y":489.4123089881991}},{"label":"TCGA.06.2557","pos":{"x":4799.991131005361,"y":129.41230898819907}},{"label":"TCGA.06.2558","pos":{"x":5759.991131005361,"y":449.4123089881991}},{"label":"TCGA.06.2559","pos":{"x":5039.991131005361,"y":409.4123089881991}},{"label":"TCGA.06.2561","pos":{"x":5279.991131005361,"y":89.41230898819907}},{"label":"TCGA.06.2562","pos":{"x":5599.991131005361,"y":169.41230898819907}},{"label":"TCGA.06.2563","pos":{"x":5039.991131005361,"y":49.41230898819907}},{"label":"TCGA.06.2564","pos":{"x":4959.991131005361,"y":129.41230898819907}},{"label":"TCGA.06.2565","pos":{"x":5919.991131005361,"y":609.4123089881991}},{"label":"TCGA.06.2566","pos":{"x":5759.991131005361,"y":169.41230898819907}},{"label":"TCGA.06.2567","pos":{"x":5039.991131005361,"y":449.4123089881991}},{"label":"TCGA.06.2569","pos":{"x":5999.991131005361,"y":409.4123089881991}},{"label":"TCGA.06.2570","pos":{"x":5679.991131005361,"y":449.4123089881991}},{"label":"TCGA.06.5408","pos":{"x":5679.991131005361,"y":9.412308988199072}},{"label":"TCGA.06.5410","pos":{"x":5919.991131005361,"y":489.4123089881991}},{"label":"TCGA.06.5411","pos":{"x":5599.991131005361,"y":569.4123089881991}},{"label":"TCGA.06.5412","pos":{"x":5039.991131005361,"y":489.4123089881991}},{"label":"TCGA.06.5413","pos":{"x":5359.991131005361,"y":369.4123089881991}},{"label":"TCGA.06.5414","pos":{"x":5279.991131005361,"y":129.41230898819907}},{"label":"TCGA.06.5415","pos":{"x":5839.991131005361,"y":609.4123089881991}},{"label":"TCGA.06.5416","pos":{"x":5279.991131005361,"y":49.41230898819907}},{"label":"TCGA.06.5417","pos":{"x":5439.991131005361,"y":369.4123089881991}},{"label":"TCGA.06.5418","pos":{"x":4879.991131005361,"y":649.4123089881991}},{"label":"TCGA.06.5856","pos":{"x":4799.991131005361,"y":169.41230898819907}},{"label":"TCGA.06.5858","pos":{"x":5279.991131005361,"y":569.4123089881991}},{"label":"TCGA.06.5859","pos":{"x":5999.991131005361,"y":649.4123089881991}},{"label":"TCGA.06.6388","pos":{"x":5039.991131005361,"y":169.41230898819907}},{"label":"TCGA.06.6389","pos":{"x":5039.991131005361,"y":9.412308988199072}},{"label":"TCGA.06.6390","pos":{"x":5439.991131005361,"y":689.4123089881991}},{"label":"TCGA.06.6391","pos":{"x":5439.991131005361,"y":329.4123089881991}},{"label":"TCGA.06.6693","pos":{"x":5199.991131005361,"y":249.41230898819907}},{"label":"TCGA.06.6694","pos":{"x":5599.991131005361,"y":649.4123089881991}},{"label":"TCGA.06.6695","pos":{"x":5119.991131005361,"y":209.41230898819907}},{"label":"TCGA.06.6697","pos":{"x":5519.991131005361,"y":129.41230898819907}},{"label":"TCGA.06.6698","pos":{"x":5519.991131005361,"y":89.41230898819907}},{"label":"TCGA.06.6699","pos":{"x":5679.991131005361,"y":49.41230898819907}},{"label":"TCGA.06.6700","pos":{"x":4799.991131005361,"y":489.4123089881991}},{"label":"TCGA.06.6701","pos":{"x":4879.991131005361,"y":449.4123089881991}},{"label":"TCGA.08.0244","pos":{"x":-84.28287506103516,"y":2689.362548828125}},{"label":"TCGA.08.0245","pos":{"x":832.6099243164062,"y":2512.453857421875}},{"label":"TCGA.08.0246","pos":{"x":4066.52001953125,"y":-1431.519775390625}},{"label":"TCGA.08.0344","pos":{"x":-1930.3531494140625,"y":2456.821533203125}},{"label":"TCGA.08.0345","pos":{"x":-2686.53125,"y":771.924560546875}},{"label":"TCGA.08.0346","pos":{"x":-3063,"y":-1073}},{"label":"TCGA.08.0347","pos":{"x":312.2944030761719,"y":2393.764892578125}},{"label":"TCGA.08.0348","pos":{"x":-3797.027587890625,"y":1457.6829833984375}},{"label":"TCGA.08.0349","pos":{"x":3948.976806640625,"y":1147.1341552734375}},{"label":"TCGA.08.0350","pos":{"x":-2854.2802734375,"y":2486.293701171875}},{"label":"TCGA.08.0351","pos":{"x":-2379.390625,"y":2338.394775390625}},{"label":"TCGA.08.0352","pos":{"x":-2962.557373046875,"y":-548.6646728515625}},{"label":"TCGA.08.0353","pos":{"x":-2140.904541015625,"y":964.5629272460938}},{"label":"TCGA.08.0354","pos":{"x":4146.52001953125,"y":-1431.519775390625}},{"label":"TCGA.08.0355","pos":{"x":-193.40200805664062,"y":2771.143798828125}},{"label":"TCGA.08.0356","pos":{"x":884.822509765625,"y":2782.9189453125}},{"label":"TCGA.08.0357","pos":{"x":835.9346313476562,"y":2645.59228515625}},{"label":"TCGA.08.0358","pos":{"x":-99.08676147460938,"y":2774.980224609375}},{"label":"TCGA.08.0359","pos":{"x":-2892.05712890625,"y":1113.5860595703125}},{"label":"TCGA.08.0360","pos":{"x":-4226.01171875,"y":-560.8804931640625}},{"label":"TCGA.08.0373","pos":{"x":-4138.5517578125,"y":-659.1683959960938}},{"label":"TCGA.08.0375","pos":{"x":3746.52001953125,"y":-1431.519775390625}},{"label":"TCGA.08.0380","pos":{"x":3243.8583984375,"y":1076.1168212890625}},{"label":"TCGA.08.0385","pos":{"x":-3957.582763671875,"y":698.623291015625}},{"label":"TCGA.08.0386","pos":{"x":4024.23779296875,"y":1123.4385986328125}},{"label":"TCGA.08.0389","pos":{"x":3704.23779296875,"y":1123.4385986328125}},{"label":"TCGA.08.0390","pos":{"x":-1949.005126953125,"y":-1167.5242919921875}},{"label":"TCGA.08.0392","pos":{"x":-2961.61669921875,"y":-793.406494140625}},{"label":"TCGA.08.0509","pos":{"x":-3223,"y":-1153}},{"label":"TCGA.08.0510","pos":{"x":-3143,"y":-1233}},{"label":"TCGA.08.0511","pos":{"x":4307.92724609375,"y":-532.2835083007812}},{"label":"TCGA.08.0512","pos":{"x":887.8472290039062,"y":2340.776123046875}},{"label":"TCGA.08.0514","pos":{"x":3897.443115234375,"y":-1586.9813232421875}},{"label":"TCGA.08.0516","pos":{"x":2629.200439453125,"y":-1480.5355224609375}},{"label":"TCGA.08.0517","pos":{"x":-2255.6748046875,"y":2330.73388671875}},{"label":"TCGA.08.0518","pos":{"x":4062.18212890625,"y":-1563.2857666015625}},{"label":"TCGA.08.0520","pos":{"x":3133.006591796875,"y":717.2885131835938}},{"label":"TCGA.08.0521","pos":{"x":4156.5634765625,"y":-1155.7039794921875}},{"label":"TCGA.08.0522","pos":{"x":-4186.7099609375,"y":-683.162353515625}},{"label":"TCGA.08.0524","pos":{"x":-3507.1142578125,"y":311.34893798828125}},{"label":"TCGA.08.0525","pos":{"x":4217.44287109375,"y":-1586.9813232421875}},{"label":"TCGA.08.0529","pos":{"x":3817.443115234375,"y":-1586.9813232421875}},{"label":"TCGA.08.0531","pos":{"x":4297.44287109375,"y":-1666.9813232421875}},{"label":"TCGA.12.0615","pos":{"x":5679.991131005361,"y":609.4123089881991}},{"label":"TCGA.12.0616","pos":{"x":-2583.33447265625,"y":-66.12604522705078}},{"label":"TCGA.12.0618","pos":{"x":-3269.286865234375,"y":1157.6353759765625}},{"label":"TCGA.12.0619","pos":{"x":810.8988647460938,"y":2372.943603515625}},{"label":"TCGA.12.0620","pos":{"x":-2903,"y":-993}},{"label":"TCGA.12.0653","pos":{"x":5839.991131005361,"y":449.4123089881991}},{"label":"TCGA.12.0654","pos":{"x":-3303,"y":-993}},{"label":"TCGA.12.0656","pos":{"x":1498.6690673828125,"y":2722.241455078125}},{"label":"TCGA.12.0657","pos":{"x":4079.5775146484375,"y":-572.1997680664062}},{"label":"TCGA.12.0662","pos":{"x":5439.991131005361,"y":529.4123089881991}},{"label":"TCGA.12.0670","pos":{"x":309.6658935546875,"y":2476.547119140625}},{"label":"TCGA.12.0688","pos":{"x":394.11407470703125,"y":2598.609619140625}},{"label":"TCGA.12.0691","pos":{"x":5199.991131005361,"y":409.4123089881991}},{"label":"TCGA.12.0692","pos":{"x":3019.9228515625,"y":-1268.76953125}},{"label":"TCGA.12.0703","pos":{"x":3248,"y":-1178}},{"label":"TCGA.12.0707","pos":{"x":3421.959228515625,"y":1150.453857421875}},{"label":"TCGA.12.0769","pos":{"x":5359.991131005361,"y":89.41230898819907}},{"label":"TCGA.12.0772","pos":{"x":2033.33544921875,"y":2256.875}},{"label":"TCGA.12.0773","pos":{"x":1947.579833984375,"y":2406.009033203125}},{"label":"TCGA.12.0775","pos":{"x":-2983,"y":-1073}},{"label":"TCGA.12.0776","pos":{"x":-2460.160400390625,"y":-1750.1417236328125}},{"label":"TCGA.12.0778","pos":{"x":-1944.2659912109375,"y":-1063.8287353515625}},{"label":"TCGA.12.0780","pos":{"x":4386.52001953125,"y":-1351.519775390625}},{"label":"TCGA.12.0818","pos":{"x":4959.991131005361,"y":449.4123089881991}},{"label":"TCGA.12.0819","pos":{"x":4879.991131005361,"y":209.41230898819907}},{"label":"TCGA.12.0820","pos":{"x":2962.615234375,"y":-884.691650390625}},{"label":"TCGA.12.0821","pos":{"x":3689.24658203125,"y":1585.15625}},{"label":"TCGA.12.0822","pos":{"x":-75.14063835144043,"y":2540.202880859375}},{"label":"TCGA.12.0826","pos":{"x":3323.8583984375,"y":1156.1168212890625}},{"label":"TCGA.12.0827","pos":{"x":775.1395263671875,"y":2265.226806640625}},{"label":"TCGA.12.0828","pos":{"x":3597.941162109375,"y":812.870361328125}},{"label":"TCGA.12.0829","pos":{"x":-2379.826171875,"y":-1034.4856872558594}},{"label":"TCGA.12.1088","pos":{"x":1493.5943603515625,"y":2326.184814453125}},{"label":"TCGA.12.1089","pos":{"x":4174.00732421875,"y":660.8999633789062}},{"label":"TCGA.12.1090","pos":{"x":-2818.260986328125,"y":-1609.304443359375}},{"label":"TCGA.12.1091","pos":{"x":888.698974609375,"y":2652.162841796875}},{"label":"TCGA.12.1092","pos":{"x":-2743,"y":-1713}},{"label":"TCGA.12.1093","pos":{"x":-4112.6695556640625,"y":-718.0882568359375}},{"label":"TCGA.12.1094","pos":{"x":4297.44287109375,"y":-1906.9813232421875}},{"label":"TCGA.12.1095","pos":{"x":-2903,"y":-1633}},{"label":"TCGA.12.1096","pos":{"x":-2366.005615234375,"y":-1974.2945556640625}},{"label":"TCGA.12.1097","pos":{"x":3618.76416015625,"y":754.0271606445312}},{"label":"TCGA.12.1098","pos":{"x":3024.46142578125,"y":-1744.2310791015625}},{"label":"TCGA.12.1099","pos":{"x":-3088.562744140625,"y":1313.4564208984375}},{"label":"TCGA.12.1597","pos":{"x":5359.991131005361,"y":529.4123089881991}},{"label":"TCGA.12.1598","pos":{"x":5119.991131005361,"y":489.4123089881991}},{"label":"TCGA.12.1599","pos":{"x":4879.991131005361,"y":329.4123089881991}},{"label":"TCGA.12.1600","pos":{"x":5199.991131005361,"y":529.4123089881991}},{"label":"TCGA.12.1601","pos":{"x":5759.991131005361,"y":9.412308988199072}},{"label":"TCGA.12.1602","pos":{"x":5599.991131005361,"y":329.4123089881991}},{"label":"TCGA.12.3644","pos":{"x":5999.991131005361,"y":329.4123089881991}},{"label":"TCGA.12.3646","pos":{"x":5039.991131005361,"y":369.4123089881991}},{"label":"TCGA.12.3648","pos":{"x":5439.991131005361,"y":489.4123089881991}},{"label":"TCGA.12.3649","pos":{"x":5839.991131005361,"y":129.41230898819907}},{"label":"TCGA.12.3650","pos":{"x":5199.991131005361,"y":9.412308988199072}},{"label":"TCGA.12.3651","pos":{"x":5919.991131005361,"y":249.41230898819907}},{"label":"TCGA.12.3652","pos":{"x":5759.991131005361,"y":489.4123089881991}},{"label":"TCGA.12.3653","pos":{"x":5119.991131005361,"y":169.41230898819907}},{"label":"TCGA.12.5295","pos":{"x":4879.991131005361,"y":569.4123089881991}},{"label":"TCGA.12.5299","pos":{"x":4799.991131005361,"y":529.4123089881991}},{"label":"TCGA.12.5301","pos":{"x":5039.991131005361,"y":129.41230898819907}},{"label":"TCGA.14.0736","pos":{"x":-2663,"y":-1713}},{"label":"TCGA.14.0740","pos":{"x":4799.991131005361,"y":649.4123089881991}},{"label":"TCGA.14.0781","pos":{"x":5919.991131005361,"y":49.41230898819907}},{"label":"TCGA.14.0783","pos":{"x":-2419.951416015625,"y":-1647.6190185546875}},{"label":"TCGA.14.0786","pos":{"x":-176.0115966796875,"y":2678.095458984375}},{"label":"TCGA.14.0787","pos":{"x":4080.5986328125,"y":-492.09100341796875}},{"label":"TCGA.14.0789","pos":{"x":-2028.804443359375,"y":-908.3672485351562}},{"label":"TCGA.14.0790","pos":{"x":5679.991131005361,"y":289.4123089881991}},{"label":"TCGA.14.0812","pos":{"x":4959.991131005361,"y":249.41230898819907}},{"label":"TCGA.14.0813","pos":{"x":-2684.401611328125,"y":702.3648071289062}},{"label":"TCGA.14.0817","pos":{"x":3645.147216796875,"y":1592.7335205078125}},{"label":"TCGA.14.0862","pos":{"x":5119.991131005361,"y":449.4123089881991}},{"label":"TCGA.14.0865","pos":{"x":5759.991131005361,"y":409.4123089881991}},{"label":"TCGA.14.0866","pos":{"x":5359.991131005361,"y":569.4123089881991}},{"label":"TCGA.14.0867","pos":{"x":-4154.03662109375,"y":-465.8147888183594}},{"label":"TCGA.14.0871","pos":{"x":-4149.44677734375,"y":-1001.2687377929688}},{"label":"TCGA.14.1034","pos":{"x":-2982.79931640625,"y":-1693.843017578125}},{"label":"TCGA.14.1037","pos":{"x":4879.991131005361,"y":689.4123089881991}},{"label":"TCGA.14.1043","pos":{"x":5599.991131005361,"y":249.41230898819907}},{"label":"TCGA.14.1395","pos":{"x":5999.991131005361,"y":209.41230898819907}},{"label":"TCGA.14.1396","pos":{"x":-2964.144775390625,"y":-658.1971435546875}},{"label":"TCGA.14.1401","pos":{"x":-2139.58349609375,"y":909.4827880859375}},{"label":"TCGA.14.1402","pos":{"x":851.5665893554688,"y":2786.28369140625}},{"label":"TCGA.14.1450","pos":{"x":4959.991131005361,"y":289.4123089881991}},{"label":"TCGA.14.1451","pos":{"x":-89.9654541015625,"y":2376.2841796875}},{"label":"TCGA.14.1452","pos":{"x":-2344.26611328125,"y":-1623.8287353515625}},{"label":"TCGA.14.1453","pos":{"x":4075.801025390625,"y":-682.3726196289062}},{"label":"TCGA.14.1454","pos":{"x":-3838.58447265625,"y":1239.622802734375}},{"label":"TCGA.14.1455","pos":{"x":5119.991131005361,"y":289.4123089881991}},{"label":"TCGA.14.1456","pos":{"x":5999.991131005361,"y":489.4123089881991}},{"label":"TCGA.14.1458","pos":{"x":5679.991131005361,"y":369.4123089881991}},{"label":"TCGA.14.1459","pos":{"x":3864.23779296875,"y":724.4386596679688}},{"label":"TCGA.14.1794","pos":{"x":5759.991131005361,"y":249.41230898819907}},{"label":"TCGA.14.1795","pos":{"x":5439.991131005361,"y":249.41230898819907}},{"label":"TCGA.14.1821","pos":{"x":4799.991131005361,"y":449.4123089881991}},{"label":"TCGA.14.1823","pos":{"x":5839.991131005361,"y":489.4123089881991}},{"label":"TCGA.14.1824","pos":{"x":5119.991131005361,"y":369.4123089881991}},{"label":"TCGA.14.1825","pos":{"x":5999.991131005361,"y":9.412308988199072}},{"label":"TCGA.14.1827","pos":{"x":5679.991131005361,"y":649.4123089881991}},{"label":"TCGA.14.1829","pos":{"x":4879.991131005361,"y":289.4123089881991}},{"label":"TCGA.14.2554","pos":{"x":4799.991131005361,"y":689.4123089881991}},{"label":"TCGA.14.2555","pos":{"x":5439.991131005361,"y":49.41230898819907}},{"label":"TCGA.14.3476","pos":{"x":5679.991131005361,"y":169.41230898819907}},{"label":"TCGA.14.3477","pos":{"x":5599.991131005361,"y":609.4123089881991}},{"label":"TCGA.14.4157","pos":{"x":5759.991131005361,"y":609.4123089881991}},{"label":"TCGA.15.0742","pos":{"x":4307.87353515625,"y":-1270.166259765625}},{"label":"TCGA.15.1444","pos":{"x":5359.991131005361,"y":689.4123089881991}},{"label":"TCGA.15.1446","pos":{"x":3817.443115234375,"y":-1826.9813232421875}},{"label":"TCGA.15.1447","pos":{"x":-2818.3359375,"y":763.3707275390625}},{"label":"TCGA.15.1449","pos":{"x":-2882.334228515625,"y":1260.373291015625}},{"label":"TCGA.16.0846","pos":{"x":-3506.257568359375,"y":-6.139932155609131}},{"label":"TCGA.16.0848","pos":{"x":-3072.368408203125,"y":76.87283325195312}},{"label":"TCGA.16.0849","pos":{"x":-3718.481201171875,"y":2484.677734375}},{"label":"TCGA.16.0850","pos":{"x":-3426.43994140625,"y":2483.468505859375}},{"label":"TCGA.16.0861","pos":{"x":3906.720703125,"y":-1252.36279296875}},{"label":"TCGA.16.1045","pos":{"x":-2871.0830078125,"y":-1761.35205078125}},{"label":"TCGA.16.1047","pos":{"x":4137.44287109375,"y":-1906.9813232421875}},{"label":"TCGA.16.1048","pos":{"x":5599.991131005361,"y":409.4123089881991}},{"label":"TCGA.16.1055","pos":{"x":4057.443115234375,"y":-1906.9813232421875}},{"label":"TCGA.16.1056","pos":{"x":3236.81689453125,"y":-1573.6116943359375}},{"label":"TCGA.16.1060","pos":{"x":-1949.005126953125,"y":-1647.5242919921875}},{"label":"TCGA.16.1062","pos":{"x":3977.443115234375,"y":-1826.9813232421875}},{"label":"TCGA.16.1063","pos":{"x":3704.23779296875,"y":724.4386596679688}},{"label":"TCGA.16.1460","pos":{"x":4959.991131005361,"y":689.4123089881991}},{"label":"TCGA.19.0955","pos":{"x":2624.46142578125,"y":-1744.2310791015625}},{"label":"TCGA.19.0957","pos":{"x":4799.991131005361,"y":49.41230898819907}},{"label":"TCGA.19.0960","pos":{"x":-3069.611328125,"y":132.58220291137695}},{"label":"TCGA.19.0962","pos":{"x":-2969.19677734375,"y":-600.474609375}},{"label":"TCGA.19.0963","pos":{"x":2990.242919921875,"y":738.9629516601562}},{"label":"TCGA.19.0964","pos":{"x":3817.443115234375,"y":-1906.9813232421875}},{"label":"TCGA.19.1385","pos":{"x":5199.991131005361,"y":569.4123089881991}},{"label":"TCGA.19.1386","pos":{"x":5119.991131005361,"y":89.41230898819907}},{"label":"TCGA.19.1387","pos":{"x":5199.991131005361,"y":649.4123089881991}},{"label":"TCGA.19.1388","pos":{"x":5119.991131005361,"y":529.4123089881991}},{"label":"TCGA.19.1389","pos":{"x":4959.991131005361,"y":369.4123089881991}},{"label":"TCGA.19.1390","pos":{"x":5919.991131005361,"y":529.4123089881991}},{"label":"TCGA.19.1392","pos":{"x":-3544.549072265625,"y":1078.0386962890625}},{"label":"TCGA.19.1786","pos":{"x":5279.991131005361,"y":449.4123089881991}},{"label":"TCGA.19.1787","pos":{"x":5199.991131005361,"y":209.41230898819907}},{"label":"TCGA.19.1788","pos":{"x":5199.991131005361,"y":289.4123089881991}},{"label":"TCGA.19.1789","pos":{"x":5279.991131005361,"y":369.4123089881991}},{"label":"TCGA.19.1790","pos":{"x":5999.991131005361,"y":289.4123089881991}},{"label":"TCGA.19.1791","pos":{"x":5679.991131005361,"y":209.41230898819907}},{"label":"TCGA.19.2619","pos":{"x":5759.991131005361,"y":289.4123089881991}},{"label":"TCGA.19.2620","pos":{"x":5279.991131005361,"y":169.41230898819907}},{"label":"TCGA.19.2621","pos":{"x":4879.991131005361,"y":369.4123089881991}},{"label":"TCGA.19.2623","pos":{"x":5439.991131005361,"y":449.4123089881991}},{"label":"TCGA.19.2624","pos":{"x":5039.991131005361,"y":329.4123089881991}},{"label":"TCGA.19.2625","pos":{"x":4959.991131005361,"y":89.41230898819907}},{"label":"TCGA.19.2629","pos":{"x":4959.991131005361,"y":649.4123089881991}},{"label":"TCGA.19.2631","pos":{"x":5359.991131005361,"y":289.4123089881991}},{"label":"TCGA.19.4065","pos":{"x":4959.991131005361,"y":409.4123089881991}},{"label":"TCGA.19.4068","pos":{"x":5279.991131005361,"y":249.41230898819907}},{"label":"TCGA.19.5947","pos":{"x":5439.991131005361,"y":289.4123089881991}},{"label":"TCGA.19.5950","pos":{"x":5999.991131005361,"y":49.41230898819907}},{"label":"TCGA.19.5951","pos":{"x":5839.991131005361,"y":569.4123089881991}},{"label":"TCGA.19.5952","pos":{"x":5919.991131005361,"y":209.41230898819907}},{"label":"TCGA.19.5953","pos":{"x":5519.991131005361,"y":49.41230898819907}},{"label":"TCGA.19.5954","pos":{"x":4799.991131005361,"y":289.4123089881991}},{"label":"TCGA.19.5955","pos":{"x":4879.991131005361,"y":49.41230898819907}},{"label":"TCGA.19.5956","pos":{"x":5519.991131005361,"y":289.4123089881991}},{"label":"TCGA.19.5958","pos":{"x":5199.991131005361,"y":449.4123089881991}},{"label":"TCGA.19.5959","pos":{"x":5119.991131005361,"y":689.4123089881991}},{"label":"TCGA.19.5960","pos":{"x":5199.991131005361,"y":489.4123089881991}},{"label":"TCGA.26.1438","pos":{"x":-3436.308349609375,"y":-906.8438720703125}},{"label":"TCGA.26.1439","pos":{"x":5359.991131005361,"y":9.412308988199072}},{"label":"TCGA.26.1440","pos":{"x":4386.82568359375,"y":-1670.008056640625}},{"label":"TCGA.26.1442","pos":{"x":5839.991131005361,"y":369.4123089881991}},{"label":"TCGA.26.1443","pos":{"x":4057.443115234375,"y":-1826.9813232421875}},{"label":"TCGA.26.1799","pos":{"x":5199.991131005361,"y":49.41230898819907}},{"label":"TCGA.26.5132","pos":{"x":5599.991131005361,"y":89.41230898819907}},{"label":"TCGA.26.5133","pos":{"x":5519.991131005361,"y":409.4123089881991}},{"label":"TCGA.26.5134","pos":{"x":4799.991131005361,"y":329.4123089881991}},{"label":"TCGA.26.5135","pos":{"x":5119.991131005361,"y":129.41230898819907}},{"label":"TCGA.26.5136","pos":{"x":5359.991131005361,"y":49.41230898819907}},{"label":"TCGA.26.5139","pos":{"x":5599.991131005361,"y":529.4123089881991}},{"label":"TCGA.26.6173","pos":{"x":4959.991131005361,"y":169.41230898819907}},{"label":"TCGA.26.6174","pos":{"x":5279.991131005361,"y":689.4123089881991}},{"label":"TCGA.27.1830","pos":{"x":4799.991131005361,"y":609.4123089881991}},{"label":"TCGA.27.1831","pos":{"x":5519.991131005361,"y":209.41230898819907}},{"label":"TCGA.27.1832","pos":{"x":5919.991131005361,"y":569.4123089881991}},{"label":"TCGA.27.1833","pos":{"x":5759.991131005361,"y":129.41230898819907}},{"label":"TCGA.27.1834","pos":{"x":4879.991131005361,"y":169.41230898819907}},{"label":"TCGA.27.1835","pos":{"x":5839.991131005361,"y":9.412308988199072}},{"label":"TCGA.27.1836","pos":{"x":5999.991131005361,"y":369.4123089881991}},{"label":"TCGA.27.1837","pos":{"x":5999.991131005361,"y":89.41230898819907}},{"label":"TCGA.27.1838","pos":{"x":5999.991131005361,"y":609.4123089881991}},{"label":"TCGA.27.2518","pos":{"x":5439.991131005361,"y":129.41230898819907}},{"label":"TCGA.27.2519","pos":{"x":5199.991131005361,"y":689.4123089881991}},{"label":"TCGA.27.2521","pos":{"x":5359.991131005361,"y":609.4123089881991}},{"label":"TCGA.27.2523","pos":{"x":5039.991131005361,"y":649.4123089881991}},{"label":"TCGA.27.2524","pos":{"x":5999.991131005361,"y":169.41230898819907}},{"label":"TCGA.27.2526","pos":{"x":5279.991131005361,"y":329.4123089881991}},{"label":"TCGA.27.2527","pos":{"x":5279.991131005361,"y":289.4123089881991}},{"label":"TCGA.27.2528","pos":{"x":5439.991131005361,"y":169.41230898819907}},{"label":"TCGA.28.1745","pos":{"x":5839.991131005361,"y":49.41230898819907}},{"label":"TCGA.28.1746","pos":{"x":5279.991131005361,"y":489.4123089881991}},{"label":"TCGA.28.1747","pos":{"x":5519.991131005361,"y":369.4123089881991}},{"label":"TCGA.28.1749","pos":{"x":5119.991131005361,"y":409.4123089881991}},{"label":"TCGA.28.1750","pos":{"x":5759.991131005361,"y":369.4123089881991}},{"label":"TCGA.28.1751","pos":{"x":5839.991131005361,"y":169.41230898819907}},{"label":"TCGA.28.1752","pos":{"x":4959.991131005361,"y":9.412308988199072}},{"label":"TCGA.28.1753","pos":{"x":4799.991131005361,"y":369.4123089881991}},{"label":"TCGA.28.1755","pos":{"x":4799.991131005361,"y":569.4123089881991}},{"label":"TCGA.28.1756","pos":{"x":5439.991131005361,"y":569.4123089881991}},{"label":"TCGA.28.1757","pos":{"x":5599.991131005361,"y":9.412308988199072}},{"label":"TCGA.28.1760","pos":{"x":5199.991131005361,"y":89.41230898819907}},{"label":"TCGA.28.2499","pos":{"x":5759.991131005361,"y":89.41230898819907}},{"label":"TCGA.28.2501","pos":{"x":5999.991131005361,"y":569.4123089881991}},{"label":"TCGA.28.2502","pos":{"x":5519.991131005361,"y":649.4123089881991}},{"label":"TCGA.28.2506","pos":{"x":5519.991131005361,"y":449.4123089881991}},{"label":"TCGA.28.2509","pos":{"x":5679.991131005361,"y":529.4123089881991}},{"label":"TCGA.28.2510","pos":{"x":4879.991131005361,"y":9.412308988199072}},{"label":"TCGA.28.2513","pos":{"x":5359.991131005361,"y":209.41230898819907}},{"label":"TCGA.28.2514","pos":{"x":4959.991131005361,"y":209.41230898819907}},{"label":"TCGA.28.5204","pos":{"x":5519.991131005361,"y":9.412308988199072}},{"label":"TCGA.28.5207","pos":{"x":5039.991131005361,"y":209.41230898819907}},{"label":"TCGA.28.5208","pos":{"x":5039.991131005361,"y":689.4123089881991}},{"label":"TCGA.28.5209","pos":{"x":5919.991131005361,"y":129.41230898819907}},{"label":"TCGA.28.5211","pos":{"x":5839.991131005361,"y":329.4123089881991}},{"label":"TCGA.28.5213","pos":{"x":5119.991131005361,"y":249.41230898819907}},{"label":"TCGA.28.5214","pos":{"x":5919.991131005361,"y":289.4123089881991}},{"label":"TCGA.28.5215","pos":{"x":5119.991131005361,"y":49.41230898819907}},{"label":"TCGA.28.5216","pos":{"x":4879.991131005361,"y":409.4123089881991}},{"label":"TCGA.28.5218","pos":{"x":5919.991131005361,"y":449.4123089881991}},{"label":"TCGA.28.5219","pos":{"x":5599.991131005361,"y":489.4123089881991}},{"label":"TCGA.28.5220","pos":{"x":5519.991131005361,"y":529.4123089881991}},{"label":"TCGA.28.6450","pos":{"x":5519.991131005361,"y":489.4123089881991}},{"label":"TCGA.32.1970","pos":{"x":5679.991131005361,"y":409.4123089881991}},{"label":"TCGA.32.1973","pos":{"x":5759.991131005361,"y":329.4123089881991}},{"label":"TCGA.32.1976","pos":{"x":5919.991131005361,"y":89.41230898819907}},{"label":"TCGA.32.1977","pos":{"x":5839.991131005361,"y":249.41230898819907}},{"label":"TCGA.32.1978","pos":{"x":4959.991131005361,"y":609.4123089881991}},{"label":"TCGA.32.1979","pos":{"x":5439.991131005361,"y":209.41230898819907}},{"label":"TCGA.32.1980","pos":{"x":5519.991131005361,"y":569.4123089881991}},{"label":"TCGA.32.1982","pos":{"x":5039.991131005361,"y":529.4123089881991}},{"label":"TCGA.32.1986","pos":{"x":5839.991131005361,"y":89.41230898819907}},{"label":"TCGA.32.1987","pos":{"x":5839.991131005361,"y":649.4123089881991}},{"label":"TCGA.32.1991","pos":{"x":5359.991131005361,"y":329.4123089881991}},{"label":"TCGA.32.2491","pos":{"x":5679.991131005361,"y":89.41230898819907}},{"label":"TCGA.32.2494","pos":{"x":5919.991131005361,"y":329.4123089881991}},{"label":"TCGA.32.2495","pos":{"x":5679.991131005361,"y":569.4123089881991}},{"label":"TCGA.32.2498","pos":{"x":5199.991131005361,"y":129.41230898819907}},{"label":"TCGA.32.2615","pos":{"x":4879.991131005361,"y":129.41230898819907}},{"label":"TCGA.32.2616","pos":{"x":4879.991131005361,"y":489.4123089881991}},{"label":"TCGA.32.2632","pos":{"x":5519.991131005361,"y":329.4123089881991}},{"label":"TCGA.32.2634","pos":{"x":5519.991131005361,"y":249.41230898819907}},{"label":"TCGA.32.2638","pos":{"x":4959.991131005361,"y":489.4123089881991}},{"label":"TCGA.32.4208","pos":{"x":5839.991131005361,"y":289.4123089881991}},{"label":"TCGA.32.4209","pos":{"x":4799.991131005361,"y":209.41230898819907}},{"label":"TCGA.32.4210","pos":{"x":5439.991131005361,"y":89.41230898819907}},{"label":"TCGA.32.4211","pos":{"x":5999.991131005361,"y":449.4123089881991}},{"label":"TCGA.32.4213","pos":{"x":5359.991131005361,"y":649.4123089881991}},{"label":"TCGA.32.4719","pos":{"x":4959.991131005361,"y":529.4123089881991}},{"label":"TCGA.32.5222","pos":{"x":5839.991131005361,"y":409.4123089881991}},{"label":"TCGA.41.2571","pos":{"x":5279.991131005361,"y":9.412308988199072}},{"label":"TCGA.41.2572","pos":{"x":5359.991131005361,"y":169.41230898819907}},{"label":"TCGA.41.2573","pos":{"x":5359.991131005361,"y":129.41230898819907}},{"label":"TCGA.41.2575","pos":{"x":5039.991131005361,"y":89.41230898819907}},{"label":"TCGA.41.3392","pos":{"x":4879.991131005361,"y":249.41230898819907}},{"label":"TCGA.41.3393","pos":{"x":5919.991131005361,"y":409.4123089881991}},{"label":"TCGA.41.3915","pos":{"x":5759.991131005361,"y":649.4123089881991}},{"label":"TCGA.41.4097","pos":{"x":5679.991131005361,"y":129.41230898819907}},{"label":"TCGA.41.5651","pos":{"x":5199.991131005361,"y":169.41230898819907}},{"label":"TCGA.41.6646","pos":{"x":4799.991131005361,"y":89.41230898819907}},{"label":"TCGA.74.6573","pos":{"x":5119.991131005361,"y":9.412308988199072}},{"label":"TCGA.74.6575","pos":{"x":5199.991131005361,"y":369.4123089881991}},{"label":"TCGA.74.6577","pos":{"x":5999.991131005361,"y":129.41230898819907}},{"label":"TCGA.74.6578","pos":{"x":5359.991131005361,"y":449.4123089881991}},{"label":"TCGA.74.6581","pos":{"x":5039.991131005361,"y":289.4123089881991}},{"label":"TCGA.74.6584","pos":{"x":5759.991131005361,"y":49.41230898819907}},{"label":"TCGA.76.4925","pos":{"x":5119.991131005361,"y":329.4123089881991}},{"label":"TCGA.76.4926","pos":{"x":5039.991131005361,"y":569.4123089881991}},{"label":"TCGA.76.4927","pos":{"x":5759.991131005361,"y":209.41230898819907}},{"label":"TCGA.76.4928","pos":{"x":4959.991131005361,"y":329.4123089881991}},{"label":"TCGA.76.4929","pos":{"x":5039.991131005361,"y":249.41230898819907}},{"label":"TCGA.76.4931","pos":{"x":5599.991131005361,"y":209.41230898819907}},{"label":"TCGA.76.4932","pos":{"x":4879.991131005361,"y":609.4123089881991}},{"label":"TCGA.76.4934","pos":{"x":4799.991131005361,"y":409.4123089881991}},{"label":"TCGA.76.4935","pos":{"x":5599.991131005361,"y":449.4123089881991}},{"label":"TCGA.76.6191","pos":{"x":5279.991131005361,"y":609.4123089881991}},{"label":"TCGA.76.6192","pos":{"x":5279.991131005361,"y":649.4123089881991}},{"label":"TCGA.76.6193","pos":{"x":5199.991131005361,"y":609.4123089881991}},{"label":"TCGA.76.6280","pos":{"x":5919.991131005361,"y":9.412308988199072}},{"label":"TCGA.76.6282","pos":{"x":5439.991131005361,"y":9.412308988199072}},{"label":"TCGA.76.6283","pos":{"x":5759.991131005361,"y":529.4123089881991}},{"label":"TCGA.76.6285","pos":{"x":4799.991131005361,"y":249.41230898819907}},{"label":"TCGA.76.6286","pos":{"x":5279.991131005361,"y":529.4123089881991}},{"label":"TCGA.76.6656","pos":{"x":4799.991131005361,"y":9.412308988199072}},{"label":"TCGA.76.6657","pos":{"x":5839.991131005361,"y":529.4123089881991}},{"label":"TCGA.76.6660","pos":{"x":5439.991131005361,"y":409.4123089881991}},{"label":"TCGA.76.6661","pos":{"x":5919.991131005361,"y":369.4123089881991}},{"label":"TCGA.76.6662","pos":{"x":5599.991131005361,"y":369.4123089881991}},{"label":"TCGA.76.6663","pos":{"x":5119.991131005361,"y":569.4123089881991}},{"label":"TCGA.76.6664","pos":{"x":5279.991131005361,"y":409.4123089881991}},{"label":"TCGA.81.5910","pos":{"x":5919.991131005361,"y":169.41230898819907}},{"label":"TCGA.81.5911","pos":{"x":5199.991131005361,"y":329.4123089881991}},{"label":"TCGA.87.5896","pos":{"x":5359.991131005361,"y":249.41230898819907}},{"label":"TCGA.CS.4938","pos":{"x":-5984.839843750051,"y":480.605973177175}},{"label":"TCGA.CS.4941","pos":{"x":-5344.839843750051,"y":280.605973177175}},{"label":"TCGA.CS.4942","pos":{"x":-6064.839843750051,"y":880.605973177175}},{"label":"TCGA.CS.4943","pos":{"x":-6304.839843750051,"y":560.605973177175}},{"label":"TCGA.CS.4944","pos":{"x":-4704.839843750051,"y":80.60597317717497}},{"label":"TCGA.CS.5390","pos":{"x":-6064.839843750051,"y":480.605973177175}},{"label":"TCGA.CS.5393","pos":{"x":-5264.839843750051,"y":120.60597317717497}},{"label":"TCGA.CS.5394","pos":{"x":-4704.839843750051,"y":440.605973177175}},{"label":"TCGA.CS.5395","pos":{"x":-5504.839843750051,"y":600.605973177175}},{"label":"TCGA.CS.5396","pos":{"x":-4624.839843750051,"y":840.605973177175}},{"label":"TCGA.CS.5397","pos":{"x":-5344.839843750051,"y":640.605973177175}},{"label":"TCGA.CS.6186","pos":{"x":-5584.839843750051,"y":680.605973177175}},{"label":"TCGA.CS.6188","pos":{"x":-5264.839843750051,"y":280.605973177175}},{"label":"TCGA.CS.6290","pos":{"x":-6224.839843750051,"y":560.605973177175}},{"label":"TCGA.CS.6665","pos":{"x":-5184.839843750051,"y":720.605973177175}},{"label":"TCGA.CS.6666","pos":{"x":-5184.839843750051,"y":640.605973177175}},{"label":"TCGA.CS.6667","pos":{"x":-5664.839843750051,"y":280.605973177175}},{"label":"TCGA.CS.6668","pos":{"x":-5904.839843750051,"y":560.605973177175}},{"label":"TCGA.CS.6669","pos":{"x":-4944.839843750051,"y":240.60597317717497}},{"label":"TCGA.CS.6670","pos":{"x":-5744.839843750051,"y":640.605973177175}},{"label":"TCGA.DB.5270","pos":{"x":-5904.839843750051,"y":0.6059731771749739}},{"label":"TCGA.DB.5273","pos":{"x":-4704.839843750051,"y":400.605973177175}},{"label":"TCGA.DB.5274","pos":{"x":-5264.839843750051,"y":640.605973177175}},{"label":"TCGA.DB.5275","pos":{"x":-4864.839843750051,"y":0.6059731771749739}},{"label":"TCGA.DB.5276","pos":{"x":-5664.839843750051,"y":600.605973177175}},{"label":"TCGA.DB.5277","pos":{"x":-5744.839843750051,"y":520.605973177175}},{"label":"TCGA.DB.5278","pos":{"x":-5424.839843750051,"y":280.605973177175}},{"label":"TCGA.DB.5279","pos":{"x":-5344.839843750051,"y":800.605973177175}},{"label":"TCGA.DB.5280","pos":{"x":-5504.839843750051,"y":440.605973177175}},{"label":"TCGA.DB.5281","pos":{"x":-5904.839843750051,"y":280.605973177175}},{"label":"TCGA.DB.A4X9","pos":{"x":-5264.839843750051,"y":200.60597317717497}},{"label":"TCGA.DB.A4XA","pos":{"x":-5024.839843750051,"y":120.60597317717497}},{"label":"TCGA.DB.A4XB","pos":{"x":-5104.839843750051,"y":-39.394026822825026}},{"label":"TCGA.DB.A4XC","pos":{"x":-5424.839843750051,"y":-39.394026822825026}},{"label":"TCGA.DB.A4XD","pos":{"x":-5984.839843750051,"y":560.605973177175}},{"label":"TCGA.DB.A4XE","pos":{"x":-5984.839843750051,"y":400.605973177175}},{"label":"TCGA.DB.A4XF","pos":{"x":-5664.839843750051,"y":640.605973177175}},{"label":"TCGA.DB.A4XG","pos":{"x":-5504.839843750051,"y":240.60597317717497}},{"label":"TCGA.DB.A4XH","pos":{"x":-4624.839843750051,"y":80.60597317717497}},{"label":"TCGA.DB.A64L","pos":{"x":-5824.839843750051,"y":280.605973177175}},{"label":"TCGA.DB.A64O","pos":{"x":-6064.839843750051,"y":520.605973177175}},{"label":"TCGA.DB.A64P","pos":{"x":-6064.839843750051,"y":40.605973177174974}},{"label":"TCGA.DB.A64Q","pos":{"x":-4784.839843750051,"y":680.605973177175}},{"label":"TCGA.DB.A64R","pos":{"x":-5264.839843750051,"y":440.605973177175}},{"label":"TCGA.DB.A64S","pos":{"x":-5264.839843750051,"y":80.60597317717497}},{"label":"TCGA.DB.A64U","pos":{"x":-5584.839843750051,"y":720.605973177175}},{"label":"TCGA.DB.A64V","pos":{"x":-6064.839843750051,"y":760.605973177175}},{"label":"TCGA.DB.A64W","pos":{"x":-4944.839843750051,"y":840.605973177175}},{"label":"TCGA.DB.A64X","pos":{"x":-4704.839843750051,"y":680.605973177175}},{"label":"TCGA.DB.A75K","pos":{"x":-5664.839843750051,"y":520.605973177175}},{"label":"TCGA.DB.A75L","pos":{"x":-5584.839843750051,"y":520.605973177175}},{"label":"TCGA.DB.A75M","pos":{"x":-4704.839843750051,"y":360.605973177175}},{"label":"TCGA.DB.A75O","pos":{"x":-4864.839843750051,"y":840.605973177175}},{"label":"TCGA.DB.A75P","pos":{"x":-6224.839843750051,"y":800.605973177175}},{"label":"TCGA.DH.5140","pos":{"x":-6064.839843750051,"y":840.605973177175}},{"label":"TCGA.DH.5141","pos":{"x":-4864.839843750051,"y":560.605973177175}},{"label":"TCGA.DH.5142","pos":{"x":-5984.839843750051,"y":320.605973177175}},{"label":"TCGA.DH.5143","pos":{"x":-5744.839843750051,"y":280.605973177175}},{"label":"TCGA.DH.5144","pos":{"x":-5504.839843750051,"y":680.605973177175}},{"label":"TCGA.DH.A669","pos":{"x":-4624.839843750051,"y":40.605973177174974}},{"label":"TCGA.DH.A66B","pos":{"x":-5104.839843750051,"y":800.605973177175}},{"label":"TCGA.DH.A66D","pos":{"x":-6224.839843750051,"y":400.605973177175}},{"label":"TCGA.DH.A66F","pos":{"x":-5104.839843750051,"y":600.605973177175}},{"label":"TCGA.DH.A66G","pos":{"x":-4704.839843750051,"y":640.605973177175}},{"label":"TCGA.DH.A7UR","pos":{"x":-5584.839843750051,"y":360.605973177175}},{"label":"TCGA.DH.A7US","pos":{"x":-5424.839843750051,"y":840.605973177175}},{"label":"TCGA.DH.A7UT","pos":{"x":-5824.839843750051,"y":120.60597317717497}},{"label":"TCGA.DH.A7UU","pos":{"x":-5824.839843750051,"y":800.605973177175}},{"label":"TCGA.DH.A7UV","pos":{"x":-6064.839843750051,"y":800.605973177175}},{"label":"TCGA.DU.5847","pos":{"x":-5104.839843750051,"y":120.60597317717497}},{"label":"TCGA.DU.5849","pos":{"x":-6304.839843750051,"y":280.605973177175}},{"label":"TCGA.DU.5851","pos":{"x":-4864.839843750051,"y":80.60597317717497}},{"label":"TCGA.DU.5852","pos":{"x":-5904.839843750051,"y":600.605973177175}},{"label":"TCGA.DU.5853","pos":{"x":-6144.839843750051,"y":240.60597317717497}},{"label":"TCGA.DU.5854","pos":{"x":-4864.839843750051,"y":680.605973177175}},{"label":"TCGA.DU.5855","pos":{"x":-4704.839843750051,"y":40.605973177174974}},{"label":"TCGA.DU.5870","pos":{"x":-5984.839843750051,"y":760.605973177175}},{"label":"TCGA.DU.5871","pos":{"x":-5344.839843750051,"y":520.605973177175}},{"label":"TCGA.DU.5872","pos":{"x":-6064.839843750051,"y":280.605973177175}},{"label":"TCGA.DU.5874","pos":{"x":-4944.839843750051,"y":720.605973177175}},{"label":"TCGA.DU.6392","pos":{"x":-5824.839843750051,"y":360.605973177175}},{"label":"TCGA.DU.6393","pos":{"x":-5024.839843750051,"y":720.605973177175}},{"label":"TCGA.DU.6394","pos":{"x":-5024.839843750051,"y":200.60597317717497}},{"label":"TCGA.DU.6395","pos":{"x":-5744.839843750051,"y":40.605973177174974}},{"label":"TCGA.DU.6396","pos":{"x":-5184.839843750051,"y":680.605973177175}},{"label":"TCGA.DU.6397","pos":{"x":-4784.839843750051,"y":280.605973177175}},{"label":"TCGA.DU.6399","pos":{"x":-5424.839843750051,"y":0.6059731771749739}},{"label":"TCGA.DU.6400","pos":{"x":-5824.839843750051,"y":640.605973177175}},{"label":"TCGA.DU.6401","pos":{"x":-5744.839843750051,"y":360.605973177175}},{"label":"TCGA.DU.6402","pos":{"x":-5664.839843750051,"y":40.605973177174974}},{"label":"TCGA.DU.6403","pos":{"x":-5504.839843750051,"y":280.605973177175}},{"label":"TCGA.DU.6404","pos":{"x":-5184.839843750051,"y":200.60597317717497}},{"label":"TCGA.DU.6405","pos":{"x":-5344.839843750051,"y":720.605973177175}},{"label":"TCGA.DU.6406","pos":{"x":-4784.839843750051,"y":360.605973177175}},{"label":"TCGA.DU.6407","pos":{"x":-4784.839843750051,"y":0.6059731771749739}},{"label":"TCGA.DU.6408","pos":{"x":-5504.839843750051,"y":760.605973177175}},{"label":"TCGA.DU.6410","pos":{"x":-5824.839843750051,"y":400.605973177175}},{"label":"TCGA.DU.6542","pos":{"x":-6144.839843750051,"y":760.605973177175}},{"label":"TCGA.DU.7006","pos":{"x":-5504.839843750051,"y":400.605973177175}},{"label":"TCGA.DU.7007","pos":{"x":-5824.839843750051,"y":240.60597317717497}},{"label":"TCGA.DU.7008","pos":{"x":-4704.839843750051,"y":0.6059731771749739}},{"label":"TCGA.DU.7009","pos":{"x":-5584.839843750051,"y":600.605973177175}},{"label":"TCGA.DU.7010","pos":{"x":-5184.839843750051,"y":80.60597317717497}},{"label":"TCGA.DU.7011","pos":{"x":-5024.839843750051,"y":560.605973177175}},{"label":"TCGA.DU.7012","pos":{"x":-5264.839843750051,"y":600.605973177175}},{"label":"TCGA.DU.7013","pos":{"x":-5424.839843750051,"y":40.605973177174974}},{"label":"TCGA.DU.7014","pos":{"x":-4704.839843750051,"y":280.605973177175}},{"label":"TCGA.DU.7015","pos":{"x":-5584.839843750051,"y":800.605973177175}},{"label":"TCGA.DU.7018","pos":{"x":-6144.839843750051,"y":440.605973177175}},{"label":"TCGA.DU.7019","pos":{"x":-6224.839843750051,"y":-39.394026822825026}},{"label":"TCGA.DU.7290","pos":{"x":-5824.839843750051,"y":320.605973177175}},{"label":"TCGA.DU.7292","pos":{"x":-5504.839843750051,"y":560.605973177175}},{"label":"TCGA.DU.7294","pos":{"x":-5744.839843750051,"y":80.60597317717497}},{"label":"TCGA.DU.7298","pos":{"x":-5824.839843750051,"y":560.605973177175}},{"label":"TCGA.DU.7299","pos":{"x":-4864.839843750051,"y":440.605973177175}},{"label":"TCGA.DU.7300","pos":{"x":-5344.839843750051,"y":680.605973177175}},{"label":"TCGA.DU.7301","pos":{"x":-4784.839843750051,"y":480.605973177175}},{"label":"TCGA.DU.7302","pos":{"x":-4704.839843750051,"y":200.60597317717497}},{"label":"TCGA.DU.7304","pos":{"x":-5744.839843750051,"y":120.60597317717497}},{"label":"TCGA.DU.7306","pos":{"x":-6064.839843750051,"y":560.605973177175}},{"label":"TCGA.DU.7309","pos":{"x":-5184.839843750051,"y":440.605973177175}},{"label":"TCGA.DU.8158","pos":{"x":-4624.839843750051,"y":440.605973177175}},{"label":"TCGA.DU.8161","pos":{"x":-5744.839843750051,"y":760.605973177175}},{"label":"TCGA.DU.8162","pos":{"x":-5744.839843750051,"y":320.605973177175}},{"label":"TCGA.DU.8163","pos":{"x":-5744.839843750051,"y":200.60597317717497}},{"label":"TCGA.DU.8164","pos":{"x":-5344.839843750051,"y":600.605973177175}},{"label":"TCGA.DU.8165","pos":{"x":-4624.839843750051,"y":120.60597317717497}},{"label":"TCGA.DU.8166","pos":{"x":-6144.839843750051,"y":720.605973177175}},{"label":"TCGA.DU.8167","pos":{"x":-5424.839843750051,"y":520.605973177175}},{"label":"TCGA.DU.8168","pos":{"x":-5424.839843750051,"y":440.605973177175}},{"label":"TCGA.DU.A5TP","pos":{"x":-4944.839843750051,"y":0.6059731771749739}},{"label":"TCGA.DU.A5TR","pos":{"x":-5504.839843750051,"y":840.605973177175}},{"label":"TCGA.DU.A5TS","pos":{"x":-5984.839843750051,"y":680.605973177175}},{"label":"TCGA.DU.A5TT","pos":{"x":-5824.839843750051,"y":-39.394026822825026}},{"label":"TCGA.DU.A5TU","pos":{"x":-5424.839843750051,"y":600.605973177175}},{"label":"TCGA.DU.A5TW","pos":{"x":-6304.839843750051,"y":-39.394026822825026}},{"label":"TCGA.DU.A5TY","pos":{"x":-5744.839843750051,"y":880.605973177175}},{"label":"TCGA.DU.A6S2","pos":{"x":-5824.839843750051,"y":680.605973177175}},{"label":"TCGA.DU.A6S3","pos":{"x":-5744.839843750051,"y":440.605973177175}},{"label":"TCGA.DU.A6S6","pos":{"x":-5584.839843750051,"y":0.6059731771749739}},{"label":"TCGA.DU.A6S7","pos":{"x":-5024.839843750051,"y":520.605973177175}},{"label":"TCGA.DU.A6S8","pos":{"x":-5264.839843750051,"y":560.605973177175}},{"label":"TCGA.DU.A76K","pos":{"x":-5744.839843750051,"y":480.605973177175}},{"label":"TCGA.DU.A76L","pos":{"x":-4704.839843750051,"y":560.605973177175}},{"label":"TCGA.DU.A76O","pos":{"x":-6144.839843750051,"y":0.6059731771749739}},{"label":"TCGA.DU.A76R","pos":{"x":-5824.839843750051,"y":0.6059731771749739}},{"label":"TCGA.DU.A7T6","pos":{"x":-5824.839843750051,"y":880.605973177175}},{"label":"TCGA.DU.A7T8","pos":{"x":-5584.839843750051,"y":240.60597317717497}},{"label":"TCGA.DU.A7TA","pos":{"x":-5184.839843750051,"y":280.605973177175}},{"label":"TCGA.DU.A7TB","pos":{"x":-5424.839843750051,"y":320.605973177175}},{"label":"TCGA.DU.A7TC","pos":{"x":-5104.839843750051,"y":720.605973177175}},{"label":"TCGA.DU.A7TD","pos":{"x":-5664.839843750051,"y":560.605973177175}},{"label":"TCGA.DU.A7TG","pos":{"x":-4784.839843750051,"y":640.605973177175}},{"label":"TCGA.DU.A7TI","pos":{"x":-4944.839843750051,"y":320.605973177175}},{"label":"TCGA.DU.A7TJ","pos":{"x":-4784.839843750051,"y":240.60597317717497}},{"label":"TCGA.E1.5302","pos":{"x":-5664.839843750051,"y":80.60597317717497}},{"label":"TCGA.E1.5303","pos":{"x":-5024.839843750051,"y":0.6059731771749739}},{"label":"TCGA.E1.5304","pos":{"x":-5424.839843750051,"y":640.605973177175}},{"label":"TCGA.E1.5305","pos":{"x":-5664.839843750051,"y":400.605973177175}},{"label":"TCGA.E1.5307","pos":{"x":-5904.839843750051,"y":720.605973177175}},{"label":"TCGA.E1.5311","pos":{"x":-4944.839843750051,"y":80.60597317717497}},{"label":"TCGA.E1.5318","pos":{"x":-4624.839843750051,"y":560.605973177175}},{"label":"TCGA.E1.5319","pos":{"x":-4864.839843750051,"y":160.60597317717497}},{"label":"TCGA.E1.5322","pos":{"x":-5904.839843750051,"y":800.605973177175}},{"label":"TCGA.E1.A7YD","pos":{"x":-5584.839843750051,"y":760.605973177175}},{"label":"TCGA.E1.A7YE","pos":{"x":-5664.839843750051,"y":320.605973177175}},{"label":"TCGA.E1.A7YH","pos":{"x":-5264.839843750051,"y":480.605973177175}},{"label":"TCGA.E1.A7YI","pos":{"x":-5264.839843750051,"y":680.605973177175}},{"label":"TCGA.E1.A7YJ","pos":{"x":-5904.839843750051,"y":520.605973177175}},{"label":"TCGA.E1.A7YK","pos":{"x":-5904.839843750051,"y":480.605973177175}},{"label":"TCGA.E1.A7YL","pos":{"x":-4784.839843750051,"y":120.60597317717497}},{"label":"TCGA.E1.A7YM","pos":{"x":-5424.839843750051,"y":120.60597317717497}},{"label":"TCGA.E1.A7YN","pos":{"x":-5344.839843750051,"y":-39.394026822825026}},{"label":"TCGA.E1.A7YO","pos":{"x":-5664.839843750051,"y":160.60597317717497}},{"label":"TCGA.E1.A7YQ","pos":{"x":-4784.839843750051,"y":720.605973177175}},{"label":"TCGA.E1.A7YS","pos":{"x":-5664.839843750051,"y":680.605973177175}},{"label":"TCGA.E1.A7YU","pos":{"x":-4944.839843750051,"y":680.605973177175}},{"label":"TCGA.E1.A7YV","pos":{"x":-5344.839843750051,"y":0.6059731771749739}},{"label":"TCGA.E1.A7YW","pos":{"x":-5024.839843750051,"y":80.60597317717497}},{"label":"TCGA.E1.A7YY","pos":{"x":-4944.839843750051,"y":560.605973177175}},{"label":"TCGA.E1.A7Z2","pos":{"x":-5984.839843750051,"y":240.60597317717497}},{"label":"TCGA.E1.A7Z3","pos":{"x":-4864.839843750051,"y":520.605973177175}},{"label":"TCGA.E1.A7Z4","pos":{"x":-5104.839843750051,"y":560.605973177175}},{"label":"TCGA.E1.A7Z6","pos":{"x":-5024.839843750051,"y":440.605973177175}},{"label":"TCGA.EZ.7264","pos":{"x":-5024.839843750051,"y":640.605973177175}},{"label":"TCGA.F6.A8O3","pos":{"x":-5024.839843750051,"y":320.605973177175}},{"label":"TCGA.F6.A8O4","pos":{"x":-5584.839843750051,"y":480.605973177175}},{"label":"TCGA.FG.5962","pos":{"x":-4704.839843750051,"y":-39.394026822825026}},{"label":"TCGA.FG.5963","pos":{"x":-5984.839843750051,"y":640.605973177175}},{"label":"TCGA.FG.5964","pos":{"x":-5504.839843750051,"y":320.605973177175}},{"label":"TCGA.FG.5965","pos":{"x":-5344.839843750051,"y":560.605973177175}},{"label":"TCGA.FG.6688","pos":{"x":-5184.839843750051,"y":560.605973177175}},{"label":"TCGA.FG.6689","pos":{"x":-6304.839843750051,"y":40.605973177174974}},{"label":"TCGA.FG.6690","pos":{"x":-5424.839843750051,"y":800.605973177175}},{"label":"TCGA.FG.6691","pos":{"x":-5024.839843750051,"y":280.605973177175}},{"label":"TCGA.FG.6692","pos":{"x":-6224.839843750051,"y":0.6059731771749739}},{"label":"TCGA.FG.7634","pos":{"x":-4944.839843750051,"y":-39.394026822825026}},{"label":"TCGA.FG.7636","pos":{"x":-5744.839843750051,"y":840.605973177175}},{"label":"TCGA.FG.7637","pos":{"x":-6064.839843750051,"y":0.6059731771749739}},{"label":"TCGA.FG.7638","pos":{"x":-5904.839843750051,"y":400.605973177175}},{"label":"TCGA.FG.7641","pos":{"x":-6304.839843750051,"y":160.60597317717497}},{"label":"TCGA.FG.7643","pos":{"x":-6144.839843750051,"y":560.605973177175}},{"label":"TCGA.FG.8181","pos":{"x":-5344.839843750051,"y":440.605973177175}},{"label":"TCGA.FG.8182","pos":{"x":-4944.839843750051,"y":200.60597317717497}},{"label":"TCGA.FG.8185","pos":{"x":-6304.839843750051,"y":240.60597317717497}},{"label":"TCGA.FG.8186","pos":{"x":-6304.839843750051,"y":520.605973177175}},{"label":"TCGA.FG.8187","pos":{"x":-4624.839843750051,"y":280.605973177175}},{"label":"TCGA.FG.8188","pos":{"x":-6224.839843750051,"y":600.605973177175}},{"label":"TCGA.FG.8189","pos":{"x":-6224.839843750051,"y":720.605973177175}},{"label":"TCGA.FG.8191","pos":{"x":-4864.839843750051,"y":640.605973177175}},{"label":"TCGA.FG.A4MT","pos":{"x":-5184.839843750051,"y":400.605973177175}},{"label":"TCGA.FG.A4MU","pos":{"x":-4944.839843750051,"y":160.60597317717497}},{"label":"TCGA.FG.A4MW","pos":{"x":-5024.839843750051,"y":240.60597317717497}},{"label":"TCGA.FG.A4MX","pos":{"x":-6144.839843750051,"y":840.605973177175}},{"label":"TCGA.FG.A4MY","pos":{"x":-5824.839843750051,"y":200.60597317717497}},{"label":"TCGA.FG.A60J","pos":{"x":-4624.839843750051,"y":480.605973177175}},{"label":"TCGA.FG.A60K","pos":{"x":-5744.839843750051,"y":560.605973177175}},{"label":"TCGA.FG.A60L","pos":{"x":-5664.839843750051,"y":440.605973177175}},{"label":"TCGA.FG.A6IZ","pos":{"x":-6144.839843750051,"y":800.605973177175}},{"label":"TCGA.FG.A6J1","pos":{"x":-6224.839843750051,"y":840.605973177175}},{"label":"TCGA.FG.A6J3","pos":{"x":-6224.839843750051,"y":120.60597317717497}},{"label":"TCGA.FG.A70Y","pos":{"x":-5424.839843750051,"y":560.605973177175}},{"label":"TCGA.FG.A70Z","pos":{"x":-6064.839843750051,"y":640.605973177175}},{"label":"TCGA.FG.A710","pos":{"x":-4864.839843750051,"y":-39.394026822825026}},{"label":"TCGA.FG.A711","pos":{"x":-6064.839843750051,"y":320.605973177175}},{"label":"TCGA.FG.A713","pos":{"x":-5504.839843750051,"y":0.6059731771749739}},{"label":"TCGA.FG.A87N","pos":{"x":-4784.839843750051,"y":200.60597317717497}},{"label":"TCGA.FG.A87Q","pos":{"x":-5184.839843750051,"y":840.605973177175}},{"label":"TCGA.FN.7833","pos":{"x":-5344.839843750051,"y":760.605973177175}},{"label":"TCGA.HT.7467","pos":{"x":-5184.839843750051,"y":40.605973177174974}},{"label":"TCGA.HT.7468","pos":{"x":-5504.839843750051,"y":40.605973177174974}},{"label":"TCGA.HT.7469","pos":{"x":-5344.839843750051,"y":400.605973177175}},{"label":"TCGA.HT.7470","pos":{"x":-5984.839843750051,"y":360.605973177175}},{"label":"TCGA.HT.7471","pos":{"x":-6224.839843750051,"y":280.605973177175}},{"label":"TCGA.HT.7472","pos":{"x":-5664.839843750051,"y":800.605973177175}},{"label":"TCGA.HT.7473","pos":{"x":-4624.839843750051,"y":360.605973177175}},{"label":"TCGA.HT.7474","pos":{"x":-4864.839843750051,"y":480.605973177175}},{"label":"TCGA.HT.7475","pos":{"x":-5744.839843750051,"y":240.60597317717497}},{"label":"TCGA.HT.7476","pos":{"x":-5744.839843750051,"y":720.605973177175}},{"label":"TCGA.HT.7477","pos":{"x":-4784.839843750051,"y":40.605973177174974}},{"label":"TCGA.HT.7478","pos":{"x":-5424.839843750051,"y":720.605973177175}},{"label":"TCGA.HT.7479","pos":{"x":-5584.839843750051,"y":840.605973177175}},{"label":"TCGA.HT.7480","pos":{"x":-5984.839843750051,"y":520.605973177175}},{"label":"TCGA.HT.7481","pos":{"x":-5184.839843750051,"y":240.60597317717497}},{"label":"TCGA.HT.7482","pos":{"x":-5824.839843750051,"y":760.605973177175}},{"label":"TCGA.HT.7483","pos":{"x":-6224.839843750051,"y":200.60597317717497}},{"label":"TCGA.HT.7485","pos":{"x":-4864.839843750051,"y":800.605973177175}},{"label":"TCGA.HT.7601","pos":{"x":-6064.839843750051,"y":720.605973177175}},{"label":"TCGA.HT.7602","pos":{"x":-6224.839843750051,"y":680.605973177175}},{"label":"TCGA.HT.7603","pos":{"x":-5344.839843750051,"y":360.605973177175}},{"label":"TCGA.HT.7604","pos":{"x":-5264.839843750051,"y":0.6059731771749739}},{"label":"TCGA.HT.7605","pos":{"x":-5344.839843750051,"y":480.605973177175}},{"label":"TCGA.HT.7606","pos":{"x":-4864.839843750051,"y":720.605973177175}},{"label":"TCGA.HT.7607","pos":{"x":-6064.839843750051,"y":440.605973177175}},{"label":"TCGA.HT.7608","pos":{"x":-4624.839843750051,"y":160.60597317717497}},{"label":"TCGA.HT.7609","pos":{"x":-5104.839843750051,"y":520.605973177175}},{"label":"TCGA.HT.7610","pos":{"x":-5424.839843750051,"y":680.605973177175}},{"label":"TCGA.HT.7611","pos":{"x":-5984.839843750051,"y":600.605973177175}},{"label":"TCGA.HT.7616","pos":{"x":-5904.839843750051,"y":440.605973177175}},{"label":"TCGA.HT.7620","pos":{"x":-4784.839843750051,"y":-39.394026822825026}},{"label":"TCGA.HT.7676","pos":{"x":-5104.839843750051,"y":320.605973177175}},{"label":"TCGA.HT.7677","pos":{"x":-5744.839843750051,"y":160.60597317717497}},{"label":"TCGA.HT.7680","pos":{"x":-5184.839843750051,"y":360.605973177175}},{"label":"TCGA.HT.7681","pos":{"x":-5024.839843750051,"y":760.605973177175}},{"label":"TCGA.HT.7684","pos":{"x":-6064.839843750051,"y":200.60597317717497}},{"label":"TCGA.HT.7686","pos":{"x":-5344.839843750051,"y":840.605973177175}},{"label":"TCGA.HT.7687","pos":{"x":-5104.839843750051,"y":160.60597317717497}},{"label":"TCGA.HT.7688","pos":{"x":-6144.839843750051,"y":880.605973177175}},{"label":"TCGA.HT.7689","pos":{"x":-6144.839843750051,"y":480.605973177175}},{"label":"TCGA.HT.7690","pos":{"x":-5504.839843750051,"y":160.60597317717497}},{"label":"TCGA.HT.7691","pos":{"x":-5584.839843750051,"y":440.605973177175}},{"label":"TCGA.HT.7692","pos":{"x":-5344.839843750051,"y":160.60597317717497}},{"label":"TCGA.HT.7693","pos":{"x":-5264.839843750051,"y":240.60597317717497}},{"label":"TCGA.HT.7694","pos":{"x":-5984.839843750051,"y":0.6059731771749739}},{"label":"TCGA.HT.7695","pos":{"x":-4784.839843750051,"y":320.605973177175}},{"label":"TCGA.HT.7854","pos":{"x":-4864.839843750051,"y":360.605973177175}},{"label":"TCGA.HT.7855","pos":{"x":-5824.839843750051,"y":600.605973177175}},{"label":"TCGA.HT.7856","pos":{"x":-5664.839843750051,"y":480.605973177175}},{"label":"TCGA.HT.7857","pos":{"x":-5904.839843750051,"y":-39.394026822825026}},{"label":"TCGA.HT.7858","pos":{"x":-5024.839843750051,"y":160.60597317717497}},{"label":"TCGA.HT.7860","pos":{"x":-5264.839843750051,"y":520.605973177175}},{"label":"TCGA.HT.7873","pos":{"x":-6304.839843750051,"y":200.60597317717497}},{"label":"TCGA.HT.7874","pos":{"x":-6224.839843750051,"y":880.605973177175}},{"label":"TCGA.HT.7875","pos":{"x":-5104.839843750051,"y":680.605973177175}},{"label":"TCGA.HT.7877","pos":{"x":-5824.839843750051,"y":80.60597317717497}},{"label":"TCGA.HT.7879","pos":{"x":-5344.839843750051,"y":200.60597317717497}},{"label":"TCGA.HT.7880","pos":{"x":-4624.839843750051,"y":800.605973177175}},{"label":"TCGA.HT.7881","pos":{"x":-4864.839843750051,"y":760.605973177175}},{"label":"TCGA.HT.7882","pos":{"x":-5024.839843750051,"y":-39.394026822825026}},{"label":"TCGA.HT.7884","pos":{"x":-5344.839843750051,"y":240.60597317717497}},{"label":"TCGA.HT.7902","pos":{"x":-5184.839843750051,"y":520.605973177175}},{"label":"TCGA.HT.8010","pos":{"x":-5104.839843750051,"y":360.605973177175}},{"label":"TCGA.HT.8011","pos":{"x":-5904.839843750051,"y":760.605973177175}},{"label":"TCGA.HT.8012","pos":{"x":-5904.839843750051,"y":40.605973177174974}},{"label":"TCGA.HT.8013","pos":{"x":-5264.839843750051,"y":160.60597317717497}},{"label":"TCGA.HT.8015","pos":{"x":-6224.839843750051,"y":760.605973177175}},{"label":"TCGA.HT.8018","pos":{"x":-5424.839843750051,"y":480.605973177175}},{"label":"TCGA.HT.8019","pos":{"x":-5264.839843750051,"y":720.605973177175}},{"label":"TCGA.HT.8104","pos":{"x":-4704.839843750051,"y":760.605973177175}},{"label":"TCGA.HT.8105","pos":{"x":-6144.839843750051,"y":80.60597317717497}},{"label":"TCGA.HT.8106","pos":{"x":-5584.839843750051,"y":880.605973177175}},{"label":"TCGA.HT.8107","pos":{"x":-4784.839843750051,"y":520.605973177175}},{"label":"TCGA.HT.8108","pos":{"x":-5024.839843750051,"y":360.605973177175}},{"label":"TCGA.HT.8109","pos":{"x":-6144.839843750051,"y":280.605973177175}},{"label":"TCGA.HT.8110","pos":{"x":-5744.839843750051,"y":-39.394026822825026}},{"label":"TCGA.HT.8111","pos":{"x":-5904.839843750051,"y":200.60597317717497}},{"label":"TCGA.HT.8113","pos":{"x":-6064.839843750051,"y":600.605973177175}},{"label":"TCGA.HT.8114","pos":{"x":-5584.839843750051,"y":640.605973177175}},{"label":"TCGA.HT.8558","pos":{"x":-5504.839843750051,"y":120.60597317717497}},{"label":"TCGA.HT.8563","pos":{"x":-4704.839843750051,"y":160.60597317717497}},{"label":"TCGA.HT.8564","pos":{"x":-5584.839843750051,"y":320.605973177175}},{"label":"TCGA.HT.A4DS","pos":{"x":-5584.839843750051,"y":80.60597317717497}},{"label":"TCGA.HT.A4DV","pos":{"x":-4864.839843750051,"y":240.60597317717497}},{"label":"TCGA.HT.A5R5","pos":{"x":-5664.839843750051,"y":360.605973177175}},{"label":"TCGA.HT.A5R7","pos":{"x":-5984.839843750051,"y":800.605973177175}},{"label":"TCGA.HT.A5R9","pos":{"x":-5264.839843750051,"y":840.605973177175}},{"label":"TCGA.HT.A5RA","pos":{"x":-4944.839843750051,"y":640.605973177175}},{"label":"TCGA.HT.A5RB","pos":{"x":-6304.839843750051,"y":0.6059731771749739}},{"label":"TCGA.HT.A5RC","pos":{"x":-6144.839843750051,"y":40.605973177174974}},{"label":"TCGA.HT.A614","pos":{"x":-4944.839843750051,"y":800.605973177175}},{"label":"TCGA.HT.A615","pos":{"x":-4784.839843750051,"y":760.605973177175}},{"label":"TCGA.HT.A616","pos":{"x":-6304.839843750051,"y":800.605973177175}},{"label":"TCGA.HT.A617","pos":{"x":-5824.839843750051,"y":160.60597317717497}},{"label":"TCGA.HT.A618","pos":{"x":-5984.839843750051,"y":120.60597317717497}},{"label":"TCGA.HT.A619","pos":{"x":-5504.839843750051,"y":360.605973177175}},{"label":"TCGA.HT.A61A","pos":{"x":-4704.839843750051,"y":320.605973177175}},{"label":"TCGA.HT.A61B","pos":{"x":-6144.839843750051,"y":680.605973177175}},{"label":"TCGA.HT.A61C","pos":{"x":-5104.839843750051,"y":400.605973177175}},{"label":"TCGA.HT.A74H","pos":{"x":-6224.839843750051,"y":40.605973177174974}},{"label":"TCGA.HT.A74J","pos":{"x":-4784.839843750051,"y":80.60597317717497}},{"label":"TCGA.HT.A74K","pos":{"x":-5824.839843750051,"y":520.605973177175}},{"label":"TCGA.HT.A74L","pos":{"x":-5184.839843750051,"y":760.605973177175}},{"label":"TCGA.HT.A74O","pos":{"x":-5104.839843750051,"y":480.605973177175}},{"label":"TCGA.HW.7486","pos":{"x":-6144.839843750051,"y":640.605973177175}},{"label":"TCGA.HW.7487","pos":{"x":-6304.839843750051,"y":680.605973177175}},{"label":"TCGA.HW.7489","pos":{"x":-6224.839843750051,"y":440.605973177175}},{"label":"TCGA.HW.7490","pos":{"x":-6304.839843750051,"y":400.605973177175}},{"label":"TCGA.HW.7491","pos":{"x":-5984.839843750051,"y":200.60597317717497}},{"label":"TCGA.HW.7493","pos":{"x":-4784.839843750051,"y":400.605973177175}},{"label":"TCGA.HW.7495","pos":{"x":-5344.839843750051,"y":40.605973177174974}},{"label":"TCGA.HW.8319","pos":{"x":-5984.839843750051,"y":80.60597317717497}},{"label":"TCGA.HW.8320","pos":{"x":-6144.839843750051,"y":120.60597317717497}},{"label":"TCGA.HW.8321","pos":{"x":-5504.839843750051,"y":640.605973177175}},{"label":"TCGA.HW.8322","pos":{"x":-5904.839843750051,"y":680.605973177175}},{"label":"TCGA.HW.A5KJ","pos":{"x":-6304.839843750051,"y":80.60597317717497}},{"label":"TCGA.HW.A5KK","pos":{"x":-5184.839843750051,"y":160.60597317717497}},{"label":"TCGA.HW.A5KL","pos":{"x":-5184.839843750051,"y":320.605973177175}},{"label":"TCGA.HW.A5KM","pos":{"x":-4704.839843750051,"y":480.605973177175}},{"label":"TCGA.IK.7675","pos":{"x":-6304.839843750051,"y":760.605973177175}},{"label":"TCGA.IK.8125","pos":{"x":-5264.839843750051,"y":760.605973177175}},{"label":"TCGA.KT.A74X","pos":{"x":-4624.839843750051,"y":320.605973177175}},{"label":"TCGA.KT.A7W1","pos":{"x":-5904.839843750051,"y":120.60597317717497}},{"label":"TCGA.P5.A5ET","pos":{"x":-5264.839843750051,"y":360.605973177175}},{"label":"TCGA.P5.A5EU","pos":{"x":-6304.839843750051,"y":360.605973177175}},{"label":"TCGA.P5.A5EV","pos":{"x":-5744.839843750051,"y":600.605973177175}},{"label":"TCGA.P5.A5EW","pos":{"x":-5344.839843750051,"y":120.60597317717497}},{"label":"TCGA.P5.A5EX","pos":{"x":-5664.839843750051,"y":880.605973177175}},{"label":"TCGA.P5.A5EY","pos":{"x":-5264.839843750051,"y":40.605973177174974}},{"label":"TCGA.P5.A5EZ","pos":{"x":-5104.839843750051,"y":640.605973177175}},{"label":"TCGA.P5.A5F0","pos":{"x":-6144.839843750051,"y":320.605973177175}},{"label":"TCGA.P5.A5F1","pos":{"x":-6304.839843750051,"y":480.605973177175}},{"label":"TCGA.P5.A5F2","pos":{"x":-5504.839843750051,"y":80.60597317717497}},{"label":"TCGA.P5.A5F4","pos":{"x":-5584.839843750051,"y":560.605973177175}},{"label":"TCGA.P5.A5F6","pos":{"x":-4944.839843750051,"y":280.605973177175}},{"label":"TCGA.P5.A72U","pos":{"x":-4704.839843750051,"y":120.60597317717497}},{"label":"TCGA.P5.A72W","pos":{"x":-4944.839843750051,"y":400.605973177175}},{"label":"TCGA.P5.A72X","pos":{"x":-6224.839843750051,"y":240.60597317717497}},{"label":"TCGA.P5.A72Z","pos":{"x":-6304.839843750051,"y":840.605973177175}},{"label":"TCGA.P5.A730","pos":{"x":-5184.839843750051,"y":800.605973177175}},{"label":"TCGA.P5.A731","pos":{"x":-5024.839843750051,"y":40.605973177174974}},{"label":"TCGA.P5.A733","pos":{"x":-5424.839843750051,"y":160.60597317717497}},{"label":"TCGA.P5.A735","pos":{"x":-5664.839843750051,"y":0.6059731771749739}},{"label":"TCGA.P5.A736","pos":{"x":-4784.839843750051,"y":800.605973177175}},{"label":"TCGA.P5.A737","pos":{"x":-4624.839843750051,"y":200.60597317717497}},{"label":"TCGA.P5.A77W","pos":{"x":-6304.839843750051,"y":440.605973177175}},{"label":"TCGA.P5.A77X","pos":{"x":-5824.839843750051,"y":840.605973177175}},{"label":"TCGA.P5.A780","pos":{"x":-5824.839843750051,"y":480.605973177175}},{"label":"TCGA.P5.A781","pos":{"x":-5664.839843750051,"y":760.605973177175}},{"label":"TCGA.QH.A65R","pos":{"x":-5184.839843750051,"y":600.605973177175}},{"label":"TCGA.QH.A65S","pos":{"x":-5504.839843750051,"y":-39.394026822825026}},{"label":"TCGA.QH.A65V","pos":{"x":-5184.839843750051,"y":480.605973177175}},{"label":"TCGA.QH.A65X","pos":{"x":-5184.839843750051,"y":120.60597317717497}},{"label":"TCGA.QH.A65Z","pos":{"x":-4864.839843750051,"y":320.605973177175}},{"label":"TCGA.QH.A6CS","pos":{"x":-6064.839843750051,"y":680.605973177175}},{"label":"TCGA.QH.A6CU","pos":{"x":-4624.839843750051,"y":400.605973177175}},{"label":"TCGA.QH.A6CV","pos":{"x":-5584.839843750051,"y":40.605973177174974}},{"label":"TCGA.QH.A6CW","pos":{"x":-5344.839843750051,"y":320.605973177175}},{"label":"TCGA.QH.A6CX","pos":{"x":-4704.839843750051,"y":840.605973177175}},{"label":"TCGA.QH.A6CY","pos":{"x":-5584.839843750051,"y":200.60597317717497}},{"label":"TCGA.QH.A6CZ","pos":{"x":-5584.839843750051,"y":400.605973177175}},{"label":"TCGA.QH.A6X3","pos":{"x":-5664.839843750051,"y":-39.394026822825026}},{"label":"TCGA.QH.A6X4","pos":{"x":-5104.839843750051,"y":760.605973177175}},{"label":"TCGA.QH.A6X5","pos":{"x":-5424.839843750051,"y":80.60597317717497}},{"label":"TCGA.QH.A6X8","pos":{"x":-4624.839843750051,"y":720.605973177175}},{"label":"TCGA.QH.A6X9","pos":{"x":-5184.839843750051,"y":0.6059731771749739}},{"label":"TCGA.QH.A6XA","pos":{"x":-4784.839843750051,"y":440.605973177175}},{"label":"TCGA.QH.A6XC","pos":{"x":-4624.839843750051,"y":600.605973177175}},{"label":"TCGA.QH.A86X","pos":{"x":-5264.839843750051,"y":-39.394026822825026}},{"label":"TCGA.QH.A870","pos":{"x":-4944.839843750051,"y":520.605973177175}},{"label":"TCGA.R8.A6MK","pos":{"x":-5824.839843750051,"y":440.605973177175}},{"label":"TCGA.R8.A6ML","pos":{"x":-5824.839843750051,"y":720.605973177175}},{"label":"TCGA.R8.A6MO","pos":{"x":-4784.839843750051,"y":160.60597317717497}},{"label":"TCGA.R8.A6YH","pos":{"x":-6144.839843750051,"y":200.60597317717497}},{"label":"TCGA.R8.A73M","pos":{"x":-4864.839843750051,"y":200.60597317717497}},{"label":"TCGA.RY.A83X","pos":{"x":-4784.839843750051,"y":560.605973177175}},{"label":"TCGA.RY.A83Y","pos":{"x":-5504.839843750051,"y":200.60597317717497}},{"label":"TCGA.RY.A83Z","pos":{"x":-5984.839843750051,"y":880.605973177175}},{"label":"TCGA.RY.A840","pos":{"x":-5584.839843750051,"y":160.60597317717497}},{"label":"TCGA.RY.A843","pos":{"x":-6144.839843750051,"y":160.60597317717497}},{"label":"TCGA.RY.A845","pos":{"x":-5504.839843750051,"y":520.605973177175}},{"label":"TCGA.RY.A847","pos":{"x":-4704.839843750051,"y":520.605973177175}},{"label":"TCGA.S9.A6TS","pos":{"x":-5264.839843750051,"y":800.605973177175}},{"label":"TCGA.S9.A6TU","pos":{"x":-5104.839843750051,"y":200.60597317717497}},{"label":"TCGA.S9.A6TV","pos":{"x":-5984.839843750051,"y":160.60597317717497}},{"label":"TCGA.S9.A6TW","pos":{"x":-6064.839843750051,"y":120.60597317717497}},{"label":"TCGA.S9.A6TX","pos":{"x":-4944.839843750051,"y":40.605973177174974}},{"label":"TCGA.S9.A6TY","pos":{"x":-5664.839843750051,"y":200.60597317717497}},{"label":"TCGA.S9.A6TZ","pos":{"x":-4784.839843750051,"y":600.605973177175}},{"label":"TCGA.S9.A6U0","pos":{"x":-4624.839843750051,"y":680.605973177175}},{"label":"TCGA.S9.A6U1","pos":{"x":-6144.839843750051,"y":-39.394026822825026}},{"label":"TCGA.S9.A6U2","pos":{"x":-4704.839843750051,"y":240.60597317717497}},{"label":"TCGA.S9.A6U5","pos":{"x":-6224.839843750051,"y":520.605973177175}},{"label":"TCGA.S9.A6U6","pos":{"x":-5424.839843750051,"y":240.60597317717497}},{"label":"TCGA.S9.A6U8","pos":{"x":-6304.839843750051,"y":600.605973177175}},{"label":"TCGA.S9.A6U9","pos":{"x":-5344.839843750051,"y":80.60597317717497}},{"label":"TCGA.S9.A6UA","pos":{"x":-5584.839843750051,"y":120.60597317717497}},{"label":"TCGA.S9.A6UB","pos":{"x":-4944.839843750051,"y":360.605973177175}},{"label":"TCGA.S9.A6WD","pos":{"x":-5664.839843750051,"y":720.605973177175}},{"label":"TCGA.S9.A6WE","pos":{"x":-6064.839843750051,"y":160.60597317717497}},{"label":"TCGA.S9.A6WG","pos":{"x":-4944.839843750051,"y":760.605973177175}},{"label":"TCGA.S9.A6WH","pos":{"x":-5424.839843750051,"y":760.605973177175}},{"label":"TCGA.S9.A6WI","pos":{"x":-5984.839843750051,"y":440.605973177175}},{"label":"TCGA.S9.A6WL","pos":{"x":-6144.839843750051,"y":360.605973177175}},{"label":"TCGA.S9.A6WM","pos":{"x":-6144.839843750051,"y":600.605973177175}},{"label":"TCGA.S9.A6WN","pos":{"x":-4704.839843750051,"y":800.605973177175}},{"label":"TCGA.S9.A6WO","pos":{"x":-5424.839843750051,"y":200.60597317717497}},{"label":"TCGA.S9.A6WP","pos":{"x":-5104.839843750051,"y":80.60597317717497}},{"label":"TCGA.S9.A6WQ","pos":{"x":-5104.839843750051,"y":40.605973177174974}},{"label":"TCGA.S9.A7IQ","pos":{"x":-5264.839843750051,"y":320.605973177175}},{"label":"TCGA.S9.A7IS","pos":{"x":-5104.839843750051,"y":440.605973177175}},{"label":"TCGA.S9.A7IX","pos":{"x":-4944.839843750051,"y":600.605973177175}},{"label":"TCGA.S9.A7IY","pos":{"x":-5104.839843750051,"y":0.6059731771749739}},{"label":"TCGA.S9.A7IZ","pos":{"x":-4784.839843750051,"y":840.605973177175}},{"label":"TCGA.S9.A7J0","pos":{"x":-5904.839843750051,"y":640.605973177175}},{"label":"TCGA.S9.A7J1","pos":{"x":-5024.839843750051,"y":480.605973177175}},{"label":"TCGA.S9.A7J2","pos":{"x":-5984.839843750051,"y":280.605973177175}},{"label":"TCGA.S9.A7J3","pos":{"x":-5744.839843750051,"y":0.6059731771749739}},{"label":"TCGA.S9.A7QW","pos":{"x":-5104.839843750051,"y":280.605973177175}},{"label":"TCGA.S9.A7QX","pos":{"x":-6064.839843750051,"y":240.60597317717497}},{"label":"TCGA.S9.A7QY","pos":{"x":-5584.839843750051,"y":280.605973177175}},{"label":"TCGA.S9.A7QZ","pos":{"x":-4944.839843750051,"y":120.60597317717497}},{"label":"TCGA.S9.A7R1","pos":{"x":-4624.839843750051,"y":640.605973177175}},{"label":"TCGA.S9.A7R2","pos":{"x":-5504.839843750051,"y":480.605973177175}},{"label":"TCGA.S9.A7R3","pos":{"x":-6064.839843750051,"y":400.605973177175}},{"label":"TCGA.S9.A7R4","pos":{"x":-6224.839843750051,"y":640.605973177175}},{"label":"TCGA.S9.A7R7","pos":{"x":-6304.839843750051,"y":720.605973177175}},{"label":"TCGA.S9.A7R8","pos":{"x":-5984.839843750051,"y":40.605973177174974}},{"label":"TCGA.S9.A89V","pos":{"x":-5504.839843750051,"y":720.605973177175}},{"label":"TCGA.S9.A89Z","pos":{"x":-4624.839843750051,"y":240.60597317717497}},{"label":"TCGA.TM.A7C3","pos":{"x":-5504.839843750051,"y":800.605973177175}},{"label":"TCGA.TM.A7C4","pos":{"x":-4864.839843750051,"y":280.605973177175}},{"label":"TCGA.TM.A7C5","pos":{"x":-5904.839843750051,"y":160.60597317717497}},{"label":"TCGA.TM.A7CA","pos":{"x":-5584.839843750051,"y":-39.394026822825026}},{"label":"TCGA.TM.A7CF","pos":{"x":-6064.839843750051,"y":-39.394026822825026}},{"label":"TCGA.TM.A84B","pos":{"x":-4864.839843750051,"y":400.605973177175}},{"label":"TCGA.TM.A84C","pos":{"x":-5664.839843750051,"y":240.60597317717497}},{"label":"TCGA.TM.A84F","pos":{"x":-6224.839843750051,"y":480.605973177175}},{"label":"TCGA.TM.A84G","pos":{"x":-6144.839843750051,"y":520.605973177175}},{"label":"TCGA.TM.A84H","pos":{"x":-4704.839843750051,"y":720.605973177175}},{"label":"TCGA.TM.A84I","pos":{"x":-5904.839843750051,"y":840.605973177175}},{"label":"TCGA.TM.A84J","pos":{"x":-5424.839843750051,"y":400.605973177175}},{"label":"TCGA.TM.A84L","pos":{"x":-6144.839843750051,"y":400.605973177175}},{"label":"TCGA.TM.A84M","pos":{"x":-4944.839843750051,"y":480.605973177175}},{"label":"TCGA.TM.A84O","pos":{"x":-5024.839843750051,"y":680.605973177175}},{"label":"TCGA.TM.A84Q","pos":{"x":-4624.839843750051,"y":0.6059731771749739}},{"label":"TCGA.TM.A84R","pos":{"x":-6224.839843750051,"y":160.60597317717497}},{"label":"TCGA.TM.A84S","pos":{"x":-6304.839843750051,"y":880.605973177175}},{"label":"TCGA.TM.A84T","pos":{"x":-6304.839843750051,"y":640.605973177175}},{"label":"TCGA.TQ.A7RF","pos":{"x":-4864.839843750051,"y":40.605973177174974}},{"label":"TCGA.TQ.A7RG","pos":{"x":-5984.839843750051,"y":720.605973177175}},{"label":"TCGA.TQ.A7RH","pos":{"x":-6224.839843750051,"y":360.605973177175}},{"label":"TCGA.TQ.A7RI","pos":{"x":-5984.839843750051,"y":840.605973177175}},{"label":"TCGA.TQ.A7RJ","pos":{"x":-5904.839843750051,"y":360.605973177175}},{"label":"TCGA.TQ.A7RK","pos":{"x":-4864.839843750051,"y":120.60597317717497}},{"label":"TCGA.TQ.A7RM","pos":{"x":-5664.839843750051,"y":120.60597317717497}},{"label":"TCGA.TQ.A7RN","pos":{"x":-4704.839843750051,"y":600.605973177175}},{"label":"TCGA.TQ.A7RO","pos":{"x":-5744.839843750051,"y":800.605973177175}},{"label":"TCGA.TQ.A7RP","pos":{"x":-4624.839843750051,"y":-39.394026822825026}},{"label":"TCGA.TQ.A7RQ","pos":{"x":-5904.839843750051,"y":80.60597317717497}},{"label":"TCGA.TQ.A7RR","pos":{"x":-5744.839843750051,"y":680.605973177175}},{"label":"TCGA.TQ.A7RS","pos":{"x":-4944.839843750051,"y":440.605973177175}},{"label":"TCGA.TQ.A7RU","pos":{"x":-5984.839843750051,"y":-39.394026822825026}},{"label":"TCGA.TQ.A7RV","pos":{"x":-5024.839843750051,"y":400.605973177175}},{"label":"TCGA.TQ.A7RW","pos":{"x":-5104.839843750051,"y":840.605973177175}},{"label":"TCGA.TQ.A8XE","pos":{"x":-5184.839843750051,"y":-39.394026822825026}},{"label":"TCGA.VM.A8C8","pos":{"x":-6304.839843750051,"y":320.605973177175}},{"label":"TCGA.VM.A8C9","pos":{"x":-4864.839843750051,"y":600.605973177175}},{"label":"TCGA.VM.A8CA","pos":{"x":-6304.839843750051,"y":120.60597317717497}},{"label":"TCGA.VM.A8CB","pos":{"x":-5104.839843750051,"y":240.60597317717497}},{"label":"TCGA.VM.A8CD","pos":{"x":-5264.839843750051,"y":400.605973177175}},{"label":"TCGA.VM.A8CE","pos":{"x":-5904.839843750051,"y":320.605973177175}},{"label":"TCGA.VM.A8CF","pos":{"x":-5744.839843750051,"y":400.605973177175}},{"label":"TCGA.VM.A8CH","pos":{"x":-5904.839843750051,"y":880.605973177175}},{"label":"TCGA.VV.A829","pos":{"x":-6224.839843750051,"y":80.60597317717497}},{"label":"TCGA.VV.A86M","pos":{"x":-4624.839843750051,"y":520.605973177175}},{"label":"TCGA.VW.A7QS","pos":{"x":-6064.839843750051,"y":80.60597317717497}},{"label":"TCGA.VW.A8FI","pos":{"x":-5424.839843750051,"y":360.605973177175}},{"label":"TCGA.W9.A837","pos":{"x":-6064.839843750051,"y":360.605973177175}},{"label":"TCGA.WH.A86K","pos":{"x":-5024.839843750051,"y":840.605973177175}},{"label":"TCGA.WY.A858","pos":{"x":-4624.839843750051,"y":760.605973177175}},{"label":"TCGA.WY.A859","pos":{"x":-5824.839843750051,"y":40.605973177174974}},{"label":"TCGA.WY.A85A","pos":{"x":-5904.839843750051,"y":240.60597317717497}},{"label":"TCGA.WY.A85B","pos":{"x":-5024.839843750051,"y":800.605973177175}},{"label":"TCGA.WY.A85C","pos":{"x":-6224.839843750051,"y":320.605973177175}},{"label":"TCGA.WY.A85D","pos":{"x":-5664.839843750051,"y":840.605973177175}},{"label":"TCGA.WY.A85E","pos":{"x":-5024.839843750051,"y":600.605973177175}},{"label":"TCHH","pos":{"x":529.0613555908203,"y":-1584.5782470703125}},{"label":"TCL1A","pos":{"x":-315.8439636230469,"y":-1509.2239990234375}},{"label":"TCL6","pos":{"x":-368.3155517578125,"y":-1545.47119140625}},{"label":"TERT","pos":{"x":342.9088134765625,"y":498.64935302734375}},{"label":"TET1","pos":{"x":1954.76708984375,"y":-222.38583374023438}},{"label":"TET2","pos":{"x":-28.736708641052246,"y":152.5183563232422}},{"label":"TEX15","pos":{"x":3985.8769945190743,"y":2925.4749624919054}},{"label":"TFE3","pos":{"x":1242.4501953125,"y":1028.4446716308594}},{"label":"TFEB","pos":{"x":769.6503295898438,"y":391.1011047363281}},{"label":"TFG","pos":{"x":-222.82571411132812,"y":-800.7308959960938}},{"label":"TFPT","pos":{"x":228.72264099121094,"y":1221.6163330078125}},{"label":"TFRC","pos":{"x":-63.581153869628906,"y":-644.2485961914062}},{"label":"THSD7B","pos":{"x":3425.8769945190743,"y":2685.4749624919054}},{"label":"TLX1","pos":{"x":1789.525390625,"y":-176.05271911621094}},{"label":"TLX3","pos":{"x":432.60552978515625,"y":493.0312042236328}},{"label":"TMEM150B","pos":{"x":3105.8769945190743,"y":3205.4749624919054}},{"label":"TMEM190","pos":{"x":3665.8769945190743,"y":3125.4749624919054}},{"label":"TMEM238","pos":{"x":3745.8769945190743,"y":2845.4749624919054}},{"label":"TMEM86B","pos":{"x":3985.8769945190743,"y":2725.4749624919054}},{"label":"TMPRSS2","pos":{"x":551.5911865234375,"y":-749.068603515625}},{"label":"TMPRSS6","pos":{"x":3105.8769945190743,"y":2925.4749624919054}},{"label":"TNFAIP3","pos":{"x":705.2071533203125,"y":145.2279930114746}},{"label":"TNFRSF14","pos":{"x":-1048.6981201171875,"y":927.3444213867188}},{"label":"TNNT1","pos":{"x":3745.8769945190743,"y":2645.4749624919054}},{"label":"TP53","pos":{"x":-860.9069213867188,"y":-1541.154052734375}},{"label":"TPM3","pos":{"x":528.5639038085938,"y":-1370.7259521484375}},{"label":"TPM4","pos":{"x":223.39642333984375,"y":1121.0042724609375}},{"label":"TPTE","pos":{"x":4065.8769945190743,"y":3045.4749624919054}},{"label":"TPTE2","pos":{"x":3265.8769945190743,"y":2645.4749624919054}},{"label":"TRAF7","pos":{"x":-331.65155029296875,"y":661.25}},{"label":"TRAPPC2","pos":{"x":3105.8769945190743,"y":2645.4749624919054}},{"label":"TRIM24","pos":{"x":1512.923583984375,"y":-989.537353515625}},{"label":"TRIM33","pos":{"x":-907.3533325195312,"y":913.2040405273438}},{"label":"TRIP11","pos":{"x":-273.4644241333008,"y":-1431.6895751953125}},{"label":"TRPM2","pos":{"x":3665.8769945190743,"y":3165.4749624919054}},{"label":"TRPV6","pos":{"x":3905.8769945190743,"y":3005.4749624919054}},{"label":"TRRAP","pos":{"x":1508.7706298828125,"y":-1433.260009765625}},{"label":"TSC1","pos":{"x":-898.1585083007812,"y":-93.82179260253906}},{"label":"TSC2","pos":{"x":-368.753662109375,"y":662.4025268554688}},{"label":"TSHR","pos":{"x":-213.15760803222656,"y":-1368.497802734375}},{"label":"TSHZ2","pos":{"x":3345.8769945190743,"y":2765.4749624919054}},{"label":"TTL","pos":{"x":-482.7261962890625,"y":1091.9990234375}},{"label":"TTN","pos":{"x":-433.4782409667969,"y":1391.6910400390625}},{"label":"TUBBP5","pos":{"x":4305.876994519074,"y":3165.4749624919054}},{"label":"TUBGCP2","pos":{"x":3665.8769945190743,"y":2685.4749624919054}},{"label":"U2AF2","pos":{"x":3745.8769945190743,"y":2965.4749624919054}},{"label":"UBC","pos":{"x":3345.8769945190743,"y":3125.4749624919054}},{"label":"UBE2S","pos":{"x":3265.8769945190743,"y":2765.4749624919054}},{"label":"UBR5","pos":{"x":856.19970703125,"y":-309.0078125}},{"label":"USH2A","pos":{"x":-1065.6251220703125,"y":799.0966796875}},{"label":"USP29","pos":{"x":3585.8769945190743,"y":2565.4749624919054}},{"label":"USP6","pos":{"x":-991.7044677734375,"y":-1464.06640625}},{"label":"VHL","pos":{"x":-215.24819946289062,"y":-488.08709716796875}},{"label":"VN1R1","pos":{"x":3105.8769945190743,"y":2725.4749624919054}},{"label":"VOPP1","pos":{"x":1691.8223876953125,"y":-1631.9298095703125}},{"label":"VPS13C","pos":{"x":3825.8769945190743,"y":2685.4749624919054}},{"label":"VSTM2A","pos":{"x":1687.517333984375,"y":-2048.32763671875}},{"label":"VTI1A","pos":{"x":1833.4793701171875,"y":-136.75732803344727}},{"label":"WAS","pos":{"x":1249.4632568359375,"y":1069.012451171875}},{"label":"WASH3P","pos":{"x":3345.8769945190743,"y":3085.4749624919054}},{"label":"WBSCR17","pos":{"x":3105.8769945190743,"y":3005.4749624919054}},{"label":"WDR90","pos":{"x":3345.8769945190743,"y":3005.4749624919054}},{"label":"WHSC1","pos":{"x":97.12677764892578,"y":97.08111572265625}},{"label":"WIF1","pos":{"x":1914.830322265625,"y":379.0746765136719}},{"label":"WT1","pos":{"x":1894.134521484375,"y":1161.857666015625}},{"label":"WWOX","pos":{"x":-265.12017822265625,"y":652.10302734375}},{"label":"WWTR1","pos":{"x":-386.8182678222656,"y":-581.73193359375}},{"label":"XIRP2","pos":{"x":3265.8769945190743,"y":3085.4749624919054}},{"label":"XPA","pos":{"x":-943.3294067382812,"y":-36.2509126663208}},{"label":"XPC","pos":{"x":-212.4093475341797,"y":-471.31390380859375}},{"label":"YWHAE","pos":{"x":-996.6334228515625,"y":-1506.2276611328125}},{"label":"ZBTB16","pos":{"x":1911.66845703125,"y":1262.9276123046875}},{"label":"ZBTB20","pos":{"x":3905.8769945190743,"y":3125.4749624919054}},{"label":"ZDBF2","pos":{"x":3745.8769945190743,"y":2925.4749624919054}},{"label":"ZEB1","pos":{"x":1821.2135009765625,"y":-389.28070068359375}},{"label":"ZFP28","pos":{"x":3425.8769945190743,"y":3005.4749624919054}},{"label":"ZIM2","pos":{"x":4225.876994519074,"y":3165.4749624919054}},{"label":"ZIM3","pos":{"x":4065.8769945190743,"y":2885.4749624919054}},{"label":"ZMYM2","pos":{"x":1033.5382080078125,"y":-1236.400634765625}},{"label":"ZNF17","pos":{"x":3825.8769945190743,"y":3165.4749624919054}},{"label":"ZNF264","pos":{"x":3185.8769945190743,"y":3045.4749624919054}},{"label":"ZNF292","pos":{"x":3185.8769945190743,"y":2605.4749624919054}},{"label":"ZNF304","pos":{"x":3665.8769945190743,"y":3085.4749624919054}},{"label":"ZNF331","pos":{"x":227.79269409179688,"y":1209.3519287109375}},{"label":"ZNF384","pos":{"x":1766.337646484375,"y":506.469970703125}},{"label":"ZNF419","pos":{"x":3905.8769945190743,"y":2725.4749624919054}},{"label":"ZNF444","pos":{"x":3745.8769945190743,"y":3045.4749624919054}},{"label":"ZNF460","pos":{"x":3585.8769945190743,"y":2885.4749624919054}},{"label":"ZNF470","pos":{"x":3745.8769945190743,"y":3005.4749624919054}},{"label":"ZNF471","pos":{"x":4145.876994519074,"y":3005.4749624919054}},{"label":"ZNF511","pos":{"x":3505.8769945190743,"y":2605.4749624919054}},{"label":"ZNF521","pos":{"x":587.9656372070312,"y":1433.742431640625}},{"label":"ZNF524","pos":{"x":3585.8769945190743,"y":3165.4749624919054}},{"label":"ZNF542P","pos":{"x":3185.8769945190743,"y":3125.4749624919054}},{"label":"ZNF547","pos":{"x":3265.8769945190743,"y":3005.4749624919054}},{"label":"ZNF548","pos":{"x":3905.8769945190743,"y":2645.4749624919054}},{"label":"ZNF579","pos":{"x":3905.8769945190743,"y":2605.4749624919054}},{"label":"ZNF580","pos":{"x":3345.8769945190743,"y":2965.4749624919054}},{"label":"ZNF581","pos":{"x":4225.876994519074,"y":3205.4749624919054}},{"label":"ZNF582","pos":{"x":3985.8769945190743,"y":3045.4749624919054}},{"label":"ZNF583","pos":{"x":3345.8769945190743,"y":2725.4749624919054}},{"label":"ZNF628","pos":{"x":3905.8769945190743,"y":2885.4749624919054}},{"label":"ZNF667","pos":{"x":3825.8769945190743,"y":2965.4749624919054}},{"label":"ZNF71","pos":{"x":3825.8769945190743,"y":3125.4749624919054}},{"label":"ZNF713","pos":{"x":1686.74072265625,"y":-1549.4940185546875}},{"label":"ZNF749","pos":{"x":3665.8769945190743,"y":2765.4749624919054}},{"label":"ZNF772","pos":{"x":3105.8769945190743,"y":3125.4749624919054}},{"label":"ZNF773","pos":{"x":3505.8769945190743,"y":2725.4749624919054}},{"label":"ZNF784","pos":{"x":3825.8769945190743,"y":2845.4749624919054}},{"label":"ZNF787","pos":{"x":3265.8769945190743,"y":3045.4749624919054}},{"label":"ZNF805","pos":{"x":3665.8769945190743,"y":2965.4749624919054}},{"label":"ZNF814","pos":{"x":4225.876994519074,"y":3085.4749624919054}},{"label":"ZNF835","pos":{"x":3825.8769945190743,"y":2925.4749624919054}},{"label":"ZNF845","pos":{"x":4145.876994519074,"y":3165.4749624919054}},{"label":"ZNF865","pos":{"x":3185.8769945190743,"y":2725.4749624919054}},{"label":"ZNF91","pos":{"x":4305.876994519074,"y":3005.4749624919054}},{"label":"ZRSR2","pos":{"x":1216.6136474609375,"y":973.8613891601562}},{"label":"ZSCAN5A","pos":{"x":3185.8769945190743,"y":2565.4749624919054}},{"label":"ZSCAN5B","pos":{"x":3585.8769945190743,"y":2845.4749624919054}},{"label":"ZSCAN5C","pos":{"x":3585.8769945190743,"y":2965.4749624919054}},{"label":"ZSCAN5D","pos":{"x":4065.8769945190743,"y":2565.4749624919054}},{"label":"chr1","pos":{"x":-971.6949462890625,"y":849.0050659179688}},{"label":"chr10","pos":{"x":1879.923828125,"y":-179.4615936279297}},{"label":"chr11","pos":{"x":1954.7183837890625,"y":1124.1976318359375}},{"label":"chr12","pos":{"x":1823.7652587890625,"y":359.4603271484375}},{"label":"chr13","pos":{"x":1076.4320068359375,"y":-1183.5975341796875}},{"label":"chr14","pos":{"x":-288.4932556152344,"y":-1576.884521484375}},{"label":"chr15","pos":{"x":-877.2595825195312,"y":386.1282958984375}},{"label":"chr16","pos":{"x":-294.668212890625,"y":579.3158569335938}},{"label":"chr17","pos":{"x":-857.8323974609375,"y":-1495.5223388671875}},{"label":"chr18","pos":{"x":649.6647338867188,"y":1458.806640625}},{"label":"chr19","pos":{"x":282.6548767089844,"y":1154.9901123046875}},{"label":"chr2","pos":{"x":-485.12420654296875,"y":1161.943359375}},{"label":"chr20","pos":{"x":1060.0203857421875,"y":1419.244873046875}},{"label":"chr21","pos":{"x":891.3468017578125,"y":679.511474609375}},{"label":"chr22","pos":{"x":1325.4498291015625,"y":218.5226287841797}},{"label":"chr3","pos":{"x":-158.1291046142578,"y":-599.4402465820312}},{"label":"chr4","pos":{"x":11.975418090820312,"y":97.98661041259766}},{"label":"chr5","pos":{"x":355.03472900390625,"y":540.0452270507812}},{"label":"chr6","pos":{"x":773.085205078125,"y":239.60576629638672}},{"label":"chr7","pos":{"x":1708.71142578125,"y":-1111.0909423828125}},{"label":"chr8","pos":{"x":948.5714721679688,"y":-298.0948486328125}},{"label":"chr9","pos":{"x":-1088.906982421875,"y":-78.65689659118652}},{"label":"chrX","pos":{"x":1316.9232177734375,"y":950.81201171875}},{"label":"chrY","pos":{"x":-1109.79052734375,"y":2405.0447998046875}}];

layout.map(function(nodeInfo) {
var label = nodeInfo.label;
var x = nodeInfo.pos.x;
var y=nodeInfo.pos.y;
console.log("--- using node " + label + " position: " + x + ", " + y);
var selectorString = "[label='" + label + "']";
var node = cwMarkers.nodes(selectorString)[0];
if(typeof(node) != "undefined"){
node.position({x: x, y: y});
console.log(node.data().label);
}
});


--- now save the layout, so that it can be used ordinally on the next run
layoutByLabel = JSON.stringify(cw.nodes().map(function(node) {return {label: node.data().label,  pos:node.position()}}))


*----------------------------------------------------------------------------------------------------
* cyjs fast load data in console from files (27 apr 2015)

cd ~/s/examples/cyjs/fileDriven
python -m SimpleHTTPServer

open ~/s/examples/cyjs/fileDriven/index.html
loadNetwork("mutCopyNumberChromNetwork.js")
loadLayout("layoutFull.js")
loadStyle("style.js")

a huge speedup comes from turning edge display off when loading the network.
the haystack
i do this in the cy.cytoscape({}) initializer:
.selector('edge')
.css({'line-color': 'green',
'source-arrow-shape': 'circle',
'display': 'none',
'source-arrow-color': 'red',
'curve-style': 'haystack' // not bezier, buthaystack for faster drawing (no arrows)
})

---- loadNetwork
function addNetwork(filename){
s = "http://localhost:8000/" + filename;
console.log("=== about to getScript on " + s);
$.getScript(s)
.done(function(script, textStatus) {
console.log("getScript: " + textStatus);
console.log("nodes: " + network.elements.nodes.length);
if(typeof(network.elements.edges) != "undefined")
console.log("edges: " + network.elements.nodes.length);
cy.add(network.elements);  // no positions yet
cy.nodes().map(function(node){node.data({degree: node.degree()})});
}) // .done
.fail(function( jqxhr, settings, exception ) {
console.log("getScript error trying to read " + filename);
});
}

---- loadLayout
s = "http://localhost:8000/" + filename;
console.log("=== about to getScript on " + s);
$.getScript(s)
.done(function( script, textStatus ) {
console.log( textStatus );
console.log("layout length " + layout.length);
cy.nodes().positions(function(i, node){return{x: layout[i].pos.x, y:layout[i].pos.y};});
cy.fit();
})
.fail(function( jqxhr, settings, exception ) {
console.log("getScript error trying to read " + filename);
});


--- loadStyle
function loadStyle(filename){
s = "http://localhost:8000/" + filename;
console.log("=== about to getScript on " + s);

$.getScript(s)
.done(function(script, textStatus) {
console.log(textStatus);
//console.log("style elements " + layout.length);
cy.style(vizmap);
})
.fail(function( jqxhr, settings, exception ) {
console.log("getScript error trying to read " + filename);
});
}

---- were the network file starts like this:
network = {
"format_version" : "1.0",
"generated_by" : "cytoscape.js",
data : {
"selected" : true,
"shared_name" : "gbm + lgg mut/cnv",
"SUID" : 12380,
"name" : "gbm + lgg mut/cnv"
},
"elements" :{"nodes":[
{data:{name:"TCGA.02.0266",nodeType:"patient",label:"TCGA.02.0266",id:"TCGA.02.0266"}},
{data:{name:"TCGA.12.0818",nodeType:"patient",label:"TCGA.12.0818",id:"TCGA.12.0818"}},

--- layout file like this
layout = [{"label":"ABCA1","pos":{"x":-931.72119140625,"y":-85.06956481933594}},
{"label":"ABCA13","pos":{"x":4385.876994519074,"y":2685.4749624919054}},
{"label":"ABCB1","pos":{"x":3265.8769945190743,"y":2965.4749624919054}},

--- style file like this:
vizmap =  [
{"selector":"node","css": {
"text-valign":"center",
"text-halign":"center",
"background-color":"rgb(240, 240, 240)",
"border-color":"black",
"border-width":"1px"}},

{"selector":"node:selected","css": {
"content":"data(label)",

--- create file from R, write to javascript loadable file
g.json <- as.character(biocGraphToCytoscapeJSON(g.p2)
write(paste("network = ", g.json), file="gp2.txt")




*----------------------------------------------------------------------------------------------------
* good json validator (26 apr 2015)

http://codebeautify.org/jsonvalidate

can cut & paste 1.3M test into its text input box, gives good error messages.

*----------------------------------------------------------------------------------------------------
* rebuild gbm/lgg markers & patients graph (26 apr 2015)

cd ~/oncodev/hbolouri/dataPackages/networks/TCGAbrainMarkersAndTissues/prep

cd    ~/oncodev/hbolouri/oncoDev14/Oncoscape/inst/scripts/markersAndSamples

--- 9pm: realize that the large json file could be best built directly
emacs-edited version down to 1.352M
replace the old one in widget.html
include(/Users/pshannon/oncodev/hbolouri/dataPackages/networks/TCGAbrainMarkersAndTissues/prep/gbmlgg0-noView.cyjs)
include(../markersAndSamples/mutCopyNumberChromNetwork.json)

*----------------------------------------------------------------------------------------------------
* rcyjs todo

1) fitSelectedContent (25 apr 2015)
2) setEdgeWidthInterpolatingRule (25 apr 2015)
3) x <- RCyjs(portRange=9047:9057, quiet=TRUE, graph=graphNEL()) # empty graph fails (31 may 2015)

*----------------------------------------------------------------------------------------------------
* reimburse johnny for new england trip (24 apr 2015)

Airport hotel: $146.24 ($292.48 / 2)
Car: $50.00 (Gas / 2)
Concert: $87 (Tickets + Ridiculous Service Charge / 2)
146.24 + 50 + 87 ->  283.24
>

*----------------------------------------------------------------------------------------------------
* wombat loses localhost (23 apr 2015)
don't know why, but adding this line to the previously empty /etc/hosts fixed the problem

127.0.0.1 localhost

*----------------------------------------------------------------------------------------------------
* cannot remove R build lock (23 apr 2015)

use lsof to find process which is holding the lock

lopez.tests> rm -rf /home/sttrweb/R/x86_64-unknown-linux-gnu-library/3.1/00LOCK-Oncoscape
rm: cannot remove ‘/home/sttrweb/R/x86_64-unknown-linux-gnu-library/3.1/00LOCK-Oncoscape/OncoDev14/
scripts/tabsApp/.nfs00000000011dcc6a00000008’: Device or resource busy

lopez.tests> lsof | grep nfs00000000011dcc6a00000008
R         12646          sttrweb   17r      REG               0,51   3246099 18730090 /home/sttrweb/R/x86_64-unknown-linux-gnu-library/3.1/00LOCK-Oncoscape/OncoDev14/scripts/tabsApp/.nfs00000000011dcc6a00000008 (home:/vol/home_ad1/unix/sttrweb)
R         15722          sttrweb   16r      REG               0,51   3246099 18730090 /home/sttrweb/R/x86_64-unknown-linux-gnu-library/3.1/00LOCK-Oncoscape/OncoDev14/scripts/tabsApp/.nfs00000000011dcc6a00000008 (home:/vol/home_ad1/unix/sttrweb)
R         15722          sttrweb   18r      REG               0,51   3246099 18730090 /home/sttrweb/R/x86_64-unknown-linux-gnu-library/3.1/00LOCK-Oncoscape/OncoDev14/scripts/tabsApp/.nfs00000000011dcc6a00000008 (home:/vol/home_ad1/unix/sttrweb)
R         17061          sttrweb   16r      REG               0,51   3246099 18730090 /home/sttrweb/R/x86_64-unknown-linux-gnu-library/3.1/00LOCK-Oncoscape/OncoDev14/scripts/tabsApp/.nfs00000000011dcc6a00000008 (home:/vol/home_ad1/unix/sttrweb)
R         17061          sttrweb   18r      REG               0,51   3246099 18730090 /home/sttrweb/R/x86_64-unknown-linux-gnu-library/3.1/00LOCK-Oncoscape/OncoDev14/scripts/tabsApp/.nfs00000000011dcc6a00000008 (home:/vol/home_ad1/unix/sttrweb)
lopez.tests> kill 12646 15722 17061
lopez.tests> lsof | grep nfs00000000011dcc6a00000008
lopez.tests> rm -rf /home/sttrweb/R/x86_64-unknown-linux-gnu-library/3.1/00LOCK-Oncoscape/

*----------------------------------------------------------------------------------------------------
* markers & tissues cyjs network for oncoscape, for eric: apply his layout from json (24 apr 2015)

--- get the layout
start public oncotest1
in javascript console:
layout_json = JSON.stringify(cwMarkers.nodes().map(function(node){return{label: node.data().label, pos: node.position()}}));
save as: a chrome console menu command. then edit this into a form:
layout = [{"label":"Y","pos":{"x":1617.1904587862193,"y":2153.788086012285}},
{"label":"X","pos":{"x":1617.1904587862193,"y":2153.788086012285}},
{"label":"9","pos":{"x":-1414.245902212248,"y":865.743450822403}},
{"label":"8","pos":{"x":585.1446430507284,"y":1024.2557831514835}},
...
{"label":"TCGA.02.0003","pos":{"x":-2520.40842979611,"y":1254.6557928847542}},
{"label":"TCGA.02.0001","pos":{"x":3008,"y":-1578}}];

cd ~/oncodev/hbolouri/dataPackages/networks/TCGAbrainMarkersAndTissues/prep/
cp ~/Downloads/cwMarkers-layout.json .
cd ~/www/stage;
chmod 644 cwMarkers-layout.json
python -m SimpleHTTPServer
http://localhost:8000/cwMarkers-layout.json

--- load and apply  in rcyjs console:
s = "http://localhost:8000/cwMarkers-layout.json"
$.getScript(s);
cy.nodes().positions(function(i, node){return{x: layout[i].pos.x, y:layout[i].pos.y};});
*----------------------------------------------------------------------------------------------------
* markers & tissues cyjs network for oncoscape, for eric (20 apr 2015)

context: creating markers & samples graph for lgg & gbm combined

cd ~/oncodev/hbolouri/dataPackages/networks/TCGAbrainMarkersAndTissues/prep/

---- what patients to use?   563 from gbm, 513 from lgg

gbm <- TCGAgbm()
mtx.cn.gbm <- matrices(gbm)$mtx.cn
dim(mtx.cn.gbm) # 563 x 23575

lgg <- TCGAlgg()
mtx.cn.lgg <- matrices(lgg)$mtx.cn
dim(mtx.cn.lgg) # 513 22184


---- what genes to use?    note the high threshold on copy number.
reload(0:5)   # or print(load("allLists.RData"))
goi: 545
gbm.mutant.genes.sig: 142
lgg.mutant.genes.sig: 102
lgg.cn.genes.sig:     86      # number of genes with sub(abs(cn)) > 325
gbm.cn.genes.sig:     57      # number of genes with sub(abs(cn)) > 525
goi.all:              834

--- create copynumber
list.cnL.gbm <<- createGisticList(goi.all, mtx.cn.gbm, "loss")   # 558/563
list.cnG.gbm <<- createGisticList(goi.all, mtx.cn.gbm, "gain")   # 560/563
list.cnL.lgg <<- createGisticList(goi.all, mtx.cn.lgg, "loss")   # 491/513
list.cnG.lgg <<- createGisticList(goi.all, mtx.cn.lgg, "gain")   # 441/513


--- create graph with mutant, chrom and copyNumber edges
six genes don't have associated chromosomes.  don't worry for now
setdiff(goi.all, names(list.chrom))
[1] "C2ORF44"    "CDKN2A-AS1" "CXORF22"    "MIR-31/31"  "MIR-31/31*" "STL"        "ZSCAN5D"

reload(11)   # creates g07.RData
g  # Number of Nodes = 2515
# Number of Edges = 278046
noa.names(g)   # [1] "nodeType" "subType"  "label"
table(as.character(noa(g, "nodeType")))
chromosome       gene    patient
24        834       1657

eda.names(g)   # [1] "edgeType" "mutation" "gistic"
table(as.character(eda(g, "edgeType")))
chromosome copyNumberGain copyNumberLoss       mutantIn
827         184433          89078           1635



*----------------------------------------------------------------------------------------------------
* markers & tissues cyjs network for oncoscape, for eric (20 apr 2015)

--- next up:  add copy number (-2:2) and mutations

--- this work (mutations only) suspended on (20 mar 2015)
cd ~/oncodev/hbolouri/dataPackages/networks/TCGAbrainMarkersAndTissues/prep
results deployed in
~/oncodev/hbolouri/oncoDev14/Oncoscape/inst/scripts/markersAndSamples
as
include(../markersAndSamples/ericsLayout-2015jan02.json)
include(../markersAndSamples/mutNetwork.json)
include(../markersAndSamples/vizmap.json)

*----------------------------------------------------------------------------------------------------
* testing async calls in qunit (18 apr 2015)

--- ajax

function getPersons(callback) {
$.ajax({type: "POST",
dataType: "json",
data: "{}",
contentType: "application/json",
url: "AjaxService.asmx/GetPersons",
success: function(response) {callback(response);}
});
}

QUnit.test("getPersons", function() {
var done = assert.async();   // create one of these for every async test. replaces stop & start
getPersons(function(response){
persons = $.evalJSON(response.d);
equals(persons[0].FirstName, "Mohammad");
done();
});
});


--- dom manipulation

*----------------------------------------------------------------------------------------------------
* ugly orange query-ui tabs background (15 apr 2015)

this element:
$(".ui-tabs-nav").css("background-image")        "url(http://localhost/home/css/images/ui-bg_gloss-wave_35_f6a828_500x100.png)"
$(".ui-tabs-nav").css({"background-image": "none"})
$(".ui-tabs-nav").css({"background": "#e6e6e6"})

--- fixed this way, in common.css

.ui-tabs-nav {
background-image: none;
background: "#e6e6e6";
}

--- this removes that same ugly orange from the patient history sliders

.ui-slider-range {
background-image: none;
background: lightgrey;
}



*----------------------------------------------------------------------------------------------------
* what IS oncoscape? (13 apr 2015, oberlin)

Hamid's analysis seems just right to me.

This question may arise. It often does.  Or it doesn't arise, and people don't
understand what we are doing.

What IS oncoscape?  Just another website?  Why should I be interested?  Why should I
invest in it?

My answer...

Every human tool (this is especially easy to see in software tools) embodies a
view of the world.  That view (you can call it an ontology) is usually not stated, but
it is usually easy to see.  Some things are included, can be operated on or explored.
Many other things are ignored.  They simply don't exist in the world of that tool.

For example:

1) to Microsoft Word, for example, the world consists of words, paragraphs, documents.
2) UCSC genome browser:  DNA sequence and events upon them
3) cytoscape: nodes and edges
4) cbioportal:  large-scale cancer genomics data sets

In cbioportal several world views are present.  Oncoprint, some small networks,
heatmaps, the mutation lollipop widget.  Connecgtions among these world views
are hard to make, as we have recently learned.  The complexity of cbio's original
goals -- to explore several kinds of data, gain insight into tumorigenesis --
ensures that.  But Niki freely admits it is monolithic and hard to extend.  It
has a rigidity which arises naturally from its initial focus upon just TCGA data.

Research projects (and the websites they produce) suffer the same limitation.
They are funded to refine and deepen comprehension of a narrowly-defined problem
area.  This limitation is of course also a virtue.  One needs a well-defined
narrow focus in order to learn anything new, or to create software which delivers
new capabilities.

Oncoscape is a different beast entirely.

It is shaped by these premises:

- The world views we need to explore are many and varied.

- Each has its own native kinds of data, analyses and visualizations.

- Real progress in understanding arises from judicious blending
of insights from the different world views.

- The blending happens in the mind of the exploring scientist.

- The blending is possible because, despite their differences,
some core entities are found in all of them.  For cancer research:

* patients (or samples, or cell lines)

* genes (however defined: chromosomal locations, exons, mRNA, protein
product, post-translational modifications)

Oncoscape is not committed to any specialized world view.  Instead, it is
committed to support ALL specialized world views, and to linking them together
for the benefit of the exploring scientist.


*----------------------------------------------------------------------------------------------------
* deduction, induction, abduction

deduction: given that all bachelors are unmarried males, and given
that this person is a bachelor, one can deduce that this person is
an unmarried male.

induction: if all swans that we have observed so far are white, we
may induce that the possibility that all swans are white is
reasonable.

abduction: in a billiard game, after glancing and seeing the eight
ball moving towards us, we may abduce that the cue ball struck the
eight ball. The strike of the cue ball would account for the
movement of the eight ball. It serves as a hypothesis that explains
our observation. Given the many possible explanations for the
movement of the eight ball, our abduction does not leave us certain
that the cue ball in fact struck the eight ball, but our abduction,
still useful, can serve to orient us in our surroundings. Despite
many possible explanations for any physical process that we observe,
we tend to abduce a single explanation (or a few explanations) for
this process in the expectation that we can better orient ourselves
in our surroundings and disregard some possibilities.


*----------------------------------------------------------------------------------------------------
* socket connected, document ready:

loadingDataset
*----------------------------------------------------------------------------------------------------
* chinook spiel

The repo will have four parts:

1) The Chinook Protocol.  This is simple core code in R, python and
Javascript for the creation, setup of and running of websocket
servers & clients.  These enable the exchange of "chinook" messages,
simple four-field JSON (cmd, status, callback, payload) passed over
websockets.

Our protocol gets its name from the "Chinook Jargon", a very simple
trading language -- a pidgin, a contact language -- used in the
Pacific Northwest for many centuries. The last Chinook speakers
lived in Seattle, and passed away in the 1930's.  With a vocabulary
of about 400 words and a very simple grammar, it allowed speakers of
many Amerindian languages to communicate enough to conduct extensive
trade.  A few French and English words were added in the nineteenth
century.

Chinook is a model and inspiration for us because we have a similar
need: that is, like Chinook speakers, we need to connect rich
complex entities as simply as possible.  Economies were connected in
the historical case; problem domains, subdisciplines, computational
and visualization practices are to be connected in our case.
Chinook speakers developed a broad and extensive economy using only
a small number of shared words. Similarly, we are creating an
extensive computational environment based upon the exchange simple
messages between powerful computational services and visualization
tools.

2) Directory of services.  The repo will grow to include directory
of computational resources offering chinook-compatible services. The
nature of inputs and outputs will be described here in enough detail
for clients (usually Javascript modules running in a web browser) to
use them.  Source code will be offered, directly or indirectly.  In
some cases the services will be running, publicly available, and
ready to be called.

3) Directory of visualization tools.  The repo will also offer a
directory of (and sometimes actual code for) useful web-based
visualization tools, nicely wrapped for easy inclusion in your web
application.  Cytoscape.js, heatmaps, cbioportal's oncoprint,
interactive plotters, histograms, the new version of the Regulome
Explorer, ...

These three parts of the github repository make it possible to
create web-based exploratory data analysis environments.  They
depend upon a software engineering strategy characterized by
loose-coupling, maximum ignorance among the constituent parts,
separation of concerns, and user- and test-driven development. This
strategy makes it possible to craft and connect webapps which follow
our slogan, "No More Silos!"  There is too much data and too many
computational tools available today for websites to remain isolated
and unconnected.

4) Oncoscape - our own project - is one such loosely coupled webapp.
Here we apply the above principles and software elements into a web
application for the Solid Tumor Translational Research project at
the Fred Hutch, combining exploratory data analysis and
computational tools with which to analyze patient clinical histories
together with many dimensions of molecular data, all with the goal
of improving patient treatment as quickly as possible.


*----------------------------------------------------------------------------------------------------
* safe-keeping of prossibly unneeded imports in NAMESPACE of RCyjs (29 mar 2015)

importClassesFrom(graph, graph, graphBase)

importClassesFrom(methods, character, integer)

importMethodsFrom(graph, edgeData, "edgeData<-", edgeDataDefaults,
"edgeDataDefaults<-", edgeNames, edges, inEdges,
nodeData, "nodeData<-", nodeDataDefaults,
"nodeDataDefaults<-", nodes,
edgemode, "edgemode<-",
addNode, addEdge)

importFrom(methods, new)
import(BrowserViz)
import(igraph)
import(httpuv)

*----------------------------------------------------------------------------------------------------
* ugly yellowish background, jqueryui oncoscape (17 mar 2015)
$(".ui-widget-header").css("background")
"rgb(248, 248, 248) \
url(http://oncoscape.sttrcancer.org/oncoscape/css/images/ui-bg_gloss-wave_35_f6a828_500x100.png) repeat-x scroll 50% 50% / auto padding-box border-box"

*----------------------------------------------------------------------------------------------------
* put latest js/css and  css/images on lopez (16 mar 2015)

--- explicit uris used during recent development of the collaborator-ready oncoscape
cd ~/oncodev/hbolouri/oncoDev14/Oncoscape/inst/scripts

grep localhost index.wombat
<script src="http://localhost/home/js/jquery-2.1.3.min.js"></script>
<script src="http://localhost/home/js/jquery-ui-1.11.4.min.js"></script>
href="http://localhost/home/css/jquery-ui-1.11.4.min.css">
<script src="http://localhost/home/js/cytoscape-2.3.10.min.js"></script>
<script src="http://localhost/home/js/jquery.cytoscape.js-panzoom.js"></script>
<link   href="http://localhost/home/css/jquery.cytoscape.js-panzoom.css"
<script src="http://localhost/home/js/d3.min.js"></script>
<script src="http://localhost/home/js/jquery.dataTables-1.10.5.min.js"></script>
href="http://localhost/home/css/jquery.dataTables-1.10.5.min.css">

--- make a tarball
js/jquery-2.1.3.min.js"></script>
js/jquery-ui-1.11.4.min.js
js/cytoscape-2.3.10.min.js
js/jquery.cytoscape.js-panzoom.js
js/d3-3.5.5.min.js
js/jquery.dataTables-1.10.5.min.js
css/jquery.cytoscape.js-panzoom.css
css/jquery-ui-1.11.4.min.css
css/jquery.dataTables-1.10.5.min.css
css/images/ui-bg_diagonals-thick_18_b81900_40x40.png
css/images/ui-bg_diagonals-thick_20_666666_40x40.png
css/images/ui-bg_flat_10_000000_40x100.png
css/images/ui-bg_glass_100_f6f6f6_1x400.png
css/images/ui-bg_glass_100_fdf5ce_1x400.png
css/images/ui-bg_glass_65_ffffff_1x400.png
css/images/ui-bg_gloss-wave_35_f6a828_500x100.png
css/images/ui-bg_highlight-soft_100_eeeeee_1x100.png
css/images/ui-bg_highlight-soft_75_ffe45c_1x100.png
css/images/ui-icons_222222_256x240.png
css/images/ui-icons_228ef1_256x240.png
css/images/ui-icons_ef8c08_256x240.png
css/images/ui-icons_ffd27a_256x240.png
css/images/ui-icons_ffffff_256x240.png

--- put these filenames into files-for-lopez-2015-16-mar.txt
cd ~/www
tar cvf jslibs.tar -T files-for-lopez-2015-16-mar.txt   # 950272 Mar 16 10:58 jslibs.tar
scp jslibs.tar lopez:tmp/

on lopez
sudo -s sttrweb
cd /home/sttrweb/lopez/public_html
cp ~pshannon/tmp/jslibs.tar .

*----------------------------------------------------------------------------------------------------
* simple oncolauncher demo (10 mar 2015)

is mongod running?
ps aux | grep -i mongod | egrep -v grep
if not:
mongod --dbpath /Users/pshannon/mongo/data/db

oncoscape is launched dynamically:
node launcher -> utils/createOncocapeInstance.py -> runOncoScripts/run-4050.R
with that port number incrementing with every launch

user: test@nowhere.org
pw: fooBAR!8

*----------------------------------------------------------------------------------------------------
* holland lab, hamid big storage


-- by example:

scp cgds_public_dump_20150116.sql rhino:/fh/fast/_HB/STTR/

*----------------------------------------------------------------------------------------------------
* css tips

--- in a pulldown menu with a specified ID, locate the menu item (the option) with a specified
value

html:  <select type="button" id="datasetMenu" style="margin: 5px;"><option> </option></select>
Module.js:

for(var i=0; i < dataSetNames.length; i++){
s = dataSetNames[i];
datasetMenu.append("<option value='" + s + "'>" + s + "</option>");
}

in the javascript consold:
document.body.querySelector("#datasetMenu option[value='DEMOdz']")

*----------------------------------------------------------------------------------------------------
* emacs tips, on the fly, emacs flycheck (6 mar 2015)

https://flycheck.readthedocs.org/en/latest/
apprently uses hadley wickam rules

*----------------------------------------------------------------------------------------------------
* oncoscape/cgc meeting followup (6 mar 2015)

--- my proposal to hamid:

- a github site for  the latest oncoscape (your good idea)

- also, somehow, a related github site which provides only the
low-level infrastructure.  This would include the json format,
the basic websocket and message dispatch setup in Javascript, in
R, and also in python (though that may take a while, and maybe
they could help)

- maybe even a third github site for sharing widgets.  this idea is
ill-defined as yet


All of this (especially the latter two) seeks to foster, in a small
way, a loose collabortive community.  Low threshold to join, no big
architecture to adopt.  We don't want people to actually adopt
Oncoscape, but rather we hope that they might use our protocol;
that people would contribute widgets we too could use; that
analysis services could be more easily shared.  Add your javascript
widget (a heatmap, timelines, regulome explorer's successor, a
multi-featured wrapper around cyjs, ...).  Provide links to
analyses which respond to the JSON/websocket protocol.

--- hamid's helpful reply

All sounds good. A small 'tweak' in how we think of all this might be useful:

I would NOT say "We don't want people to actually adopt
Oncoscape", we certainly do and I don't think you meant it
either. Rather, we want to provide a low-threshold substrate that
people can use to develop Oncoscape-compatible tools. I am
assuming (please reality-check me here!) that if tools are
developed based on your 'minimal architecture' then we/they will
be able to integrate those tools into Oncoscape in very
straight-forward ways.

A useful 'side-effect' of your 'minimal architecture' would be that
it may be adopted by many teams who do not want to or do not have
the resources etc to integrate their tools into Oncoscape, thereby
making the tools thus developed easy to integrate into Oncoscape
(if we should want to).

--- Details regarding your plan:

If possible, it would be advantageous if we could keep a single
github repository with multiple offerings/sub-directories (I have
seen others do this). One offering will be the latest, coolest
Oncoscape release. Another offering will be the 'minimal
architecture'. We could even have a folder for 3rd party
contributions.

In fact, since the ISB team is strong in Python, it would be cool
if they could take your R/JS 'minimal architecture' and add a
Python interface (I guess this would be a collaboration with
you). Having the ISB (and maybe cBio?) contribute some (even
small) pieces of code would have the nice side-effect of making
the project truly a multi-site development.


--- synthesis (6 mar 2015)

It was a pleasure to meet with all of you last Friday.  We are excited to
collaborate on software, and we feel that the time is ripe for sharing some
of these things:

- a lightweight communication protocol (four-field JSON over websockets)

- some Javascript widgets (cytoscape.js, crex, a heatmap)

- more speculatively, some computational services (using BigQuery,
Bioconductor offerings, maybe network inference and other applications
of machine learning).

The key to successful collaboration and sharing software lies in the cost/benefit
ratio.  How much policy, and how much overhead, does one need to accept in order to
use new software?  The costs must be vanishingly low, and the benefits must be high.

We have designed Oncoscape and its underlying architecture to achieve these ends.
You can help us put thta claim to the test, and to revise our approach as needed.

Here is what we will offer, with a target date of April 1st:

- all code on github

- small Javascript, R and python libraries which provides all websocket setup and
message passing

- a small jQuery demo webapp, with a few tabs, running off a python
or R websocket server

- the latest Oncoscape, which is in esssence a large jQuery demo webapp
running off an R  websocket server

- code and documentation for all of the above

- a repository for compatible browser widgets, which may be the actual code or
may be just a description and a link.

- some of these widgets will be just browser widgets,  others may be widgets
intimately tied to a computational service

Not all of this will be ready by April 1st, but enough will be on github for
our collaboration to begin.

*----------------------------------------------------------------------------------------------------
* install phantomjs on lopez from source (6 mar 2015)

[status: abandoned.  carl installed this for us]

-- on wombat
phantomjs is /Users/pshannon/s/src/phantomjs/bin/phantomjs
casperjs is /usr/local/bin/casperjs


--- downloaded zip source is huge
110 092 872 Mar  5 19:40 phantomjs-2.0.0-source.zip
aband

*----------------------------------------------------------------------------------------------------
* intro to BrowserViz vignette, and newsletter (5 mar 2015)

The BrowserViz package is inspired by the recognition that the data
analysis capabilities of R benefit from the increasingly rich and
interactive graphics of today's HTML5 web browsers.  BrowserViz is not
the first package to tackle this combination: Shiny and htmlwidgets
already provide extensive support for those writing code to connect an
R session to the web browser.  Both of these packages have a large and
loyal community of users.

Why, then, did we create another package for programmers wishing to
connect R to the browser?

The BrowserViz strategy is based upon observations and
principles which appear to be different from those which inspired
Shiny and htmlwidgets.  Inspired by observations and principles, we
believe that BrowserViz permits and encourages a different
style of programming than that of the existing packages, to which we
hope to play a complementary role.

Principles and observations:

1) R and browser programming environments are very different: in the
language used, in the computing tasks they are specialized for, in
the nature of the "native" objects in each domain.

2) We use the venerable principles of ``loose coupling'' and ``maximum
ignorance'' to join these two environments.  In slogan form, we want
"R to be R, and Javascript to be Javascript."

3) To accomplish this, we use simple message passing over lightweight
connections between the two environments.  We use the same libraries
skillfully developed and offered by the Shiny community: httpuv for
websockets, and jsonlite for translating objects into a universal
format.  We limit the content of these messages to those entities
which, at a high level of abstraction, are meaningful in -both-
domains.  Thus do not represent the DOM in R, nor do we represent
generalized linear models in Javascript.  Points, lines, character
strings, numbers, lists, matrices, data.frames, graphs (networks) are
meaningful in both domains.  Selections and subsets.  Requests and
responses.

4) Though the two environments use different languages, and employ
different programming sensibilities, both R and Javascript/HTML/CSS
are increasingly widespread skill sets.  We cater to programmers who
are skilled in, or willing to learn, how to code in both environments.

5) We opted for an explicit event-driven model throughout. Our
paradigmatic use case is a data analysis working in an R console,
calling functions and performing interactive graphical manipulations
in the browser, and getting results back into R from operations
performed there.

Based upon these, BrowserViz is a simple concrete base class,
functional on its own, but primarily intended to be subclassed by
those creating new packages for novel interactive graphical displays
for R.  BrowserViz provides and packages up the complexities of web socket
initiation and message passing, and includes a sample
Javascript/HTML/CSS file showing how to program the web browser end of
these connected environments.


*----------------------------------------------------------------------------------------------------
* foucault & taylor

f: "the order of discourse" in robert young, ed, "Untying the Text" 1981, p67
t: "language and human nature"  plaut Memorail Lecture, 1978
t: "foucault on freedom and truth" Political theory 12, may 1984, p162

*----------------------------------------------------------------------------------------------------
* casperjs bug:  duplicate test@nowhere.org added repeatedly to mongo groups collection (25 feb 2015)

--- problem seen after hundreds of casperjs userDetailsTest.js:

db.groups.find({groupName: "public"})[0]["users"].length   // 1123

--- cleaned up with
db.groups.update({groupName: "public"}, {$set: { users: ["test@nowhere.org"]}})
db.groups.find({groupName: "public"})[0]["users"].length   // 1

--- now recreate with repeated calls
cd /Users/pshannon/oncodev/hbolouri/oncoDev14/launcher/tests
casperjs --no-colors test userDetailsTest.js

--- surprised, this fails.  related?
=== submitting registration for 'test@nowhere.org'
FAIL "#registrationSuccess" still did not exist in 5000ms

use lean().exec(function ...    idiom to get query hit count:

AccessGroups.find({groupName: "public", users: newUserID}).lean().exec(function(err, docs){
if(err){
console.log("err: " + err);
}
else{
groupCount = docs.length;
console.log("prior occurrences of " + newUserID + " in public group: " + groupCount);
if(groupCount == 0){
console.log("adding " + newUserID + " to public group");
AccessGroups.update({groupName: "public"}, {$push: {users: newUserID}});
}// groupCount == 0
} // else
});

*----------------------------------------------------------------------------------------------------
* mongo update a field (25 beb 2015)

db.groups.find()[2]["users"].length   # 1123

--- follow this form
db.collection.update( { field: value1 }, { $set: { field1: value2 } } );

db.groups.find({groupName: "public"})   # field name does not have to be quoted
# this works
db.groups.find({groupName: "public"})[0]["users"].length   // 1123
# this doesn't
db.groups.find({groupName: "public"})["users"].length

db.groups.update({groupName: "public"}, {$set: { users: ["test@nowhere.org"]}})

db.groups.find({groupName: "public"})[0]["users"].length   // 1


*----------------------------------------------------------------------------------------------------
* mongoexport, mongo export, mongo dump

mongo daemon:  mongod --dbpath /Users/pshannon/mongo/data/db &


use oncodev
show collections  # datasets groups system.indexes todos userprofiles users
db.find.groups()[0]
Object.keys(db.groups.find()[0]) # [ "_id", "groupName", "password", "gid", "users" ]

mongoexport --host localhost --db oncodev --collection groups --fields groupName,users --csv

--- mongodump
mongodump --dbpath /Users/pshannon/mongo/data/db --db oncodev

*----------------------------------------------------------------------------------------------------
* oncoLaunch.js cribsheet (24 feb 2015)

--- to run simple demo, login (registration also possible), run OncoDev13/inst/scripts/userDetails/index.html

make userDetails    # node oncoLaunch.js ./userDetails.json

*----------------------------------------------------------------------------------------------------
* useful controls & plotting surface css & html layout (23 feb 2015)

developed in oncodev13, a web page for the histogram controls and display


#histogramControlsDiv {
background-color: #FFFFFF;
position: relative;
height: 400px;
width: 600px;
border: 1px solid #aaa;
border-radius: 5px;
margin-right: auto;
margin-left: auto;
margin-top: 10px;
margin-bottom: 5px;
padding: 0px;
}

#histogramPlottingDiv {
background-color: #FFFFFF;
position: relative;
height: 400px;
width: 600px;
border: 1px solid #aaa;
border-radius: 5px;
margin-right: auto;
margin-left: auto;
margin-top: 5px;
margin-bottom: 5px;
padding: 0px;
}



<div id="histogramDiv">

<div id="histogramControlsDiv">  </div>
<div id="histogramPlottingDiv">  </div>

</div>


function handleWindowResize(){
console.log("=== histogram handleWindowResize")

histogramDiv.width($(window).width());
histogramDiv.height($(window).height() * 0.98);

controlsDiv.width($(window).width() * 0.97);
controlsDiv.height("100px")

plottingDiv.width($(window).width() * 0.97);
plottingDiv.height($(window).height() - 130);

}; // handleWindowResize

*----------------------------------------------------------------------------------------------------
* mongo tops: inspect, dump, load oncolaunch database (24 feb 2015)

bash> mongo
use oncodev
show collections

test@nowhere.org", "password" : "fooBAR!8

db.userprofiles.find({firstName: "test"}).pretty() {
"_id" : ObjectId("54e2a817914c5dbf7ebb68b0"),
"firstName" : "test",
"lastName" : "user",
"affiliation" : "erewhon",
"email" : "test@nowhere.org",
"password" : "fooBAR!8",
"registrationDate" : ISODate("2015-02-17T02:31:51.862Z"),
"loginCount" : 0,
"__v" : 0
}


*----------------------------------------------------------------------------------------------------
* mongo tips:  assign an empty array to  field currently null (16 feb 2015)

db.groups.find({groupName: "public"})
db.groups.find({groupName: "public"}).users == null   // true

db.groups.remove({"users": []})
db.groups.insert({groupName:"public", password:null, gid: 0, users:[]})



*----------------------------------------------------------------------------------------------------
* add new user to oncolaunch mongodb

use web interfact to add user
db.groups.update({groupName: "hollandLab"}, {$push: {users: "nobody@nowhere.net"}})

*----------------------------------------------------------------------------------------------------
*  mongodb add user@test.com to oncoLaunch.js mongo db (16 feb 2015)
[status:  a bit broken.  see above]

mongodb: add new user, user@test.com, to the oncolaunch db (10 feb 2015)

bash> mongo
MongoDB shell version: 2.6.5
connecting to: test
use oncodev  //     switched to db oncodev
show collections

// Date.now()  1424116794828

x = {firstName: "User",
lastName: "Anonymous",
affiliation: "none",
email: "user@test.net",
password: "U8V9!!abc",
registrationDate: Date.now(),
loginCount: 0}

db.users.insert(x)

--- don't forget to add groups

db.groups.update({groupName: "hollandLab"}, {$push: {users: "user@test.com"}})
// now check
db.groups.find({groupName: "hollandLab"})[0].users
// db

[ "pshannon@fredhutch.org", "eholland@fhcrc.org", "user@test.com" ].groups.find({groupName: "hollandLab"})[0].users   // [ "pshannon@fredhutch.org", "eholland@fhcrc.org" ]
prevUsers = db.groups.find({groupName: "hollandLab"})[0].users //  "pshannon@fredhutch.org", "eholland@fhcrc.org" ]
prevUsers.push("user@test.com") // 3
prevUsers // [ "pshannon@fredhutch.org", "eholland@fhcrc.org", "user@test.com" ]

db.groups.update({groupName: "hollandLab"}


*----------------------------------------------------------------------------------------------------
* oberlin nonfiction writing class (15 feb 2015)

RWR 340 - Nonfiction Workshop

Semester Offered: First Semester, Second Semester
Full Course
Credits: 4 credits
Attribute: 4HU, WADV

The writing of personal narratives which employ the techniques of both the traditional essay and fiction, with an emphasis on nonfiction as a literary art form. Students will read work by modern and contemporary authors with an eye toward understanding the variety of modes which come under the current heading ‘creative nonfiction’ (memoir, meditation, travel, cultural critique, etc.), and will be asked to employ a number of these methods and approaches in their own work.
Enrollment Limit: 12
Instructor: A. Osanloo, S. Watanabe
Consent of the Instructor Required: Yes
Prerequisites & Notes
Admission to this workshop requires the completion of CrWr 201 and an application with appropriate work sample. Applications should be submitted to the the CrWr Program Office by 12 noon on the last day of classes. Check the program webpage for details.



*----------------------------------------------------------------------------------------------------
* python tips, python exec tips, python subprocess tips (15 feb 2015)

from stackoverflow:
http://stackoverflow.com/questions/4417546/constantly-print-subprocess-output-while-process-is-running

import subprocess
import sys

def execute(command):
popen = subprocess.Popen(command, stdout=subprocess.PIPE, stderr=subprocess.STDOUT)
lines_iterator = iter(popen.stdout.readline, b"")
count = 0
for line in lines_iterator:
sys.stdout.write("%5d) %s" % (count, line)) # yield line
count += 1

execute(["ls", "-lR", "/Users/pshannon/oncodev/hbolouri"])


*----------------------------------------------------------------------------------------------------
* BrowserViz, httpuv sequence of events (15 feb 2015)

~/s/bioc/trunk/RpacksTesting/BrowserViz/R/BrowserViz-class.R

wsCon <- new.env(parent=emptyenv())
x <- .startDaemonizedServerOnFirstAvailableLocalHostPort(portRange, wsCon)
browserURL("http://%s:%s", host, actualPort)
wsCon <- setupWebSocketHandlers(wsCon, browserFile)
wsCon$wsID <- x$wsID
setupMessageHandlers() # for incoming javascript json msgs
obj <- .BrowserViz(uri=uri, websocketConnection=wsCon, port=actualPort, quiet=quiet)

waits until ready(obj)
returns obj

*----------------------------------------------------------------------------------------------------
* bioc man page example, .Rd file, package tips, man tips, check tips (13 feb 2015)

marc carlson suggests
~/s/bioc/trunk/Rpacks/AnnotationHub/man/AnnotationHub-class.Rd
*----------------------------------------------------------------------------------------------------
* oncoLaunch.js, createOncoscapeInstance.py (17,24 feb 2015)

cd ~/oncodev/hbolouri/launcher

./createOncoscapeInstance.py 5010 userDetails user@test.net "TCGAgbm;DEMOdz"

*----------------------------------------------------------------------------------------------------
* oncoLaunch.js, createOncoscapeInstance.py (12 feb 2015)

want to run onco 1.3 without oncoLaunch.js
since oncoLaunch.js calls
~/oncodev/hbolouri/launcher/createOncoscapeInstance.py
we can too
onco 1.3 needs this information:
the port for httpuv websocket server to listen on
the onco package directory in which to find the webpage html, js and css

thus createOncoscapeInstance.py 9001 userDetails
gets its web content from
dir ~/oncodev/hbolouri/oncoDev13/OncoDev13/inst/scripts/userDetails/index.html
which is there assembled from a makefile, widget.html, index.pre, Module.js

when the httpuv web server receives its first get,

~/oncodev/hbolouri/oncoDev13/OncoDev13/R/OncoDev13.R in .setupWebSocketServer

1) it extracts userID (pshannon@fredhutch.org) and datasetNames ("DEMOdz")
2) adds them to R webapp global env
state <- new.env(parent=emptyenv())
...
state[["userID"]] = parsedArgs$userID
state[["datasetNames"]] = parsedArgs$dataset


the queryString

, it assumes that it will include


*----------------------------------------------------------------------------------------------------
* add pvalue-of-subset to GeneSetTTests packages (11 feb 2015)


*----------------------------------------------------------------------------------------------------
* cbio, clone src repo (11 feb 2015)

-- ben says

Clone the source code repository to your local file system.  Via
ssh it would look something like this:

git clone  ssh://hg@bitbucket.org/cbio_mskcc/cbioportal.org

Warning: Permanently added 'bitbucket.org,131.103.20.168' (RSA) to the list of known hosts.
Permission denied (publickey).

found this on the

hg clone https://paulTshannon@bitbucket.org/cbio_mskcc/cbioportal.org
suggesting maybe this:

git clone  ssh://paulTshannon@bitbucket.org/cbio_mskcc/cbioportal.org

bitbucket: paulTshannon, old animal

after installing SourceTree
launch SourceTree from https://bitbucket.org/cbio_mskcc/cbioportal.org/src
choose the ... menu in top left of web page
then click on "Clone in SourceTree" button, which launches the now-installed app
with what seems to be the right command/url:

finally got this to work using SourceTree GUI
hg clone https://paulTshannon@bitbucket.org/cbio_mskcc/cbioportal.org /Users/pshannon/cbio/src/cbioportal.org
requesting all changes
adding changesets
adding manifests
adding file changes
added 8568 changesets with 29425 changes to 8225 files (+1 heads)
updating to branch default
2785 files updated, 0 files merged, 0 files removed, 0 files unresolved
Completed successfully

installed to: ~/cbio/src/cbioportal.org
business/
cgds-matlab/
cgds-r/
core/
importer/
liftover/
mutation-assessor/
oncotator/
pom.xml
portal/
src/
web/

*----------------------------------------------------------------------------------------------------
* oncoLaunch, straightToR, skipping login & data selection (11 feb 2015)

*----------------------------------------------------------------------------------------------------
* mongodb: add new dataset to the oncolaunch db (10 feb 2015)

bash> mongo
MongoDB shell version: 2.6.5
connecting to: test

db.datasets.find()
{ "_id" : ObjectId("5499c20aeb168bc73d036541"), "name" : "TCGAgbm", "groups" : [ "public" ] }
{ "_id" : ObjectId("5499c212eb168bc73d036542"), "name" : "MSKgbm", "groups" : [ "hollandLab" ] }


add DEMOdz:
db.datasets.insert({name: "DEMOdz",  groups: ["public"]})

db.datasets.insert({name: "DEMOdz",  groups: ["public"]});   // WriteResult({ "nInserted" : 1 })
db.datasets.find()
{ "_id" : ObjectId("5499c20aeb168bc73d036541"), "name" : "TCGAgbm", "groups" : [ "public" ] }
{ "_id" : ObjectId("5499c212eb168bc73d036542"), "name" : "MSKgbm", "groups" : [ "hollandLab" ] }
{ "_id" : ObjectId("54da98b8a330a3614ae6dddc"), "name" : "DEMOdz", "groups" : [ "public" ] }


--- test it out

cd ~/oncodev/hbolouri/launcher/
make
node calls python to customize then run httpuv server at
http://localhost:4051/?userID=pshannon@fredhutch.org&dataset=DEMOdz

crafted out of ~/oncodev/hbolouri/launcher/Rtest/app.R-pre, index.html-pre



*----------------------------------------------------------------------------------------------------
* python tips:  detect if script is running interactively or batch (6 feb 2015)

import sys
interactive = (sys.argv[0] != "testWrapper.py")
if(not(interactive)):
runTests()



*----------------------------------------------------------------------------------------------------
* cyjs tips: get names of all selected nodes

var names = [];
var noi = cwMarkers.filter('node:selected');
for(var n=0; n < noi.length; n++){
names.push(noi[n].data('name'));
}

*----------------------------------------------------------------------------------------------------
* cyjs tips: select nodes by label, type, visibility


cy.filter("node[name='FHRB.252 (2011-10-03)']").select()
cy.nodes("node[name='FHRB.252 (2011-10-03)']").select()
cy.nodes("node[nodeType='gene']").map(function(node){node.data({mutation:""})})
cy.nodes("node[nodeType='patient']:visible").layout({name:'grid', boundingBox: box})

--- get the names of all the chromosome nodes in markers & tissues

cwMarkers.nodes('[label ^= "chr"]').length   // 24
cwMarkers.nodes('[label ^= "chr"]').map(function(node) {return (node.data().label)})
["chr1", "chr10", "chr11", "chr12", "chr13", "chr14", "chr15", "chr16", "chr17", "chr18", "chr19",
"chr2", "chr20", "chr21", "chr22", "chr3", "chr4", "chr5", "chr6", "chr7", "chr8", "chr9", "chrX", "chrY"]

cwMarkers.nodes('[label ^= "chr"]').map(function(node) {return ({label: node.data().label, pos: node.position()})})
JSON.stringify(cwMarkers.nodes('[label ^= "chr"]').map(function(node) {return ({label: node.data().label, pos: node.position()})}))

"[{"label":"chr1","pos":{"x":-971.6949462890625,"y":849.0050659179688}},
{"label":"chr10","pos":{"x":1879.923828125,"y":-179.4615936279297}},
{"label":"chr11","pos":{"x":1954.7183837890625,"y":1124.1976318359375}},
{"label":"chr12","pos":{"x":1823.7652587890625,"y":359.4603271484375}},
{"label":"chr13","pos":{"x":1076.4320068359375,"y":-1183.5975341796875}},
{"label":"chr14","pos":{"x":-288.4932556152344,"y":-1576.884521484375}},
{"label":"chr15","pos":{"x":-877.2595825195312,"y":386.1282958984375}},
{"label":"chr16","pos":{"x":-294.668212890625,"y":579.3158569335938}},
{"label":"chr17","pos":{"x":-857.8323974609375,"y":-1495.5223388671875}},
{"label":"chr18","pos":{"x":649.6647338867188,"y":1458.806640625}},
{"label":"chr19","pos":{"x":282.6548767089844,"y":1154.9901123046875}},
{"label":"chr2","pos":{"x":-485.12420654296875,"y":1161.943359375}},
{"label":"chr20","pos":{"x":1060.0203857421875,"y":1419.244873046875}},
{"label":"chr21","pos":{"x":891.3468017578125,"y":679.511474609375}},
{"label":"chr22","pos":{"x":1325.4498291015625,"y":218.5226287841797}},
{"label":"chr3","pos":{"x":-158.1291046142578,"y":-599.4402465820312}},
{"label":"chr4","pos":{"x":11.975418090820312,"y":97.98661041259766}},
{"label":"chr5","pos":{"x":355.03472900390625,"y":540.0452270507812}},
{"label":"chr6","pos":{"x":773.085205078125,"y":239.60576629638672}},
{"label":"chr7","pos":{"x":1708.71142578125,"y":-1111.0909423828125}},
{"label":"chr8","pos":{"x":948.5714721679688,"y":-298.0948486328125}},
{"label":"chr9","pos":{"x":-1088.906982421875,"y":-78.65689659118652}},
{"label":"chrX","pos":{"x":1316.9232177734375,"y":950.81201171875}},
{"label":"chrY","pos":{"x":-1109.79052734375,"y":2405.0447998046875}}]"


layout_json = JSON.stringify(cwMarkers.nodes().map(function(node){return{label: node.data().label, pos: node.position()}}));

*----------------------------------------------------------------------------------------------------
* cyjs tips:  get layout in json, apply layout from json (25 mar 2015)

--- (22 apr 2015)

layout_json = JSON.stringify(cy.nodes().map(function(node){return{label: node.data().label, pos: node.position()}}));
layout = JSON.parse(layout_json)
cy.nodes().positions(function(i, node){return{x: layout[i].pos.x, y:layout[i].pos.y};});



---- get the layout
cw = cy;  // or whatever its called in your cyjs session
layout = JSON.stringify(cw.nodes().map(function(node) {return {id: node.data().id,  pos:node.position()}}))

---- apply the layout
layout.map(function(x){
label = x.label;
selector = "[label='" + x.label + "']";
cwMarkers.nodes(selector).position({x: x.pos.x, y: x.pos.ya});
return(label);
})


cw.nodes().positions(function(i, node){
return{x: layout[i].position.x, y:layout[i].position.y};
});

cy.nodes().positions(function(i, node){
return{x: layout[i].position.x, y:layout[i].position.y};
});




*----------------------------------------------------------------------------------------------------
* cyjs tips, cy.filter('node[label="chr1"]').select()

cy.style().selector('node:selected').css({'background-color': "red"})

*----------------------------------------------------------------------------------------------------
* max and me on speeding up node layout (5 feb 2015)

-- from me
I've learned how to batch up a filter string, but I'm not clear about position arguments.
I now have this grossly inefficient approach:

layout.map(function(node){
var id = node.id;
var filterString = 'node[id="' + id + '"]'
cy.filter(filterString).position(node.position);
});

Got a tip for me on how to replace this with one cy.filter call?

-- max's reply

I think you can use `nodes.positions( function( node ){} )` for
that.  The callback returns the position for each node.  So if you
build up a map of id=>position prior to the `.positions()` call you
can just return the map value efficiently.

-- from the website
// this lines up all nodes in constant y, incrementing x
cy.nodes().positions(function(i, node){console.log(i); return {x: i * 100, y: 100};});

--- get default layout of angio

pos = JSON.parse(JSON.stringify(cy.nodes().map(function(n){return{id:n.id(), position:n.position()}})))
pos = cy.nodes().map(function(n){return{id:n.id(), position:n.position()}})

works fast:  cy.nodes().positions(function(i, node){return{x: pos[i].position.x, y:pos[i].position.y};});

cy.nodes().positions(function(i, node){console.log(i + ": " + i*100 + ", " + 100); return{x: i * 100, y: 100};});
cy.nodes().positions(function(i, node){console.log(i + ": " + i*100 + ", " + 100); return{x: i * 100, y: 100};});


*----------------------------------------------------------------------------------------------------
* efficient node positioning, efficient layout in cyjs (5 feb 2015)  [see just above]

--- get an existiong layout
pos = JSON.parse(JSON.stringify(cy.nodes().map(function(n){return{id:n.id(), position:n.position()}})))

cy.nodes().map(function(node){return(node.position())})
cy.nodes()[0].id() // "81"
cy.nodes().map(function(node){return({node.id(): node.position()})})
create a list of {id: "81", position:
cy.nodes().map(function(node){var id = node.id(); return({id: id, position:88})})
cy.nodes().map(function(node){var id = node.id(); return({id: id, position:node.position()})})
*----------------------------------------------------------------------------------------------------
* for rachel (5 feb 2015

please provide a summary of your progress with this research to date.

*----------------------------------------------------------------------------------------------------
* lego block software architecture metaphor (5 feb 2015)

http://agile.dzone.com/articles/real-lessons-lego-software

*----------------------------------------------------------------------------------------------------
* python GeneSetTTests websocket tests (4 feb 2015)

cd ~/oncodev/hbolouri/websocketTests/GeneSetTTests/

--- start wrapper
source("wsWrapper.R");  deploy(9003)

--- start python client

execfile("testWrapper.py"); runTests()
--- testEcho
--- testScore_1_geneset
--- testScore_2_genesets

*----------------------------------------------------------------------------------------------------
* node tips, ws tips, websocket tips (4 feb 2015)

figure out how to test an oncoscape-stye websocket server from node [failed! switched to python]

cd ~/oncodev/hbolouri/websocketTests/GeneSetTTests/


--- simplest node ws client, talking to echo.websocket.org
~/oncodev/hbolouri/websocketTests/GeneSetTTests/testEchoServer.js

var WebSocket = require('ws');
var url = "ws://echo.websocket.org";
var ws = new WebSocket(url)
ws.on('open', function() {
ws.send("hello");
ws.send("hi there");
ws.send("ho there");
});
ws.on('message', function(message) {
console.log('received: %s', message);
});

--- run it
node testEchoServer.js
received: hello
received: hi there
received: ho there
^C to end

--- now turn to my simple exploratory R ws server,  wsWrapper.R
start R
source("wsWrapper.R")
deploy(9002)   # 9001 already claimed

--- start simple client in a terminal
wscat --connect ws://localhost:9002
send:
> {"cmd": "echo", "payload": "kidsInALine"}
got back:
<  {"cmd": "echoBack",
"callback": "",
"status": "response",
"payload": "kidsInALine-kidsInALine"}

--- now try to do this from node


*----------------------------------------------------------------------------------------------------
* convert wade's logistic regression with genesets to a package ready to deploy

cd ~/s/examples/R/logisticRegression/wadeCopeland

original vignette, bibliography and .R found here

package here: package/WCLogisticRegression/

starting with, then renaming and adapting the AnalysisDemo package, copied here:
~/s/examples/R/logisticRegression/wadeCopeland/package/AnalysisDemo

*----------------------------------------------------------------------------------------------------
* onco12 failure after hundreds of calls to survival (1 feb 2015)

cd ~/oncodev/hbolouri/oncoDev12/Oncoscape/inst/scripts/survivalStats/
make
in javascript console:
for(var i=0; i < 1000; i++) analyzeSelectedTissuesWithDemoData()

in R console:
[1] receive.callback 296
[1] ==== oncoscape receiveMessage: calculateSurvivalCurves
[1] receive.callback 298
[1] "dispatchMessage 1"
[1] "dispatchMessage 2"
[1] "dispatchMessage 3"
[1] "dispatchMessage 4"
[1] "dispatchMessage 5"
[1] "dispatchMessage 6"
[1] 2015-02-01 15:08:09 dispatchMessage, calculateSurvivalCurves [calculateSurvivalCurves]
[1] === entering calculateSurvivalCurves
[1] calling survivalCurveByAttribute, 4 patients, attribute: NA
[1] 1
[1] 2
[1] 3
[1] 4
[1] 5
[1] 6
[1] 7
[1] 8
[1] "dispatchMessage 7"
[1] receive.callback 299
Error: attempt to apply non-function

--- vague analysis
presumed to be a flaw in the old websockets package
see it if happens in onco13 using httpuv
options(error=recover) when running interactively did not claify
*----------------------------------------------------------------------------------------------------
* js heatmap (2014)

   mentioned http://stackoverflow.com/questions/8491097/interactive-heatmap-matrix-visualization
   http://openscreen.cz/software/inchlib/home/

requires
jQuery (tested with version 2.0.3, download jQuery 2.0.3)
KineticJS (tested with version 5.1.0, download KineticJS 5.1.0)

*----------------------------------------------------------------------------------------------------
* d3 heatmap,

cd ~/s/examples/js/d3/heatmap/
reads tsv data:  d3.tsv("http://localhost/home/data/data_heatmap.tsv",
which is ~/www/home/data
stolen from http://bl.ocks.org/ianyfchang/8119685

*----------------------------------------------------------------------------------------------------
* marc's collection of reviewer tools

library(BiocContributions)
ls(2)
installDeps
...

*----------------------------------------------------------------------------------------------------
* cbio build (10 feb 2015)

mvn 3.0.3 already installed
pom.xml is the makefile equivalent

20 940 706 846
*----------------------------------------------------------------------------------------------------
* cbio deployed with database (10 feb 2015)

gzip file allegedly larger than the original by -33%!

~/cgds_public_dump_20150116.sql.gz  4,997,804,845 Jan 30 12:26
compressed        uncompressed  ratio uncompressed_name
4,997,804,845          3,760,837,662 -32.9% cgds_public_dump_20150116.sql

but actually 5x bigger:
gunzip cgds_public_dump_20150116.sql.gz
20,940,706,846 Jan 30 12:26 cgds_public_dump_20150116.sql

mysql --user=cbio --password=cbio
mysql> CREATE DATABASE cgds_public;

mysql -u username -p database_name < file.sql
starting at 1230p (10 feb 2015):
mysql --host=localhost --user=cbio --password=cbio -D cgds_public < cgds_public_dump_20150116.sql

with a change to /Library/Tomcat/conf/context.xml
careful slaugther of all catalina processes
a fresh /Library/Tomcat/bin/catalina.sh start  it all worked!

<Resource name="jdbc/cbioportal" auth="Container" type="javax.sql.DataSource"
maxActive="100" maxIdle="30" maxWait="10000"
username="cbio" password="cbio" driverClassName="com.mysql.jdbc.Driver"
connectionProperties="zeroDateTimeBehavior=convertToNull;"
url="jdbc:mysql://localhost:3306/cgds_public"/>


*----------------------------------------------------------------------------------------------------
* cbio deployed successfully (30 jan 2015) (but not database just yet)

http://localhost:8080/cbioportal/

--- helpful videoconference with ben gross
make sure no stray tomcats are running:
ps aux | grep -i tom
added this to /Library/Tomcat/conf/context.xml
<Resource name="jdbc/cbioportal" auth="Container" type="javax.sql.DataSource"
maxActive="100" maxIdle="30" maxWait="10000"
username="cbio" password="cbio" driverClassName="com.mysql.jdbc.Driver"
connectionProperties="zeroDateTimeBehavior=convertToNull;"
url="jdbc:mysql://localhost:3306/cbio"/>

--- later (10 feb 2015) changed, once 20G database had been installed:

<Resource name="jdbc/cbioportal" auth="Container" type="javax.sql.DataSource"
maxActive="100" maxIdle="30" maxWait="10000"
username="cbio" password="cbio" driverClassName="com.mysql.jdbc.Driver"
connectionProperties="zeroDateTimeBehavior=convertToNull;"
url="jdbc:mysql://localhost:3306/cgds_public"/>




obviating these entries in
# Portal Database Settings
# db.user=cbio
# db.password=cbio
# db.host=localhost
# db.portal_db_name=cbio
# db.driver=com.mysql.jdbc.Driver
# db.connection_string=jdbc:mysql://localhost/cbioportal

leaving only these live values in ~/cbio/portal.properties
app.name=mycbio
db.tomcat_resource_name=jdbc/cbioportal


with this (inflexible) small addition to /Library/Tomcat/bin/catalina.sh

JAVA_OPTS="-DPORTAL_HOME=/Users/pshannon/cbio"


--- status: need database
fails now -- but with significant success -- because there is no database
Caused by: com.mysql.jdbc.exceptions.jdbc4.MySQLSyntaxErrorException: Unknown database 'cbio'

get mysql dump of public database:

http://cbio.mskcc.org/cancergenomics/public-portal/downloads/cgds_public_dump_20150116.sql.gz
5 GB see above

--- bitbucket notes, towards adding a tab
https://bitbucket.org/cbio_mskcc/cbioportal.org,pshannon@fhcrc.org, old animmal
https://bitbucket.org/cbio_mskcc/cbioportal.org/src
src/main/resources/content

cbioportal.org / portal / src / main / webapp /

*----------------------------------------------------------------------------------------------------
* from V, thomas pynchon, p 366
love with your mouth shut, help without breaking your ass or publicizing it; keep cool, but care.

*----------------------------------------------------------------------------------------------------
* oncolaunch (next up)

cd ~/oncodev/hbolouri/launcher
add phantom/casper auto testing and timing of the "Get User Details" demo

*----------------------------------------------------------------------------------------------------
* oncolaunch (29 jan 2015)  how to run "Get User Details" demo

[with DEMOdz package ready (the first SttrDataPackage), returning to evolving oncodev13]
cd ~/oncodev/hbolouri/launcher

--- run demo
start mongo: mongod --dbpath /Users/pshannon/mongo/data/db &
cd ~/oncodev/hbolouri/launcher; make
node oncoLaunch.js ./userDetails.json
"startingPort":         4050,
"mode":                "test",
"oncoscapeScriptDir":  "userDetails",
"pythonLauncher":  "/Users/pshannon/oncodev/hbolouri/launcher/createOncoscapeInstance.py",


when "Start Analysis" button is clicked, these event ensue:
oncoLaunch.js function createNewOncoscapeInstance(userID, datasets, oncoscapeScriptDir) runs
userID and a datasets string is from users choices
oncoscapeScriptDir is set in the userDetails.json
out of app.post('/launchOncoscape', function(req, res){
pythonLauncher <port> <oncoscapeScriptDir> is execed, port (incremented) is returned
then:
var uri = "http://localhost:" + port + "?userID=" + loginID + "&scriptDir=" +
oncoscapeScriptDir + "&dataset=" + datasets;
setTimeout(function(){ res.redirect(307, uri);}, 3000);


that 3000 msec delay gives (maybe not always?) enough time for the R websocket app to load and listen
should replace this timeout with a check to see if http get header returns


these configurations, made in these places:
userID: interactively from webapp, passed in redirect url to R webapp
datasets: same
port and  R scriptDir: initial value specified in userDetails.json
port & scriptDir passed to python launcher in argv
port is placed into the name of a processed R script ("run-4054.R"):
edited by createOncosxapeInstance.py into raw script launcher/run.R-pre:

library(OncoDev13)
scriptDir <- "__SCRIPT_DIR__"
onco <- OncoDev13(port=__PORT__, htmlFile=scriptDir)
run(onco)

producing

library(OncoDev13)
scriptDir <- "userDetails"
onco <- OncoDev13(port=4054, htmlFile=scriptDir)
run(onco)


crafted into redirect url

python launcher of R app


*----------------------------------------------------------------------------------------------------
* SttrDataPackage instructions for lisa (29 jan 2015)

cd ROOT/hbolouri/dataPackages
svn up
R CMD build SttrDataPackage
R CMD install SttrDataPackage_0.99.4.tar.gz    # or whatever version build creates
R CMD build DEMOdz
R CMD install DEMOdz_0.99.1.tar.gz    # or whatever version build creates

R CMD check SttrDataPackage_0.99.4.tar.gz
R CMD check DEMOdz_0.99.1.tar.gz

cd SttrDataPackage/inst/unitTests
start R
R> source("test_SttrDataPackage.R");
R> runTests()

cd DEMOdz/inst/unitTests
start R
R> source("test_DEMOdz.R");
R> runTests()



*----------------------------------------------------------------------------------------------------
* checkout an sttr directory, to tmp/, for testing (29 jan 2015)

cd ~/tmp
mkdir sttr; cd sttr
svn co https://hedgehog.fhcrc.org/hb/devel/hbolouri/dataPackages




*----------------------------------------------------------------------------------------------------
* simple tomcat mysql servlet (29 jan 2015)
apache tomcat 7.0.52

cd ~/s/examples/java/servlets/helloMYSQL/
2740 Jan 29 12:37 HelloMYSQL.java
243 Jan 29 12:40 makefile

ls -laR /Library/Tomcat/webapps/mysqlDemo/
136 Jan 29 13:03 WEB-INF/
231 Jan 29 13:04 index.html

/Library/Tomcat/webapps/mysqlDemo//WEB-INF:
102 Jan 29 12:52 classes
292 Jan 29 13:03 web.xml

/Library/Tomcat/webapps/mysqlDemo//WEB-INF/classes:
2909 Jan 29 12:52 HelloMYSQL.class

http://localhost:8080/mysqlDemo/mysql
displays "Database Result"  and rowCount: 5

--- customizations in HelloMYSQL.java

String JDBC_DRIVER="com.mysql.jdbc.Driver";
String DB_URL="jdbc:mysql://localhost/ebookshop";
Class.forName("com.mysql.jdbc.Driver");

String DB_URL="jdbc:mysql://localhost/ebookshop";
String USER = "cbio";
String PASS = "cbio";
conn = DriverManager.getConnection(DB_URL,USER,PASS);


*----------------------------------------------------------------------------------------------------
* simple tomcat servlet (28 jan 2015)
apache tomcat 7.0.52

intalled in /Library/Tomcat (28 mar 2014)
points to /usr/local/apache-tomcat-7.0.52/

start: /Library/Tomcat/bin/catalina.sh start
stop:  /Library/Tomcat/bin/catalina.sh stop

manager control panel at http://localhost:8080  (id/pw:  tomcat, tomcat) (mgr, mgr)?

need the servlet jar:
echo $CLASSPATH | tr ":" "\n" | grep servlet   # /Library/Tomcat/lib/servlet-api.jar

cd ~/s/examples/java/servlets/helloEarth
cat HelloEarth.java
import java.io.*;
import javax.servlet.*;
import javax.servlet.http.*;

public class HelloEarth extends HttpServlet {

public void doGet(HttpServletRequest request, HttpServletResponse response)
throws IOException, ServletException
{
response.setContentType("text/html");
PrintWriter out = response.getWriter();
out.println("<html>");
out.println("<head>");
out.println("<title>Hello Earth!</title>");
out.println("</head>");
out.println("<body>");
out.println("<h1>Hello Earth!</h1>");
out.println("</body>");
out.println("</html>");
}
}

--- deploy (without explicit jar)
ls -lR /Library/Tomcat/webapps/earth/
total 16
drwxr-xr-x  4 pshannon  staff  136 Jan 28 09:16 WEB-INF
-rw-r--r--  1 pshannon  staff  223 Jan 28 09:16 index.html

/Library/Tomcat/webapps/earth//WEB-INF:
total 8
drwxr-xr-x  3 pshannon  staff  102 Jan 28 08:58 classes
-rw-r--r--  1 pshannon  staff  292 Jan 28 09:16 web.xml

/Library/Tomcat/webapps/earth//WEB-INF/classes:
total 8
-rw-r--r--  1 pshannon  staff  867 Jan 28 08:58 HelloEarth.class

wombat.helloEarth> cat /Library/Tomcat/webapps/earth/WEB-INF/web.xml
<?xml version="1.0" encoding="UTF-8"?>
<web-app>
<servlet>
<servlet-name>HelloEarth</servlet-name>
<servlet-class>HelloEarth</servlet-class>
</servlet>
<servlet-mapping>
<servlet-name>HelloEarth</servlet-name>
<url-pattern>/hello</url-pattern>
</servlet-mapping>
</web-app>

# this provides a static web page launcher
wombat.helloEarth>  cat /Library/Tomcat/webapps/earth/index.html
<!DOCTYPE HTML><html lang="en">
<head>
<meta charset="UTF-8">
<title>earth launcher</title>
</head>
<body>
<p>
<h3>earth launcher</h3>
<p></p>
<ul>
<li><a href="hello">Earth</a>
</ul>
</body>
</html>

---- view/run
http://localhost:8080/earth/        # the static launcher at webapps/earth/index.html
http://localhost:8080/earth/hello   # run the servlet directly

*----------------------------------------------------------------------------------------------------
* rosto twist1, postn network ideas


twist1 regulates periostin expression (pmid 12210745)
bmp2 induces periostin expression
periostin binds integrins (21997759)
initiating cross-talk between integrins and RTKs (i.e. EGFR)
crosstalk activates Akt/PKB signaling pathway
FAK-mediated signaling pathway
Periostin secreted by epithelial ovarian carcinoma is a ligand for αVβ3 and αVβ5 integrins and promotes cell motility
Periostin-integrin interaction through FAS1 domain... (17616943)
tgf-b1 & FAK regulate postn expression (periodontal)
PI3K sigaling mediates postn exprssion (smooth muscle)(gbm)
wnt signaling?
postn activates integrin a5b1 via PI3K/AKT pathway (cholangiocarcinoma)
dna aptamer binds FAS1 domain of periostin, inhibits metastasis (brca)
Transduction of a mesenchyme-specific gene periostin into 293T cells induces cell invasive activity
through epithelial-mesenchymal transformation.  16702213  2006
The multifaceted role of periostin in tumorigenesis. 19308325  2009


Protein kinase B (PKB), also known as Akt, is a serine/threonine-specific protein kinase that
plays a key role in multiple cellular processes such as glucose metabolism, apoptosis, cell
proliferation, transcription and cell migration.


PKB/AKT phosphorylation of the transcription factor Twist-1 at Ser42 inhibits p53 activity in response to DNA damage
Phosphorylation of serine 68 of Twist1 by MAPKs stabilizes Twist1 protein and promotes breast cancer cell invasiveness
Redundant or separate entities?—roles of Twist1 and Twist2 as molecular switches during gene transcription
The involvement of Twist1 and Twist2 in a broad spectrum of regulatory pathways highlights the
importance of understanding their roles in normal development, homeostasis and disease. Here we
focus on the mechanistic models of transcriptional regulation and summarize the similarities
and differences between Twist1 and Twist2 in the context of myogenesis, osteogenesis, immune
system development and cancer.

postn "Enhances incorporation of BMP1 in the fibronectin matrix of connective tissues" genecards

3 InterPro protein domains:
IPR011489 EMI_domain
IPR016666 TGFb-ind_bIGH3/osteoblast_fac2
IPR000782 FAS1_domain


Structural characterization and interaction of periostin and bone morphogenetic protein for
regulation of collagen cross-linking. pmid 24858685

*----------------------------------------------------------------------------------------------------
* signaling network around periostin for bob rostomily (24 jan 2015)

cd ~/s/data/rosto/postn-try0/


--- Phosphoregulation of Twist1 provides a mechanism of cell fate control.
PMID: 18855684

Basic Helix-loop-Helix (bHLH) factors play a significant role in both development and
disease. bHLH factors function as protein dimers where two bHLH factors compose an active
transcriptional complex. In various species, the bHLH factor Twist has been shown to play
critical roles in diverse developmental systems such as mesoderm formation, neurogenesis,
myogenesis, and neural crest cell migration and differentiation. Pathologically, Twist1 is a
master regulator of epithelial-to-mesenchymal transition (EMT) and is causative of the
autosomal-dominant human disease Saethre Chotzen Syndrome (SCS). Given the wide spectrum of
Twist1 expression in the developing embryo and the diverse roles it plays within these forming
tissues, the question of how Twist1 fills some of these specific roles has been largely
unanswered. Recent work has shown that Twist's biological function can be regulated by its
partner choice within a given cell. Our work has identified a phosphoregulatory circuit where
phosphorylation of key residues within the bHLH domain alters partner affinities for Twist1;
and more recently, we show that the DNA binding affinity of the complexes that do form is
affected in a cis-element dependent manner. Such perturbations are complex as they not only
affect direct transcriptional programs of Twist1, but they indirectly affect the
transcriptional outcomes of any bHLH factor that can dimerize with Twist1. Thus, the resulting
lineage-restricted cell fate defects are a combination of loss-of-function and gain-of-function
events. Relating the observed phenotypes of defective Twist function with this complex
regulatory mechanism will add insight into our understanding of the critical functions of this
complex transcription factor.


--- Periostin expression and epithelial-mesenchymal transition in cancer: a review and an update.
has a pathway map obtained from "Signalling via integrins: Implications for cell survival and anticancer strategies"


Periostin, also called osteoblast-specific factor 2, is a secreted cell adhesion protein,
which shares a homology with the insect cell adhesion molecule fasciclin I.

Recent studies revealed that periostin plays an important role in
tumor development and is upregulated in a wide variety of cancers such as colon, pancreatic,
ovarian, breast, head and neck, thyroid, and gastric cancer as well as in
neuroblastoma.

Periostin binding to the integrins activates the Akt/PKB- and FAK-mediated
signaling pathways which lead to increased cell survival, angiogenesis, invasion, metastasis,
and importantly, epithelial-mesenchymal transition of carcinoma cells. I

--- integrins

Integrins are transmembrane receptors that are the bridges for cell-cell and cell-extracellular
matrix (ECM) interactions. When triggered, integrins in turn trigger chemical pathways to the
interior (signal transduction), such as the chemical composition and mechanical status of the
ECM, which results in a response (activation of transcription) such as regulation of the cell
cycle, cell shape, and/or motility; or new receptors being added to the cell membrane. This
allows rapid and flexible responses to events at the cell surface, for example to signal
platelets to initiate an interaction with coagulation factors.

Genes associated with EMT were regulated by TWIST1 in SNB19 and/or T98G GBM cells including
extracellular matrix proteins fibronectin 1 (FN1) [14], periostin (POSTN) [15] and SPARC [16-18]
protease MMP2 [19,20], transcription factor SNAI2 [21-23] transcriptional modifier ID1 [24], growth
factor HGF [21,25] lysyl oxidase (LOX) [26] and cell adhesion protein cadherin 11 (CDH11)
[27]. Other genes associated with mesenchymal phenotypes and glioma invasion, not yet formally
linked to EMT, included laminin, alpha 4 (LAMA4) [28] and fibroblast activation protein alpha (FAP)


--- from rosto's own paper, "TWIST1 promotes invasion through mesenchymal change in human glioblastoma" 2010

Individual genes upregulated by TWIST1 known to promote EMT and/or GBM invasion included SNAI2,
MMP2, HGF, FAP and FN1. Distinct from carcinoma EMT, TWIST1 did not generate an E- to N-cadherin
“switch” in GBM cell lines. The clinical relevance of putative TWIST target genes SNAI2 and
fibroblast activation protein alpha (FAP) identified in vitro was confirmed by their highly
correlated expression with TWIST1 in 39 human tumors. The potential therapeutic importance of
inhibiting TWIST1 was also shown through a decrease in cell invasion in vitro and growth of GBM stem
cells


--- The multifaceted role of periostin in tumorigenesis.

Periostin, also called osteoblast-specific factor 2 (OSF-2), is a member of the fasciclin
family and a disulfide-linked cell adhesion protein that has been shown to be expressed
preferentially in the periosteum and periodontal ligaments, where it acts as a critical
regulator of bone and tooth formation and maintenance. Furthermore, periostin plays an
important role in cardiac development. Recent clinical evidence has also revealed that
periostin is involved in the development of various tumors, such as breast, lung, colon,
pancreatic, and ovarian cancers. Periostin interacts with multiple cell-surface receptors, most
notably integrins, and signals mainly via the PI3-K/Akt and other pathways to promote cancer
cell survival, epithelial-mesenchymal transition (EMT), invasion, and metastasis. In this
review, aspects related to the function of periostin in tumorigenesis are summarized.



--- got cytoscape session file from "Construction of human activity-based phosphorylation networks"
pmid: 23549483
http://www.ncbi.nlm.nih.gov/pmc/articles/PMC3658267/#S1
exported to network/x.sif

--- email (21 jan 2015)

If your analysis shows any evidence for potential diversity in POSTN regulated signaling then it
would be helpful.  In this R01 we are essentially trying to build a model of the cellular and
molecular networks or niche through which POSTN regulates malignancy in gliomas.  Therefore any
data related to specific cell types or contexts in which POSTN activates different pathways or
phenotypes would be very helpful.

---

I am in the final stages of putting together the POSTN R01 and wondered if you had a chance yet
to run it through oncoscape?  The current grant will seek to idnetify "non-canonical" signaling
pathways in GBM stem cells using RNAseq and phosphoproteomics.  We have not yet been able to
directly test for these so it would be great if something turned up in your analysis that would
support their relevance.


from meeting in atrium with bob:
twist regulates postn, p53, and master regulator of EMT
build out network starting from twist & postn

--- email sent (19 dec 2014)


Just a quick checkin to make sure that what I gleaned from our meeting, and what I will work on, is indeed what you want.

From my notes:  curate a web-viewable network centered on periostin and twist, capturing as many relevant mechanistic relations as possible.  Allow for update and further curation.  Overlay patient data upon this network.

Close?  Set me straight as needed.

To give you a sense of how I will do this, please see this 1m48sec youtube video. Unfortunately, I couldn't get the audio to work, so I'll add a few notes below:

https://www.youtube.com/watch?v=BOVeziKtYYI&feature=youtube_gdata_player

Am I barking up the right tree?

Cheers!

- Paul


video notes:

1) starts with a view of the Oncoscape welcome page
(you can replicate the steps in the video by browsing to
http://oncoscape.sttrcancer.org)

2) shows a tabular view of clinical data from 325 TCGA GBM patients

3) shows a graphical view of that data.   colors indicate events: birth, diagnosis, recurrence, chemo, radiation, death.

4) align all patients by diagnosis (brown dots now all vertically aligned)

5) sort patients by time to first progression

6) select 3 patients with the shortest times to first progression

7) view these 3 patients in the tabular clinical data view

8) click back to the timelines view, send these 3 patients to the angiogenesis tb

9) render the network, one patient at a time, with expression & copynumber data
red nodes: over-expression
green: under-expression
blue node border: copy number gain (gistic score of 1 or 2, but only '1' found here)
black node border: copy number loss (gistic score of -1)

10) turn on abstract viewing ("enable abstracts")

11) click on lines connecting nodes, read pubmed abstract documenting the relationship

Note (importantly!) that though these three patients are, in a small
way at least, phenotypically similar, they seem to share no
hypoxia-signaling expression or copy number signature.  We'd be
surprised to see that: too simple! Upcoming versions of oncoscape will
have statistical tools to find patients with similar molecular
signatures, correlated (or not) to phenotype -- finding sometimes
subtle similarities and differences among patients, connecting them to
clinical features and possible treatments when possible.


*----------------------------------------------------------------------------------------------------
* the StudyData package, email to Lisa (23 jan 2015)

I have been focusing on the molecular data, but just reviewed what we came up with last summer -- which was the "multi-flat" event list.

There is a working (it should still work) example of this in

hbolouri/oncoDev/Oncoscape/inst/explorations/tcgaPatientHistoryToEventList/go.R

where tsv files dumped out of a database are read, parsed, and compiled into a single big list of events:

dob.events <- lapply(patient.ids, function(id) create.DOB.record(id))
chemo.events <- create.all.Chemo.records(patient.ids)
diagnosis.events <- lapply(patient.ids, create.Diagnosis.record)
status.events <- lapply(patient.ids, create.status.record)
progression.events <- create.all.Progression.records(patient.ids)
radiation.events <- create.all.Radiation.records(patient.ids)

events <- append(dob.events, chemo.events)
events <- append(events, diagnosis.events)
events <- append(events, status.events)
events <- append(events, progression.events)
events <- append(events, radiation.events)

We save this to an RData file, and then (I believe) parse it into a clinical table compatible format, and into the timelines.   Make sure I am right!

The data package scheme, in my current thinking, consists of one package for every "study" -- where a study may be as large as TCGA GBM, or as small as some mouse experiment out of Eric's lab.

Each package has only two kinds of formatted data:

1) matrix data, where the rownames are "entities" and the colnames are "features"
A gene expression matrix, patients x genes, is a classic example

2) event list (or multi-flat) data

To create a new data package, we need to transform input data into one of the other standard format.

Each data package also has a manifest which will look something like this:

shortName:  cn
longName:  gistic copy number for MSK GBM patients
format:  matrix
#ofentities:  300
entity title: samples, patientIDs
#of features: 1200
feature title: genes, Hugo symbols
underlying data type:  integer
data range:  -2:2, NA for missing values
comments:  transformed from array CGH, code found <here>, from file "xxxx" downloaded 16 oct 2014

shortName: pt timelines
longName: caisis event data on 300 MSK GBM patients
format: eventList (aka, "multi-flat")
#of entities: 300
entity title: patients
# of features: 10-80 events per patient
feature title: various clinical events
underlying data type: heterogeneous
data range: mixed
comments:  parsed from mysql database "xxx.db" downloaded from "zzzz" on 20 oct 2014

The data package base class, let's call it StudyData, has a slot for the manifest (itself a data.frame with all of the above colunns, e.g., "shortName", "longName"), and a slot for a list of matrix data, and another slot for a list of multi-flat.  Each package will implement some of its own custom transformations.   One we need will convert from the multi-flat data into a hetergenous data structure suitable for import into the clinical data table tab.

One good thing to include from the start (maybe Eric's lab can help with this) is an eventList example with just mouse laboratory time line data.   This will be very different in content from a patient caisis record, but it performs a similar role:  a history of what had been done to, and what responses were seen, all of which we want to explore in conjunction with the molecular data.

If you buy that, then one of our early data pacakges (one of our early StudyData subclasses) will have all "clinical" and molecular data from a mouse experiment.

Can
*----------------------------------------------------------------------------------------------------
* mysql/java/jdbc cbio: get a small program working (26 jan 2015)

cd ~/cbio/javaDemo
make

--- the working code
import java.sql.*;

public class JdbcSelectTest {
public static void main(String[] args) {
String dbURI = "jdbc:mysql://localhost/ebookshop";
String user = "cbio";
String password = "cbio";
try (
Connection conn = DriverManager.getConnection(dbURI, user, password); // MySQL
Statement stmt = conn.createStatement();
) {
String strSelect = "select title, price, qty from books";
System.out.println("The SQL query is: " + strSelect); // Echo For debugging
System.out.println();
ResultSetos
from crontest.py (via email):

...F..
======================================================================
FAIL: test_6conditions (__main__.MicroarrayResultSetTestCase)
----------------------------------------------------------------------
Traceback (most recent call last):
File "MicroarrayResultSetTest.py", line 188, in test_6conditions
assert (conditions       == ['sham', 'saline', 'CLP+ABX', 'CLP', 'LPS', 'minor'])
AssertionError

----------------------------------------------------------------------
Ran 6 tests in 4.718s

FAILED (failures=1)
testCreateMatrixNoArgs
['NULL_vs_MDP', 'RAW_NULL_vs_RAW_LPS']
['log10_ratio', 'lambda']
rows: 11
cols: 3
testOldCreateMatrixExplicitArgs
testOldCreateMatrixNoArgs
test_6conditions
test_1condition
testHaloResultSets

*--------------------------------------------------------------------------------
* nat goodman reports discrepancy between his go trees and mine, cont (03 nov 2004)
on trickster,
cd /Users/mpshannon/data/natGoodmanGoAnnotationBug
make
browse annotation
*--------------------------------------------------------------------------------
* nat goodman reports discrepancy between his go trees and mine (30 oct 2004)
cd /users/pshannon/data/go/natGoodmanBug
choosing one path at random from nat's
GO:0001835	2, 3, 7
GO:0008150, GO:0007275, GO:0001824, GO:0009790, GO:0009792,
GO:0043009, GO:0001701	process
stategy:  use my old tools, see what path i come up with for this leaf

http://www.godatabase.org/dev/database/archive/latest/go_200409-termdb.xml.gz
gunzip
/tools/bin/python /users/pshannon/data/import/go/parseGoTermsToFlatFile.py \
go_200409-termdb.xml   > go_200409-termdb.txt
no [isa: x0 x1 x2] elements appeard at the end of the line.
apparently, the xml has changed.  to check this:
cp -p  /users/pshannon/data/import/go/yeast/2003.05.15/go_200305-termdb.xml .
now have
13790988 May 15  2003 go_200305-termdb.xml
19850439 Oct 30 10:27 go_200409-termdb.xml
the xml change may be limited to
old style (go_200305-termdb.xml):
<go:term rdf:about="http://www.geneontology.org/go#GO:0000083" n_associations="0">
<go:accession>GO:0000083</go:accession>
<go:name>G1/S-specific transcription in mitotic cell cycle</go:name>
<go:part-of rdf:resource="http://www.geneontology.org/go#GO:0000082" />
<go:isa rdf:resource="http://www.geneontology.org/go#GO:0006357" />
</go:term>

new style (go_200409-termdb.xml)
<go:term rdf:about="http://www.geneontology.org/go#GO:0000083" n_associations="0">
<go:accession>GO:0000083</go:accession>
<go:name>G1/S-specific transcription in mitotic cell cycle</go:name>
<go:definition>Any process that regulates transcription such that the target genes are transcribed during the G1/S phase of the mitotic cell cycle.</go:definition>
<go:part_of rdf:resource="http://www.geneontology.org/go#GO:0000082" />
<go:is_a rdf:resource="http://www.geneontology.org/go#GO:0006357" />
<go:dbxref rdf:parseType="Resource">
<go:database_symbol>Reactome</go:database_symbol>
<go:reference>69205</go:reference>
</go:dbxref>
</go:term>


in /users/pshannon/data/go/natGoodmanBug, cp /users/pshannon/data/import/go/parseGoTermsToFlatFile.py .
made these changes:
regex3 = '<go:is_a\s*rdf:resource="http://www.geneontology.org/go#GO:(.*?)"\s*/>'
cregex3 = re.compile (regex3, re.DOTALL)

regex4 = '<go:part_of\s*rdf:resource="http://www.geneontology.org/go#GO:(.*?)"\s*/>'
cregex4 = re.compile (regex4, re.DOTALL)
now re-rerun:
/tools/bin/python parseGoTermsToFlatFile.py  go_200409-termdb.xml   > go_200409-termdb.txt
head go_200409-termdb.txt:
(curator=GO) (type=all)
0000001 = mitochondrion inheritance [isa: 0048308 0048311 ]
0048308 = organelle inheritance [isa: 0006996 ]
0048311 = mitochondrion distribution [isa: 0007005 ]
0000002 = mitochondrial genome maintenance [isa: 0007005 ]
0007005 = mitochondrion organization and biogenesis [isa: 0006996 ]
0000003 = reproduction [isa: 0007275 ]
0007275 = development [isa: 0008150 ]
0000004 = biological_process unknown [isa: 0008150 ]
0008150 = biological_process

now, directly compare nat's
GO:0001835	2, 3, 7
GO:0008150, GO:0007275, GO:0001824, GO:0009790, GO:0009792,
GO:0043009, GO:0001701	process
which i take to mean
1835

my version:
0001835 = blastocyst hatching [isa: 0007275 ] [partof: 0001824 ]
0007275 = development [isa: 0008150 ]
0008150 = biological_process

0001824 = blastocyst development [isa: 0007275 ] [partof: 0001701 ]
0001701 = embryonic development (sensu Mammalia) [isa: 0043009 ]
0043009 = embryonic development (sensu Vertebrata) [isa: 0009792 ]
0009792 = embryonic development (sensu Animalia) [isa: 0009790 ]
0009790 = embryonic development [isa: 0007275 ]
0007275 = development [isa: 0008150 ]
0008150 = biological_process


here's the acutal mail I sent:
To: natg@shore.net
In-reply-to: <auto-000004714548@systemsbiology.org> (natg@shore.net)
Subject: Re: GO annotations
BCC: pshannon@systemsbiology.org
References:  <auto-000004714548@systemsbiology.org>
--text follows this line--
Hi Nat,

I don't think I have the answer on this yet, but I do have a little
info, which I'll briefly present below.  Then let's figure out what I
can do next to track this down.

I started my sleuthing by choosing one GO leaf term from go_level.goslim_yeast.out:

GO:0005740    2, 3    GO:0005575, GO:0016020, GO:0005739, GO:0005737  component

goslim_yeast.obo says of this term:

[Term]
id: GO:0005740
name: mitochondrial membrane
namespace: component
def: "The lipid bilayer surrounding the mitochondrion and separating its contents
from the cell cytoplasm." [GO:ai]
subset: goslim_yeast
relationship: part_of GO:0005739
is_a: GO:0016020


Here's what I get with my parsing of go_200409-termdb.xml:

0005740 = mitochondrial membrane [isa: 0016020 ] [partof: 0005739 ]
0016020 = membrane  [partof: 0005623 ]
0005623 = cell [isa: 0005575 ]
0005575 = cellular_component

0005740 = mitochondrial membrane [isa: 0016020 ] [partof: 0005739 ]
0005739 = mitochondrion  [partof: 0005737 ]
0005737 = cytoplasm  [partof: 0005622 ]
0005622 = intracellular  [partof: 0005623 ]
0005623 = cell [isa: 0005575 ]
0005575 = cellular_component

These two results (go slim, and mine) don't conflict; am I working on
the right problem?

I will have to do further checks to be sure that these two paths (from 5740 to 5575)
show up properly in the the cytoscape annotation browser, but I think
it best to check in with you first:  Am I (so to speak) barking up the
the right tree?

- Paul

*--------------------------------------------------------------------------------
* get yeast go annotation into flat files, loading into rmi server on db (06 mar 2003)

---------------- GET INTO THE RIGHT DIRECTORY FOR IMPORTING DATA

cd ~/data/import/go/yeast/yyyy.mm.dd

---------------- GET THE DATA (3 files)

ftp ftp.geneontology.org   (for the ontology in xml, and yeast annotation)

cd pub/go/xml
bin; hash; get go_yyyyMM-termdb.xml.gz    (about 700K)
cd ../gene-associations
get gene_association.sgd                  (about 3.3M)


---------------- PREPARE THE DATA (3 files -> 5 files)

gunzip go_yyyyMM-termdb.xml.gz
../../parseGoTermsToFlatFile.py go_200302-termdb.xml > goTerms.txt  (13k terms)
../../parseAssignmentsToFlatFile.py gene_association.sgd 'Saccharomyces cerevisiae'
(creates bioproc.txt, molfunc.txt, cellcomp.txt)
*--------------------------------------------------------------------------------
* next up with MetaDataNavigatorTest (29 oct 2004)
on trickster:
/users/pshannon/gaggle-fromCvsUCSD2/csplugins/isb/pshannon/experiment/metadata/unitTests
(cd ..; make) && make 4
*--------------------------------------------------------------------------------
* TreeDataBrowser/MetaDataNavigator bug (29 oct 2004)
when perturbation strings include:

<predicate category='perturbation' value='genetic:knockout:phr1'/>
<predicate category='perturbation' value='genetic:knockout:phr1_and_phr2'/>

then the test for matching (given a selection from the jtree)
gets confused on the partial match evident here.  Fix!

*--------------------------------------------------------------------------------
* new plan:  create a big R object from all microarray data (30 oct 2004)
used data matrix browser to combine all the irradiation experiments:

irradiation:gamma
irradiation:sunlight:circadian:dark1,dark2,light2
irradiation:uv

export both lambdas & ratios to files, copy from trickster to
db:~/data/halo/microarrayXml/checkAgainstRichsDataOct2004/
start R
ratios = read.table ("irradiation.ratio", row.names=1, header=T, sep="\t")
lambdas = read.table ("irradiation.lambda", row.names=1, header=T, sep="\t")
quick check:
rownames (lambdas) [2300] ->  "VNG6293C"
rownames (ratios) [2300]  ->  "VNG6293C"

*--------------------------------------------------------------------------------
* check newly rationalized data  against rich's R version, cont (28 oct 2004)
cd ~/data/halo/microarrayXml/checkAgainstRichsDataOct2004/
jython
execfile ('extract.py')
runs method
x = compareFeso4 (columnTitleMap, rowTitleMap, rats,
'/users/pshannon/tomcat/server1/webapps/halo/data/feso4.ratio')

which right now returns a hash of columns of hashes (keyed by vng gene name)
next up:
compareFeso4 calls 'getRColumn' for every column
create something to read in the new ratios file -- maybe datamatrixreader?
then compare row by row, in each column
*--------------------------------------------------------------------------------
* check newly rationalized microarray data against rich's R version (28 oct 2004)
my data (that displayed in Condition Chooser):
/users/pshannon/tomcat/server1/webapps/halo/data
rich's data
in /users/pshannon/data/halo/microarrayXml/checkAgainstRichsDataOct2004
3485555 Oct 28 13:01 RatiosInf_10-2004.RData

using jython/RServe tricks figured out in august, see below
"reading new bicluster data into python objects, via jython & rserve (2 aug 2004)"
want to get the ratios from this object (see Rich's comments just below)
cp /users/pshannon/data/halo/biclusters/2004.08.26/explore.py .
jython -i explore.py
[x for x in r.eval ('dim (ratios)').getContent ()] -> [2409, 142]
rats = r.eval ('ratios').asDoubleMatrix ()
len (rats) --> 2409
len (rats [0]) --> 142
cnames = [x.getContent () for x in r.eval ('colnames (ratios)').getContent()]
cnames [:3] -> ['C60.rat', 'D30.rat', 'D60.rat']
rnames = [x.getContent () for x in r.eval ('rownames (ratios)').getContent()]
rnames [:3] -> ['o2', 'light', 'uv']
for i in range (len (rnames)):
x = rnames [i]
if (x.lower() == 'vng0001h'):
print i
--> 1574
find the column for feso4__0000m_vs_NRC-1 (the name now seen in the data matrxi browser)

[c for c in cnames if c.lower().count('feso') > 0]#target = -0.11

['FeSO4_.1_vs_NRC.1', 'FeSO4_0_vs_NRC.1', 'FeSO4_5_vs_NRC.1b', 'FeSO4_10_vs_NRC.1b',
'FeSO4_15_vs_NRC.1b', 'FeSO4_20_vs_NRC.1', 'FeSO4_25_vs_NRC.1b', 'FeSO4_40_vs_NRC.1',
'FeSO4_80_vs_NRC.1', 'FeSO4_160_vs_NRC.1', 'FeSO4_320_vs_NRC.1']

vng0001values = rats [1574]
could not find any of these values in the 40 (or so) microarray experiments
that mentioned vng0001h.  talked to rich.  he said these values are normalized,
0-to-1.  rich gives me new data: ratiosLambdas-10-28.RData

*--------------------------------------------------------------------------------
* rich's comments accompanying RatiosInf_10-2004.RData (28 oct 2004)

in prep/ for the "BIG RUN" here is the RData that has the ratios matrix
in it as
well as the lambdas matrix.

to get this up in R: load("RatiosInf....Rdata")

a few things to note:
the dimensions are not the same on the two matricies:
ratios has more rows, which are environment rows,
these environment rows are present for the inferelator
and the evolvolator but not for the biclusterererrer.

see a R excerpt:
> dim(ratios)
[1] 2409  142
> dim(lambdas)
[1] 2399  142
> colnames(ratios)[1:20]
[1] "C60.rat" "D30.rat" "D60.rat" "L30.rat" "L60.rat" "X1"      "X2"
[8] "X3"      "X4"      "X5"      "X6"      "X7"      "X8"      "X9"
[15] "X10"     "X11"     "X12"     "X13"     "X14"     "X15"
> rownames(ratios)[1:20]
[1] "o2"       "light"    "uv"       "gama"     "temp"     "sal"
[7] "Fe"       "Mn"       "Zn"       "Cu"       "VNG6413h" "VNG2396g"
[13] "VNG2276g" "VNG6430c" "VNG2240g" "VNG2406c" "VNG2135g" "VNG2285c"
[19] "VNG2249g" "VNG2416g"


so you can see that a row in the "ratios" mat has the name o2 and is
the O2 concentration
as best we know it for each experiemnt. You can also see that I
missspelled gamma.

*--------------------------------------------------------------------------------
* all column titles for all halo microarray data rationalized (27 oct 2004)
/users/pshannon/tomcat/server1/webapps/halo/data
everything (xml, ratio, lambda) under RCS control
mj loading into sbeams
next:  cross check these data with rich's R matrix, attached to email sent
26 oct 2004
*--------------------------------------------------------------------------------
* bicluster/inferelator prep (26 oct 2004)
cd /users/pshannon/tomcat/server1/webapps/halo/data
grep alias *.xml  > ~/data/halo/experiments/conditionNames/raw
study these names, prepare final set
*--------------------------------------------------------------------------------
* protein structure url's broken from keggwbi system (25 oct 2004)
simple & diagnostic (but not critical) example:
two images  should appear in the top left of the ProteinStructure page you get after
clicking on node 2.7.1.2 on this page
http://db.systemsbiology.net/cytoscape/keggwbi-hm?mode=rewriteForBrowsing&keggUrl=\
http://www.genome.ad.jp/kegg-bin/mark_pathway_www?17516/hal00010.args   1.1.1.1
1.1.1.27
1.2.1.3
1.2.1.12
1.2.4.1
1.8.1.4
2.3.1.12
2.7.1.1
2.7.1.2
2.7.1.11
2.7.1.40
but these images do not appear when running from outside the ISB
looking at the page source, the url's are
see http://db.systemsbiology.net/cytoscape/projects/dynamic/keggwbi/halo/tests/
diagnosis:
relative url's are in the page, and the implicit base is that server from which
the page came, in this case, http://db.systemsbiology.net
two fixes seem possible:

1) in the <head> element, add a base element:
<BASE href="https://db.systemsbiology.net">
see example in db:/local/tomcat/webapps/cytoscape/projects/dynamic/keggwbi/halo/tests
ec5139-https.html:        <BASE href="https://db.systemsbiology.net">
2) better yet, is to modify all of the url's rewritten in
/local/tomcat/webapps/cytoscape/projects/dynamic/keggwbi/halo/KeggRewriter.py, line 100,
method: fixImageMapTags (text, modeString):
enzymeUrlReplacement = \
'https://db.systemsbiology.net/cytoscape/keggwbi-hm?mode=%s&ec=' % modeString
this makes each of the image map url's go through the https server, allowing
access to everything to which the login permits.
remaining question:  can we set this project so that is read-only open to
people browsing without logins?


*--------------------------------------------------------------------------------
* make an index page for  haloarcula/halo rewritten kegg maps, KeggRewriter.py (23 oct 2004)
a daily crontab creates a fresh web page.

04 04 * * * (cd /local/tomcat/webapps/cytoscape/projects/dynamic/keggwbi/halo;/tools/bin/python createStaticBrowsingList.py > static.html)
04 34 * * * (cd /local/tomcat/webapps/cytoscape/projects/dynamic/keggwbi/halo;/tools/bin/python checkStaticBrowsingList.py)

not only does this daily recreation
ensure the latest info from KEGG, it also ensures that the cached image maps
in static.html are present when asked for.  i don't know how often kegg clears
their cache, but daily recreation seems to be enough.

*--------------------------------------------------------------------------------
* tracking down the KeggRewriter bug (23 oct 2004)
the cause turned out to be an invalid 'static.html', produced from this line
in /local/tomcat/webapps/cytoscape/crontests/crontab
04 04 * * * (cd /local/tomcat/webapps/cytoscape/projects/dynamic/keggwbi/halo;/tools/bin/python createStaticBrowsingList.py > static.html)

reproduce the servlet error by

http://db.systemsbiology.net/cytoscape/projects/dynamic/keggwbi/halo/static.html
http://www.genome.ad.jp/kegg-bin/mark_pathway_www?25743/hal00010.args

to reproduce this de novo,

1) http://www.genome.jp/kegg-bin/mk_point_html
2) Search against: Halobacterium sp. NRC-1
3) paste these ec numbers into the text box
1.1.1.1
1.1.1.27
1.2.1.3
1.2.1.12
1.2.4.1
1.8.1.4
2.3.1.12
2.7.1.1
2.7.1.2
2.7.1.11
2.7.1.40
2.7.1.69
4) press the 'Exec button'

*--------------------------------------------------------------------------------
* nitin's kegg rewriter bug report (23 oct 2004)
Hi Paul-

I am back from Greece!  I woke up at 3:30am this morning and have ben
wide awake for the last one hour.  I was checking the KEGG rewriter
for Haloarcula and ran into an error.  When I click on a pathway name
to view the pathway map I get this error message:

Traceback (most recent call last): constructing KeggRewriter with url:
http://www.genome.ad.jp/kegg-bin/mark_pathway_www?25743/hal00020.args
File
"/local/tomcat/webapps/cytoscape/projects/dynamic/keggwbi/halo/KeggRewriter.py",
line 50, in __init__ self.html2 = replaceImageMap (self.text,
self.referencePathwayImageMap) File
"/local/tomcat/webapps/cytoscape/projects/dynamic/keggwbi/halo/KeggRewriter.py",
line 164, in replaceImageMap assert (start >= 0) AssertionError

I will see you on Monday.  It feels good to be back.
Nitin

*--------------------------------------------------------------------------------
* saturday todo (22 oct 2004)
/users/pshannon/gaggle/csplugins/isb/pshannon/experiment/datamatrix/unitTests
-- continue converting MatrixCombinerTest
-- try to convert TreeDataBrowser.py to use these new java classes
*--------------------------------------------------------------------------------
* wednesday eve todo: (20 oct 2004)

figure out why all rows in browser are selected from actions/CorrelationFinderDialog.java

this is due to muddy semantics on the LensedDataMatrix.  the class and unit
test are now a little cleaner, but study

datamatrix/*.java and their unit tests until they are just right
keeping in mind the need of the correlation finder to:
obtain the currently selected rows, *and*
obtain all the rows in the underlying matrix
(since correlation is sought between those rows selected in the browser,
and those in the whole matrix.)   maybe the JTable selection should not
(always?) be passed to the lens, but should be stored separately, with
the matrix, and only optionally used to form a lens?

/users/pshannon/gaggle/csplugins/isb/pshannon/experiment/gui
with this classpath:
.
/users/pshannon/gaggle
/users/pshannon/cy2
/users/pshannon/cy/cytoscape/build/classes
/users/pshannon/jars/jython.jar
/users/pshannon/jars/junit.jar
/users/pshannon/jars/jdom.jar
/users/pshannon/jars/spyconsole.jar
/users/pshannon/jars/jfreechart.jar
/users/pshannon/jars/jcommon.jar
/users/pshannon/jars/y.jar
/users/pshannon/jars/getopt-1.0.8.jar
/users/pshannon/jars/jnlp.jar
/users/pshannon/jars/JRclient-RE321.jar
/users/pshannon/jars/jnlp.jar
/users/pshannon/jars/jython-lib.jar
/users/pshannon/jars/tspaces/tspaces_fixes.jar
/users/pshannon/jars/tspaces/tspaces.jar
/users/pshannon/jars/tspaces/tspaces_client.jar
scripts.jar

*--------------------------------------------------------------------------------
* re-establishing cvs access to ucsd (20 oct 2004)
ssh pshannon@bordeaux.ucsd.edu   (password sunny_day)
[pshannon@bordeaux pshannon]$ /usr/local/sbin/cvsd-passwd /common/cvsdir4 +pshannon
pw: sunny_day
pw: sunny_day
logout
cvs -d :pserver:pshannon@bordeaux.ucsd.edu:/common/cvsdir4 login  (pw: sunny_day)

then checkout the csplugins/trial package
cd ~/cy/cpslugins
cvs -d :pserver:pshannon@bordeaux.ucsd.edu:/common/cvsdir4 up -d trial

------------------------
| or, as summarized for dreiss:
First you need to ssh into bordeaux and create a cvs password:

ssh pshannon@bordeaux.ucsd.edu   (password sunny_day)
[pshannon@bordeaux pshannon]$ /usr/local/sbin/cvsd-passwd /common/cvsdir4 +pshannon
pw:
pw:
logout

now all of the cvs commands are avaialable (login, status, update, checkout, ...)
as long as you specify the root (accomplished below with the -d switch; CVSROOT
ought to work also):

cvs -d :pserver:pshannon@bordeaux.ucsd.edu:/common/cvsdir4 login

*--------------------------------------------------------------------------------
* install fetchmail on trickster (22 oct 2004)
cd /Users/mpshannon/src/fetchmail-6.2.5
./configure
make  [failed!]
gcc -DHAVE_CONFIG_H  -DLOCALEDIR=\"/usr/local/share/locale\" -c  -I. -I. -I./intl -I./intl \
-O rcfile_y.c
In file included from ./rcfile_y.y:30:
i18n.h:8:21: libintl.h: No such file or directory
google 'macos libintl.h' found  http://lists.gnu.org/archive/html/gcl-devel/2004-07/msg00062.html

I got my copy of 'libintl.h' from the program 'fink' (available at
'fink.sourceforge.net'.) It appears to be available as part of the
'gettext' package.

try this:
fink install gettext  -> No packages to install.
then this:
fink list gettext
i   gettext       0.10.40-17   Message localization support
i   gettext-bin   0.10.40-17   Executables for gettext package
i   gettext-dev   0.10.40-17   Developer files for gettext package
suggesting that libintl.h -is- present, but not in the include path used by gcc above
indeed it is (from the Finder): 4397 13 Nov  2003 /sw/include/libintl.h
tried this, but it didn't work:
./configure --with-included-gettext=/sw/include

then tried simple modification of gcc command:
this:
gcc -DHAVE_CONFIG_H  -DLOCALEDIR=\"/usr/local/share/locale\" -c  -I. -I. -I./intl -I./intl \
became this:
gcc -DHAVE_CONFIG_H -c -I/sw/include -I. -I./intl -I./intl -O rcfile_y.c

no /usr/local/share/locale on trickster
changed one line in Makefile (automatically generated from Makefile.in)
.c.o:
#	$(CC) $(defines) -c $(CPFLAGS) -I. -I$(srcdir) -I$(top_builddir)/intl\
-I$(top_srcdir)/intl $(CEFLAGS) $(CFLAGS) $<
$(CC) $(defines) -c $(CPFLAGS) -I. -I$(srcdir) -I$(top_builddir)/intl \
-I/sw/include $(CEFLAGS) $(CFLAGS) $<

next error:
gcc -DHAVE_CONFIG_H  -DLOCALEDIR=\"/usr/local/share/locale\" -c  -I. -I. \
-I./intl -I/sw/include  -O odmr.c
In file included from odmr.c:30:
fetchmail.h:465: error: conflicting types for `lock_release'
/usr/include/mach/lock_set.h:67: error: previous declaration of `lock_release'
left it there for now (22 oct 2004)

*--------------------------------------------------------------------------------
* install fetchmail on db (atlas) (20 oct 2004)
new db has no fetchmail
got fetchmail-6.2.5.tar.gz from http://catb.org/~esr/fetchmail/
build in /users/pshannon/src/fetchmail/fetchmail-6.2.5
./configure --prefix=/users/pshannon --with-ssl
make
make install
wrote to these directories:
./man/man1
./bin
./share

fetchmail -d 10 -k --ssl   (-d 10:  run daemon every 10 seconds)
(-k: save new messages after retrieval)
*--------------------------------------------------------------------------------
* from dan: get the latest dataCube code (19 oct 2004)
OK, I checked in the package
$cvsdir4:/csplugins/trial/pshannon/dataCube
and all subpackages. There may or may not be external dependencies
that I forgot to check in.

You will also need csplugins.isb.dtenenbaum.speciesGuesser

Let me know if there's anything else it complains about.....
*--------------------------------------------------------------------------------
* restart atlas:8080 tomcat (19 oct 2004)
source ~/bin/setup-atlast-tomcat-8080-environment
cd
export JAVA_HOME=/usr/java/jdk1.5
export PATH=$PATH:$JAVA_HOME/bin:$JAVA_HOME/jre/bin
export TOMCAT_HOME=/local/tomcat/jakarta-tomcat
/local/tomcat/jakarta-tomcat/bin/startup.sh
or
/local/tomcat/jakarta-tomcat/bin/catalina.sh
*--------------------------------------------------------------------------------
* javadoc 'make doc' good example (19 oct 2004)
/users/pshannon/gaggle/csplugins/isb/pshannon/experiment
javadoc -source 1.4 \
-d ./htdocs\
-overview ./overview.html \
-sourcepath ../../../.. \
csplugins.isb.pshannon.experiment \
csplugins.isb.pshannon.experiment.unitTests \
csplugins.isb.pshannon.experiment.metadata \
csplugins.isb.pshannon.experiment.metadata.unitTests \
csplugins.isb.pshannon.experiment.datamatrix \
csplugins.isb.pshannon.experiment.datamatrix.unitTests \
csplugins.isb.pshannon.experiment.readers \
csplugins.isb.pshannon.experiment.readers.unitTests \
-windowtitle Experiment \
-doctitle "Experiment"

*--------------------------------------------------------------------------------
* db move from db01 to atlas, where are the tomcats? (19 oct 2004)

---  httpIndirect experiment repository:
/local/tomcat/webapps/cytoscape/jyserv/DataFetcher.py
http://db:8080/halo/DataFetcher.py?debug
http://db.systemsbiology.net:8080/halo/DataFetcher.py?debug
and reads data from:
/users/pshannon/halo/data

--- httpDirect experiment repository
http://db:8060/halo/data/unitTests
/local/tomcat/jakarta-tomcat/tomcat-halo/conf/server.xml maps db:8060/halo to
/users/pshannon/tomcat/server1/webapps/halo
*--------------------------------------------------------------------------------
* monday night todo (18 oct)
cd /users/pshannon/gaggle/csplugins/isb/pshannon/experiment/unitTests
(cd ..; make) && make 0
make sure fetcher can get metadata & data.  try passwords.
*--------------------------------------------------------------------------------
* friday todo (15 oct 2004) continue with testing MetaData.java
cd /users/pshannon/gaggle/csplugins/isb/pshannon/datamatrix/metadata/unitTests
(cd ..; make) && make 3

*--------------------------------------------------------------------------------
* jocelyne diruggiero's email: jd92@umail.umd.edu (13 oct 2004)
UV and gamma data
*--------------------------------------------------------------------------------
* set up password protected httpIndirect halo data server on db (13 oct 2004)

<Context path="/jyserv"
docBase="/Users/mpshannon/tomcat/pauls-webapps/jyserv"
debug="3"
reloadable="true">
</Context>

in WEB-INF/web.xml:

<web-app>

<display-name>experimental jython servlets: ~/tomcat/pauls-webapps/jyserv </display-name>
<description> jython-scripted servlets.</description>

<servlet>
<servlet-name>PyServlet</servlet-name>
<servlet-class>org.python.util.PyServlet</servlet-class>
<init-param>
<param-name>python.home</param-name>
<param-value>/users/pshannon/jython-2.1</param-value>
</init-param>

</servlet>

<servlet-mapping>
<servlet-name>PyServlet</servlet-name>
<url-pattern>*.py</url-pattern>
</servlet-mapping>

</web-app>

*--------------------------------------------------------------------------------
* summary of changes required by httpIndirect file reading (13 oct 2004)
for cy/csplugins/isb/pshannon/experimentNavigation-new/TreeDataBrowser.py
occasioned by jocelyn's (u md) need to have access to our data over the net

/users/pshannon/cy/csplugins/trial/pshannon/newDataCube/TextHttpIndirectFileReader.java
mediates contact to this server.  it has these public methods:

TextHttpIndirectFileReader (String URI) throws Exception
TextHttpIndirectFileReader (String URI, String user, String password) throws Exception
String getAdjustedUri ()
int read () throws Exception
String getText ()

TreeDataBrowser.py (in ~/cy/csplugins/isb/pshannon/experimentNavigator-new)
1) imports
from csplugins.trial.pshannon.newDataCube import *
from csplugins.trial.pshannon.newDataCube.browsers import *

sys.path.append ('../dataMatrix/metadata')
from MatrixSlicer import *
from MatrixCombiner import *
from MetaDataFetcher import *
from MetaDataNavigator import *

1) creates a MetaDataNavigator (repository) where repository can be

'file:///users/pshannon/data/halo/microarrayXml/tbpTfbKnockout'
'http://db:8060/halo/data/'
'httpIndirect://trickster:8080/jyserv/haloDataFetcher.py'


2) which uses MetaDataFetcher (and the three types of textfile readers) to

def getXmlFilesList (self):
def getWebPage (self, uri):

def readXmlFilenames (self):
def httpGetXmlFilenames (self):
def httpIndirectGetXmlFilenames (self):
def fileSystemGetXmlFilenames (self):
def getXmlFileContents (self, filename):

3) the actual data files are obtained by MatrixSlicer, of which there
are currently two versions:

3203 10 Oct 16:14 ./isb/pshannon/dataMatrix/metadata/MatrixSlicer.py
3227 12 Oct 13:55 ./isb/pshannon/experimentNavigator/MatrixSlicer.py

we are now using the first of these, which in MatrixSlicer.slice
constructs a csplugins/isb/pshannon/dataMatrix/readers/DataMatrixFileReader.java
which uses any of these four readers:

TextFileReader reader = new TextFileReader (path);
TextJarReader reader = new TextJarReader (protocol + path);
TextHttpReader reader = new TextHttpReader (protocol + path);
TextHttpIndirectFileReader reader = new TextHttpIndirectFileReader (protocol + path);

for now, TextHttpIndirectFileReader.java lives in csplugins/isb/pshannon/dataMatrix/readers/
but should move to (something like) cytoscape/data/readers in time.


/users/pshannon/cy/csplugins/isb/pshannon/dataMatrix/metadata:
9911 12 Oct 15:46 MetaDataNavigator.py
790 12 Oct 15:35 Util.py
4300 12 Oct 15:17 MetaDataFetcher.py
8067 10 Oct 16:40 MetaDataXmlParser.py
3620 10 Oct 16:15 MatrixCombiner.py
3203 10 Oct 16:14 MatrixSlicer.py
12173 10 Oct 15:30 MetaData.py
1520 10 Oct 14:32 Variable.py
2217 10 Oct 14:29 Condition.py
1348 10 Oct 14:28 DataSetDescription.py


*--------------------------------------------------------------------------------
* setup jython servlet for returning password-protected halo data via http (13 oct 2004)

the data server:
need tomcat running on localhost:8080
define a context in  ~/tomcat/jakarta-tomcat-5.0.28/conf/server.conf

<Context path="/jyserv"
docBase="/Users/mpshannon/tomcat/pauls-webapps/jyserv"
debug="3"
reloadable="true">
</Context>

~/tomcat/pauls-webapps/jyserv/WEB-INF/lib/jython.jar
~/tomcat/pauls-webapps/jyserv/haloDataFetcher.py

which runs in reponse to these urls:

http://trickster:8080/jyserv/haloDataFetcher.py
httpIndirect://trickster:8080/jyserv/haloDataFetcher.py

jyserv/haloDataFetcher.py?mode=dir&name=xml&user=tester0&pw=pw0
jyserv/haloDataFetcher.py?mode=getFile&name=test0.xml&user=tester0&pw=pw0
jyserv/haloDataFetcher.py?mode=getFile&name=test1.xml&user=tester0&pw=pw0
jyserv/haloDataFetcher.py?mode=getFile&name=test1.ratio&user=tester0&pw=pw0
jyserv/haloDataFetcher.py?mode=getFile&name=test1.lambda&user=tester0&pw=pw0

Trickster> cat ~/datamatrix.props
user=tester0
password=pw0



in WEB-INF/web.xml:

<web-app>

<display-name>experimental jython servlets: ~/tomcat/pauls-webapps/jyserv </display-name>
<description> jython-scripted servlets.</description>

<servlet>
<servlet-name>PyServlet</servlet-name>
<servlet-class>org.python.util.PyServlet</servlet-class>
<init-param>
<param-name>python.home</param-name>
<param-value>/users/pshannon/jython-2.1</param-value>
</init-param>

</servlet>

<servlet-mapping>
<servlet-name>PyServlet</servlet-name>
<url-pattern>*.py</url-pattern>
</servlet-mapping>

</web-app>
*--------------------------------------------------------------------------------
* experimental data reading using httpIndirect, cont (12 oct 2004)
this ensures that all three protocols can:
find a repository of xml files
get their names
read each file
on trickster:
cd /users/pshannon/cy/csplugins/isb/pshannon/dataMatrix/metadata/unitTests
make metaDataFetch

this works!
in /users/pshannon/cy/csplugins/isb/pshannon/experimentNavigator-new,
with  datamatrix.props
user=tester0
password=pw0
make tree creates a condition chooser with the right files
to do:
review everything
add a reload button to the condition chooser
add repositories:
repository.1=httpIndirect://trickster:8080/jyserv/haloDataFetcher.py
repository.2=http://db:8060/haloweb/data
repository.3=./myDataFiles
are directories right?  (with dataMatrix/metadata holding lots of classes?)


*--------------------------------------------------------------------------------
* nitin requests fix to keggwbi/sbeams link for haloarcula paper  (12 oct 2004)
from nitin:

As the genome paper release date is approaching I am re-testing our
web services.  I found one small problem- go to the "Examine
Haloarcula Proteins in Kegg Metabolic Pathways

http://db/cytoscape/projects/dynamic/keggwbi/halo/static.html>
and choose Citrate Cycle

Problem 1: Click on enzyme 4.2.1.3 you get all the correct matches and
in addition you get other matches such as 4.2.1.33.

Solution: This problem can be fixed by doing search for only an
identical match.

Problem 2: Click on enzyme 1.2.4.2 -this will not yield any matches.
This is because the Paul's KEGG search protocol parses the Domain E.C.
numbers in the SBEAMS table and the subsequent search for the identified
E.C match is conducted on the curated EC numbers field.

Solution: Would it be possible to do a search for an exact match on the
curated EC number field first and subsequently implement a second search
on the domain E.C. number field?  The outputs of the two will have to be
parsed separately to give two non-redundant tables: one with the curated
information and the second with those matches that did not make it into
the curated table.

my exploration of problem 1:  multiple hits for 4.2.1.3:

pNG6049 acnA 4.2.1.3 Aconitate hydratase I
rrnAC0334 leuC 4.2.1.33 3-isopropylmalate dehydratase large subunit
rrnAC0336 leuD 4.2.1.33 3-isopropylmalate dehydratase small subunit
rrnAC2158 acnB 4.2.1.3 Aconitate hydratase

all come from this link:
http://db.systemsbiology.net/cytoscape/keggwbi-hm?mode=browseSbeamsProteins&ec=4.2.1.3
db:/local/tomcat/webabpps/cytoscape/WEB-INF/web.xml has these elements


<servlet>
<servlet-name>keggwbi</servlet-name>
<servlet-class>KeggWbiServlet</servlet-class>
</servlet>

<servlet-mapping>
<servlet-name>keggwbi</servlet-name>
<url-pattern>/keggwbi-hm</url-pattern>
</servlet-mapping>

meaning that the above url invokes
/local/tomcat/webapps/cytoscape/WEB-INF/classes/KeggWbiServlet.java
which calls
/local/tomcat/webapps/cytoscape/projects/dynamic/keggwbi/halo/main.py
which calls
/local/tomcat/webapps/cytoscape/projects/dynamic/keggwbi/halo/keggwbiUtil.py
def browseSbeamsProteins (ecNumber):
print 'arg: %s' % ecNumber
url0 = 'https://db.systemsbiology.net/sbeams/cgi/ProteinStructure/GetAnnotations?'
url1 = 'biosequence_set_id=3&search_key=%s&search_scope=ECNumbers&' % ecNumber
url2 = 'SBEAMSentrycode=DF45jasj23jh&action=GOapply_action=QUERY'
text = getPageWithCookies (url0 + url1 + url2)

return text

eric explains that search_scope=ECNumber is meant to match multiple entries
in a field:

Although not visible, you can now provide a search_scope of
ECNumbers_exact and it will do an exact match rather than a fuzzy match.
Note that the data could look like:

4.1.2.2
4.1.2.2; 4.1.3.3

The fuzzy search will pick up any value containing the search key.  The
exact search means to you need to provide the entire value to get a hit.

then nitin suggests:

For a fuzzy search can we add a wild-card character; for example, if I
say 4.1.2.2 I will get exact matches but if I say 4.1.2% I will get all
matches to this expression including 4.1.2.3, 4.1.2.22 etc.  So for
purpose of the KEGG search we can restrict it to exact search and while
searching from the home-page for HM and NRC-1 genome we could use a
default fuzzy search as is currently the case.  If this is confusing I
will be happy to stop by to explain it better.


eric's suggestion for problem 2:
Problem 2 is a lot harder. GetAnnotations is designed only to browse the
human annotations given to proteins.  It does not have access to domain
hit information.  It could, but the relationship between annotations and
domain hits is complex. The domain hit EC numbers are not even
validated, while everything that GetAnnotations returns is supposed to

the current (rewritten kegg map) query for 1.2.4.2:
https://db.systemsbiology.net/sbeams/cgi/ProteinStructure/GetAnnotations?biosequence_set_id=3&search_key=1.2.4.2&search_scope=ECNumbers_exact&SBEAMSentrycode=DF45jasj23jh&action=GOapply_action=QUERYapply_action=QUERY
eric's proposal:
http://db.systemsbiology.net/sbeams/cgi/ProteinStructure/GetDomainHits?row_limit=30000&QUERY_NAME=PS_GetDomainHit&project_id=150&biosequence_set_id=3&EC_number_constraint=%251.2.4.2%25&display_options=ApplyChilliFilter,ShowExtraProteinProps&action=QUERYapply_action=QUERY


*--------------------------------------------------------------------------------
* made paranoid copy of trickster's haloDataServer.py tomcat (11 oct 2004)
hazel:/local/tomcat-trickster.tar
-rwxrw-r--  1 pshannon isb 44625920 Oct 11 16:01 ./tomcat-trickster.tar
*--------------------------------------------------------------------------------
* nextup todo (12 oct 2004)
/users/pshannon/cy/csplugins/isb/pshannon/dataMatrix/readers/unitTests
i just added a (uri, user, password) alternate ctor to TextHttpIndirectFileReader,
which should allow for easy testing of the different broken & changed user
scenarios.
test programs to extend:
/users/pshannon/cy/csplugins/isb/pshannon/dataMatrix/readers/unitTests/TextHttpIndirectFileReaderTest.java
/users/pshannon/cy/csplugins/isb/pshannon/dataMatrix/metadata/unitTests/MetaDataXmlParserTest.py

monday night:
completed tests for TextHttpIndirectFileReaderTest
decided against adding tests to MetaDataXmlParserTest.py
now looking at replacing MetaDataFetcher in

csplugins/isb/pshannon/experimentNavigator/MetaDataNavigator.py

find reasonable example code in:
/users/pshannon/cy/csplugins/isb/pshannon/dataMatrix/metadata/unitTests/
testFullMetaDataReadUsingHttpIndirect.  think about using
~/datamatrix.props
to specify  data repositories (see baseUrl variable just below):

repository.1=httpIndirect://trickster:8080/jyserv/haloDataFetcher.py
repository.2=http://db:8060/haloweb/data
repository.3=./myDataFiles

print 'testFullMetaDataReadUsingHttpIndirect'
baseUrl = 'httpIndirect://trickster:8080/jyserv/haloDataFetcher.py'

reader = TextHttpIndirectFileReader (baseUrl)
count = reader.read ();

filenames = reader.getText ().split ('\n');
if (filenames [len (filenames) - 1].strip() == ''):
del filenames [len (filenames) - 1]

for filename in filenames:
uri = '%s/%s' % (baseUrl, filename)
parser = MetaDataXmlParser (uri)
metaData = parser.getMetaData ()
assert (metaData.getName () in ['bop knockout, light and oxygen', 'iron concentrations'])
assert (len (metaData.getConditions ()) == 4)


*--------------------------------------------------------------------------------
* nextup todo (11 oct 2004)
continue to refine trickster:~/tomcat/pauls-webapps/jyserv/haloDataFetcher.py
ensuring that the

/users/pshannon/cy/csplugins/isb/pshannon/dataMatrix/readers/TextHttpIndirectFileReader.java
automatically extracts user/password from ./datamatrix.props or ~/datamatrix.props
and passes that to haloDataFetcher.py on every call
add list of data source to datamatrix.props too.
then re-integrate these changes into experimentNavigator/TreeDataBrowser.py
make sure that this test works for
/users/pshannon/cy/csplugins/isb/pshannon/dataMatrix/readers/unitTests/TextHttpIndirectFileReaderTest.java

1) list of metadata file names
2) meta data files (their contents)
3) the ratio & lambda files

*--------------------------------------------------------------------------------
* nextup todo (8 oct 2004)
/users/pshannon/cy/csplugins/isb/pshannon/dataMatrix/unitTests
(cd ..; make) && make 7
this tests TextHttpIndirectFileReaderTest
which can be a companion (in DataMatrixFileReader) to

TextFileReader reader = new TextFileReader (path);
TextJarReader reader = new TextJarReader (protocol + path);
TextHttpReader reader = new TextHttpReader (protocol + path);
TextHttpIndirectFileReader reader = ...

trickster:~/tomcat/pauls-webapps/jyserv/haloDateFetcher.py
tested by
/users/pshannon/cy/csplugins/isb/pshannon/experimentNavigator/NewMetaDataFetcher.py
though (see below) i want to change the design to consist of generic

dataMatrix.MetaDataReader
dataMatrix.DataMatrixReader

*--------------------------------------------------------------------------------
* decipher the structure of TreeDataBrowser, MetaDataFetchers, ExperimentXmlParser (8 oct 2004)

---- goal 1:  get a full list of experiment descriptions from a uri source

TreeDataBrowser ctor, single uri assigned
createFrame
createGui
experimentNavigator = MetaDataNavigator (uri)
MetaDataNavigator (uri)
loadXmlFiles ()
fetcher = [PasswordProtectedMetaDataFetcher|MetaDataFetcher|NewMetaDataFetcher] (uri)
xmlFiles = fetcher.getXmlFilesList ()
for file in xmlFiles:
parser = ExperimentXmlParser (uri/file)   [this reads the xml from file or url into sax document]
experiment = parser.getExperiment ()
self.nameToExperimentsHash [experiment.getName ()] = experiment

---- goal 2:  combine selected portions of all experiments into a single matrix, or
pair of matrices
TreeDataBrowser 'Load Selected Condtions' button calls loadSelectedConditions
matrices = combineSelectedConditions ()
combineSelectedConditions:
for experiment in self.currentlySelectedExperiments:
(accumulate matrix slices, all types (e.g., ratios & lambdas)
(MatrixSlicer.slice invokes DataMatrixReader to read actual matrix file)
for each type, create a finalMatrix from the accumulated slices)

sample uri's:
-------------
file:///users/pshannon/haloweb/data
http://db:8060/halo/data
from these, get a list of xml file names; from each file name, read & parse an experiment description
display experiment in a jtree widget
once selections are made, a MatrixSlicer calls DataMatrixReader, and then slices

possible new scheme
-------------------
two basic classes: DataMatrixReader, MetaDataReader
each should take 4 uri forms:  file://, htpp://  httpIndirect://   sbeams://






*--------------------------------------------------------------------------------
* NewMetaDataFetcher todo (7 oct 2004)
on trickster,
cd   /users/pshannon/cy/csplugins/isb/pshannon/experimentNavigator/unitTests
make newMetaDataFetch
the  method testXmlFileRetrieval does not yet get xml file contents

*--------------------------------------------------------------------------------
* add a servlet to tomcat 5.0.28 (7 oct 2004)
using /users/pshannon/tomcat/server1 (installed on db:8060) as an example
add a context to conf/server.xml

<Context path="/test1"
docBase="/users/pshannon/tomcat/server1/webapps/test1"
debug="3"
reloadable="true">

this goes in the <Engine> element:

<Engine defaultHost="localhost" name="Catalina">
<Host appBase="webapps" name="localhost">
<Logger className="org.apache.catalina.logger.FileLogger"
prefix="localhost_log."
suffix=".txt"
timestamp="true"/>
<Valve className="org.apache.catalina.valves.AccessLogValve"
fileDateFormat="yyyy-MM-dd"
prefix="localhost_access_log."
suffix=".txt"
resolveHosts="true"/>

<Context path="/test1"
docBase="/users/pshannon/tomcat/server1/webapps/test1"
debug="3"
reloadable="true">
</Context>

</Host>
</Engine>




in the docBase directory:
drwxr-xr-x    4 pshannon isb            96 Oct  7 10:44 WEB-INF
-rw-r--r--    1 pshannon isb           163 Oct  7 10:36 index.html

in that WEB-INF directory:
drwxr-xr-x    2 pshannon isb            96 Oct  6 11:25 classes
drwxr-xr-x    2 pshannon isb            96 Oct  6 11:21 lib
-rw-r--r--    1 pshannon isb           424 Oct  6 12:07 web.xml


that web.xml:
<?xml version="1.0" encoding="ISO-8859-1"?>

<!-- !DOCTYPE web-app
PUBLIC "-//Sun Microsystems, Inc.//DTD Web Application 2.3//EN"
"http://java.sun.com/dtd/web-app_2_3.dtd"  -->

<web-app>
<servlet>
<servlet-name>args</servlet-name>
<servlet-class>DoGetArgs</servlet-class>
</servlet>

<servlet-mapping>
<servlet-name>args</servlet-name>
<url-pattern>/args</url-pattern>
</servlet-mapping>

</web-app>

which says:
http:db:8060/test1/args runs the servlet DoGetArgs.class
which may be found in

/users/pshannon/tomcat/server1/webapps/test1/WEB-INF/classes/DoGetArgs.class

browse to http://db:8060/manager/html  (mgr, mgr)
start or reload the context (test1, which may have many servlets)



*--------------------------------------------------------------------------------
* build JGR from source, debug linux RHOME problem (26 jul 2005)
see 'get JGR to run on linux (jul 2005)' just below
(27 jul 2005) build verbose jni lib, see if difference between success & failure can be found
trickster:
installed jni lib is in
/Library/Frameworks/R.framework/Versions/2.1/Resources/library/JGR/cont
106608 12 May 13:52 libjri.jnilib
source for this is /Users/mpshannon/src/jgr/JGR
change Makefile to include Makefile.osx
make
creates  106572 27 Jul 10:33 libjri.jnilib
build R 2.1.1 from source:
/Users/mpshannon/src/R-2.1.1  (had to install g77, see above 'install g77 on trickster (27 jul 2005)'
./configure --prefix=/users/mpshannon/test/r211 --enable-R-shlib --with-readline=no --with-x=no
*------------------------------------------------------------------------------------------------------
* get JGR to run on linux (jul 2005)

---- my mail to the rosuda mailing list (25 jul 2005)
I realize that JGR is not supported on linux, but maybe :} I can get a little help nonetheless...

The symptom:

With JGR 1.2, R 2.1.0 running happily on linux (Fedora Core release 1), I open the
object browser, and get the following message, and no list of objects to browse:

> object.browser()
Error in lazyLoadDBfetch(key, datafile, compressed, envhook) :
open failed on /usr/lib/R/library/datasets/data/Rdata.rdb
Error in get(objects[i]) : recursive default argument reference
Error in get(objects[i]) : recursive default argument reference
Error in get(objects[i]) : recursive default argument reference

I can execute R statements in JGR just fine.  The problem seems to be with JGR (in java)
obtaining references to R objects.

To avoid uncertainty, I trimmed down the 'run' script so that it now looks like this:

RHOME=/local/R210/lib/R
export R_HOME=$RHOME
export R_DEFAULT_PACKAGES="utils, stats, rJava, methods, JGR, JavaGD, graphics, datasets"
export DYLD_LIBRARY_PATH=/local/R210/lib/R/bin
export LD_LIBRARY_PATH=.:/local/R210/lib/R/bin:/local/R210/lib/R/lib:/tools/java/jdk1.5.0/jre/lib/i386:/tools/java/jdk1.5.0/jre/lib/i386/client:/tools/java/jdk1.5.0/jre/bin/classic
/tools/java/jdk1.5.0/bin/java -cp /local/R210/lib/R/library/JGR/cont/JGR.jar:. -Xmx512m org.rosuda.JGR.JGR $*

My hunch (see the complaint, above, about the failed open on '/usr/lib/R/library/datasets/data/Rdata.rdb') is that
the value for  R_HOME is somehow not being communicated to R.

For what it's worth, my MacOS and windows installations of JGR work fine.


---- track down the JGR/R/gaggle bug
>  broadcast (rownames (m0))
Error in lazyLoadDBfetch(key, datafile, compressed, envhook) :
open failed on /usr/lib/R/library/datasets/data/Rdata.rdb
Error in get(objects[i]) : recursive default argument reference
Error in get(objects[i]) : recursive default argument reference
Error in get(objects[i]) : recursive default argument reference
./src/main/serialize.c
SEXP R_lazyLoadDBfetch(SEXP key, SEXP file, SEXP compsxp, SEXP hook)
./src/main/registration.c
CALLDEF(R_lazyLoadDBfetch, 4),

./src/main/eval.c
_("recursive default argument reference"));
_("recursive default argument reference"));
the first of these is in call to 'eval (e, rho)'


---- install for linux (25 jul 2005) against R 2.1.0 (same bug as below)
so now, try building R 2.1.0, and installing it for JGR to use:
cd ~/src/R-2.1.0
hazel.R-2.1.0>  ./configure --prefix=/local/R210 --enable-R-shlib
make; make check; make install

start R on hazel: /local/R210/bin/R
install.packages ("JGR", contriburl="http://www.rosuda.org/R")
install.packages ("JavaGD", contriburl="http://www.rosuda.org/R")
install.packages ("rJava", contriburl="http://www.rosuda.org/R")
install.packages ("iplots", contriburl="http://www.rosuda.org/R")
install.packages ("iWidgets", contriburl="http://www.rosuda.org/R")

rebuild JGR
cd hazel:~/src
mv JGR JGR-with-R211
in Makefile.linux, make these changes:
RHOME=/local/R210/lib/R
JAVAHOME=/tools/java/jdk1.5.0
remove sudo lines
./run



---- install for linux (21 jul 2005) against R 2.1.1 (not completely successful)
http://stats.math.uni-augsburg.de/JGR/down.shtml
on hazel, downloaded 'source for R 2.x.x: JGR-1.2.tar.gz (ca. 26kB, updated 2005/05/13)'
prerequisite: build R 2.1.1 from source on hazel, including dynamic library
-> see  R tip  "build from source on linux (hazel) (v 2.1.1, 22 jul 2005)"

start R on hazel
install.packages ("JGR", contriburl="http://www.rosuda.org/R")
install.packages ("JavaGD", contriburl="http://www.rosuda.org/R")
install.packages ("rJava", contriburl="http://www.rosuda.org/R")
install.packages ("iplots", contriburl="http://www.rosuda.org/R")
install.packages ("iWidgets", contriburl="http://www.rosuda.org/R")


get and compile JRI:
http://www.rosuda.org/JGR/down.shtml, JGR-1.2.tar.gz  (26k, 2005/05/13)
cd hazel:~/src
tar xvf ~/ftp/JGR-1.2.tar
cd ~/src/JGR
edit Makefile.linux
RHOME=/local/lib/R  (location of installation, libraries etc: 16543 files)
JAVAHOME=/tools/java/jdk1.5.0
edit Makefile, removing 'sudo' warning and use (with R installed w/o root privilege,
this is unnecessary)
make creates /users/pshannon/src/JGR/run:
The run script (unless edited) assumes that you start it from the path
where it's been compiled (simply it needs JGR.jar in the current directory).
not so!  JGR.jar is found in 'run' via
/tools/java/jdk1.5.0/bin/java -cp /local/lib/R/library/JGR/cont/JGR.jar

now try replacing this jar with a gaggled JGR.jar
works, almost.  after receiving a matrix, this fails:

>  broadcast (rownames (m0))
Error in lazyLoadDBfetch(key, datafile, compressed, envhook) :
open failed on /usr/lib/R/library/datasets/data/Rdata.rdb
Error in get(objects[i]) : recursive default argument reference
Error in get(objects[i]) : recursive default argument reference
Error in get(objects[i]) : recursive default argument reference



why '/usr/lib/R/' ?
*--------------------------------------------------------------------------------
* windows tips

---- set environment variables
control panel:system:advanced

---- cygwin x startup
X -mulitwindow &
xterm -display localhost:0 &



*--------------------------------------------------------------------------------
* excel tips

---- export worksheet to tab-delimited text
replace all commas with, eg, ;;;
save as 'CSV (Windows)'
in emacs, convert all commas to tabs, and all ;;; to commas
resulting text has '\r' at eol; use this in python to split:
lines = open (f).read().split ('\r\n')

--- histogram
cd ~/s/data/tortugas/demo1
read in (or recreate) 100 normally distributed integers
in R: x = round (rnorm (100, 100, 20)); write (x, file='counts.txt', sep='\n')
read into excel, add 'eggCount' in A1 as title

** first:  create the data, specifying the bins of the histogram, and calculating counts for each
in, eg, C1, add label 'Bins'.
in successive C rows, add 0, 20, 40, ..., 180
label in D1: 'Counts'
click (select) D2, insert->function->statistics->FREQUENCY
- displays a dialog box
- in data_array: a2:a101
- in bins_array: c2:c11
now D2 should read 0
select D2:D11
click in the Formula Bar, which should now display
=FREQUENCY(A2:A101,C2:C11)
to propagate the function into all the selecte cells
on mac: cmd-shift-enter
on pc: control shift enter
now you should see the counts column populated with, eg, 0,0,3,9,38,33,15,2,0

** second: create the histogram plot itself
1) select d1:d11, the Counts column
1) in the toolbar, click on the chart wizard
2) choose the first sub-type, the 'column chart', Next
3) offered tabbed choice of 'Data Range' and 'Series', choose the latter
4) interactively assign  'Category (X) axis labels'  eg: b2:b11
5) give a title to the chart
6) finish

*--------------------------------------------------------------------------------
* NameXref tips

----- sample use
import sys
sys.path.append ('/local/tomcat/webapps/cytoscape/projects/dynamic/mergeTest/src/')
from NameXref import *
xref = NameXref ()
np = 'NP_034602'   # geneID =  15463
print '%s: %s' % (np, xref.npToLocusID (np))

----- NameXref methods

def getLog (self):
def getLastLogMessage (self):
def sql (self, sqlCommand):
def destroyCache (self):
def readCache (self):
def nameCacheToString (self):
def writeCache (self):
def anyNameToLocusID (self, givenName, mergeOrganism = None):
def affyToLocusID (self,affyID):
def genbankToLocusID (self, genbank):
def nmToLocusID (self, nm):
def xmToLocusID (self, xm):
def npToLocusID (self, np):
def xpToLocusID (self, xp):
def unigeneToLocusID (self, unigene):
def ipiToLocusID (self, ipi):
def geneSymbolToLocusID (self, geneSymbol):
def locusIdToGeneSymbol (self, id):
def locusIdToOrganism (self, id):
def locusIdToGeneName (self, id):
def locusIdToNp (self, id):
def locusIdToNm (self, id):
def getHomologLocusID (self, locusID, targetOrganims = None):
def yeastOrfToGeneSymbol (self, orf):
def yeastOrfToNP (self, orf):
def yeastGeneSymbolToOrf (self, geneSymbol):
def nameCacheToString (self):
def givenNameToGeneSymbol (self, givenName):
def givenNameToLocusID (self, givenName):
def givenNameToNP (self, givenName):
def isGenbankAccessionNumber (self, givenName):
def guessNameType (self, givenName):



*--------------------------------------------------------------------------------
* svn tips

---- checkout old version of Oncoscape/inst/scripts/pca/code.js

---- svn: checkout old versions of a file (of a directory); track down when and what changes were made
1) using oligo package methods-PLMset.R as example
2) but cannot get just one file (easily)
3) create a safe & distant directory to work in
4) go to the directory with file of interest:
cd ~/s/bioc/trunk/Rpacks/oligo/R
svn log
r63712 | bcarvalh@jhsph.edu | 2012-03-09 16:17:25 -0800 (Fri, 09 Mar 2012) | 1 line  Adding PLM methods
r63711 | bcarvalh@jhsph.edu | 2012-03-09 16:17:06 -0800 (Fri, 09 Mar 2012) | 1 line  Adding unit tests
r63710 | bcarvalh@jhsph.edu | 2012-03-09 16:16:47 -0800 (Fri, 09 Mar 2012) | 1 line  Adding 1st unit test

5) get svn url from .svn:
cat .svn/entries | grep http
https://hedgehog.fhcrc.org/bioconductor/trunk/madman/Rpacks/oligo/R

6) cd ~/s/bioc/trunk/Rpacks/oligo/inst
7) mkdir tmp

# now get all of R/ at r63712 & r63710
8) svn co -r r63712 https://hedgehog.fhcrc.org/bioconductor/trunk/madman/Rpacks/oligo/R r63712
9) svn co -r r63710 https://hedgehog.fhcrc.org/bioconductor/trunk/madman/Rpacks/oligo/R r63710
10) now compare:
dir r*/methods-PLMset.R
7373 Mar 22 13:30 r63710/methods-PLMset.R
9788 Mar 22 13:20 r63712/methods-PLMset.R

---- svn diff
svn log DESCRIPTION | head -10   # displays version numbers
r64275 | bcarvalh@jhsph.edu | 2012-03-22 04:58:30 -0700 (Thu, 22 Mar 2012) | 1 line
r64274 | bcarvalh@jhsph.edu | 2012-03-22 04:58:19 -0700 (Thu, 22 Mar 2012) | 1 line
r63946 | bcarvalh@jhsph.edu | 2012-03-15 03:27:01 -0700 (Thu, 15 Mar 2012) | 1 line

svn diff -r r64275:r63946  DESCRIPTION

---- new svn repository on db (24 jul 2007)
from eric:
SVN url: http://db.systemsbiology.net/svn/pshannon
ViewVC url: http://db.systemsbiology.net/cgi-bin/pshannon/viewcvs/viewcvs.cgi/
Both should be password controlled. When using http access. Access is
somewhat less restricted when using internal file access.
Username is pshannon. Password to follow.

-- initial use, on book
mv'd old ~/svn to ~/svnPublic
mkdir svn; cd svn
svn checkout --username pshannon --password PS3000 http://db.systemsbiology.net/svn/pshannon
mkdir pshannon/notes; cd pshannon/notes
cp ~/notes/hidden/log .


---- merge a branch back into the head, to become the latest trunk
# need to know the version of the head at which the branch was formed.
# find this by doing an svn status in that directory

svn merge -r 1520:HEAD http://gaggle.systemsbiology.net/svn/gaggle/webapp/branches/four

---- get *all* of the gaggle svn repository:
aphelion, cd ~/work/svnisb
svn checkout http://gaggle.systemsbiology.net/svn/gaggle
FireGoose biclusterviewer gaggle metaDataLoader OrthologMapper
Translator cy2_3goose globalTranslator webapp



---- checkout a previous version of a file
form is:  svn co -r <version number> <file or http uri to repos> <optional destination directory>
to determine which version, use emacs in svn load, type 'l' (lowercase L) to
get the log

then, in a shell,
svn co -r 842 http://gaggle.systemsbiology.net/svn/gaggle/gaggle/trunk/src/main/org/systemsbiology/gaggle/geese/dmv ~/tmp

A    /Users/mpshannon/tmp/dmv/dmv.jnlp-raw
A    /Users/mpshannon/tmp/dmv/GaggledTreeDataViewer.java
A    /Users/mpshannon/tmp/dmv/manifest
A    /Users/mpshannon/tmp/dmv/makefile
A    /Users/mpshannon/tmp/dmv/GaggledMovieController.java
U   /Users/mpshannon/tmp/dmv
Checked out revision 842.

---- create a user/password for apache (which runs svn as a module)
on atlas, cd /local/wwwspecial/gaggle/lib
htpasswd -b htpasswd <user> <password>
then, do a fresh checkout
svn checkout --username pshannon --password <password>  http://gaggle.systemsbiology.net/svn/gaggle/gaggle/trunk gaggleSvn
this seems to write user/password into key places in the checked out tree.

---- delete, rm
svn delete <filename>

---- svn client location on linux (db)  (28 nov 2005)
/usr/local/bin/svn

---- svn ignore
create a file called, eg, .ignore:
*.class
*.jar
*.jnlp

svn ps -R svn:ignore -F .ignore .  property set, recursive, from file '.ignore' on current directory

----- see ignored files too

----- svn checkout
db; mkdir ~/svnWork; cd svnWork
svn checkout http://gaggle.systemsbiology.net/svn/gaggle

---- tell status to ignore .class and .jar files
trickster:~/bin/svn-ignore-java-binary-files

ls *.class  > ~/tmp/junk
ls *.jar   >> ~/tmp/junk
svn propset svn:ignore -F ~/tmp/junk .
svn commit -m "ignore .class and jar files"

---- ask status to ignore some files (using '.class' as example)
cd to the directory which has the files
ls  -1 *.class > ~/tmp/junk
svn propset svn:ignore -F ~/tmp/junk .
svn commit -m "ignore .class files"
check with 'svn status'

---- in psvn, ask status mode to ignore files by filename extension
place cursor, for instance, on Boss.class
P I   (then confirm with 'y')


---- figure out how a file has changed
in emacs svn, 'l'  (lowercase L) shows the log, or history (with version numbers)
svn diff <file> -r 181

* end svn tips
*--------------------------------------------------------------------------------
* psvn tips

---- turn on svn keyword expansion
from svn status buffer, mark file, type 'P k'
then add some or all of: Url Rev Author Date Id

----
g     - svn-status-update:               run 'svn status -v'
C-u g - svn-status-update:               run 'svn status -vu'
=     - svn-status-show-svn-diff         run 'svn diff'
l     - svn-status-show-svn-log          run 'svn log'
i     - svn-status-info                  run 'svn info'
r     - svn-status-revert                run 'svn revert'
X v   - svn-status-resolved              run 'svn resolved'
U     - svn-status-update-cmd            run 'svn update'
c     - svn-status-commit-file           run 'svn commit'
a     - svn-status-add-file              run 'svn add --non-recursive'
A     - svn-status-add-file-recursively  run 'svn add'
+     - svn-status-make-directory        run 'svn mkdir'
R     - svn-status-mv                    run 'svn mv'
C-d   - svn-status-rm                    run 'svn rm'
M-c   - svn-status-cleanup               run 'svn cleanup'
b     - svn-status-blame                 run 'svn blame'
RET   - svn-status-find-file-or-examine-directory
^     - svn-status-examine-parent
~     - svn-status-get-specific-revision
E     - svn-status-ediff-with-revision
X X   - svn-status-resolve-conflicts
s     - svn-status-show-process-buffer
e     - svn-status-toggle-edit-cmd-flag
?     - svn-status-toggle-hide-unknown
_     - svn-status-toggle-hide-unmodified
m     - svn-status-set-user-mark
u     - svn-status-unset-user-mark
$     - svn-status-toggle-elide
w     - svn-status-copy-filename-as-kill
DEL   - svn-status-unset-user-mark-backwards
* !   - svn-status-unset-all-usermarks
* ?   - svn-status-mark-unknown
* A   - svn-status-mark-added
* M   - svn-status-mark-modified
* D   - svn-status-mark-deleted
* *   - svn-status-mark-changed
.     - svn-status-goto-root-or-return
f     - svn-status-find-file
o     - svn-status-find-file-other-window
v     - svn-status-view-file-other-window
I     - svn-status-parse-info
V     - svn-status-svnversion
P l   - svn-status-property-list
P s   - svn-status-property-set
P d   - svn-status-property-delete
P e   - svn-status-property-edit-one-entry
P i   - svn-status-property-ignore-file
P I   - svn-status-property-ignore-file-extension
P C-i - svn-status-property-edit-svn-ignore
P k   - svn-status-property-set-keyword-list
P y   - svn-status-property-set-eol-style
P x   - svn-status-property-set-executable
h     - svn-status-use-history
q     - svn-status-bury-buffer

The output in the buffer contains this header to ease reading
of svn output:
FPH BASE CMTD Author   em File
F = Filemark
P = Property mark
H = History mark
BASE = local base revision
CMTD = last committed revision
Author = author of change
em = "**" or "(Update Available)" [see `svn-status-short-mod-flag-p']
if file can be updated
File = path/filename

*--------------------------------------------------------------------------------
* kegg tips

-- * KEGG.db (4 jan 2010), get all the contents
ls ("package:KEGG.db")
KEGG
KEGG_dbconn
KEGG_dbfile
KEGG_dbInfo
KEGG_dbschema
KEGGENZYMEID2GO
KEGGEXTID2PATHID
KEGGGO2ENZYMEID
KEGGMAPCOUNTS
KEGGPATHID2EXTID
KEGGPATHID2NAME
KEGGPATHNAME2ID

-- easy access to path id numbers & names
results: on wombat ~/s/data/public/kegg/graphNELs/index.tsv
write.table (tbl.kp, sep='\t', row.names=F, quote=F, file='~/s/data/public/kegg/graphNELs/index.tsv')

library (KEGG.db)
tbl.kp = toTable (KEGGPATHID2NAME)
tbl.kp [grep ('mapk', tbl.kp$path_name, ignore.case=T), ]
tbl.kp [grep ('toll', tbl.kp$path_name, ignore.case=T),]
path_id                            path_name
04620 Toll-like receptor signaling pathway



--- get latest ligand files (reaction, compound, enzyme)
trickster:~/data/kegg/import/ligand/2006-01-17
ftp ftp.genome.ad.jp
cd pub/kegg/ligand
bin; hash; get reaction; get compound; get enzyme

--- reaction names
available for now in ~/s/data/public/kegg/cy/commonNames.noa

--- compound names
available for now in ~/s/data/public/kegg/cy/compoundSynonyms.noa


*--------------------------------------------------------------------------------
* awk tips

--- split the contents of a line in a sif file into two lines

head -10 humanTest.sif | awk '{print $1 "\n"  $3}'

*--------------------------------------------------------------------------------
* grep tips

---- print out context (more than one line)
-A <number>   match plus A lines after
-B <number>                      before
-C <number>                      context (before and after)

---- match start and end of a word  (macos x)
^ $    start and end of line
\< \>  start and end of word

grep ^31039 homologene.data  | egrep '\<7227\>'
31039	7227	41709	foxo	45553353	NP_996204.1

*--------------------------------------------------------------------------------
* other unix pipe tips

--- present first (title) line of a tsv file as a numbered list:
head -1 youngAh.tsv | tr '\t' '\n' | nl -v 0

0	entry no.
1	group probability
2	protein
3	protein link
4	protein probability

*--------------------------------------------------------------------------------
* jgr tips  jaguar tips

---- to get exactly jgr 1.2, even though 1.3 is current (26 sep 2005)
http://stats.math.uni-augsburg.de/JGR/1.2/windows/2.1.x/JGR-1.2.exe

* end jgr tips  jaguar tips
*--------------------------------------------------------------------------------
* jgr, jaguar, build Instructions for Linux & Compiling from JGR/JRI sources (jul 2005)

Although we have success reports from users running JGR on
Linux, we are reluctant to offer official support, because we perform
very limited tests on Linux. At least for Linux it is crucial that you
get the very latest JDK version 1.5 (yes, 1.4 doesn't work due to some
JNI issues that were fixed in the 1.5 release). Your mileage may vary,
but you can give it a shot:

In order to install JGR, you'll need R 2.0.x or later and Sun's JDK
(the latest you can find - see java.sun.com). R must be configured
with --enable-R-shlib, that is there should be a file libR.so in the
bin or lib subdirectory of R. Then install the packages JGR, JavaGD
and rJava from our R repository (see http://www.rosuda.org/R/ for
instructions), JGR-1.2 tries to install these packages automatically
from the web. You can install iplots and iWidgets, too, but that step
is optional (well, it doesn't hurt and both are nicely integrated in
JGR - iWidgets allow you to create new windows and widgets in JGR).

Once all three packages are installed (hopefully without problems),
you'll need to compile JRI (Java/R Interface). You can download the
sources here: JGR-1.2.tar.gz Since JRI is very fresh and not really an
R package, it doesn't use autoconf (yet), but the Makefile is already
prepared. After unpacking, you'll need to edit the Makefile.linux file
to point to the correct paths to R and Java (see comments in the
file). Under normal circumstances you don't need to modify anything
else (might even work on Solaris, too, if gcc is used - just replace
/linux by /solaris in the -I flag ... we didn't test it on a Sun, so
success/failure reports are welcome!). Then just run make

After make is through there should be a file libjri.so (actually a
softlink) and a "run" script. (If make fails with many, many errors,
look right at the beginning and make sure it's not complaining about
missing jni.h - adjust the paths in the Makefile.linux if that's the
problem). The run script (unless edited) assumes that you start it
from the path where it's been compiled (simply it needs JGR.jar in the
current directory). If everything worked out, you can just run it and
it should start JGR ...

*--------------------------------------------------------------------------------
* tomcat tips and tricks

--- increase heap size
to tcStart, add a new environment variable
#!/bin/sh
export CATALINA_HOME=/usr/local/apache-tomcat-5.5.20
export JAVA_HOME=/usr
export JAVA_OPTS=-Xmx1G
$CATALINA_HOME/bin/startup.sh

----- manager on db:8080
http://db.systemsbiology.net:8080/manager/html/
user: mgr
password: NtnsBrn
to recognize and run a new version of an existing servlet in the cytoscape group:
stop the cytoscape application; start it up again

---- file upload demo
cd /local/tomcat/webapps/cytoscape/WEB-INF/classes
/tools/java/j2sdk1.4.2/bin/javac \
-classpath ../lib/cos.jar:/users/pshannon/jars/tomcatServletUnpacked/  FileUploadDemo.java

---- where does System.out.println go?
logs/catalina.out    # seems to be on by default

---- turn on user access logging
de-comment this lines, found near the bottom of conf/server.xml

<Valve className="org.apache.catalina.valves.AccessLogValve"
directory="logs"  prefix="localhost_access_log." suffix=".txt"
pattern="common" resolveHosts="true"/>

*--------------------------------------------------------------------------------
* tomcat db:8060 conf/tomcat-users.xml  (7 oct 2004)

<?xml version='1.0' encoding='utf-8'?>
<tomcat-users>
<role rolename="tomcat"/>
<role rolename="role1"/>
<role rolename="manager"/>
<role rolename="admin"/>
<user username="tomcat" password="tomcat" roles="tomcat"/>
<user username="both" password="tomcat" roles="tomcat,role1"/>
<user username="role1" password="tomcat" roles="role1"/>
<user username="mgr" password="mgr" roles="tomcat,manager"/>
<user username="admin" password="admin" roles="tomcat,admin"/>
</tomcat-users>

*--------------------------------------------------------------------------------
* reinstall and reconfigure home directory on  trickster (6 oct 2004)
after deleting part of my home directroy
xemacs is /sw/bin/xemacs
repeated ssh keygen seen below at
"set up ssh authorization between trickster and db (6 aug 2004)"
*--------------------------------------------------------------------------------------------
* tomcat container-managed security (6 oct 04)
from (jun 03):
specified in an application's (a context's) web.xml file.  see p41 of the ora book.
takes the place of apache .htaccess files
test this out in db:tomcat/server1/webabpps/tests
this continually failed, so i'll try a fresh install, see above
i can get my own webapp servlet to work
then check out security

http://jakarta.apache.org/site/binindex.cgi
got tomcat 5.0.28.tar.gz
untar'd to /Users/mpshannon/tomcat/jakarta-tomcat-5.0.28
JAVA_HOME=/usr
*--------------------------------------------------------------------------------------------
* gaggle todo (4 oct 2004)
/users/pshannon/work/org/systemsbiology/gaggle/sampleApps
refine the clunky GaggleMatrixBrowser until it can broadcast, eg,

VNG6430C: array([-0.025, -0.006, -0.045, -0.064, 0.004, 0.0, -0.096, -0.053, -0.047, 0.204, -0.057], double)
VNG2276G: array([-0.14, 0.002, 0.095, -0.02, 0.008, -0.053, -0.067, -0.086, 0.014, -0.012, -0.061], double)
VNG2406C: array([-0.039, -0.068, 0.028, -0.026, -0.027, -0.023, -0.04, -0.015, 0.052, 0.005, 0.038], double)

into the selection space
then create a GagglePlotter, which sees this broadcast

*--------------------------------------------------------------------------------
* gaggle todo (1 oct 2004)
/users/pshannon/work/org/systemsbiology/gaggle/unitTests
TSpaceGaggleBusTest.java:  add many threads, one per client, making sure
that the boss can send (say) 12 'hide' commands, and these seen
by all clients.  maybe:
*--------------------------------------------------------------------------------
* load halo microarray data: tbp tfb knockout data (1 oct 2004)
from nitin's email (30 sep 2004)

When you get a chance can you stick this data into the datamatrix
browser?

They are microarray comparisons of strains with a knockout in a tbp or a
tfb.

munpacked data to /users/pshannon/data/halo/microarrayXml/tbpTfbKnockout/created halo_tfb_tbp_ko.mrna
removed ^M

cp ../nickelCobalt-2004.09.03/createMatrices.py .
db.tbpTfbKnockout> head -1 tbpTfbKnockout.raw | tr '\t' '\n' | sort | uniq
gene_name
sequence_name
tbp_A_vs_NRC-1_c.sig
tbp_C_vs_NRC-1_c.sig
tbp_D_vs_NRC-1_c.sig
tfb_A_vs_NRC-1_c.sig
tfb_B_vs_NRC-1_c.sig
tfb_C_vs_NRC-1_c.sig
tfb_D_vs_NRC-1_c.sig

*--------------------------------------------------------------------------------
* create datamatrix browser project for mjohnson (1 oct 2004)
db, cd  /local/tomcat/webapps/cytoscape/projects/static/mjohnson/2004.oct
deleted top line of both mjohsonData.matrix-orig
awestonData.matrix-orig
creating mjohnson.raw, aweston.raw
ran these through cleanup.py to delete last column on every line ('11 -- num sig conds')
creating mjohnson.cooked, aweston.cooked
hand-edit columns to make them sortable, changing a few 'hour' columns to minutes
head -1 mjohnson.cooked  | tr '\t' '\n' | sort | uniq
000min_vs_0min.sig
001min_vs_0min.sig
005min_vs_0min.sig
010min_vs_0min.sig
020min_vs_0min.sig
030min_vs_0min.sig
060min_vs_0min.sig
090min_vs_0min.sig
180min_vs_0min.sig
360min_vs_0min.sig
720min_vs_0min.sig
DESCRIPT
GENE

msv ~/data/halo/microarrayXml/experiment.xsd mjohnson.xml

now do the same with aweston.cooked:

*--------------------------------------------------------------------------------
* gaggle todo (30 sep 2004)
/users/pshannon/work/org/systemsbiology/gaggle/unitTests
testSendCommandsToClients fails, getting goose-02 when the granted name
should be simply 'goose'
*--------------------------------------------------------------------------------
* steve lasky's monkey puberty cytoscape project (29 sep 2004)
/net/techdev/neuro/
working in /users/pshannon/data/slasky/neuro
convert hugo names to locusID
quick check:  do we have GO annotation for locusID? yes:
head /local/tomcat/webapps/cytoscape/annotation/human/molfunc.txt
(species=Homo sapiens) (type=Molecular Function) (curator=GO)
IPI00020258 = 4674
11184 = 4674
NP_009112 = 4674

/local/tomcat/webapps/cytoscape/projects/dynamic/mergeTest/src/NameXref.py
provides method:  xref.geneSymbolToLocusID (id)
python
import sys
sys.path.append ('/local/tomcat/webapps/cytoscape/projects/dynamic/mergeTest/src/')
from NameXref import *
symbol = 'CD86'
xref = NameXref ()
xref.geneSymbolToLocusID (symbol)  -> '942'


*--------------------------------------------------------------------------------
* pat copeland, snowdogs  (28 sep 2004)
hired by amgen to find java developers,  956-9200
*--------------------------------------------------------------------------------
* backup of tomcat/server2 logs, from db to trickster (23 sep 2004)
my nfs account was over quota, so i copied to
trickster:~/bu/tomcat-server2-logs.tar.gz
*--------------------------------------------------------------------------------
* real Gaggle (28 sep 2004)
cd trickster:/users/pshannon/work/org/systemsbiology/gaggle
cp -p /users/pshannon/examples/java/swing/table/gaggleBoss/*.java .

*--------------------------------------------------------------------------------
* GaggleBoss potemkin ui (28 sep 2004)
/users/pshannon/examples/java/swing/table/gaggleBoss
*--------------------------------------------------------------------------------
* gaggle todo (24 sep 2004)

- make it possible for a goose to tell the helper its preferred & default size
- have gaggle boss set the default size on a stagger.  or maybe have that
as a variation on stagger
- make the plotter a goose; set it up to listen for
matrix broadcast (which will come from the exp-nav
gene names, which might come from cytoscape

- add broadcast to experiment navigator
- broadcast selected row names
- broadcast selected rows, data, column titles, and all

- find a way to toggle listening from the gaggle boss

*--------------------------------------------------------------------------------
* start tspaces on trickster, without webstart  (24 sep 2004)
start up a Terminal
cd ~/tspace
go -b  (if no previous checkpoints exist, or if you don't want to use them)
go (otherwise)
point browser at http://localhost:8201
*--------------------------------------------------------------------------------
* examples/jython/gaggle and client base class (24 sep 2004)
Goose.py is a very simple jframe with 2 button, which has a
GaggleMemberHelper.py; in all other regards it is a stand-alone swing application
a few quick modifications created
/users/pshannon/cy/csplugins/isb/pshannon/experimentNavigator/GaggleTreeDataBrowser.py

*--------------------------------------------------------------------------------
* gaggle in java (24 sep 2004)
made a tiny start (1 file of 30 lines) on a GaggleMember abstract base
class in /users/pshannon/work/org/systemsbiology/gaggle/GaggleMember
before reverting to jython, and creating the equivalent base class there.
*--------------------------------------------------------------------------------
* a good start, demo-able jython gaggle (23 sep 2004)
/users/pshannon/examples/jython/tspaceManagedApps/hide-and-show-threads/
Manager.py has these buttons:
select all, show, hide, hide others, refresh, tile, stagger, terminate
rename client window is incomplete, and presently hidden
new clients (from client.py) don't always show up in the manager's listbox
now turning to
/users/pshannon/examples/jython/gaggle
to create a client base class, and then (i hope) use this with a plotter,
datamatrixbrowser, cytoscape, kegg wbi, ....
Manager.py may work as is.
*--------------------------------------------------------------------------------
* halo marray data from nitin, dark2 & oxygen time series (24 sep 2004)
email sent   Wed, 22 Sep 2004 08:47:36 -0700
titled 'new circadian data (constant dark set II) as well as oxygen time series'
with message:

I think you know the meta-data information for the constant dark data.
We will have to discuss how to structure the meta-data information
for the oxygen-time series.

in discussion, nitin proposed simply numbering the columns ordinally
working in
/users/pshannon/data/halo/microarrayXml/
/users/pshannon/data/halo/microarrayXml/oxygenTimeSeries
/users/pshannon/data/halo/microarrayXml/circadian/dark2

/users/pshannon/data/halo/microarrayXml/circadian/dark2/halo_circadian_constant_dark_setII.mrna

/users/pshannon/data/halo/microarrayXml/oxygenTimeSeries/HLO1_ts.mrna
cp HL01_ts.mrna cooked.txt
deleted ^M's
added leading zero to 1-digit hour names:  HLO_1_ becomes HLO_01_
28 conditions, 60 columns (includes gene_name and sequence_name)
head -1 cooked.txt | tr '\t' '\n' | sort | uniq > titles
cp ../nickelCobalt-2004.09.03/createMatrices.py .
edit it to handle the actual conditions in these data
python createMatrices.py

-------- dark2
on db, cd /users/pshannon/data/halo/microarrayXml/circadian/dark2
cp halo_circadian_constant_dark_setII.mrna cooked.txt
added zero's to column titles to get good sorting
removed ^M's at end of all lines
head -1 cooked.txt | tr '\t' '\n' | sort | uniq > titles.txt
cp ../../oxygenTimeSeries/createMatrices.py .

moved dark2.* and oxygenTimeSeries.* to ~/haloweb/data; updated .permissions
*--------------------------------------------------------------------------------
* cy2 cvs cvsdir5, new instructions (23 sep 2004)
There are now 3 ways to access cytoscape cvsdir5 (and there may be a 4th
coming soon...)

1.  localhost:> cvs -d [:ext:]<user>@<bordeaux>:<cvsdir>
2.  localhost:> cvs -d :pserver:<user>@<bordeaux>:<cvsdir>
3.  bordeaux:> cvs blah

- Method 1, "ext" access still works and uses your bordeaux system
account information and passwd. Requires the environment variable
CVS_RSH is set to "ssh" and requires your bordeaux system passwd for
every cvs command (I think).

- Method 2, "pserver" will require adding a pserver passwd for
each member of the core developers (see below). Your cvs "session" would
consist of:

cvs -d :pserver:... login
cvs -d :pserver:... [commands]
cvs -d :pserver:... logout

- Method 3, logging onto bordeaux, still works but requires
environment variable CVSROOT is set to /common/cvsdir5 and requires
copying (scp'ing) files around. (primarily UCSD developers)

CREATING A PSERVER PASSWD:
Since Ryan and I have changed some things to allow anonymous cvs access,
looks like all the cvs writers using pserver method (2) will need to
follow this procedure to add themselves to the cvs passwd file.
Your pserver passwd does not need to be the same as your bordeaux system
passwd.

localhost:> ssh <user>@bordeaux.ucsd.edu
bordeaux:> /usr/local/sbin/cvsd-passwd /common/cvsdir5 +<user>

If you are using pserver, then login might look like this

localhost:> cvs -d :pserver:xmas@bordeaux.ucsd.edu:/common/cvsdir5 login
Logging in to :pserver:xmas@bordeaux.ucsd.edu:2401/common/cvsdir5
CVS password:

-Chris
*--------------------------------------------------------------------------------
* the long-deferred halo synonyms problem, continued (22 sep 2004)
todo: check with marc and nitin to see how many identical genes they
expect me to find.  isn't there a big chunk of the replicons
which are supposed to be identical?
moved all of cd /users/pshannon/data/halo/naming to trickster directory
of same name
(23 sep 2004) conversation with nitin.  he claims that there are
4 identical regions on the two small replicons, each with
30 genes.  test my techniques there....
*--------------------------------------------------------------------------------
* the long-deferred halo synonyms problem, continued (21 sep 2004)
on db, cd /users/pshannon/data/halo/naming
in discussing this with nitin, he pointed out that the duplicates i list
below (for instance: birL is the geneSymbol for orfs VNG0664G and VNG1535G)
do not include identical genes which have no gene symbol.
so he proposed:
do an all against all match on the full halo genome
there should be 2404 unique genes; 2600+ genes total
all legit genes start with ATG
end with TGA, TAG, or TAA
/usr/local/genome/bin/extract <dna-file> <coord-file>
for these files, see  http://halo.systemsbiology.net/halobacterium/data/
downloaded them into /users/pshannon/data/halo/naming

74672 Jul 26 10:37 chromosome_coordinates.txt
2669717 Jul 26 09:33 gene_sequence
6923 Jul 26 10:37 pnrc100_coordinates.txt
13107 Jul 26 10:37 pnrc200_coordinates.txt

extract is actually /usr/local/genome/Glimmer/glimmer2.02/extract

and is described at http://www.sacs.ucsf.edu/Resources/glimmer/
where the glim-extract README says:

Program glim-extract takes a FASTA format sequence file and a file
with a list of start/stop positions in that file  (e.g., as produced
by the  long-orfs  program) and extracts and outputs the
specified sequences.


the long-orfs format is   id, start position, end position
for example (grabbing just one orf from chromosome_coordinates.txt):
VNG0003C 2145 3251
/usr/local/genome/bin/extract gene_sequence junk.coord
produces: VNG0003C   atggcgtggc....
question:  does extract handle reverse sequences properly?  use these 3 test 'genes':
VNG0003C 2145 3251
VNG1957GR 1445883 1444129
VNG1957GF  1444129 1445883
1957 reverse  starts with  atgac,   ends with aacga
1957 forward  starts with  tcgtt,    ends with gtcat
are atgac & gtcat reverse complements?   yes  (a/t, g/c)
are aacga & tcgtt reverse complements?   yes
concluding: the extract program corrects for genes transcribed
in the reverse direction

do the work:
1) on db,  cd /users/pshannon/data/halo/naming
2)  awk -F'\t'  '{print $1, $3, $4}' chromosome_coordinates.txt > chromosome.coord
awk -F'\t'  '{print $1, $3, $4}' pnrc100_coordinates.txt    > pnrc100.coord
awk -F'\t'  '{print $1, $3, $4}' pnrc200_coordinates.txt    > pnrc200.coord
3) cat chromosome.coord pnrc100.coord pnrc200.coord  > all.coord
edit title lines out:  3 instances of 'canonical_Name Start Stop'
4) /usr/local/genome/bin/extract gene_sequence all.coord > all.sequence
5)  wc -l all.*
2627 all.coord
2627 all.sequence
6) formatdb -i all.sequence -p F  -> 'Formatted 2627 sequences in volume 0'
7) blast one gene:
blastall -p blastn -d ./all.fasta -i vng0664g.fasta -m0
Score    E
Sequences producing significant alignments:        (bits) Value

VNG0664G                                               1677   0.0
VNG6294G                                                 42   4e-04
VNG1327G                                                 42   4e-04
VNG0281G                                                 42   4e-04
...
VNG1535G                                                  40   0.001

previously, i had:

VNG0664G birL
VNG1535G birL

nitin says this
blastall -p blastn -d ./all.fasta -i all.fasta -m0 -e 0.1 > allAgainstAll.out
extract the perfect matches from this set (which took 5-10 minutes to run)
egrep '( 0.0 |Query=)'  allAgainstAll.out | head -100
[this works because
1) the ' 0.0 ' indicates a perfect match
2) 'Query=' picks out the name of the source sequence
3) the number of bits (2183, 2018, 5947, ...) is the number of bases
in the match

summarized
-----------

Query= VNG0085G
VNG0085G                                                             2183   0.0
VNG6097C                                                             2018   0.0
VNG5100C                                                             2018   0.0

Query= VNG0003C
VNG6007H                                                             2194   0.0
VNG5007H                                                             2194   0.0
VNG0003C                                                             2194   0.0

Query= VNG0011C
VNG6013G                                                             2795   0.0
VNG5013G                                                             2795   0.0
VNG0011C                                                             2795   0.0

Query= VNG0128C
VNG6136H                                                             1540   0.0
VNG5139C                                                             1540   0.0
VNG0128C                                                             1540   0.0

Query= VNG0171C
VNG6173C                                                             1427   0.0
VNG0171C                                                             1427   0.0

Query= VNG0190C
VNG0190C                                                             1903   0.0
VNG6199G                                                             1820   0.0

Query= VNG0231C
VNG0231C                                                             1404   0.0
VNG6250G                                                             1326   0.0

Query= VNG0255C
VNG0255C                                                             1142   0.0
VNG6270G                                                             1049   0.0

Query= VNG0309C
VNG6313G                                                             1576   0.0
VNG0309C                                                             1576   0.0

full result of egrep
--------------------


Query= VNG0085G
VNG0085G                                                             2183   0.0
VNG6097C                                                             2018   0.0
VNG5100C                                                             2018   0.0
Query= VNG1706G
Query= VNG0108G
VNG0108G                                                             5947   0.0
VNG6127H                                                             1927   0.0
VNG5131H                                                             1927   0.0
Query= VNG2575G
VNG2575G                                                             1065   0.0
Query= VNG0003C
VNG6007H                                                             2194   0.0
VNG5007H                                                             2194   0.0
VNG0003C                                                             2194   0.0
Query= VNG0011C
VNG6013G                                                             2795   0.0
VNG5013G                                                             2795   0.0
VNG0011C                                                             2795   0.0
Query= VNG0110C
VNG0110C                                                             1433   0.0
VNG6128H                                                              868   0.0
VNG5132H                                                              868   0.0
Query= VNG0128C
VNG6136H                                                             1540   0.0
VNG5139C                                                             1540   0.0
VNG0128C                                                             1540   0.0
Query= VNG0156C
VNG0156C                                                             1380   0.0
VNG5160H                                                              981   0.0
Query= VNG0171C
VNG6173C                                                             1427   0.0
VNG0171C                                                             1427   0.0
VNG5191H                                                              807   0.0
Query= VNG0189C
VNG0189C                                                             2849   0.0
VNG6196G                                                             1475   0.0
VNG5215H                                                             1174   0.0
VNG5213G                                                              938   0.0
Query= VNG0190C
VNG0190C                                                             1903   0.0
VNG6199G                                                             1820   0.0
VNG5215H                                                             1233   0.0
Query= VNG0222C
VNG0222C                                                             2498   0.0
VNG6237G                                                             1291   0.0
VNG5255H                                                             1096   0.0
VNG5256H                                                              868   0.0
VNG6235G                                                              648   0.0
Query= VNG0230C
VNG0230C                                                             3711   0.0
VNG6247G                                                             1380   0.0
VNG6244G                                                             1364   0.0
VNG6246G                                                              660   0.0
Query= VNG0231C
VNG0231C                                                             1404   0.0
VNG6250G                                                             1326   0.0
Query= VNG0247C
VNG0247C                                                             1796   0.0
VNG6261G                                                              979   0.0
VNG6262G                                                              735   0.0
Query= VNG0255C
VNG0255C                                                             1142   0.0
VNG6270G                                                             1049   0.0
Query= VNG0262C
VNG0262C                                                             2206   0.0
VNG6275H                                                              791   0.0
Query= VNG0268C
VNG0268C                                                             2153   0.0
VNG6281G                                                             1098   0.0
VNG6283H                                                              779   0.0
Query= VNG0270C
VNG0270C                                                             1814   0.0
VNG6284H                                                             1207   0.0
Query= VNG0274C
VNG0274C                                                             1195   0.0
Query= VNG0284C
VNG0284C                                                             3354   0.0
VNG6296C                                                             1951   0.0
Query= VNG0286C
VNG0286C                                                             2284   0.0
VNG6298C                                                             1179   0.0
VNG6297C                                                              868   0.0
Query= VNG0309C
VNG6313G                                                             1576   0.0
VNG0309C                                                             1576   0.0
Query= VNG0310C
VNG0310C                                                             2302   0.0
VNG6315G                                                             1754   0.0
Query= VNG0316C
VNG0316C                                                             1409   0.0
VNG6318G                                                              991   0.0
Query= VNG0351C
VNG0351C                                                             2551   0.0
VNG6347H                                                             1076   0.0
VNG6346H                                                              747   0.0
Query= VNG0354C
VNG0354C                                                             1522   0.0
Query= VNG0359C
VNG0359C                                                             1784   0.0

blastall -p tblastx -d ./all.fasta -i all.fasta -m0 -e 0.1 > allAgainstAllProtein.out
took about an hour
egrep '( 0.0  |Query=)'  allAgainstAllProtein.out > eValue0ProteinMatches
wc -l  allAgainstAllProtein.out eValue0ProteinMatches
4279063 allAgainstAllProtein.out
3943 eValue0ProteinMatches

which boils down to 132 perfect (or nearly perfect) protein homologs
compared to only 9 perfect nucleotide matches

*-------------------------------------------------------------------------------------------------
* meme mac osx segment fault problem from marc (21 sep 2004)

[resolution:  his 'gcc' command ran an older version.  explicitly calling gcc-3xx
solved the problem]

email titled 'here it is'
Here are the two files:  I have typed the following at the command line:
meme tfbftrialshort.chip -dna -mod zoops -maxw 30 -revcomp -bfile opUpstream.bg > out.html
This gives the segmentation fault error.
When I omit the -bfile opUpstream.bg it works fine.
I changed the GCC flags in the makefile from

GCC  = gcc -Wall -O3 #-g #-DEXP -pg -m64
to
GCC   = /usr/bin/gcc-3.3 -Wall -O3 -mcpu=970 -mtune=970  -mpowerpc64 -mpowerpc-gpopt

and happily show my true ignorance on the subject.  However, now I get
a "Bus error" instead.  I have no idea what is going on here. Ack.
Using the default compiler flags works fine with my G4 laptop.
place where I "learned" about the compiler flags:
http://developer.apple.com/technotes/tn/tn2086.html

got meme.3.0.10.tar.Z
opened it  to /Users/mpshannon/data/halo/meme/latest/src
cd /Users/mpshannon/data/halo/meme/latest
bin/install meme
bin/runtests ->  Passed all tests.

mkdir marc
cd marc
cp -p /users/pshannon/attachments/* .
../bin/meme tfbftrialshort.chip -dna -mod zoops -maxw 30 -revcomp -bfile opUpstream.bg > out.html

*--------------------------------------------------------------------------------
*--------------------------------------------------------------------------------
* the long-deferred halo synonyms problem (21 sep 2004)
from nitin:
the IP web start does not exhibit this problem:
http://db:8060/halo/ip/try2/cy.jnlp
it's data were created on trickster, cd /users/pshannon/data/halo/IP/2004.07.12/unitTests
from my notes below (* halo todo:  fixes to IP webstart (20,28 jul 2004))

1) 2 nodes for tbpC: these are different orfs, merge them in the
/users/pshannon/data/halo/IP/2004.07.12/PullDownResultSet.py

see PullDownResultSet.translationTable, a hash:

'tfbA': 'VNG2184G',
'tfbB': 'VNG0734G',
'tfbC': 'VNG6351G',
'tfbD': 'VNG0869G',
'tfbE': 'VNG6389G',
'tfbG': 'VNG0254G',
'tfbF': 'VNG0315G',

'tbpA': 'VNG5039G',
'tbpB_1': 'VNG5052G',
'tbpB_2': 'VNG5052G',
'tbpB': 'VNG5052G',
'tbpC': 'VNG5142G',
'tbpD': 'VNG5163G',
'tbpE': 'VNG2243G',
'tbpF': 'VNG6438G',
'bat': 'VNG1464G',

'tfeA': 'VNG0757G',

'VNG6037G': 'VNG5039G',  # tbpA
'VNG5245G': 'VNG5052G',  # tbpB
'VNG6050G': 'VNG5052G',  # tbpB
'VNG6476G': 'VNG5052G',  # tbpB

'VNG6140G': 'VNG5142G',  # tbpC

-> can geneSymbol names tell us which orfs have identical sequence?
cd /local/tomcat/webapps/cytoscape/annotation/halo
awk '{print $2}' synonyms | wc -l   -->    1069
awk '{print $2}' synonyms | sort | uniq | wc -l -->    1007

awk '{print $2}' synonyms | sort | uniq -D | sort |uniq | wc -l -->
43 geneSymbols have 2 or more occurrences

db.halo> cat duplicatedGeneSymbols
birL boa3 crt cydA cydB gvpA1 gvpC1 gvpD1 gvpE1 gvpF1 gvpG1 gvpH1 gvpI1 gvpJ1
gvpK1 gvpL1 gvpM1 gvpN1 gvpO1 hepA hsp5 htlD mcmA1 orc9 phoT1 pyrC rad25 repH
repI rpl13p rps14p rps27e sojA sojB sojC1 sojD tbpA tbpB tbpC trh trpS trxA1 trxB1

edit these into an egrep script, 'findAllSequenceDuplicatedOrfs',
finding 105 orf/gene pairs with duplicated gene names:

VNG0664G birL
VNG1535G birL
VNG5068G boa3
VNG5229G boa3
VNG6065G boa3
VNG6461G boa3
VNG5084G crt
VNG5213G crt
VNG6081G crt
VNG6445G crt
VNG5055G cydA
VNG5242G cydA
VNG6053G cydA
VNG6473G cydA
VNG5057G cydB
VNG5240G cydB
VNG6055G cydB
VNG6471G cydB
VNG5030G gvpA1
VNG6029G gvpA1
VNG5032G gvpC1
VNG6031G gvpC1
VNG5029G gvpD1
VNG6028G gvpD1
VNG5028G gvpE1
VNG6027G gvpE1
VNG5027G gvpF1
VNG6026G gvpF1
VNG5026G gvpG1
VNG6025G gvpG1
VNG5025G gvpH1
VNG6024G gvpH1
VNG5023G gvpI1
VNG6023G gvpI1
VNG5022G gvpJ1
VNG6022G gvpJ1
VNG5021G gvpK1
VNG6021G gvpK1
VNG5020G gvpL1
VNG6020G gvpL1
VNG5019G gvpM1
VNG6019G gvpM1
VNG5033G gvpN1
VNG6032G gvpN1
VNG5034G gvpO1
VNG6033G gvpO1
VNG5141G hepA
VNG6139G hepA
VNG0129G hsp5
VNG6201G hsp5
VNG5037G htlD
VNG6035G htlD
VNG0481G mcmA1
VNG0653G mcmA1
VNG5094G orc9
VNG6091G orc9
VNG5066G phoT1
VNG5231G phoT1
VNG6064G phoT1
VNG6462G phoT1
VNG0448G pyrC
VNG2533G pyrC
VNG5134G rad25
VNG6130G rad25
VNG5013G repH
VNG6013G repH
VNG5136G repI
VNG6132G repI
VNG1138G rpl13p
VNG1689G rpl13p
VNG1157G rps14p
VNG1706G rps14p
VNG0550G rps27e
VNG2047G rps27e
VNG5010G sojA
VNG6010G sojA
VNG5035G sojB
VNG6034G sojB
VNG5089G sojC1
VNG5208G sojC1
VNG6086G sojC1
VNG5126G sojD
VNG6123G sojD
VNG5039G tbpA
VNG6037G tbpA
VNG5052G tbpB
VNG5245G tbpB
VNG6050G tbpB
VNG6476G tbpB
VNG5142G tbpC
VNG6140G tbpC
VNG5078G trh
VNG5219G trh
VNG6075G trh
VNG6451G trh
VNG2208G trpS
VNG2232G trpS
VNG5076G trxA1
VNG5221G trxA1
VNG6073G trxA1
VNG6453G trxA1
VNG5077G trxB1
VNG5220G trxB1
VNG6074G trxB1
VNG6452G trxB1


*--------------------------------------------------------------------------------
* todo, tuesday
/users/pshannon/examples/jython/tspaceManagedApps/hide-and-show-threads
in Manager.py, put the JOptionPane in a proper dialog
*--------------------------------------------------------------------------------
* explore ecoli data for dave & rich (19 sep 2004)
cd  /users/pshannon/data/bicluster/eColi/cy
munpack dave's mail of (17 sep 2004), in which he said:

these are [prolinks] gene cluster (GC) and gene neighbor (GN) edges only.
gene cluster correspond most closely to operons.

wc -l *.sif

3024 prolinks_GC.sif
49586 prolinks_GN.sif

and the combined expression file (built up from the work described below
in '* prepare e.coli & etc microarray data for the biclusterer (16 sep 2004)'

~dreiss/ratios.table.txt.gz

R mangled the experiment names a bit, but it should be fine nonetheless.


*--------------------------------------------------------------------------------

*--------------------------------------------------------------------------------
* jython threads (20 sep 2004)
taken straight from chapter 4, p103 of Robert Bill's jython book
cd /users/pshannon/examples/jython/threads/simple

*--------------------------------------------------------------------------------
* jython/tspace experiments for a gaggle window manager (20 sep 2004)
/users/pshannon/examples/jython/tspaceManagedApps/hide-and-show-noThreads
- make sure a tspace is running
- in one shell:  jython -i Mangaer.py
- in another:
jython -i client.py
f = MyFrame ('yojo')
see that 'yojo' appears in the managers listbox; when selected,
it will hide or show.  the 'tile' button doesn't work yet.
*--------------------------------------------------------------------------------
* accomodate new circadian condition names in inferelator control panel
light2.xml, X.xml both have new labels on the columns
*--------------------------------------------------------------------------------
* new version of the light2 halo circadian data (17 sep 2004)
(nitin found that the old circadian data, now called 'light2', had been
filtered, leaving out some genes present in the brand new 'dark1' loaded
yesterday.  see below
'* creating standard matrix and xml metadata from halo dark1 data (16 sep 2004)'
and
'* new (and very old) circadian data from nitin (15 sep 2004)

nitin email today:

I figured why there are missing rows in the Light2 circadian data set.
The file in the condition chooser is a lambda filtered set.  I am
sending you a non-filtered set to replace the existing Light2 set.

I stumbled across this issue when I was using the jython script and (I
think) it was selecting genes with no lambda values as well!

the work:
munpacked 'merge_unscaled_all.mrna' into
/users/pshannon/data/halo/microarrayXml/circadian/raw
changed it to merge_unscaled_all.light2.mrna.
cd /users/pshannon/data/halo/microarrayXml/circadian/light2
cp -p ../raw/merge_unscaled_all.light2.mrna light2.mrna
remove ^M's from light2.mrna
cp ../dark1/createMatrices.py .

fussed with this for a while, got it to work, and then (gilding the lily)
if encountered a bug as I tried to include and load both old and new
versions of this light2 data.  the old was X, and by the time I did
this, both had the same name in their xml descriptions. here is
the fixed versions:

light2.xml:<experiment name="circadian rhythms, light 2" date="2004-03-01">
X.xml:<experiment name="circadian rhythms, light 2, old, with missing data" date="2004-03-01">

to handle this, i made a small change to MetaDataNavigator.loadXmlFiles:

if (self.nameToExperimentsHash.has_key (name)):
msg = "warning!  skipping duplicate experiment name ('%s') from file %s\n" % (name, file)
#raise NameError, msg
sys.stderr.write (msg)
else:
self.nameToExperimentsHash [name] = experiment

i abandoned the exception strategy becuase i did not (and do not) know how
to continue the original flow after the exception has been handled.
look into this...

*--------------------------------------------------------------------------------
* current halo network, with lambda pattern selection scripts (17 sep 2004)

start via jws, at db:8060
everything is in   ~/haloweb/scriptingExperiment/try0
including __run__.py, which is automatically launched with the
data matrix browser's jython button
type 'help ()' to see what commands are available



*--------------------------------------------------------------------------------
* cy 2 anonymous cvs access (16 sep 2004)
from chris workman
cvs -d :pserver:anonymous@bordeaux.ucsd.edu:/common/cvsdir5 login
cvs -d :pserver:anonymous@bordeaux.ucsd.edu:/common/cvsdir5 co <src-dir>

*--------------------------------------------------------------------------------
* prepare e.coli & etc microarray data for the biclusterer (16 sep 2004)
dave's email:
I put some of the data in ~dreiss/marray.data .
All of the e.coli data is there, and a subset of the data for the other
3 species that we are likely to want to do. Feel free to copy it to a
local disk and/or gunzip it, and/or whatever else you might need.
They are not excel files, even though for some reason they have the xls
extension. They are Stanford Microarray Database files, for which I
don't know what the "standard" is but they might have a description
somewhere on their website.

strategy, for e.coli
on trickster, cd ~/data/bicluster
cp'd all of david's data to ~/data/bicluster/fromStanford
in ~/data/bicluster/eColi:
python ../parseAll.py
which
traverses all of the files in ../fromStanford/e.coli
skips over the header lines (which begin with '!')
looks for the column number of 'name'  and either of
'log_rat2n_mean' or 'log(base2) of r/g normalized ratio (mean)'
uses these column numbers to extract those columns from the following lines,
eliminating funny gene names (they all need to have the from Bnnnn) and
genes for which there is no ratio reported.

as a last step, a simple script 'grabExperimentNames.py' traverses the
same directory, and prints to stdout

print '%s\t%s' % (filename, experimentName')

where that experiment name is found in the file with a stanford standard
header keyword like this:

!Experiment Name=10min after UVtreatment 1', 40J, MG1655 in Davis+0.4%glu



*--------------------------------------------------------------------------------
* creating standard matrix and xml metadata from halo dark1 data (16 sep 2004)

cd /users/pshannon/data/halo/microarrayXml/circadian/dark1
cp ../../marc/linearLayout/2004.09.10/createMatrices.py .
cp -p ../raw/NRC1_circ_const_dark_setI.mrna dark1.mrna
db.dark1> head -1 dark1.mrna | tr '\t' '\n' | sort | uniq | grep Dark1
Dark1_0_vs_NRC-1c.sig
Dark1_8_vs_NRC-1c.sig
Dark1_12_vs_NRC-1c.sig
Dark1_16_vs_NRC-1c.sig
Dark1_20_vs_NRC-1c.sig
Dark1_24_vs_NRC-1c.sig
Dark1_28_vs_NRC-1c.sig
Dark1_32_vs_NRC-1c.sig
Dark1_36_vs_NRC-1c.sig
Dark1_40_vs_NRC-1c.sig
Dark1_44_vs_NRC-1c.sig
Dark1_48_vs_NRC-1c.sig
Dark1_4_vs_NRC-1c.sig
Dark1_52_vs_NRC-1c.sig
Dark1_56_vs_NRC-1c.sig
Dark1_60_vs_NRC-1c.sig
Dark1_64.5_vs_NRC-1c.sig
Dark1_68.5_vs_NRC-1c.sig
Dark1_68.5_vs_NRC-1c.sig

created these substitution variables:

titlesToGrab1 = ['sequence_name',
'Dark1_0_vs_NRC-1c.sig',
'Dark1_8_vs_NRC-1c.sig',
'Dark1_12_vs_NRC-1c.sig',
'Dark1_16_vs_NRC-1c.sig',
'Dark1_20_vs_NRC-1c.sig',
'Dark1_24_vs_NRC-1c.sig',
'Dark1_28_vs_NRC-1c.sig',
'Dark1_32_vs_NRC-1c.sig',
'Dark1_36_vs_NRC-1c.sig',
'Dark1_40_vs_NRC-1c.sig',
'Dark1_44_vs_NRC-1c.sig',
'Dark1_48_vs_NRC-1c.sig',
'Dark1_4_vs_NRC-1c.sig',
'Dark1_52_vs_NRC-1c.sig',
'Dark1_56_vs_NRC-1c.sig',
'Dark1_60_vs_NRC-1c.sig',
'Dark1_64.5_vs_NRC-1c.sig',
'Dark1_68.5_vs_NRC-1c.sig',
'Dark1_68.5_vs_NRC-1c.sig']


titlesToGrab2 = ['sequence_name',
'Dark1_0_vs_NRC-1c.sig.dup',
'Dark1_8_vs_NRC-1c.sig.dup',
'Dark1_12_vs_NRC-1c.sig.dup',
'Dark1_16_vs_NRC-1c.sig.dup',
'Dark1_20_vs_NRC-1c.sig.dup',
'Dark1_24_vs_NRC-1c.sig.dup',
'Dark1_28_vs_NRC-1c.sig.dup',
'Dark1_32_vs_NRC-1c.sig.dup',
'Dark1_36_vs_NRC-1c.sig.dup',
'Dark1_40_vs_NRC-1c.sig.dup',
'Dark1_44_vs_NRC-1c.sig.dup',
'Dark1_48_vs_NRC-1c.sig.dup',
'Dark1_4_vs_NRC-1c.sig.dup',
'Dark1_52_vs_NRC-1c.sig.dup',
'Dark1_56_vs_NRC-1c.sig.dup',
'Dark1_60_vs_NRC-1c.sig.dup',
'Dark1_64.5_vs_NRC-1c.sig.dup',
'Dark1_68.5_vs_NRC-1c.sig.dup',
'Dark1_68.5_vs_NRC-1c.sig.dup']

preferredTitles = ['GENE',
'Dark1_000_vs_NRC-1c',
'Dark1_004_vs_NRC-1c',
'Dark1_008_vs_NRC-1c',
'Dark1_012_vs_NRC-1c',
'Dark1_016_vs_NRC-1c',
'Dark1_020_vs_NRC-1c',
'Dark1_024_vs_NRC-1c',
'Dark1_028_vs_NRC-1c',
'Dark1_032_vs_NRC-1c',
'Dark1_036_vs_NRC-1c',
'Dark1_040_vs_NRC-1c',
'Dark1_044_vs_NRC-1c',
'Dark1_048_vs_NRC-1c',
'Dark1_052_vs_NRC-1c',
'Dark1_056_vs_NRC-1c',
'Dark1_060_vs_NRC-1c',
'Dark1_064.5_vs_NRC-1c',
'Dark1_068.5_vs_NRC-1c',
'Dark1_068.5_vs_NRC-1c']
ran make
cp ~/haloweb/data/X.xml dark1.xml
head -1 dark1.ratio   --> use these to modify dark1.xml
cp -pv dark1.[rl]* ~/haloweb/data
in a new shell:
cd ~/cy/csplugins/isb/pshannon/experimentNavigator/
edit TreeDataBrowser.py, adding this line:
repository = 'file:///users/pshannon/data/halo/microarrayXml/circadian/dark1'
make tree
[encountered some funny business with two entries
for 'Dark1_068.5_vs_NRC-1c', perhaps due to a DOS control-r
at the end of line.  fixed this manually]

cp -pv dark1.xml ~/haloweb/data
add to ~/haloweb/data/.permissions
*--------------------------------------------------------------------------------
* new (and very old) circadian data from nitin (15 sep 2004)
nitin's email:

the files:
/users/pshannon/data/halo/microarrayXml/circadian/raw:

576189 Sep 15 17:12 NRC1_circ_const_dark_setI.mrna
100818 Sep 15 17:12 halocircadian_nrc1.xpr
18710 Sep 15 17:12 image001.gif


This is the new circadian data I was telling you about at the retreat.
Can you put this into the data-matrix browser when you find time?  The
column headers indicate the experimental condition.

Unlike the last set that is already in the data

Dark1_0_vs_NRC-1c.sig : 0 hours
Dark1_4_vs_NRC-1c.sig : 4 hours
Dark1_8_vs_NRC-1c.sig : 8 hours
Dark1_12_vs_NRC-1c.sig
Dark1_16_vs_NRC-1c.sig
Dark1_20_vs_NRC-1c.sig

The other file is Light1 circadian data conducted three years ago with
the cDNA array.


/users/pshannon/data/halo/microarrayXml/circadian/raw/NRC1_circ_const_dark_setI.mrna  column names:

gene_name
sequence_name
Dark1_0_vs_NRC-1c.sig
Dark1_4_vs_NRC-1c.sig
Dark1_8_vs_NRC-1c.sig
Dark1_12_vs_NRC-1c.sig
Dark1_16_vs_NRC-1c.sig
Dark1_20_vs_NRC-1c.sig
Dark1_24_vs_NRC-1c.sig
Dark1_28_vs_NRC-1c.sig
Dark1_32_vs_NRC-1c.sig
Dark1_36_vs_NRC-1c.sig
Dark1_40_vs_NRC-1c.sig
Dark1_44_vs_NRC-1c.sig
Dark1_48_vs_NRC-1c.sig
Dark1_52_vs_NRC-1c.sig
Dark1_56_vs_NRC-1c.sig
Dark1_60_vs_NRC-1c.sig
Dark1_64.5_vs_NRC-1c.sig
Dark1_68.5_vs_NRC-1c.sig


/users/pshannon/data/halo/microarrayXml/circadian/raw/halocircadian_nrc1.xpr column names

GENE
DESCRIPT
R_vs_1.sig
R_vs_2.sig
R_vs_3.sig
R_vs_4.sig
R_vs_5.sig
R_vs_6.sig
R_vs_7.sig
R_vs_8.sig




*--------------------------------------------------------------------------------
* jfreechart, jcommon, and a modest change to ScatterPlotter.py
the halo webstarts use these jars:

275141 May  5 11:22 jcommon-0.9.0.jar
594899 May  5 11:22 jfreechart-0.9.15.jar

changed ~/csplugins/isb/pshannon/experimentNavigator/ScatterPlotter.py so
that it converts java.lang.Double.NaN to python None.
creating ScatterPlotter version 1.3
*--------------------------------------------------------------------------------
* add tfbF to the halo data store (10 sep 2004)
cd /users/pshannon/data/halo/marc/linearLayout
mkdir 2004.08
munpacked email attachment ('tfbF_cmyc.chip' 10 sep 2004, from marc)
now convert this pipeline output to simple cytoscape matrices
cp  ../2004.08.31/createMatrices.py .
cp -p tfbF_cmyc.chip tfbF_cmyc.chip.orig
chmod 444 *.orig
deleted last line of tfbF_cmyc.chip

titlesToGrab1   = ['primer_forward_name',
'tfbF_IP_vs_tfbF_wce.sig']
titlesToGrab2   = ['primer_forward_name',
'tfbF_IP_vs_tfbF_wce.sig.dup']
preferredTitles = ['Tile',
'tfbF_IP_vs_tfbF_wce']
outputFileBaseName = 'tfbF-cmyc'

python createMatrices.py
tfbF_IP_vs_tfbF_wce.sig.dup: 3
tfbF_IP_vs_tfbF_wce.sig: 2
columnsToGrab: ['primer_forward_name', 'tfbF_IP_vs_tfbF_wce.sig']
columnsToGrab: ['primer_forward_name', 'tfbF_IP_vs_tfbF_wce.sig.dup']

cp ~/haloweb/data/tfbE-cmyc.xml tfbF-cmyc.xml
edit tfbF-cmyc.xml

db.2004.09.10> wc -l tfbF-c*
4984 tfbF-cmyc.lambda
4984 tfbF-cmyc.ratio
21 tfbF-cmyc.xml
9989 total


ediged

created:
4785 tfbE-cmyc.lambda
4785 tfbE-cmyc.ratio
with identical first rows:
Tile	tfbE_IP_vs_tfbE_wce
in preparation for creating an xml file for these data:
cp ~/tomcat/server1/webapps/halo/data/tfb-ABC-cmyc.xml tfbE-cmyc.xml
made a few changes, copied to

*--------------------------------------------------------------------------------
* added 'broadcast all' button to inferelator (10 sep 2004)
version 1.4 of ~/haloweb/inferelator/2004.sep02/__run__.py

*--------------------------------------------------------------------------------
* jython/tspaces problem fixed (10 sep 2004)

symptom: could not load com.ibm.tspaces into jython console launced from
a cy1 console

problem seems to have been due to out-of-date files is csplugins/trial/pshannon/spy
what's needed for a working version:
see webstart /users/pshannon/haloweb/scriptingExperiment/tspace/cy.jnlp
jars needed:
850264 Aug 16 13:35 ../../jars/jython-lib.jar
742104 May  5 11:22 ../../jars/jython.jar
2187 Aug 16 13:35 ../../jars/jythonHack.jar
12070 Sep 10 15:57 ../../jars/pythonconsoleplugin.jar
30187 Jul 16 10:31 ../../jars/spyconsole.jar

<jar href="cytoscape.jar"/>
<jar href="data.jar"/>
<jar href="TreeDataBrowserPlugin.jar"/>
<jar href="scripts.jar"/>
<jar href="../../jars/jcommon-0.9.0.jar"/>
<jar href="../../jars/jfreechart-0.9.15.jar"/>
<jar href="../../jars/tspaces_fixes.jar"/>
<jar href="../../jars/tspaces_client.jar"/>
<jar href="../../jars/JRclient-RE321.jar" />
<jar href="../../jars/jython.jar"/>
<jar href="../../jars/spyconsole.jar"/>
<jar href="../../jars/jython-lib.jar"/>
<jar href="../../jars/jythonHack.jar"/>
<jar href="../../jars/pythonconsoleplugin.jar"/>

*--------------------------------------------------------------------------------
* create retreat 2004 poster (10 sep 2004)
1) bring up full cy inferelator
2) open the control panel
3) select nodes explicitly: tfbe
(capture control panel & full cy inf network)
4) with tfbe selected, get first neigbors twice, ^n to new window,
do hierarchical layout  (100 nodes, 183 edges)
5) two approaches, yielding either 14 or 21 clusters:
14: select tfbE, do first neighbors, invert selection, hide, see
15 directly controlled clusters
21: select tfbE, select first neighbors, manually add in the 7 additional
(not yet selected)  clusters, invert, hide

6) create gene lists from these two sets of clusters:
with all clusters selected, popup the node browser, choose 'clusterGenes'
and export.  after emacs-ing (cleanup, sort | uniq)
/users/pshannon/tmp/allGenesIn21TfbEClusters: 265 genes
allGenesin14TfbEClusters: 178 genes
7) startup tile viewer. from plugins, load data browser, load tfbE, open
jython console, automatically get the 'marc' control panel.
set lambda slider to 34, gene distance slider to 200
142 tiles selected
66 genes additionally selected after 'Select Genes'
8) startup halo network viewer
9) broadcast from tile viewer:
66 genes recognized in network
3 genes recognized by KEGG:
hal00860 Porphyrin and chlorophyll metabolism
VNG1573G        cbiA; cobyrinic acid a,c-diamide synthase [SP:COBB_HALN1]
hal03022 Basal transcription factors
VNG6351G        tfbC; transcription initiation factor IIB [SP:TFB3_HALN1]
VNG6389G        tfbE; transcription initiation factor IIB [SP:TFB5_HALN1]
10) put these 66 genes into a new window
11) select from file clusterGenes file.  19 nodes are selected.
none of these have annotation.  they are:


VNG6143H VNG6355H VNG6367H VNG6368H VNG6371G VNG6384H VNG6385H VNG6387H
VNG6400H VNG6404H VNG6406H VNG6407H VNG6408G VNG6409H VNG6412H VNG6413H
VNG6416H VNG6430C

6416H is an overlap gene -not- found in the 14 cluster set



*--------------------------------------------------------------------------------
nitin's text for the poster:

Here we demonstrate the power of our
integrative systems approach.

We selected all biclusters under the control of the general
transcription factor TfbE.  These genes are all co-regulated in the
following conditions (list conditions).  The genes were broadcasted
using Gaggle to all other Cytoscape windows.  This identified 18 genes
that are both downstream to TfbE-binding sites in the genome (as
determined by ChIP-chip) as well as TfbE-regulated genes (as
determined through analysis of the microarray data by the biclusterer
and inferelator).  The likelihood of random occurrence of this overlap
in the two datasets is 1.725e-05.  Several of these genes are also
associated in the Halobacterium sp. association network.

Remarkably, only a few of the 18 genes had annotated functions as
shown by the results of the broadcasted search to the KEGG
encyclopedia.  The genes of unknown function in fact all localize to
the same region of the genome as does tfbE.  This region of the genome
appears to be a prophage remnant as determined by functional
annotation studies conducted through Rosetta structure determination.

Furthermore, TfbE also regulates another general transcription factor
-TfbC suggesting a complex intra-transcription factor regulation
network which may lie at the heart of the Halobacterium sp. gene
regulatory circuit.  We gain further insights into this complex
regulation of transcription factors through analysis of the
protein-protein interaction network determined by the MS/MS analysis
of proteinA-tagged transcription factor protein complexes


*--------------------------------------------------------------------------------
* inferelator/ChIP-chip discovery?  (9 sep 2004)
find the overlap fo genes regulated by tfbE
178 genes from the inferelator, in 14 clusters
ChIP-chip: 142 tiles enriched by E over lambda 34
208 selected nodes with gene selection distance set to 100:
66 genes
what is the overlap?  18
david says:
the prob. of getting an overlap of 18 at random has a p-value of 1.725e-05

but with only 331 genes in the 200 replicon, p-value may go down by order
of magnitude.

(but what's the spread of the 66 genes? all in pnrc200?)

the 18 genes:
VNG6143H VNG6355H VNG6367H VNG6368H VNG6371G VNG6384H VNG6385H VNG6387H VNG6400H VNG6404H
VNG6406H VNG6407H VNG6408G VNG6409H VNG6412H VNG6413H VNG6429H  VNG6430C

VNG6355H
VNG6367H
VNG6371G
VNG6384H
VNG6385H
VNG6387H
60VNG6404H
VNG6408G
VNG6409H
VNG6429H
VNG6430C




how are these distributed across the 14 clusters?
cd /users/pshannon/data/halo/biclusters/tfbE-regulation-with-ChIPchip
python findDistribution.py
conditions
cluster 214: 12   found:    5.56%      52
cluster  22:  8   found:    5.56%      57
cluster 206: 45   found:   22.22%      51
cluster  44: 12   found:   22.22%      61
cluster  49: 10   found:    5.56%      54
cluster  40:  4   found:   11.11%      58
cluster 296: 10   found:    0.00%
cluster 275: 10   found:    5.56%      65
cluster 134: 14   found:    5.56%      52
cluster 102: 10   found:    0.00%
cluster 129: 37   found:    0.00%
cluster 160:  9   found:   38.89%      67
cluster 302: 11   found:    5.56%      65
cluster  78: 14   found:    0.00%

*--------------------------------------------------------------------------------
* inferelator/ChIP-chip discovery?  (8 sep 2004)
hypothesis:
find cluster controlled by a tfb
genes in that cluster will be well-represented in those predicted to
be transcribed by that tfb, using the tile/ChIP-chip viewer
some stats:

tfb gene     first neighbor count (inlcludes cluster nodes)
--------     -----------------------------------------------
B           42
C            5
D            2
E           26
F           13
G           66

try 2:
-----------------
1) select all genes starting with tfb
2) set the inferelator control panle slider to 0.410
3) two clusters survive:
tfbE and GAMA -> 205
tfbF and tfbB -> 169

try 1:
-----------------
attracted to tfbD by the small number of neighbors
used the 'Select Cluster Matrix' in the Inferelator Control Panel
got 15 genes
only one of these (epf1, VNG2512G) neighbors on the 705 tiles selected
with lambda > 50)


*--------------------------------------------------------------------------------
* viewalator cont. (7 sep 2004)
db:/users/pshannon/haloweb/inferelator/2004.sep02

db.2004.sep02> wc -l conditionRep*
87 conditionRepair.fromXml.tmp
142 conditionRepair.tmp

the goal is to create a hash in __run__.py, fixConditionName
which turns all appropriate entries in conditionRepair.tmp (from rich)
into the precise spelling found in conditionRepair.fromXml.tmp

question:  why are there only 87 conditions in  conditionRepair.fromXml.tmp?
answer:  because i was drawing from an obsolete collection of xml
here's the right place:
grep alias ~/haloweb/data/*.xml | wc -l  ->  171

cat conditionRepair.fromInferelator conditionRepair.fromXml.tmp | sort | uniq > conditionsCombined
cp conditionRepair.fromInferelator inferelator.conditions
cp conditionRepair.fromXml.tmp xml.conditions

python tag.py > tagged.conditions

*--------------------------------------------------------------------------------
* rewrite dataMatrix package (7 sep 2004)
continue working in
/users/pshannon/cy/csplugins/isb/pshannon/dataMatrix/unitTests
make 0 (DataMatrixTest)
make 1 (LensedDataMatrixTest)  more & clearer tests needed
*--------------------------------------------------------------------------------
* cvs checkin of   /users/pshannon/cy2/csplugins/isb/pshannon/dataMatrix (7 sep 04)
this is the old crufty version, used to create the publicly released cy2
DataMatrixPlugin
*--------------------------------------------------------------------------------
* viewalator, next up (3 sep 2004)
add a broadcast button to the control panel which
gets all selected nodes
expands cluster nodes to their contained genes
broadcasts the results
add a 'view cluster profiles' button which talks directly
to the dmb, a la  the button in the dmb

*--------------------------------------------------------------------------------
* add halo cobalt and nickel microarray data   (3 sep 2004)
from eamil (2 sep 2004)

We just got new metal data!  This is for cobalt [control (0mM), 0.2mM,
0.3mM and 0.5mM)] and nickel [control (0mM), 0.5mM, 0.75mM and 1.5mM).
/users/pshannon/data/halo/microarrayXml/nickelCobalt-2004.09.03/halo_Ni_Co.mrna

with these titles:

gene_name       sequence_name
Co_C_vs_NRC-1c.sig, Co_0.2_vs_NRC-1c.sig, Co_0.3_vs_NRC-1c.sig, Co_0.5_vs_NRC-1c.sig,
Ni_C_vs_NRC-1c.sig, Ni_0.5_vs_NRC-1c.sig, Ni_0.75_vs_NRC-1c.sig, Ni_1.5_vs_NRC-1c.sig,
Co_C_vs_NRC-1c.sig, Co_0.2_vs_NRC-1c.sig, Co_0.3_vs_NRC-1c.sig, Co_0.5_vs_NRC-1c.sig,
Ni_C_vs_NRC-1c.sig, Ni_0.5_vs_NRC-1c.sig, Ni_0.75_vs_NRC-1c.sig, Ni_1.5_vs_NRC-1c.sig

strategy:  create 6 files:
[cobalt nickel] [.xml .ratio .lambda]

sequence_name (in column 2) uses orfs throughout

cp -p ../gamma-2004.09.02/createMatrices.py  .
edit to create ratios and lambdas for cobalt, and duplicate this code to create
the same pair of files for nickel

create xml files:
cp ~/haloweb/data/copper.xml nickel.xml
cp ~/haloweb/data/copper.xml cobalt.xml

after first pass, and first look at the data in the tree data matrix browser,
i saw that 'Co_C' and 'Ni_C' are sorted after the columns with explicit
concentrations in the titles.  with nitin's consent, i changed these to
Co_0.0 and Ni_0.0 respectively.
*--------------------------------------------------------------------------------
* creating a control panel for inferelator jws (2 sep 2004)
cd ~/haloweb/inferelator/2004.sep02/
working in test.py
continue in SliderComponent.hideEdgesCallback ()
draw upon the edge hiding worked out in ~/haloweb/ip/try2/filter.py
including hideOrphans (do this after edges are hidden)
*--------------------------------------------------------------------------------
* inferelator prep for jws (2 sep 2004)
on trickster:
cd /users/pshannon/data/halo/biclusters/2004.08.26/unitTests/cy
(cd ..; make 1)
cy -p project

*--------------------------------------------------------------------------------
* nitin requests update to gamma microarray data (2 aug 2004)

email:
If it isn't too much work can you update the gamma radiation data to
include some time points that are currently missing?  I am attaching a
file with this data.  There is no need to change the existing meta-data
structure for this experiment.  I have added "gamma-" in front of all
the data column headers to avoid confusion with UV-radiation data.

munpack'd email attachment to
~/data/halo/microarrayXml/gamma-2004.09.02/halo_gamma_all_20040504_215646.mrna

munpacked email attachment ('tfbE' 30 aug 2004, from marc)
now convert this pipeline output to simple cytoscape matrices
into ~/data/halo/marc/linearLayout/2004.08.31/tfbE_cmyc.chip
cp -p ~/data/halo/marc/linearLayout/2004.08.24/createMatrices.py .

edited createMatrices, updated ~/haloweb/data/gamma.xml, everything seems ok.

*--------------------------------------------------------------------------------
* next up for the inferelator (1 sep 2004)
cd /users/pshannon/data/halo/biclusters/2004.08.26/unitTests
the next task is to extend R2Cytoscape.writeProject so that
numberOfConditions
numbeOfGenes
are written out as attributes for each cluster node.
these values come from the Cluster object
need to (on the fly) add these for each cluster, the index of which comes
from the influencesString.  construct a Cluster using that number, get
the cols & rows, append to (new variables)
self.conditionCountAttribute
self.geneCountAttribute
*--------------------------------------------------------------------------------
* halo tiles, genes, etc, an overview of current practice (1 sep 2004)

cd /users/pshannon/data/halo/marc/linearLayout/current

data:
allHaloGenes.txt                106738 Sep  1 13:14   (2680 lines)  (has genes & RNA)
insertionElements.txt             2569 May  2 20:12   (96 lines)
tiles.txt                      2872989 Apr  6 16:05   (4812 lines)

code:
6802 May  2 17:34 GenesToGml.py
7667 May  2 20:12 InsertionElementsToGml.py
8742 Apr 16 15:02 TilesToGML.py
2521 Sep  1 13:34 combineAllToGml.py

in this directory, 'make' will create a new cytoscape project in
directory 'cy', with 20 node attribute files, and one network.gml

in unitTests:
make genes
make insertion
make tiles
each test the parsers and cy writers.

marc's rna coordinates were added to allHaloGenes.txt, after some editing.
the fruit of this work is now the default 'Marc's PCR tiles, with RNA' webstart
at db:8060/halo, in actual directory
/users/pshannon/tomcat/server1/webapps/halo/tiles
*--------------------------------------------------------------------------------
* add rna to tiles display, for marc (31 aug 2004)
found (3 jun 2004) mail from marc titled 'rRNA' table
munpacked to ~/data/halo/marc/linearLayout/rna/rnatab.txt
"Here are coordinates for more components that need to be incorporated
into the genome browser."

see below: * (15 apr 2004) getting back to marc's replicon-separated pcr tile display

/users/pshannon/data/halo/marc/linearLayout/src/unitTests
make tiles
looks like 'testSegregateReplicons' is a not-yet-used method
intended to separate the replicions on display.

detective work:  how did i do this the last time?
dir ~/haloweb/tiles/network.gml:  549175 May  2 20:35
apparently created by
/users/pshannon/data/halo/marc/linearLayout/2004.04.30/combineTileInfoGenesAndInsertionElements.py
2310 May  2 20:35 combineTileInfoGenesAndInsertionElements.py

this script reads 3 files, extracts nodes from each, extracts or infers
node attributes for each, and then creates gml & noa files.
here are the file names with 1st line of data:

../tiles.txt
Plate                          1
Row			       A
Column			       1
primer_forward_name	       Chr_1_F
primer_forward_sequence	       ttgacccactgaatcacgtc
primer_reverse_name	       Chr_1_R
primer_reverse_sequence	       cgtcgccgcgcagcgtgacc
Start			       1
Stop			       500
Source1			       2
Source2			       4
Flag (N)
Flag (F)
Gel_File
Gel_number
Gel_Row
Sample_number
regulatory_motif
sequence                       ttga...


../allHaloGeneCoordinates.txt
canonical_Name	Gene_Name	Start	Stop	Orientation	replicon
VNG0085G	moaA	73639	74739	For	Chr

../insertionElements.txt
replicon	Start	Stop	ISH ELEMENT	INTERRUPTED BY
pNRC100	1718	5019	ISH7
pNRC100	12662	14061	ISH3

../allHaloGeneCoordinates.txt
canonical_Name Gene_Name       Start   Stop    Orientation      replicon
VNG0085G       moaA            73639   74739   For              Chr
VNG1957G       tgtA2           1445883 1444129 Rev              Chr
VNG1959G       tgtA1           1447422 1445950 Rev              Chr


the new rna 'genes' have this format:
Ribosomal RNAs     Location      Gene           Product

459888..460192   -   rrt  7s RNA
1875505..1876977  +   rrs  16S ribosomal RNA
1877506..1880411  +  rrlA  23S ribosomal RNA
1880522..1880644  +  rrlB  5S ribosomal RNA

Transfer RNAs     Location       Gene  Product

95227..95300    -   trn1  tRNA-Phe
103358..103431   -   trn2  tRNA-Val

reformat them to fit the genes format, then added them to the bottom of the
allHaloGeneCoordinates.txt creating
/users/pshannon/data/halo/marc/linearLayout/current/allHaloGenes.txt
see 'halo tiles, genes, etc, an overview of current practice' above

*--------------------------------------------------------------------------------
* gene selection in ChIP-chip halo tiled data display (31 aug 2004)
my algorithm doesn't seem quite right.  for example
in the cmyc1_vs_cmyc1 slider (run marc () when jython window comes up)
select everything over the maximum: 103
fixes:
made change for this in ~/tomcat/server1/webapps/halo/tiles/__run__.py
added distance slider
made sure that any gene which starts within a selected tile is itself
always selected
*--------------------------------------------------------------------------------
* add tfbE to the halo data store (31 aug 2004)
tfb-ABC-cmyc  added 27 aug
tbpE_tfbD.xml        6 jun
tfbG_tbpB.xml        6 jun
cd /users/pshannon/data/halo/marc/linearLayout
mkdir 2004.08.31
munpacked email attachment ('tfbE' 30 aug 2004, from marc)
now convert this pipeline output to simple cytoscape matrices
into ~/data/halo/marc/linearLayout/2004.08.31/tfbE_cmyc.chip
cp ../2004.08.24/createMatrices.py .
cp -p tfbE_cmyc.chip tfbE_cmyc.chip.orig
chmod 444 tfbE_cmyc.chip.orig
deleted last line of tfbE_cmyc.chip
made these customizations to a copy of createMatrices.py, copied from ../2004.08.24
if (file == 'tfbE_cmyc.chip'):
titlesToGrab1   = ['primer_forward_name',
'tfbE_IP_vs_tfbE_wce.sig']
titlesToGrab2   = ['primer_forward_name',
'tfbE_IP_vs_tfbE_wce.sig.dup']
preferredTitles = ['Tile',
'tfbE_IP_vs_tfbE_wce']
outputFileBaseName = 'tfbE-cmyc'

make
created:
4785 tfbE-cmyc.lambda
4785 tfbE-cmyc.ratio
with identical first rows:
Tile	tfbE_IP_vs_tfbE_wce
in preparation for creating an xml file for these data:
cp ~/tomcat/server1/webapps/halo/data/tfb-ABC-cmyc.xml tfbE-cmyc.xml
made a few changes, copied to

*--------------------------------------------------------------------------------
*  next up:  complete unit test in
get marc's rna data into the cytoscape tile map.  shrink space between
chromosomes.
cd /users/pshannon/data/halo/biclusters/2004.08.26/unitTests
make 0
*--------------------------------------------------------------------------------
* create preliminary cy project from inferelator (30 aug 2004)
in /users/pshannon/data/halo/biclusters/2004.08.26

Influencers.py has a method 'getCytoscapeInteractions ()' which
produces lines for a sif file.  this, with editing and the addition
of other files, can be worked up into a cy project.  see unitTests directory.

on seeing the demo   db:8060/halo/inferelator/2004.aug26/cy.jnlp
rich pointed out that the edge weights were not used
suggested:
remove 0-weight edges
create different color (red for activators, green repressors) for
pos & neg edges
edges can be found in an array which parallels cand.inf, that is:
coeff.inf


*--------------------------------------------------------------------------------
* 26 aug version of bicluster/inferelator data, from rich (30 aug 2004)
cd /users/pshannon/data/halo/biclusters/2004.08.26

jython -i r2cy.py
reads the R clusterStack data structure, creating jython Cluster objects,
writing each one out in to a file 'clusters.cy' which can be read via the
'Select Clusters...' button in the ConditionChooser

cluster, defined:  a group of genes which, in the specified conditions,
exhibit the same microarray response.

we have two kinds of cluster:
1-304: multiple genes, multiple condtions
305-744: single gene, multiple conditions

examine a single cluster (#304)
jython -i explore.py
>>> print clusters [0].toString ()

---- cluster 304
11 rows, 51 columns
residual: 1.6657436938585402   p value: -4.028181263680143   e value: 7.5E-9
genes: ['VNG6184g', 'VNG6237g', 'VNG6373g', 'VNG6241g', 'VNG5112h', 'VNG1015h',
'VNG6372h', 'VNG5199h', 'VNG1041h', 'VNG0883h', 'VNG1317h']
conds: ['VNG0750c_HO_L_vs_NRC.1', 'X2', 'Cu_3_vs_c', 'D30.rat', 'sop2_LO.D_vs_NRC.1',
'kinA2_HO.L_vs_NRC.1', 'ark_HO.D_vs_NRC.1', 'X22', 'L60.rat', 'X4', 'FeSO4_15_vs_NRC.1b',
'NRC.1_LO.L_vs_NRC.1', 'Fe_7_vs_c', 'G20', 'gC60', 'Mn_2_vs_c', 'Fe_6_vs_c', 'X17',
'htr8_HO.D_vs_NRC.1', 'Cu_1_vs_c', 'G40', 'G0', 'X10', 'sop2_HO.D_vs_NRC.1', 'X25',
'VNG0750c_LO.L_vs_NRC.1', 'bop_LO.L_vs_NRC.1', 'G10', 'phr2_HO.D_vs_NRC.1',
'FeSO4_40_vs_NRC.1', 'X19', 'crtI2_LO.L_vs_NRC.1', 'Zn_3_vs_c', 'X5', 'gC30',
'htlD_LO.L_vs_NRC.1', 'X3', 'X7', 'G240', 'Zn_2_vs_c', 'X9', 'G480', 'X6',
'X23', 'X12', 'G60', 'gC240', 'X13', 'X8', 'G30', 'gC10']



examine a single cluster (#305)
---- cluster 305
1 rows, 142 columns
residual: NA   p value: n/a   e value: n/a
genes: VNG2276g
conds: ['C60.rat', 'D30.rat', 'D60.rat', 'L30.rat', 'L60.rat',
'X1', 'X2', 'X3', 'X4', 'X5', 'X6', 'X7', 'X8', 'X9', 'X10', 'X11',
'X12', 'X13', 'X14', 'X15', 'X16', 'X17', 'X18', 'X19', 'X20', 'X21',
'X22', 'X23', 'X24', 'X25', 'Fe_2_vs_c', 'Fe_4_vs_c', 'Fe_6_vs_c',
'Fe_7_vs_c', 'Cu_1_vs_c', 'Cu_2_vs_c', 'Cu_3_vs_c', 'Mn_1_vs_c',
'Mn_2_vs_c', 'Mn_3_vs_c', 'Zn_1_vs_c', 'Zn_2_vs_c', 'Zn_3_vs_c',
'VNG0750c_HO_D_vs_NRC.1', 'VNG0750c_HO_L_vs_NRC.1', 'VNG0750c_LO.D_vs_NRC.1',
'VNG0750c_LO.L_vs_NRC.1', 'bop_HO.D_vs_NRC.1', 'bop_HO.L_vs_NRC.1',
'bop_LO.D_vs_NRC.1', 'bop_LO.L_vs_NRC.1', 'NRC.1_HO.D_vs_NRC.1',
'NRC.1_HO.L_vs_NRC.1', 'NRC.1_LO.D_vs_NRC.1', 'NRC.1_LO.L_vs_NRC.1',
'NRC.1_vs_NRC.1', 'ark_HO.D_vs_NRC.1', 'ark_HO.L_vs_NRC.1',
'ark_LO.D_vs_NRC.1', 'ark_LO.L_vs_NRC.1', 'boa1_HO.D_vs_NRC.1',
'boa1_HO.L_vs_NRC.1', 'boa1_LO.D_vs_NRC.1', 'boa1_LO.L_vs_NRC.1',
'boa4_HO.D_vs_NRC.1', 'boa4_HO.L_vs_NRC.1', 'boa4_LO.D_vs_NRC.1',
'boa4_LO.L_vs_NRC.1', 'crtI2_HO.D_vs_NRC.1', 'crtI2_HO.L_vs_NRC.1',
'crtI2_LO.D_vs_NRC.1', 'crtI2_LO.L_vs_NRC.1', 'htlD_HO.D_vs_NRC.1',
'htlD_HO.L_vs_NRC.1', 'htlD_LO.D_vs_NRC.1', 'htlD_LO.L_vs_NRC.1',
'htr1_HO.D_vs_NRC.1', 'htr1_HO.L_vs_NRC.1', 'htr1_LO.D_vs_NRC.1',
'htr1_LO.L_vs_NRC.1', 'htr2_HO.D_vs_NRC.1', 'htr2_HO.L_vs_NRC.1',
'htr2_LO.D_vs_NRC.1', 'htr2_LO.L_vs_NRC.1', 'htr8_HO.D_vs_NRC.1',
'htr8_HO.L_vs_NRC.1', 'htr8_LO.D_vs_NRC.1', 'htr8_LO.L_vs_NRC.1',
'kinA2_HO.D_vs_NRC.1', 'kinA2_HO.L_vs_NRC.1', 'kinA2_LO.D_vs_NRC.1',
'kinA2_LO.L_vs_NRC.1', 'phoR_HO.D_vs_NRC.1', 'phoR_HO.L_vs_NRC.1',
'phoR_LO.D_vs_NRC.1', 'phoR_LO.L_vs_NRC.1', 'phr1_HO.D_vs_NRC.1',
'phr1_LO.D_vs_NRC.1', 'phr1_LO.L_vs_NRC.1', 'phr1_and_phr2_HO.D_vs_NRC.1',
'phr1_and_phr2_HO.L_vs_NRC.1', 'phr1_and_phr2_LO.D_vs_NRC.1',
'phr1_and_phr2_LO.L_vs_NRC.1', 'phr2_HO.D_vs_NRC.1', 'phr2_HO.L_vs_NRC.1',
'phr2_LO.D_vs_NRC.1', 'phr2_LO.L_vs_NRC.1', 'sop2_HO.D_vs_NRC.1',
'sop2_HO.L_vs_NRC.1', 'sop2_LO.D_vs_NRC.1', 'sop2_LO.L_vs_NRC.1',
'ura3_HO.D_vs_NRC.1', 'ura3_HO.L_vs_NRC.1', 'ura3_LO.D_vs_NRC.1',
'ura3_LO.L_vs_NRC.1', 'gC0', 'gC10', 'gC30', 'gC60', 'gC240',
'gC960', 'G0', 'G10', 'G20', 'G30', 'G40', 'G60', 'G120', 'G240',
'G480', 'G960', 'FeSO4_.1_vs_NRC.1', 'FeSO4_0_vs_NRC.1', 'FeSO4_5_vs_NRC.1b',
'FeSO4_10_vs_NRC.1b', 'FeSO4_15_vs_NRC.1b', 'FeSO4_20_vs_NRC.1',
'FeSO4_25_vs_NRC.1b', 'FeSO4_40_vs_NRC.1', 'FeSO4_80_vs_NRC.1',
'FeSO4_160_vs_NRC.1', 'FeSO4_320_vs_NRC.1']


what influences these clusters?
infl1 = [x.getContent() for x in r.eval ('cand.inf [[1]]').getContent ()]

['VNG6387h', 'VNG6438g', 'VNG2112c', 'VNG5163g', 'VNG6287h', 'VNG1886c', 'VNG1617h',
'VNG2243g.VNG2094g.max', 'VNG2243g.VNG2094g.min', 'VNG0258h.VNG2094g.max',
'VNG0258h.VNG2094g.min', 'VNG0703h.VNG2094g.max', 'VNG0703h.VNG2094g.min',
'VNG1496g.VNG2094g.max', 'VNG1496g.VNG2094g.min', 'VNG1438h.VNG6438g.max',
'VNG1438h.VNG6438g.min']

max == OR
min ==> AND
max - min ==> XOR


*--------------------------------------------------------------------------------
* TreeDataBrowser bug (27 aug 2004)
when building a tree widget from xml input files:  if two (or more) files
specify condition values for the same variable, only the last-read file's
variables are heeded.
for an example:
point the TreeDataBrowser at a directory containing only

batVbat_cmyc1Vcmyc1.xml
tfb-ABC-cmyc.xml

sampleData/bat/batVbat_cmyc1Vcmyc1.xml:    <variable name='bait' value='bat' />
sampleData/bat/batVbat_cmyc1Vcmyc1.xml:    <variable name='bait' value='cmyc1' />
sampleData/bat/tfb-ABC-cmyc.xml:    <variable name='bait' value='tfbA' />
sampleData/bat/tfb-ABC-cmyc.xml:    <variable name='bait' value='tfbB' />
sampleData/bat/tfb-ABC-cmyc.xml:    <variable name='bait' value='tfbC' />

fixed.

*--------------------------------------------------------------------------------
* combine all ChIP-chip data (27 aug 2004)
/users/pshannon/tomcat/server1/webapps/halo/data/tfb-ABC-cmyc.[xml,ratios,lambda]
has three columns of data, from three experiments.
now it's time to add the three previous data sets, from halo/tiles:
matrix.[ratio,lambda]

tiles/matrix.lambda
Tile   bat_vs_bat.sig       cmyc1_vs_cmyc1

tiles/tbpEandtfbD.lambda
Tile   tfbD_IP_vs_tfbD_wce  tbpE_IP_vs_tbpE_wce

tiles/tfbGandtbpB.lambda
Tile  tfbG_IP_vs_tfbG_wce    tbpB_IP_vs_tbpB_wce

the simplest approach is just to
- move these three files to halo/data and create xml files for them
*--------------------------------------------------------------------------------
* marc's jython gui for navigating ChIP-chip data (27 aug 2004)
developed a few classes in
/users/pshannon/tomcat/server1/webapps/halo/tiles/__run__.py

MarcsGui:
selects tiles based on thresholds of ChIP-chip data, and selection
of the genes for which they may be promoters

GeneFinder: uses proximity information to select genes possibly promoted
by selected tiles

SliderComponent: a composition of a few widgets

*--------------------------------------------------------------------------------
* fix cytoscape/jython
__run__.py in trial/pshannon/spy  does not appear to include
the 'select' script mentioned below, in log entry

use dan's python console with r, __run__.py, and local scripts: no jar (17 aug 2004)
*--------------------------------------------------------------------------------
* marc's latest ChIP-chip (24 aug 2004) (chromatin immunoprecipitation on a chip)
from email sent by marc on (23 aug 2004)
tfbA_cmyc.chip2
tfbB_cmyc.chip2
tfbC_cmyc.chip2
each has 4786 lines, beginning with a title line (see "marc's ChIP-chip titles" below)
cd /users/pshannon/data/halo/marc/linearLayout
mkdir 2004.08.24
cp -p ~/attachments/*.chip2 .
delete last line from each of the 3 files
NumSigGenes:	4784	+1
to create ratio & lambda files for each of these three experiments:
cp ../2004.06.06/createMatrices.py .
createMatrices.py, explained:
# read one (or more, as is the case here) pipeline files, and from each
# create a ratios and a lambda file.
# when the /users/pshannon/lib/PipelineToDataMatrix class digests the input file, it appends a
# '.dup' after every duplicate title -- and there is one of those for each
# ratio/lambda pair.
#
# some name substitution is performed in this program, and must be specified.
# first, specifiy the titles (and their columns) to extract
#  titlesToGrab1:  for the ratios
#  titlesToGrab2:  for the lambdas
#  preferredTitles: indentical for both output files

then we decided to put all the 1-column ratio & lambda files into one.
merge.py does this
now create an xml file for one file (and then, if it works, the others).
*--------------------------------------------------------------------------------
* marc's ChIP-chip titles (24 aug 2004)

GENE
DESCRIPT
tfbC_IP_vs_tfbC_wce.sig
tfbC_IP_vs_tfbC_wce.sig
NumSigConds
fold_change
plate_384
row_384
col_384
primer_forward_name
primer_forward_sequence
primer_reverse_name
primer_reverse_sequence
chromosome_start_position
chromosome_end_position
halo_span_source1
halo_span_source2
halo_flag_N
halo_flag_F
halo_gel_file
halo_gel_number
halo_gel_row
sample_number
regulatory_motif
sequence
plate_96
row_96
col_96
flag




*--------------------------------------------------------------------------------
*remap trickster keyboard: swap control and capslock (23 aug 2004)
as root:
cd /System/Library/Extensions/IOUSBFamily.kext/Contents/PlugIns/IOUSBHIDDriver.kext/Contents
saved old copy of Info.plist
added these 2 lines

<key>Swap control and capslock</key>
<integer>1</integer>

touch /System/Library/Extensions
reboot
*--------------------------------------------------------------------------------
* cy2 jws plugin loading (18 aug 2004)
good examples in
/users/pshannon/cy2/cyto_web/tut/yeastGal/yeastGal.jnlp
mimic this, and it should work!

other info:
cy2 --JLH
jarLoader command line arguments:
--JLD  <string>   local directory containing .jar files
--JLW  <URL>      URL of a .jar file to load
--JLL  <URL>      URL of a list of .jar files to load
--JLH             prints this help

ways to load plugins in cy2:  (from dan/rowan bug exchange)

plugin.ylo.load=yfiles.YFilesLayoutPlugin
That caused an exception when trying to instantiate the plugin.
Then I added the following to the cytoscape command line:
--JLD /foo/bar
where /foo/bar is the path to the yLayouts.jar

That works fine for standalone installations but will not work in a java
web start.

The reason is that I cannot specify a directory as an argument to --JLD
because in java web start, everything is in jar files, not directories.
Hence there is no way to use this plugin in a java web start.

rowan replies:
I think that --JLW ( --JLH is the plugin help.. ) will let you specify a
File/URL of a specific Jar file.

*--------------------------------------------------------------------------------
* create a demo jws for cy2 DataMatrixPlugin (18 aug 2004)
/local/tomcat/webapps/cytoscape/projects/static/demo/cy2/dataMatrix

*--------------------------------------------------------------------------------
* dutch bioinformatician (17 aug 2004)
wrote software to create 'genome wheel' posters
nitin speaks highly of his boss
robert kerkhoven: R.Kerkhoven@cmbi.kum.nl
http://www.cmbi.kun.nl/genome
*--------------------------------------------------------------------------------
* cy1 jws: use dan's python console with r, __run__.py, and jar'd scripts (17 aug 2004)
db: /users/pshannon/tomcat/server1/webapps/halo/scriptingExperiment/try0
db.try0> grep jar cy.jnlp
<jar href="cytoscape.jar"/>
<jar href="data.jar"/>
<jar href="TreeDataBrowserPlugin.jar"/>
<jar href="scripts.jar"/>
<jar href="../../jars/jcommon-0.9.0.jar"/>
<jar href="../../jars/jfreechart-0.9.15.jar"/>
<jar href="../../jars/jython.jar"/>
<jar href="../../jars/spyconsole.jar"/>
<jar href="../../jars/tspaces_fixes.jar"/>
<jar href="../../jars/tspaces_client.jar"/>
<jar href="../../jars/JRclient-RE321.jar" />
<jar href="jython-lib.jar"/>
<jar href="jythonHack.jar"/>
<argument>jar://project</argument>

scripts.jar contains only __run__.py, into which I folded
/users/pshannon/data/halo/microarrayXml/selectRows.py
*--------------------------------------------------------------------------------
* use dan's python console with r, __run__.py, and local scripts: no jar (17 aug 2004)
cd /users/pshannon/data/halo/microarrayXml
put scripts.jar in the CLASSPATH, eg:
...
/users/pshannon/jars/jnlp.jar
/users/pshannon/jars/jython-lib.jar
scripts.jar
ensure that __run__.py -- the customizable python boot script --
is not in the CLASSPATH.
the makefile has this target
scriptsJar:
(cd scripts; jar cvf ../scripts.jar __run__.py)
test with a python script which creates a data matrix browser:
jython -i tester.py

from csplugins.trial.pshannon.newDataCube.browsers import DataCubeBrowser
dcb = DataCubeBrowser (None, [])
from javax.swing import *
frame = JFrame ()
x = frame.getContentPane().add (dcb)
frame.show ()

this version uses
/users/pshannon/cy/csplugins/trial/pshannon/newDataCube/browsers/DataCubeBrowser.java
which creates a button for
/users/pshannon/cy/csplugins/trial/pshannon/newDataCube/browsers/actions/StartPythonConsole.java
constructed with references to
DataCubeBrowser parentBrowser
ArrayList matrixList
and has all of these variables set:

pythonConsole.set ("matrixList", matrices);
pythonConsole.set ("lenses", parentBrowser.getMatrixLenses ());
pythonConsole.set ("mb", parentBrowser);
pythonConsole.set ("webreader", webreader);
pythonConsole.set ("importer", importer);
pythonConsole.set ("scriptHome", scriptHome);
pythonConsole.set ("scriptUrl", url);

*--------------------------------------------------------------------------------
* using dan's new jython console plugin (16 aug 2004)
db:/local/tomcat/webapps/cytoscape/projects/static/r/fromDan
these jars are needed:
<jar href="cytoscape.jar"/>
<jar href="data.jar"/>
<jar href="../../../../jars/jython.jar" />
<jar href="../../../../jars/spyconsole.jar" />
<jar href="../../../../jars/JRclient-RE321.jar" />
<jar href="custompy.jar" />
<jar href="jython-lib.jar" />
<jar href="jythonHack.jar" />

jython-lib.jar:  many many python files -- the standard jython library
jythonHack.jar:  org/python/core/SyspathArchiveHack.class
custompy.py: any scripts you want to from a jar, in java web start:
__run__.py
# you don't have to use this as your boot script, but it's a guideline for what you could use.
import java
from java.lang import System
System.out.println("#hello again from bootstrap script.\n")
global execUrl
scriptHomeDefault='http://db.systemsbiology.net/cytoscape/scripts'
def execUrl (url, scriptHome=scriptHomeDefault):
fullUrl = scriptHome + url
us = webreader.read (fullUrl)
exec (compile (us, '<string>', 'exec'))

*--------------------------------------------------------------------------------
* update cytoscape 2 website (14 aug 2004)

from gary bader: If you know the cytoscape.org FTP password (for the treyideker
account), you can update with the ant script in the CVS directory.  I
probably shouldn't pass the password to you by e-mail, but a few people at
ISB know it.  If you can't find it, then I'll update the website.

in cyto_web:
ant deply -Dpassword=i00tu2

but this fails because the 'ftp' task is unknown
rowan says that he needed to assemble a new ant to get this to work.
*--------------------------------------------------------------------------------
* data matrix browser plugin todo (13 aug 2004)
andrew reports that duplicate rows, having the same gene name, render
the movie script inoperable
*--------------------------------------------------------------------------------
* install R on db, to test Rserve remote use (13 aug 2004)
downloaded R-1.9.1.tar to trickster:~/safariDownloads/R-1.9.1.tar
cd ~/src
tar xvf ~/tmp/R-1.9.1.tar
cd ~/src/R-1.9.1
[R-help says 'Need to install R with the shared libraries (it's a config option).']

./configure --prefix=/users/pshannon/src --enable-R-shlib
make
make install  -> put R in /users/pshannon/src/R-1.9.1/bin
now add Rserve:
cd /users/pshannon/src/r
../R-1.9.1/bin/R CMD INSTALL Rserve_0.3-10.tar.gz
successful test:
~/src/R-1.9.1/bin/R CMD Rserve
Error in library(SJava) : There is no package called 'SJava'
Rserv started in daemon mode.
db.pshannon> jython
Jython 2.1 on java1.4.2 (JIT: null)
import org.rosuda.JRclient.Rconnection as R
r = R ()
r.eval ('R.version.string')
[STRING "R version 1.9.1, 2004-06-21"]

*--------------------------------------------------------------------------------
* on roundpeak (14 aug 2004)
got R-1.9.1.tgz into ~pshannon/src/r
as root:
tar xvf R-1.9.1.tar
cd R-1.9.1
./configure --enable-R-shlib
make

*--------------------------------------------------------------------------------
* start Rserve in remote mode (14 aug 2004)
must have 'remote enable' in the config file (I use ~/.rserve on trickster)
R CMD Rserve --RS-conf ~/.rserve
reports 'setuid(0): failed. no user switch performed.setgid(0): failed.
no group switch performed.' with no evident consequences
switch to db
jython
import org.rosuda.JRclient.Rconnection as R
r = R ('trickster')
r.eval ('R.version.string')  -> [STRING "R version 1.9.0, 2004-04-12"]

to shutdown:
r.shutdown ()
*--------------------------------------------------------------------------------
* start Rserve on another port (13 aug 2004)
the default port is 6311
to run on another port:
R CMD Rserve --RS-port 11111

*--------------------------------------------------------------------------------
* webstart, jython, r (13 aug 2004)
import sys
sys.add_package ('org.rosuda.JRclient')
import org.rosuda.JRclient.Rconnection as R
rc = R ()
rc.eval ('R.version.string')

*--------------------------------------------------------------------------------
* build jython 2.2a from source (10 aug 2004)
/users/pshannon/src/jython-src
*--------------------------------------------------------------------------------
* another strategy for jar loading java classes, in jython (9 aug 2004)
http://sourceforge.net/mailarchive/message.php?msg_id=8993366

Try inserting this code after creating your interpreter:

Py.defaultSystemState.setClassLoader(loader);



-----Original Message-----
From: Linh T [mailto:linh253@ya...]
Sent: Sunday, July 18, 2004 1:22 AM
To: jython-users@li...
Subject: [Jython-users] downloading java classes using URLClassLoader


Hello,

I am embedding jython into my app.  I need jython to
load  class files from an httpd.

Suppose Foo.class is located at
http://foo.com/classes/

In my jython code, I want to be able to do

f = Foo()
f.bar()

Jython would use the URLClassLoader to load the class
definition of Foo() from the httpd.

This is what I tried to do, but its not working:

------
URLClassLoader loader = new URLClassLoader(new URL[] {
new URL("http://foo.com/classes/") });

Class clz =
Class.forName("org.python.util.InteractiveInterpreter",
true, loader);
InteractiveInterpreter pyInterpreter
=
(InteractiveInterpreter) clz.newInstance();

pyInterpreter.exec("f=Foo()")
pyInterpreter.exec("f.bar()")
-------
Anyone have any idea how to get jython to load classes
from an httpd?

*--------------------------------------------------------------------------------
* explore difficulty loading jar from jython jar (9 aug 2004)
/users/pshannon/examples/jython/console/try0:  make go, or make jar
creates a minimal interpreter, passes it a string; that string is
now "execfile ('test.py')":

from org.rosuda.JRclient import *
def test ():
print 'hello from test.py'
return '------------- returning from test.py'

print dir ()
test ()
the 'jar' target builds a jar first, adds jython.jar and rosuda jar,
everything works fine.

next:  in console/loadJarFromJarAtRuntime, i hope to recreate the
security problem which shows up in the single-jar plugin version used
in Cy2.

when I print out system.properties in
/users/pshannon/cy2/csplugins/isb/pshannon/dataMatrix/gui/actions/PyConsoleLauncher.java
i see only:

---- dataMatrix.gui.actions.PyConsoleLauncher props
0) java.protocol.handler.pkgs: null|sun.beanbox
which suggests that the classloader is stripping out all the information
(java.class.path in particular) which
- would be passed onto jython
- and used to find org.rosuda.JRClient



*--------------------------------------------------------------------------------
* jython classloading from jar difficulty, rosuda, etc

extended quote from
http://sourceforge.net/mailarchive/forum.php?thread_id=3332209&forum_id=5586

my advice is to not mess around with class loaders as long as you can
avoid it.

I am successfully using embedded Jython in Jboss for a long time now.
The question is: where does your class com.foo.xx reside? I guess it is
inside a .jar file, and I further guess this .jar is not mentioned on
the classpath explicitly, instead it is referenced from a manifest
inside another .jar file.

The most easiest way for you to enable from com.foo import xx is to add
the .jar file explicitly to the classpath when starting Jboss, such as

java -classpath run.jar;[jar_containing_com.foo.xx];[rest_of_classpath]
org.jboss.Main [your_conf]

Another approach would be to change the import logic of Jython a bit
(which is what I have done), but this requires some coding inside
org.python.core.

Best wishes,
Oti.

--- Stefan Baramov <Stefan.Baramov@tr...> wrote:
> Well, this is a tough question. I do not know JBoss enough to give
> you a
> precise answer but here is what I do in eclipse plugin:
>
>
> PySystemState systemState = new PySystemState();
> result.path.insert(0, new PyString("C:/jython21/Lib"));      // standard
> jython
> libraries
>
> systemState.setClassLoader(MyPlugin.class.getClassLoader()); // here
> you
> have to specified the class loader
> PyStringMap dictNamespace = new PyStringMap();
>
> // Init interpreter
> PythonInterpreter interp = new PythonInterpreter(dictNamespace,
> systemState);
>
> If this does not work, the only other options is to develop custom
> class
> loader. Good luck !
>
> - Stefan Baramov
>
> -----Original Message-----
> From: joachim.tremouroux@be...
> [mailto:joachim.tremouroux@be...]
> Sent: Wednesday, October 22, 2003 9:11 AM
> To: jython-users@li...
> Subject: [Jython-users] jython embedded in jboss
>
>
> Hello,
>
> I try to use jython embedded in jboss.
> In my scripts I can use any object givent through the
> interp.set("foo",bar)
> method.
>
> However, I can"t import anything in my scripts using
> from com.foo import xx
>
> How do I need to initialize the jython interpreter?
> I basically needs my scripts to be able to use all java packages
> visible
> with the current classloader.
>
> I have tried differents things:
>
> 1.
>      PySystemState.initialize(
>                      new Properties(),
>                      new Properties(),
>                      null,
>                      Thread.currentThread().getContextClassLoader());
>
>
> 2.
> I also tried to retrieve all jars from the
> Thread.currentThread().getContextClassLoader() and pass them
> through the addJar method
>
>                      String[] cps =
>                              new CompilePath().getCompileClasspath(
>
> Thread.currentThread().getContextClassLoader());
>
>                      for (int i=0;i<cps.length;i++) {
>                              System.out.println("adding " + cps[i]);
>
> PySystemState.packageManager.addJar(cps[i],false);
>                      }
>
>
> The getCompileClassPath comes from Jboss for the integration of
> Tomcat:
>
>
>      public String[] getCompileClasspath(ClassLoader loader) {
>              HashSet tmp = new HashSet();
>              ClassLoader cl = loader;
>              while (cl != null) {
>                      URL[] urls = getClassLoaderURLs(cl);
>                      addURLs(tmp, urls);
>                      cl = cl.getParent();
>              }
>              String[] cp = new String[tmp.size()];
>              tmp.toArray(cp);
>              return cp;
>      }
>
>      protected URL[] getClassLoaderURLs(ClassLoader cl) {
>              URL[] urls = {
>              };
>              try {
>                      Class returnType = urls.getClass();
>                      Class[] parameterTypes = {
>                      };
>                      Method getURLs = cl.getClass().getMethod("getURLs",
> parameterTypes);
>                      if
> (returnType.isAssignableFrom(getURLs.getReturnType())) {
>                              Object[] args = {
>                              };
>                              urls = (URL[]) getURLs.invoke(cl, args);
>                      }
>                      if (urls == null || urls.length == 0) {
>                              getURLs =
> cl.getClass().getMethod("getAllURLs", parameterTypes);
>                              if
> (returnType.isAssignableFrom(getURLs.getReturnType())) {
>                                      Object[] args = {
>                                      };
>                                      urls = (URL[]) getURLs.invoke(cl,
> args);
>                              }
>                      }
>              } catch (Exception ignore) {
>              }
>              return urls;
>      }
>
>      private void addURLs(Set urlSet, URL[] urls) {
>              for (int u = 0; u < urls.length; u++) {
>                      URL url = urls[u];
>                      url =
> org.jboss.net.protocol.njar.Handler.njarToFile(url);
>                      urlSet.add(url.toExternalForm());
>              }
>      }
>
>
>
> None of these two methods give me results. Has anyone any idea of the
> correct initialisation method?
>
> Thanks in advance,
>
>
> Joachim.


*-------------------------------------------------------------------------------
* more jython, jar loading difficulties from the net (9 aug 2004)

Are you attempting to use jython as a scripting tool for a webstart
app, or use jython _for_ the app.  ʁThe former will get ugly with the
security restrictions in place for JWS apps.  ʁThe latter does not
require _any_ java code to initialize the app. Create your app in
jython. Use the following trick if your main module does not subclass
a java application object, but instead is a script-style:

if __name__ == '__main__':
ʁ # main entry point into your code

Then, compile with jythonc, use the --all and --deep flags, these will
put the jython runtime files needed for your app in the generated jar.
Name the jar the same name (sans extension) as your main module, ie:

D:\jython-2.1\jythonc.bat --all --deep --jar e:\test\mine.jar
e:\test\mine.py

then make sure you reference that jar _first_ in your jnlp file:
<resources>
ʁ <j2se version="1.4+"/>
ʁ <jar href="mine.jar"/>

And that later in the file, you set the main class to the name of the jar,
sans extension:
<application-desc main-class="mine"/>

Then you'll be good to go, and have a jython webstart app.
Other notes:
- you can, as always, include other jars used by your app in the resource
section.
- if your main module imports your other jython modules (even if it doesn't
use them),
ʁthen you only need to run jythonc on the main module.
- you may need to digitally sign your jar files due to the --all flag, an
example of how
to do so is here:
http://developer.java.sun.com/developer/technicalArticles/Programming/jnlp/

> Message: 8
> Date: Fri, 05 Sep 2003 13:56:20 -0500
> From: Allan Wick <registerit@wickidcool.com>
> To: jython-users@lists.sourceforge.net
> Subject: [Jython-users] Webstart Classloader issue
>
> I am trying to use Jython inside of Webstart application. How do I tell
> Jython which class loader to use?
>
> Here is what I have tried and doesn't seem to make a difference.
>
>        Thread.currentThread().setContextClassLoader(
> MyClass.class.getClassLoader() );
>
>        // -- Python setup --
>        System.out.println( "Initializing python...." );
>
>        PySystemState.initialize( System.getProperties(),
>                     new Properties(),
>                     new String[0],
>
> Thread.currentThread().getContextClassLoader() );
>           System.out.println( "Done initializing python...." );
>
> It is only parsing the .jar files from the webstart vm and none of the
> classes that are part of the webstart application.
>
> Any help is appreciated.
>
> Thanks,
>
> -Al Wick
>
>
>
>
> --__--__--
>
> _______________________________________________
> Jython-users mailing list
> Jython-users@lists.sourceforge.net
> https://lists.sourceforge.net/lists/listinfo/jython-users
>
>
> End of Jython-users Digest
>

*--------------------------------------------------------------------------------
* interesting java system properties (9 aug 2004)
user.dir: /Volumes/netpshannon/cy2/csplugins/isb/pshannon/dataMatrix/apps
user.home: /Users/mpshannon

*--------------------------------------------------------------------------------
* traverse a java hash (9 aug 2004)

Properties sysProps = System.getProperties ();
String [] keys = (String []) sysProps.keySet().toArray (new String [0]);
for (int k=0; k < keys.length; k++)
System.out.println (k + ") " + keys [k] + ": " + sysProps.get (keys [k]));

*--------------------------------------------------------------------------------
*--------------------------------------------------------------------------------
* cy2 python cribsheet (9 aug 2004)

import cytoscape.Cytoscape as cy
cy.getCurrentNetwork().getFlagger().getFlaggedNodes ()
cy.getCurrentNetwork().getFlagger().setFlagged (cy.getCyNode ('YML054C',0), 1)
cy.getCurrentNetworkView().redrawGraph (0,0)

*--------------------------------------------------------------------------------
* for nitin:  rpy function to select lambda peaks (6 aug 2004)

parameters:  float threshold, int number of peaks, boolean must be consecutive

*--------------------------------------------------------------------------------
* debug ClassNotFoundException, in cy2 jar loading (9 aug 2004)

strategy:  find all missing classes by running first from command line

for the PythonConsolePlugin:
cd /users/pshannon/cy2/csplugins/isb/pshannon/py/
source testClasspath
then start cytoscape using this environment:
cd apps
make cy2

for the DataMatrixBrowserPlugin
cd /users/pshannon/cy2/csplugins/isb/pshannon/dataMatrix/
source testClasspath
source /users/pshannon/.cy2DataMatrixPluginTest
then start cytoscape using this environment:
cd apps
make cy2


*--------------------------------------------------------------------------------
* classNotFound exception building a single jar for DataMatrixBrowserPlugin (6 aug 2004)
servlet.jar is one:

[fixed:  my jar was not complete]

The classes required are normally stored in a file called
servlet.jar. The exact location of this file will depend on the
particular Web server software you use, but in the case of Tomcat
you can find it in the lib subdirectory of the main Tomcat
installation directory

plugin.0.load=csplugins.isb.pshannon.dataMatrix.DataMatrixPlugin

*--------------------------------------------------------------------------------
* set up ssh authorization between book and bobama (27 apr 2009)

on bobama, mkdir .ssh
cd .ssh; ssh-keygen -t rsa -b 1024   # may not be necessary
copied final line from db:.ssh/authorized_keys to same file on bobama
.ssh has mode 700
authorized_keys has 600
works!
*--------------------------------------------------------------------------------
* setup ssh between isb riptide and whovian (11 feb 2016)

  cd
  ssh-keygen -b 1025 -t rsa   # no passphrase, accept all defaults

*--------------------------------------------------------------------------------
* set up ssh authorization between book and db (9 jan 2009)
on book
ssh-keygen -b 1024 -t rsa    # accept all defaults with <cr>'s
generates ~/.ssh/id_rsa.pub
append this to db:.ssh/authorized_keys
ssh db  date  # no password needed!
*--------------------------------------------------------------------------------
* set up ssh authorization between aphelion and db (6 aug 2004)
on aphelion
ssh-keygen -b 1024 -t rsa
generates ~/ssh/id_rsa.pub
append this to db:.ssh/id_dsa.pub db:.ssh/authorized_keys
ssh db   # no password needed!
*--------------------------------------------------------------------------------
* set up ssh authorization between trickster and db (6 aug 2004)
on trickster:
ssh-keygen -b 1024 -t dsa
scp .ssh/id_dsa.pub db:.ssh/authorized_keys2
ssh db   # no password needed!
*--------------------------------------------------------------------------------
* try fetchmail with ssl  (6 aug 2004)
on db:  fetchmail -d 10 -k --ssl
emacs smtp still works (w/o ssl) on port 25.
*--------------------------------------------------------------------------------
* data matrix plugin demo (5 aug 2004)
cd /users/pshannon/cy2/csplugins/isb/pshannon/dataMatrix/apps
Trickster.apps> make cy2
java -Xmx1G cytoscape.CyMain -p project \
-b http://db.systemsbiology.net/cytoscape/annotation/yeast/manifest \
-s "Saccharomyces cerevisiae"

exec (compile (webreader.read (url), '<string>', 'exec'))
failed to find the rosuda classes when pyconsole starts up.  add them
to   /users/pshannon/cy2/csplugins/isb/pshannon/dataMatrix/makefile
*--------------------------------------------------------------------------------
* create DataMatrixPlugin.jar (5 aug 2004)
on trickster, cd /users/pshannon/cy2/csplugins/isb/pshannon/dataMatrix
make jar:


PLUGINS=/users/pshannon/cy2
EXTRA=/users/pshannon/jars/dataMatrixExtra
JAR=/users/pshannon/cy2/csplugins/isb/pshannon/dataMatrix/DataMatrixPlugin.jar
#------ jar
# make a plugin jar
#

jar:
(cd $(PLUGINS); jar cvf $(JAR) `find csplugins/isb/pshannon/dataMatrix -name "*.class" -print`)
(cd $(PLUGINS); jar uvf $(JAR) `find csplugins/isb/pshannon/py -name "*.class" -print`)
(cd $(EXTRA);   jar uvf $(JAR) `find . -name "*.class" -print`)

load into cy2 via plugin menu, got this error:

java.lang.NoClassDefFoundError: javax/servlet/http/HttpServlet

*--------------------------------------------------------------------------------
* email problem, RMAIL, ssl, fetchmail (5 aug 2004)
norman says that 10 other people have had the same problem today
and that it is a mystery that mail fetch & send without ssl ever worked.
the fixes:
- fetch mail using ssl on port 993
- send mail using ssl on port 465
*--------------------------------------------------------------------------------
* next up, in cy2 port of DataMatrixBrowser (5 aug 2004)

/users/pshannon/cy/csplugins/trial/pshannon/spy/PyConsolePlugin.java
has these extra calls in inner class StartConsole:

WebReader webreader = new WebReader ();
pythonConsole.set ("webreader", webreader);
String scriptHome = "http://db.systemsbiology.net/cytoscape/scripts";
pythonConsole.set ("scriptHome", scriptHome);

ArrayList scriptUrls = new ArrayList ();

String [] args = cytoscapeWindow.getConfiguration().getArgs ();
for (int i=0; i < args.length; i++) {
System.out.println (i + ") " + args [i]);
if (args [i].equalsIgnoreCase ("--script") && args.length > i+1)
scriptUrls.add (args [i+1]);
} // for i

System.out.println ("scripts to load: " + scriptUrls.size ());

for (int s=0; s < scriptUrls.size (); s++) {
String scriptUrl = (String) scriptUrls.get (s);
String url = scriptHome + "/" + scriptUrl;
System.out.println ("about to load " + url);
pythonConsole.set ("scriptUrl", url);
pythonConsole.exec ("scriptText = webreader.read (scriptUrl)");
pythonConsole.exec ("obj = compile (scriptText, '<string>', 'exec')");
pythonConsole.exec ("eval (obj)");
}

*--------------------------------------------------------------------------------
* cytoscape2 python intepreter, for data matrix plugin  (4 aug 04)
moved SPyConsoleThread.java, and all of SPy_Console to
/users/pshannon/cy2/csplugins/isb/pshannon/py
changed package statement in all java files to match
make
added /users/pshannon/cy2/csplugins/isb/pshannon/dataMatrix/gui/actions/PyConsoleLauncher.py
which is loaded into the data matrix browser gui at
/users/pshannon/cy2/csplugins/isb/pshannon/dataMatrix/gui/DataMatrixBrowser.java.addActions ()

sample use of py console, and Rserve
m = mb.getMatrices()[0]
m.getShortName () -> 'ratios.matrix'
columnTitles = [x for x in m.getColumnTitles ()]
c1 = [x for x in m.getColumn ('gal1+gal')]
len (c1) -> 329
from org.rosuda.JRclient import *
r = Rconnection ()
r.assign ('c1', c1)
sc1 = r.eval ('summary (c1)')


see file /users/pshannon/cy2/csplugins/isb/pshannon/dataMatrix/apps/r.py
for some rough-hewn methods for doing simple stats on matrix browser columns:
stats (vector) does an R summary, with pretty printing
boxplot (*vectors) creates a single R graph window with any number of
vector boxplots, with names.

==  had problems with the following -- java claimed that the png image
LUT had the wrong size.
fallback:  forget the file transport, just ask R to display the histogram,
which will work if the server is running on your own box, i think....

create an image file of a plot (5 may 2004)
x = rnorm (100)
hist (x, freq=F)           # draws plot on screen
graphics.off ()            # removes plot
png ('test0.png')
hist (x, freq=F)
graphics.off ()
*-------------------------------------------------------------------------------

r.voidEval ("jpeg ('test0.png')")

*-------------------------------------------------------------------------------
* rserve method to copy file from server, save locally (5 may 2004)
from jarray import *
def copyFileFromServer (filename):

inputFile = rc.openFile (filename)
buffer = zeros (4096, 'b')             # make sure this buffer is bigger than the file
bytesRead = inputFile.read (buffer)    # to be read

outputFile = open ('%s-new.png' % filename, 'wb')

for i in range (bytesRead):
data = struct.pack ('b', x [i])
outputFile.write (data)

outputFile.close ()


*--------------------------------------------------------------------------------
* create cy project from bicluster data (3 aug 2004)
now that i'm able to:
1) read & parse R object via jython & rserve (see  'reading new bicluster data
into python objects, via jython & rserve (2 aug 2004)' just below)
2) traverse all of the clusterStack data structure, creating python
Cluster objects
it is time to create a new dated directory, and do the full cy project extraction
there.  so
cd /users/pshannon/data/halo/biclusters/2004.08.03
program r2cy.py does the work, using an Rconnection, Rich's R object,
and iterating through 303 clusters

for i in range (1,max):
cmd = 'clusterStack [[%d]]' % i
rCluster = r.eval (cmd)
cluster = Cluster (rCluster)
f.write ('%s\n' % cluster.toCytoscapeFormat (i))

Cluster.py massages the cluster data in a number of ways:
- it capitalizes all orf names
- it decodes the array, into a scalar, for the 5 clusters which use
an array to store the condition count for the cluster
- it tries to convert all of Rich's experiment condition names
into those named in ~/tomcat/server1/webapps/halo/data/*.xml
(see getAllConditionNames () in
/users/pshannon/data/halo/biclusters/2004.08.03/unitTests/ClusterTest.py
for how all of Rich's names were obtained; a simple grep & emacs edit
got all the names from all of the xml files.   much remains to be done here.)

turned on the condition selector button in the newDataCube datamatrixbrowser,
which nows how to read files output by 'cluster.toCytoscapeFormat' (see above)

cleaned up the db:8060/halo webpage.

*--------------------------------------------------------------------------------
* reading new bicluster data into python objects, via jython & rserve (2 aug 2004)
cd /users/pshannon/data/halo/biclusters/2004.07.26
jython -i extract.py
execfile ('Cluster.py')
c1 = r.eval ('clusterStack [[1]]')
pc1 = Cluster (c1)
cd /users/pshannon/data/halo/biclusters/2004.07.26/unitTests
why do clusters 5, 13, 18, etc fail to return an int for rowCount?

jython ClusterTest.py
singleClusterTest
.allClusterCountTest
1: 10.0 x 62.0
2: 9.0 x 59.0
3: 11.0 x 50.0
4: 6.0 x 54.0
5: 17.0 x array([86], int)
6: 8.0 x 56.0
7: 9.0 x 62.0
8: 10.0 x 38.0
9: 12.0 x 50.0
10: 12.0 x 60.0
11: 17.0 x 46.0
12: 9.0 x 41.0
13: array([4], int) x 54.0
14: 17.0 x 31.0
15: 9.0 x 60.0
16: 13.0 x 49.0
17: 20.0 x 35.0
18: array([4], int) x 51.0
19: 14.0 x 27.0

summary of array problem:

5: 17.0 x array([86], int)
13: array([4], int) x 54.0
18: array([4], int) x 51.0
40: array([4], int) x 58.0
62: array([4], int) x 59.0

added method to Cluster class:  postParseCleanup () which
checks for an array-valued 'ncols' variable of length 1, and
if it's found extract the 0th element

*--------------------------------------------------------------------------------
* read new bicluster data from jython/rserv (2 aug 2004)
cd /users/pshannon/data/halo/biclusters/2004.07.26
jython
from org.rosuda.JRclient import *
r = Rconnection ()
f='/users/pshannon/data/halo/biclusters/2004.07.26/2004-7-26-biclutRegInfs.RData'
cmd = "load (file='%s')" % f
r.eval (cmd)
r.eval ('ls ()')

[VECTOR ([STRING "cand.inf"],      [STRING "clusterStack"],
[STRING "coeff.inf"],     [STRING "colMap"],
[STRING "cv.err"],        [STRING "gene.ids"],
[STRING "gene.names"],    [STRING "knockIn"],
[STRING "knockIn.names"], [STRING "last.warning"],
[STRING "ratios"],        [STRING "redExp"],
[STRING "reg.infs"],      [STRING "tau"])]

r.eval ('cand.inf').getContent ().size ()    -> 638
cmd = 'cand.inf [[3]]'
r.eval (cmd).getContent ().size()            -> 17
r.eval (cmd).getContent ()[1].getContent()   -> 'VNG2664g'

r.eval ('coeff.inf').getContent().size ()    -> 638

gnc = r.eval ('gene.names').getContent ()
gncKeys = gnc.keys ()

created /users/pshannon/data/halo/biclusters/2004.07.26/extract.py
which defines function ls (returnObjects=1)
sample run:

execfile ('extract.py')
data = ls (1)
cand.inf:      vector          list [638]
clusterStack:        hash          list [745]
coeff.inf:      vector          list [638]
colMap:        hash          list [143]
cv.err:      vector       numeric [638]
gene.ids:      vector     character [2399]
gene.names:        hash     character [2399]
knockIn:        hash          list [16]
knockIn.names:      vector     character [16]
ratios:      vector        matrix [342078]
redExp:      vector        matrix [105648]
reg.infs:      vector     character [116]
tau:      vector       numeric [638]

data ['knockIn.names'][0] ->  [STRING "VNG0996g"]
data ['knockIn.names'][0].getContent() -> 'VNG0996g'

len ([x.getContent() for x in data ['knockIn.names']])  -> 16
[x.getContent() for x in data ['knockIn.names']][:5] ->
['VNG0996g', 'VNG0750c', 'VNG1523g', 'VNG1754g', 'VNG1765g']


clusterStack seems to be the crucial variable.
strategy (obtained from explorations shown below):
get each element in the list as a (sub) list
get the names from each of these (they should be the same for each sublist)
get the values


cs1 = r.eval ('clusterStack [[1]]').asList ()
REXP.xtName (cs1.at ('rows').getType ())  -> 'VECTOR'

titles = cs1.keys()
for title in titles:
print '%s: %s' % (title, cs1.at (title).getContent())

nrows: 10.0
ncols: 62.0
rows: [[STRING "VNG6418h"], [STRING "VNG2174h"], [STRING "VNG5149h"], [STRING "VNG6390h"],
[STRING "VNG6416h"], [STRING "VNG5017h"], [STRING "VNG6389g"], [STRING "VNG6393h"],
[STRING "VNG6144g"], [STRING "VNG6143h"]]
cols: [[STRING "D30.rat"], [STRING "D60.rat"], [STRING "L60.rat"], [STRING "X2"],
[STRING "X5"], [STRING "X6"], [STRING "X7"], [STRING "X8"], [STRING "X9"], [STRING "X10"],
[STRING "X11"], [STRING "X12"], [STRING "X19"], [STRING "X23"], [STRING "X24"], [STRING "X25"],
[STRING "Fe_4_vs_c"], [STRING "Fe_7_vs_c"], [STRING "Cu_1_vs_c"], [STRING "Cu_2_vs_c"],
[STRING "Cu_3_vs_c"], [STRING "Mn_1_vs_c"], [STRING "Mn_2_vs_c"], [STRING "Mn_3_vs_c"],
[STRING "Zn_2_vs_c"], [STRING "VNG0750c_HO_L_vs_NRC.1"], [STRING "VNG0750c_LO.L_vs_NRC.1"],
[STRING "bop_HO.L_vs_NRC.1"], [STRING "bop_LO.D_vs_NRC.1"], [STRING "ark_HO.D_vs_NRC.1"],
[STRING "boa1_LO.L_vs_NRC.1"], [STRING "crtI2_HO.L_vs_NRC.1"], [STRING "crtI2_LO.L_vs_NRC.1"],
[STRING "htlD_HO.L_vs_NRC.1"], [STRING "htlD_LO.L_vs_NRC.1"], [STRING "htr1_HO.D_vs_NRC.1"],
[STRING "htr1_LO.D_vs_NRC.1"], [STRING "htr1_LO.L_vs_NRC.1"], [STRING "htr2_HO.D_vs_NRC.1"],
[STRING "htr8_HO.L_vs_NRC.1"], [STRING "kinA2_HO.D_vs_NRC.1"], [STRING "kinA2_HO.L_vs_NRC.1"],
[STRING "phoR_HO.D_vs_NRC.1"], [STRING "phr2_HO.L_vs_NRC.1"], [STRING "sop2_LO.D_vs_NRC.1"],
[STRING "ura3_LO.D_vs_NRC.1"], [STRING "ura3_LO.L_vs_NRC.1"], [STRING "gC0"], [STRING "gC10"],
[STRING "gC30"], [STRING "gC60"], [STRING "gC240"], [STRING "G10"], [STRING "G40"], [STRING "G60"],
[STRING "G120"], [STRING "G240"], [STRING "G480"], [STRING "FeSO4_15_vs_NRC.1b"],
[STRING "FeSO4_80_vs_NRC.1"], [STRING "FeSO4_160_vs_NRC.1"], [STRING "FeSO4_320_vs_NRC.1"]]
resid: 1.2771290577607552
p.clust: -6.422059440224974
e.val: 8.4E-10

and it appears to be a list of lists, with each list having a header
and a body.  the header has names whose values are in the body
[x.getContent() for x in r.eval ('names (clusterStack[[1]])').getContent ()]
-> ['nrows', 'ncols', 'rows', 'cols', 'resid', 'p.clust', 'e.val']

[x.getContent() for x in cs1.asList ().getHead ().getContent ()]
['nrows', 'ncols', 'rows', 'cols', 'resid', 'p.clust', 'e.val']

cs1.asList().keys ()
array(['nrows', 'ncols', 'rows', 'cols', 'resid', 'p.clust', 'e.val'], java.lang.String)


in R:
names (clusterStack [[1]])
-> "nrows"   "ncols"   "rows"    "cols"    "resid"   "p.clust" "e.val"
class (clusterStack [[1]])  -> "list"
typeof (clusterStack [[1]]) -> "list"
typeof (clusterStack [[1]][[1]]) -> "double"

cs1 = clusterStack [[1]]
cs1$nrows
$nrows
[1] 10

$ncols
[1] 62

$rows
[1] "VNG6418h" "VNG2174h" "VNG5149h" "VNG6390h" "VNG6416h" "VNG5017h"
[7] "VNG6389g" "VNG6393h" "VNG6144g" "VNG6143h"

$cols
[1] "D30.rat"                "D60.rat"                "L60.rat"
[4] "X2"                     "X5"                     "X6"
[7] "X7"                     "X8"                     "X9"
[10] "X10"                    "X11"                    "X12"
[13] "X19"                    "X23"                    "X24"
[16] "X25"                    "Fe_4_vs_c"              "Fe_7_vs_c"
[19] "Cu_1_vs_c"              "Cu_2_vs_c"              "Cu_3_vs_c"
[22] "Mn_1_vs_c"              "Mn_2_vs_c"              "Mn_3_vs_c"
[25] "Zn_2_vs_c"              "VNG0750c_HO_L_vs_NRC.1" "VNG0750c_LO.L_vs_NRC.1"
[28] "bop_HO.L_vs_NRC.1"      "bop_LO.D_vs_NRC.1"      "ark_HO.D_vs_NRC.1"
[31] "boa1_LO.L_vs_NRC.1"     "crtI2_HO.L_vs_NRC.1"    "crtI2_LO.L_vs_NRC.1"
[34] "htlD_HO.L_vs_NRC.1"     "htlD_LO.L_vs_NRC.1"     "htr1_HO.D_vs_NRC.1"
[37] "htr1_LO.D_vs_NRC.1"     "htr1_LO.L_vs_NRC.1"     "htr2_HO.D_vs_NRC.1"
[40] "htr8_HO.L_vs_NRC.1"     "kinA2_HO.D_vs_NRC.1"    "kinA2_HO.L_vs_NRC.1"
[43] "phoR_HO.D_vs_NRC.1"     "phr2_HO.L_vs_NRC.1"     "sop2_LO.D_vs_NRC.1"
[46] "ura3_LO.D_vs_NRC.1"     "ura3_LO.L_vs_NRC.1"     "gC0"
[49] "gC10"                   "gC30"                   "gC60"
[52] "gC240"                  "G10"                    "G40"
[55] "G60"                    "G120"                   "G240"
[58] "G480"                   "FeSO4_15_vs_NRC.1b"     "FeSO4_80_vs_NRC.1"
[61] "FeSO4_160_vs_NRC.1"     "FeSO4_320_vs_NRC.1"

$resid
[1] 1.277129

$p.clust
[1] -6.42206

$e.val
[1] 8.4e-10

>

*--------------------------------------------------------------------------------
* increased java jython heap  (2 aug 2004)
in file  /Users/mpshannon/src/jython/jython

"/System/Library/Frameworks/JavaVM.framework/Versions/1.4.2/Home/bin/java" \
-Xmx1024M \
-Dpython.home="/Users/mpshannon/src/jython" \
-classpath "/Users/mpshannon/src/jython/jython.jar:$CLASSPATH" \
"org.python.util.jython" "$@"

*--------------------------------------------------------------------------------
* new bicluster data from Rich (31 jul 2004)
munpacked 2004-7-26-biclutRegInfs.RData object from Rich, in email
rec'd (26 jul 2004) titled 'inf result up to biclust 303.'
see rich's included notes (just below)
'rich's notes on new bicluster data, (26 jul 2004)'

mkdir /users/pshannon/data/halo/biclusters/2004.07.26
cd /users/pshannon/data/halo/biclusters/2004.07.26
cp -prv ../2004.07.07/* .
cp -p ~/attachments/2004-7-26-biclutRegInfs.RData .
meta-x R
load (file='2004-7-26-biclutRegInfs.RData')
ls ()
[1] "cand.inf"      "clusterStack"  "coeff.inf"     "colMap"
[5] "cv.err"        "gene.ids"      "gene.names"    "knockIn"
[9] "knockIn.names" "ratios"        "redExp"        "reg.infs"
[13] "tau"

cand.inf is a list of lists, and i could not figure out how to
write it out:
write.table (influence.nw, 'influence.txt', sep='\t', quote=FALSE, col.names=NA)
sure didn't work
so to prevent further delays, i'll just print this data structure
to stdout, within R, then edit it into a tab-delimited file.

stopping point:  1pm
created two scripts for rendering hand-edited, macro'd data into
tab-delimited files:

769 Jul 31 12:44 parseRawCoefficientsIntoTSV.py
786 Jul 31 12:41 parseRawInfluencesIntoTSV.py

preparation for using these scripts:

for (i in 1:303)  print (coeff.inf [i])
for (i in 1:303)  print (cand.inf [i])

capture this text, place in

54421 Jul 31 12:41 coeff.txt.raw
245292 Jul 31 11:48 influence.txt.raw

add '--record--' between each sublist, then use python parsers above.


*--------------------------------------------------------------------------------
* rich's notes on new bicluster data, (26 jul 2004)

one new thing. Paul we've talked a little about this, Vesteinn we've
talked about this at the jamboree. I've added the lists cand.inf and
coeff.inf

cand.inf:  holds the names of the guys that I screened for regulatory
influence

eg:
print( cand.inf[[1]] )
[1] "VNG6193h"              "VNG5163g"              "VNG2414h"
[4] "VNG2579g"              "VNG6287h"              "VNG2112c"
[7] "VNG1886c"              "VNG1816g.VNG6287h.max"    "VNG1816g.VNG6287h.min"
[10] "VNG2579g.VNG0349g.max" "VNG2579g.VNG0349g.min"
[12] "VNG5130h.VNG0919g.max"
[13] "VNG5130h.VNG0919g.min" "VNG1816g.VNG6438g.max" "VNG1816g.VNG6438g.min"
[16] "VNG6287h.VNG0136g.max" "VNG6287h.VNG0136g.min"

"VNG5130h.VNG0919g.min" means that min(VNG5130h, VNG0919g) shows good
ability to predict bicluster 1. This means that VNG5130h AND VNG0919g
are required to activate the expression of bicluster 1.

max == OR
min ==> AND
max - min ==> XOR

it is the best way I could think to keep the L1-shrinkage and learn
all two way interactions in a completely general way.

coeff.int: hold the coefficients that you would use to make the
functions for the cand.infs. So:
for biclust 1 we have:
print(  coeff.inf[[1]] )
[1] 0.00000000 0.17999269 0.00000000 0.04339048 0.17938639 0.00000000
[7] 0.19518155 0.00000000 0.04698690 0.00000000 0.00000000 0.02414132
[13] 0.00000000 0.00000000 0.01686756 0.00000000 0.00000000


so the function for biclust 1 would be

X_biclust1 ~ 0.17999269 * VNG5163g  + ...
+ 0.01686756 * min(VNG1816g, VNG6438g)

i left out the middle part, but you get the overall point.

Last detail:
the Inf didn't finish for clusters higher that 303
all guys over 303 are the null model.



*--------------------------------------------------------------------------------
* TreeDataBrowser window-closing bug fix (30 jul 2004)
finding out (with Megan) that os-level window closing causes problems,
i added windowListener behavior
built jar:  984209 26 Jul 14:12 TreeDataBrowserPlugin.jar
with 'make smalljar' in /users/pshannon/data/halo/microarrayXml
test this out with Nitin's IP web start
*--------------------------------------------------------------------------------
* porting the DataMatrix & browser to cy2 (27 july 2004)

trickster: cd /users/pshannon/cy2/csplugins/isb/pshannon/dataMatrix/apps
source ~/.cy2
(cd ..; make) && make run
next job is to enact the choices presented in
/users/pshannon/cy2/csplugins/isb/pshannon/dataMatrix/gui/actions/CorrelationsFinderDialog.java
which seems to be in CorrelationFinder   (also: straighten out the names of
these 3 correlation finding classes!)

(03 aug 2004)
cd /users/pshannon/cy2/csplugins/isb/pshannon/dataMatrix/apps
int selectedRowCount = lens.getSelectedRowCount (); in CorrelationFinderDialog
does not pick up manually selected rows.
I had just changed DataMatrixLens so that all rows were deselected on
construction.  the jtable selection is not being seen by the lens.

*--------------------------------------------------------------------------------
* andrew's cy1/cy2 interface (16 jun 2004)
copied from
/users/amarkiel/cvsdir5/csplugins/trial/pshannon/newDataCube/Cy*.java
stored in:
/users/pshannon/cy2/csplugins/isb/pshannon/cyInterface  (not in CVS)

*--------------------------------------------------------------------------------
* halo IP, now using tbpE also (28 jul 04)
without tbpE: 699 rows
with: 724 rows

added nbaliga - tbpE_pA_IP -> Halbacerium-20040504 to those already
selected under 'Search Batches'
query (making sure that 'pivot multiple conditions' is OFF
saved this query as bookmark under safari:halo
result set name: query_pshannon_20040729-100241

on trickster, cd /users/pshannon/data/halo/IP/2004.07.12/unitTests
added new target 'cy723r' to makefile
which produces graph of 260 nodes, 705 edges
make webstart:
created ~/tomcat/server1/webapps/halo/ip/try2
cp -p ../try1/* .
changed cy.jnlp
cp -p ~/data/halo/IP/2004.07.12/unitTests/*.eda .
cp -p ~/data/halo/IP/2004.07.12/unitTests/network.sif .
make

added link to webapps/halo/index.html


IP demo:
startup python console: Plugins->Python Console
hideByProbability (0.99)
hideByPeptideCount (2, 20)   # all edges < 2 and > 20 are hidden
hideOrphans ()
redraw ()
show ()                      # show all edges
seleds ()                    # select all edges


*--------------------------------------------------------------------------------
* halo todo:  fixes to IP webstart (20,28 jul 2004)
1) 2 nodes for tbpC: these are different orfs, merge them in the
/users/pshannon/data/halo/IP/2004.07.12/PullDownResultSet.py

see PullDownResultSet.translationTable, a hash:

'tfbA': 'VNG2184G',
'tfbB': 'VNG0734G',
'tfbC': 'VNG6351G',
'tfbD': 'VNG0869G',
'tfbE': 'VNG6389G',
'tfbG': 'VNG0254G',
'tfbF': 'VNG0315G',

'tbpA': 'VNG5039G',
'tbpB_1': 'VNG5052G',
'tbpB_2': 'VNG5052G',
'tbpB': 'VNG5052G',
'tbpC': 'VNG5142G',
'tbpD': 'VNG5163G',
'tbpE': 'VNG2243G',
'tbpF': 'VNG6438G',
'bat': 'VNG1464G',

'tfeA': 'VNG0757G',

'VNG6037G': 'VNG5039G',  # tbpA
'VNG5245G': 'VNG5052G',  # tbpB
'VNG6050G': 'VNG5052G',  # tbpB
'VNG6476G': 'VNG5052G',  # tbpB

'VNG6140G': 'VNG5142G',  # tbpC



2) 2 nodes for tbpB (?) try same strategy
3) after KEGG layout, -all- edges are redrawn, including those which
had been hidden before the layout request.
solution:  modify the annotation browser code so that it unhides
only previously unhidden edges.
4) add python function:  hideByInteractionWith_pA_butNotIfItsBait (28 jul 2004)
other comments:

- tbpE disappears when hiding from python.  another source/target confusion?
- want to delete every edge (and target node) which comes down with pA
unless the target node is
a) a bait protein
b) is known to have DNA binding (available from Rich, in an R object)

*--------------------------------------------------------------------------------
* some jws, python, high simulator problems
http://db.systemsbiology.net/cytoscape/projects/static/highSchool/
both jws's complain about webread when the python console starts up;
this seems to occur only on john thomson's linux box with mozilla
*--------------------------------------------------------------------------------
* fixed SbmlReader bug (28 july 2004)
apparently with SBML level 1 version 2, some elements and attributes
were renamed to 'species' from 'specie'
I changed and checked in ~/cy/csplugins/sbw/readers/SbmlReader.java
unitTests/SbmlReaderTest.java
along with the brucella.xml received in a bug report from

Hi,

This is Hui Liu from Virginia Bioinformatics Institute. I am trying to use
cytoscape to visualize our biomolecule interactions (data stored in SBML
format) but encountered some problems. First, I tried the sample sbml file
that is provided on your website and it was displayed successfully, which
means the installation should be fine. But when I tried my own sbml file, I
only got several unconnected reaction nodes. All the species nodes
disappeared. I don't know what is the problem. I used the online tool from
sbml.org to successfully validate and visualize the same sbml document. The
attached is my sbml file.

And, could you please share with me your documentation and source code for
this plugin if available? Also, is it planned to support sbml level 2?

Your time and help is highly appreciated.

Hui

*--------------------------------------------------------------------------------
* test python console with sim0.py in cy2 (27 jul 2004)
rowan fixed the no-update problem
(see 'create a cy2 version of the py interpreter (15 july 2004)' below)
update the cy2 source and rebuild jar:
(see 'get and build latest cy2 from cvs (14 july 2004)' below)
switch to plugin directory, run cy2, load & execute sim0.py
cd /users/pshannon/cy2/csplugins/isb/pshannon/py
source /users/pshannon/.cy2
make run
from plugins menu, load 'py console'
(using x from db: very sluggish interaction, even before running plugin, for node selection
and node dragging)
running on trickster:  excellent!

rowan says: can you cast giny Node (or was it giny NodeView) to PNode in
jython?  if so, you gain access to all the animation capabilities of
piccolo....
*--------------------------------------------------------------------------------
* jfreechart xy (ratios/lambda) plotter for halo TreeDataBrowser.py (25 jun 04)
browser constructs a PlotControllerListBox from the 'Plot' button
which constructs a ScatterPlotter
debug example:
x = [10, 5, 7]
y = [12, 3, 0]
pointNames = ['10,5', '12,3', '7,0']

the pointNames are assigned to actual points (5,3)  (7,0)  (10,12)
telling us that they are assumed to refer to the points sorted on x.
the answer?
1) disable this sorting
2) or, sort the pointNames so that they are in order by the x
value of the point to which they refer


*--------------------------------------------------------------------------------
* demo for john thomson, 4 node network for high school project (26 jul 04)
/users/pshannon/proj/highschool/4nodedemo
*--------------------------------------------------------------------------------
* mail from megan, with cytoscape suggestions (26 jul 04)

Paul-
Here are those issues I discussed with you on Thursday about Cytoscape:
*The movie pop-up does not act as its own separate window so when it goes
behind the main screen you cannot access it again.  It would be nice to have
an icon on the bottom to click on to make it reappear.

*Movie button work for more than one window so they go at the same time.
This would be helpful when looking at a specific set of genes and the whole
network.  Also, it would be nice to have the movie play with different
screens showing different conditions playing at the same time and rate.

*There is a glitch in the window for specific conditions. Sometimes when I
press load and then that window with the option to make graphs, watch
movies, etc. does not show up.

Thats all I came up with right now. Let me know if it works out. Also, I am
not well versed in computer jargon so sorry if my descriptions are
elementary.

Thanks,
Megan Meislin

*--------------------------------------------------------------------------------
* create a jython plugin jar, put in classpath, load into cytoscape (26 jul 04)
jythonc -j treeDataBrowser.jar TreeDataBrowser.py   # result is about 700k

*--------------------------------------------------------------------------------
* tracing down bug in TreeDataBrowser (26 jul 04)
in the latest jws version of the halo condition chooser, a serious bug
appears.  symptoms:  the selected conditions do not load into a visible
matrix.  related (?) symptom:  the number of explicitly selected condition
count is consistently way too high.

these symptoms appear consistently if a tree data browser is opened, closed,
and then a second one is opened.

to track this down, i tried three strategies; only the last one worked:

1) from a single jython interpreter, open multiple successive browsers

cd /users/pshannon/data/halo/microarrayXml
make tree

2) from the jython interpreter w/in cytoscape, execfile ('TreeDataBrowser.py');
cd /users/pshannon/data/halo/microarrayXml
do this twice
Trickster.microarrayXml> make -f cyDemo/makefile fromJy

3) build (via 'make smalljar') a jython jar of TreeDataBrowser.py,
and load that plugin class via the props file
cd /users/pshannon/data/halo/microarrayXml
make smalljar
cd cyDemo
make fromJar

cd to  /users/pshannon/data/halo/microarrayXml/cyDemo; make
load DataBrowserPlugin.jar (from python) in parent directory
installed as
5. Halobacterium NRC-1 network, new data browser (9 June 2004)
in the halo 8060 web page

*--------------------------------------------------------------------------------
* (re-) installing jython on trickster (26 jul 04)
when i installed this some months ago (27 mar 04) the jython.jar file
seemed to pick up the wrong java directory -- it appeared to be the
java on net:/tools/bin/....

so let's try again.

trickster>  cd /Users/mpshannon/src/jython
cp -p ~/safariDownloads/jython_21.class .
java jython_21
change 'Destinations' directory to /Users/mpshannon/src/jython
(/Users/mpshannon/jython-2.1 is proposed)
after resetting the .profile-specified PATH on trickster,
the local jythonc was found, and ran fine (creating dbgui.jar
in /users/pshannon/data/halo/microarrayXml, in repsonse to
make smalljar)

Trickster.microarrayXml> dp
/sw/bin
/sw/sbin
/bin
/sbin
/usr/bin
/usr/sbin
/usr/X11R6/bin
/Users/mpshannon/src/jython
/users/mpshannon/bin
/usr/local/bin
/users/pshannon/src/apache-ant-1.6.1/bin

*--------------------------------------------------------------------------------
* add new 'account' to condition chooser (18 aug 2004)
cd  ~/tomcat/server1/webapps/halo/data/
add name/pw to .passwd
add name to condition in permissions
*--------------------------------------------------------------------------------
* adding password protection to the condition chooser (19 jul 2004)
cd /users/pshannon/data/halo/microarrayXml/unitTests
make pwHttpFetch
start with parsing group/password pairs in
PasswordProtectedHttpFileFetcher.py:getPasswords
then read and parse the .permissions file
only return approved filenames from overridden
geXmlFilenamesWithUrls

*--------------------------------------------------------------------------------
* pretty good swing jython user-password dialog, with validation (19 jul 2004)
cd /users/pshannon/examples/jython/swing/passwordDialog
make    # runs jython go.py
developed for the cytoscape condition chooser, data browser
*--------------------------------------------------------------------------------
* pretty good java swing JList listbox example, with DefaultListMode (16 nov 2005)

from javax.swing import *
f = JFrame ()
model = DefaultListModel ()
data = ['a', 'b', 'c']
for d in data:
model.addElement (d)

listbox = JList (model)
f.add (listbox)
f.pack ()
f.setVisible (1)
model.addElement ('yyy')
f.pack ()




* jython swing template classes: jframe & jdialog (19 jul 2004)
/users/pshannon/examples/jython/swing
frameSubclassTemplate.py
dialogSubclassTemplate.py

jython frameSubclassTemplate.py creates a toplevel frame; a button there
runs the sample modal dialog specified by dialogSubclassTemplate.py

the dialogSubclassTemplate also runs standalone, but does not call
java.lang.System.exit (0) when dismissed

*--------------------------------------------------------------------------------
* turn tomcat name resolution on (19 jul 2004)
an xml element (under <Engine ...) in conf/server.xml controls
dns name resolution:

<Valve className="org.apache.catalina.valves.AccessLogValve"
fileDateFormat="yyyy-MM-dd"
prefix="localhost_access_log."
suffix=".txt"
resolveHosts="true"/>


*--------------------------------------------------------------------------------
* autoload of python scripts to spy console (18 jul 2004)
/local/tomcat/webapps/cytoscape/scripts/....
http://db.systemsbiology.net/cytoscape/scripts/....
new files are on db:~/in/spy.tar.gz

*--------------------------------------------------------------------------------
* add filebrowser to python console (16 jul 2004)
cd /users/pshannon/cy/csplugins/trial/pshannon/spy
strategy which should work:

url = '%s/%s' % (scriptHome, 'filechooser.py')
exec (compile (webreader.read (url), '<string>', 'exec'))

where 'webreader' is an instance of a class defined in java, known to
PyConsolePlugin, and passed to jython.  and scriptHome is also
defined in the plugin, and passed to jython


*--------------------------------------------------------------------------------
* high school simulator web starts (16 jul 2004)
/local/tomcat/webapps/cytoscape/projects/static/highSchool
cy1 and cy2 web starts for blank slate, and 4 node simulation
cy1 blank slate and demo0 use these jars:
<jar href="cytoscape.jar"/>
<jar href="data.jar"/>
<jar href="../../../../../jars/jython.jar" />
<jar href="../../../../../jars/spyconsole.jar" />
cy2 dem0 uses these:
<jar href="cytoscape.jar"/>      # created by ant releast
<jar href="data.jar"/>           # created by make
<jar href="jython.jar" />        # from www.jython.org
<jar href="spyconsole.jar" />    # built by me in  ~/src/jython/SPy_Console/
<jar href="PyConsole-cy2.jar" /> # built by me in ~/cy2 from csplugins/isb/pshannon/py


*--------------------------------------------------------------------------------
* halo todo:  missing timepoints in gamma radiation data
The gamma radiation data is missing several time points -I believe there
are at least 10 time points for the gamma irradiated set.  The problem
might be that the number of samples for the control (C0, C30 etc.) and
the experimental (G0, G10, G30 etc.) do not match.  We can talk more on
this problem later today.  This is not an urgent issue -I just wanted to
mention it before it slipped my mind.

*--------------------------------------------------------------------------------
* create a cy2 version of the py interpreter (15 july 2004)
cd /users/pshannon/cy2/csplugins/isb/pshannon/py
source /users/pshannon/.cy2
make run
found a cy2 bug:  display is not updated absent mouse motion.
todo: switch back to cy1, using portable script
create a /users/pshannon/.cy1 which, when sourced, sets everything up
to compile and run cy1

*--------------------------------------------------------------------------------
* yfiles 2.1 javadoc (15 jul 2004)
copied to trickster:~mpshannon/src/yfiles
available in trickster safari under the docs bookmark menu

*--------------------------------------------------------------------------------
* cog clusters to go terms (14 jul 2004)

from gofriends mailing list (11 jun 2004)

A mapping of COG (Clusters of Orthologous Groups) functional categories to
GO terms has been added to the external2go directory:

FTP:	ftp://ftp.geneontology.org/pub/go/external2go/cog2go
Web:	http://www.geneontology.org/external2go/cog2go
CVS:	go/external2go/cog2go
*--------------------------------------------------------------------------------
* get and build latest cy2 from cvs (14 july 2004)
create tunnel:
ssh pshannon@132.239.135.20 -L 2401:132.239.135.20:2401   (password: sunny_day)
alias cvsdir5='cvs -d:pserver:pshannon@localhost:/common/cvsdir5'
export CVSROOT=:pserver:pshannon@localhost:/common/cvsdir5
mkdir ~/cy2
cvsdir5 login
cd ~/cy2
cvsdir5 checkout cytoscape    or cvsdir5 update cytoscape
cd ./cytoscape
~amarkiel/bin/ant release
find 6.5M cytoscape.jar  in release/
/users/pshannon/cy2/cytoscape/release/cytoscape.jar: 6562390 Jul 27 10:32
source ~/.cy2
try the python interpreter plugin:
java -Xmx512M cytoscape.CyMain -y giny
*--------------------------------------------------------------------------------
* cvs tips from andrew (14 july 2004)
In terminal #1:
ssh amarkiel@132.239.135.20 -L 2401:132.239.135.20:2401
In terminal #2:
cvs -d:pserver:amarkiel@localhost:/common/cvsdir5 {cvs-command}
Naturally, replace my username with yours.

I use
alias cvsdir5 'cvs -d:pserver:amarkiel@localhost:/common/cvsdir5'
which then allows commands like
cvsdir5 co cytoscape

ssh pshannon@132.239.135.20 -L 2401:132.239.135.20:2401  (pw: sunny_day)


*--------------------------------------------------------------------------------
* demo simulator python script in cytoscape, using SPyConsole (10 july 2004)
/users/pshannon/cy/csplugins/trial/pshannon/spy
make run
execfile ('sim0.py')
*--------------------------------------------------------------------------------
* cy 1 api, as useful to python console
hider = cw.getGraphHider ()
ea = cw.getEdgeAttributes ()
na = cw.getNodeAttributes ()
edges = cw.getGraph().getEdgeArray ()
hider.hide (edges [0])
hider.unhideAll ()
ea.getCanonicalName (edges [0]) -> 'VNG6037G (pullsdown) Chr_ORF0639'
ea.getGraphObject ('VNG6037G (pullsdown) Chr_ORF0639')

*--------------------------------------------------------------------------------
* todo, halo, lambda range selector in condition chooser/browser (13 jul 2004)
deep asks:

> Can I select nodes based on lambda range rather than a matching value in
> Cytoscape?

i reply:

I need to add a little plugin to make this work.  I'd be glad to
do so!

It should only take a few minutes, and I can probably have it ready
for you within a week.  (Sorry that I can't do it straight away -- I have
a few projects I need to complete first.)

*--------------------------------------------------------------------------------
* todo, halo, correlator (13 jul 2004)
no longer gets negatively correlated curves.  fix this.  add radio buttons
- positive
- negative
- both
*--------------------------------------------------------------------------------
* cytoscape python intepreter  (10 jul 2004)
cd /users/pshannon/cy/csplugins/trial/pshannon/spy
make run
uses change to SPyConsole.java found in
/users/pshannon/src/jython/SPy_Console/src/spyconsole/SPyConsole.java
edit that source
javac *.java
cd /users/pshannon/src/jython/SPy_Console
cp -p src/spyconsole/SPyConsole*.class  classes/spyconsole/
*--------------------------------------------------------------------------------
* /users/pshannon over quota (13 jul 2004)
from eriks:
3455606 data
1390004 tomcat
1349807 work
302296  rmail
166953  cy

db.data> du -sk *
3	CVS
5310	GO
6368	activePathsNew
249	alexRives
740	andrew
8264	annotation
61303	arabidopsis
3147	biodata
4508	blin
312	cyHardCases
180	das
433	davidUnderhill
33772	demo
16	dl
3915	fetch
67754	glake
165380	halo
46762	haloarcula
1351	hi
124535	human
1986129	import
489781	import.old
167	isbYeastGroup
1	loadList
37934	macrophage
1	matrix.expression
4059	mflory
10628	mouse
5131	nat
15831	nitin
3	pat
24	phenotypeGenetics
1	pluginSamples
17	proteinInteractions
14780	proteinProphet
4716	qiang
8	r
27	sbeams
2567	synonyms
5020	tb
10	testAnnotation
177	testSif
1590	tideker0
1614	tidekerBig
4349	tigrfam
8104	tuberculosis
8891	tutorial
2	uniquifyInteractions
5	util
248	validation
2103	vesteinn
1	xml
10032	xref
4	xref.old
180889	yarko
126528	yeast


*--------------------------------------------------------------------------------
* cy project halo IP (15 jul 04) working version
cd /users/pshannon/data/halo/IP/2004.07.12/unitTests
make cy699r
requests from nitin after demo:
- tbpE disappears when hiding from python.  another source/target confusion?
- want to delete every edge (and target node) which comes down with pA
unless the target node is
a) a bait protine
b) is known to have DNA binding (available from Rich, in an R object)
*--------------------------------------------------------------------------------
* cy project halo IP requests from nitin (12 jul 04)
(15 jul 04) working version:

- remove self loops
- remove all VNG7* orfs
- ensure that nitin's change to the name of ProteinA (there also used
to be a pA name) show up
- include all experiment replicas
- get annotation for all nodes (from KEGG? from COGs? using GO terms?)
- create tools to select and hide:
by edge attributes, by threshold
by node type (different kinds of regulatory control molecules: tf, promoters,
etc, using annotation from cognitor, KEGG, or the like)
by edge weight

next up: in /users/pshannon/data/halo/IP/2004.07.12/PullDownResultSet.py
accumulate PullDown objects, not in a list, but in a hash keyed by
'%s-%s' % (bait, prey) strings; store a list there
after the entire sbeams result set has been read, traverse this list,
examining duplicates, using some criteria (larger probability first, then
peptide count?) to choose among the duplicates.
add extra edge attributes to preserve information about the duplicates?

(13 jul 04):
multiple edges now possible, from replicated experiments
edge attributes are written with _n suffixes, like this:

VNG6037G (pullsdown) ProteinA = 19     # the first edge seen
VNG6037G (pullsdown) ProteinA_1 = 856  # the second edge seen

to match what cytoscape does when it encounters duplicate edges with the
same name.

tried to create a full pulldown project, with resultset
query_pshannon_20040713-154946
avaialable in /users/pshannon/data/halo/IP/2004.07.12/unitTests
with 'make cy699r'
these conditions:


nbaliga - bat_pA_IP      -> Halobacterium-20040504
nbaliga - pA_IP          -> Halobacterium-20040504
nbaliga - pA_IP_r        -> Halobacterium-20040504
nbaliga - tbpA_pA_IP     -> Halobacterium-20040504
nbaliga - tbpA_pA_IP_r   -> Halobacterium-20040504
nbaliga - tbpB_pA_IP     -> Halobacterium-20040504
nbaliga - tbpB_pA_IP_r   -> Halobacterium-20040504
nbaliga - tbpC_pA_IP     -> Halobacterium-20040504
nbaliga - tbpC_pA_IP_r   -> Halobacterium-20040504
nbaliga - tbpD_pA_IP     -> Halobacterium-20040504
nbaliga - tbpD_pA_IP_r   -> Halobacterium-20040504
nbaliga - tbpF_pA_IP     -> Halobacterium-20040504
nbaliga - tbpF_pA_IP_r   -> Halobacterium-20040504
nbaliga - tfbA_pA_IP     -> Halobacterium-20040504
nbaliga - tfbB_pA_IP     -> Halobacterium-20040504
nbaliga - tfbC_pA_IP     -> Halobacterium-20040504
nbaliga - tfbD_pA_IP     -> Halobacterium-20040504
nbaliga - tfbE_pA_IP     -> Halobacterium-20040504
nbaliga - tfbE_pA_IP_r   -> Halobacterium-20040504
nbaliga - tfbF_pA_IP     -> Halobacterium-20040504
nbaliga - tfbF_pA_IP_r   -> Halobacterium-20040504
nbaliga - tfbG_pA_IP     -> Halobacterium-20040504
nbaliga - tfbG_pA_IP_r   -> Halobacterium-20040504


(13 jul 2004): hide edges below probability & peptide thresholds
see /users/pshannon/data/halo/IP/2004.07.12/unitTests/filter.py
all bat pulldowns have no edge attributes.  figure out why.
this produces None as the result of the 'get (edgeName, 'protein probability')
in filter.py.


(14 jul 2004): create a small project to explore python manipulation oddities
nbaliga - tbpA_pA_IP     -> Halobacterium-20040504
nbaliga - tbpD_pA_IP     -> Halobacterium-20040504

20 rows: query_pshannon_20040714-135254

nbaliga - tbpA_pA_IP -> Halobacterium-20040504
nbaliga - tbpA_pA_IP_r -> Halobacterium-20040504
nbaliga - tbpD_pA_IP -> Halobacterium-20040504
nbaliga - tbpD_pA_IP_r -> Halobacterium-20040504

69 rows: query_pshannon_20040714-142721

(14 jul 2004:4pm): bug found and fixed:  the hide methods in filter.py
deleted source nodes when those nodes were targets of other, first-
encountered source nodes -- edges are deleted first, then the target
nodes.  fix:  make a list of all target nodes encountered, and only
delete them if they are not also in a list of encountered source
nodes.

typical use:
hideByProbability (0.99)
hideByPeptideCount (2, 20)   # all edges < 2 and > 20 are hidden
show ()                      # show all edges
seleds ()                    # select all edges


*--------------------------------------------------------------------------------
* create cy project from halo IP data (9 jul 04) try 2

/users/pshannon/data/halo/IP/2004.07.09

https://db.systemsbiology.net/sbeams/cgi/Proteomics/BrowseProteinSummary
Project:  nbaliga - pA_IP (351)

to develop an sbeams-to-cytoscape class, I chose 3 experiments:

nbaliga - tfbE_pA_IP -> Halobacterium-20040504
nbaliga - tfbF_pA_IP -> Halobacterium-20040504
nbaliga - tfbG_pA_IP -> Halobacterium-20040504

protein group probability > 0.7
show bait proteins
query  -> produced result set:  query_pshannon_20040709-180948

special effort beyond this straightforward extraction:
1) map tfbE to VNG6389G
2) some orf names look like this:
VNGxxxx[m,n]
which attests to their being modified genbank sequences.
when putting these into a network, use the [m,n] name as common,
but the original name (w/o the m or n) as the canonical name.
if any of these actually have a gene symbol, then use another
strategy, adding (say) a 'genbank' name as a node attribute.
3) in cytoscape (or in sbeams extraction?) exclude all edges to protein A
with total protine peptides >= some number n
since (i think) pA sticks to everything, this adds too much noise...

query_pshannon_20040709-203444: 433 interactions, all of the experiments without
the '_r' indicating repetition, which nitin wants merged with the original
experiments, using the higher values in each case.

*--------------------------------------------------------------------------------
* create cy project from halo IP data (9 jul 04) try 1

[abandoned in favor of try 2:  this approach pivots rows, which only creates
extra trouble and confusion. see try2, above!]

/users/pshannon/data/halo/IP/2004.07.09

https://db.systemsbiology.net/sbeams/cgi/Proteomics/BrowseProteinSummary
Project:  nbaliga - pA_IP (351)
Protein Group Probability > 0.7
Display Options:
Show Bait Proteins
Pivot Mutltiple Conditions
Search Batches:
everything matching
nbaliga - *_IP -> Halobacterium-20040504

to comprehend this table, i choose a single 'batch':
nbaliga - tfbE_pA_IP -> Halobacterium-20040504

which produces these columns [I omit all of the 'combined' columns, which replicate
columns 4-7]:

Protein Name:  VNG0451G
Accession:  VNG0451G
Canonical Name:
tfbE_pA_IP Pulldown Protein:  tfbE
tfbE_pA_IP Protein Prob:  0.94
tfbE_pA_IP Total Protein Peptides:  1
tfbE_pA_IP Protein Quant Average:  0.00
tfbE_pA_IP Protein Quant Uncertainty:  0.00
tfbE_pA_IP Protein Quant N:  0.00
Favored Codon Frequency:  0.00
Transmembrane Regions Class:  0
Number of Trnasmembrane Regions:  0
Protein Length:  207
Reference Description:  phoU;Transcriptional regulator

this will produce the following cy info:

tfbE pullsdown VNG0451G
probability = 0.94
peptides = 1

special effort beyond this straightforward extraction:
1) map tfbE to VNG6389G
2) some orf names look like this:
VNGxxxx[m,n]
which attests to their being modified genbank sequences.
when putting these into a network, use the [m,n] name as common,
but the original name (w/o the m or n) as the canonical name.
if any of these actually have a gene symbol, then use another
strategy, adding (say) a 'genbank' name as a node attribute.

the above 46-row result set, showing all halo genes pulled down by
bait tfbE, has name query_pshannon_20040709-160217.


*--------------------------------------------------------------------------------
* nitin's letter to molecular microbiology (jun3 2000)
Is gene expression in Halobacterium NRC-1 regulated by multiple
TBP and TFB transcription factors?

Gene expression is regulated by different mechanisms in different
organisms. The bacterial core RNA polymerase ( 2 ') discriminates
between subsets of promoters by binding different factors. Eukaryotes
have evolved a more complicated system making use of three RNA
polymerases to direct synthesis from different promoter
families. Archaea possess a simplified version of RNA polymerase II
transcription machinery with a single multisubunit RNA polymerase and
a subset, TBP and TFIIB, of general transcription factors (Reeve
etal., 1997, Cell 89: 999-1002). However, multiple transcription
factor homologues have been identified in several archaea including
Halobacterium NRC-1 (Ng etal., 1998, Genome Res 8: 1131-1141),
Haloferax volcanii (Thompson etal., 1999, Mol Microbiol 33:
1081-1092) and Pyrococcus horikoshii OT3 (Kawarabayasi etal., 1998,
DNA Res 5: 147-155). With the impending completion of the
Halobacterium NRC-1 genome project, this extreme halophile is turning
out to be a champion of multiple transcription factors, with six tbp
and seven tfb genes ( http://zdna.micro.umass.edu/haloweb ).

Multiple TBP and TFB encoding genes in Halobacterium NRC-1

Genome sequencing of Halobacterium NRC-1 suggests the presence of
multiple TATA-binding proteins, four (TBPa, TBPb, TBPc and TBPd) coded
by pNRC100, a 191kbp minichromosome, and two (TBPe and TBPf) coded
elsewhere in the genome (Fig.1). Archaeal TBPs, like their eukaryotic
counterparts, possess repeated domains that combine to form a
saddle-like structure with two stirrups (DeDecker etal., 1996, J Mol
Biol 264: 1072-1084). This domain similarity is much higher in
archaeal TBPs (42%) compared with eukaryotic TBPs (25% similarity)
(Soppa, 1999, Mol Microbiol 31: 1295-1305). In Halobacterium NRC-1,
except for TBPa, which has a single C-terminal domain, the remaining
five have C- to N-terminal domain similarities ranging from 39% to
61%. TBPa may function by dimerization.


Of the seven TFBs identified in Halobacterium NRC-1, all possess the
N-terminal zinc-finger domain, six have the imperfect cyclin repeat
and all are capable of adopting the HTH motif structure at their
C-termini. The glycine (G) and lysine (K)/arginine (R) residues within
the cyclin repeats, required for interaction with the TBP-DNA complex
(Buratowski and Zhou, 1993, Proc Natl Acad Sci USA 90: 5633-5637) were
conserved in the seven proteins with the exception of TFBe, which
lacked a positively charged residue at position 301
(Fig.2). Phylogenetic analyses suggest that the TFBs and the TBPs
evolved from single common ancestors.

A new paradigm for gene regulation?


Given this diversity of transcription factors in Halobacterium NRC-1
it is possible that the six TBPs and seven TFBs interact in up to 42
different combinations driving transcription from a correspondingly
large set of promoters (Thompson etal., 1999, Mol Microbiol 33:
1081-1092). The formation of alternative TBP-TFB-RNAP complexes, with
the possibility of interactions with different accessory factors, may
help to explain the diversity of halophilic promoters (Baliga and
DasSarma, 1999, J Bacteriol 181: 2513-2518; Soppa, 1999, Mol Microbiol
31: 1295-1305) and the lack of a requirement for the BRE sequences
(Littlefield etal., 1999, Proc Natl Acad Sci USA 96: 13668-13673;
Tsai and Sigler, 2000, EMBO J 19: 25-36) in the expression of the
Halobacterium NRC-1 bop gene (Baliga and DasSarma, 2000, Mol Microbiol
36: 000-000). This potential regulatory strategy is conceptually
similar to the use of multiple sigma factors by bacterial RNA
polymerase and represents an extension of the eukaryotic RNA
polymerase II transcription system. Finally, the presence of TBP-like
(Dantonel etal., 1999, Trends Biochem Sci 24: 335-339) and
TBP-related (Maldonado, 1999, J Biol Chem 274: 12963-12966) proteins
in some metazoan and mammalian cells, respectively, suggests that
alternative TBP-TFB-RNAP complexes may be present in eukaryotic
systems as well (Buratowski, 1997, Cell 91: 13-15).



*--------------------------------------------------------------------------------
* new halo data FeSO4 time series (7 jul 04)
metadata: FeSO4 (6mM -constant), -1 min, 0 min, 5 min
munpacked to /users/pshannon/attachments/halo_FeSO4_ts_06252004.mrna (366929  7 Jul 17:10)
created /users/pshannon/data/halo/microarrayXml/FeSO4-2004.07.07
cp -p halo_FeSO4_ts_06252004.mrna halo_FeSO4_ts_06252004.mrna.orig
chmod 400 halo_FeSO4_ts_06252004.mrna.orig
make changes:
1) in emacs, remove ^M
2) delete last line, leaving 2401 (2400 genes, 1 title line)
3) delete first column (did this, slowly, with an emacs macro.  perhaps next
time use python)
4) in title line, changed FeSO4_ to FeSO4__
5) in title line, removed all '.sig' tags to column titles
6) head -1 halo_FeSO4_ts_06252004.mrna | tr '\t' '\n' | sort |uniq > junk
7) cp /users/pshannon/data/halo/allMicroarrayData/88conds/util/splitIntoRatiosAndLambdas.py .
8) edit variable 'titlesToGrab' to include the list from junk:

titlesToGrab    = ['GENE',
'FeSO4__-1_vs_NRC-1',
'FeSO4__0_vs_NRC-1',
'FeSO4__5_vs_NRC-1b',
'FeSO4__10_vs_NRC-1b',
'FeSO4__15_vs_NRC-1b',
'FeSO4__20_vs_NRC-1',
'FeSO4__25_vs_NRC-1b',
'FeSO4__40_vs_NRC-1',
'FeSO4__80_vs_NRC-1',
'FeSO4__160_vs_NRC-1',
'FeSO4__320_vs_NRC-1']

preferredTitles = ['GENE',
'-001_vs_NRC-1',
'000_vs_NRC-1',
'005_vs_NRC-1b',
'010_vs_NRC-1b',
'015_vs_NRC-1b',
'020_vs_NRC-1',
'025_vs_NRC-1b',
'040_vs_NRC-1',
'080_vs_NRC-1',
'160_vs_NRC-1',
'320_vs_NRC-1']

9)  python splitIntoRatiosAndLambdas.py halo_FeSO4_ts_06252004.mrna
creates feso4.ratio & .lambda

10)  grabbed a copy of db:/users/pshannon/tomcat/server1/webapps/halo/data/xmlv2/zinc.xml
and edited it to create feso4.xml.  see
/users/pshannon/data/halo/microarrayXml/FeSO4-2004.07.07/feso4.xml

11) test:
add this line to /users/pshannon/data/halo/microarrayXml/TreeDataBrowser.py

repository = '/users/pshannon/data/halo/microarrayXml/FeSO4-2004.07.07'

12) once satisfied:
on db:/users/pshannon/tomcat/server1/webapps/halo/data/xmlv2
cp /users/pshannon/data/halo/microarrayXml/FeSO4-2004.07.07/feso4.xml .
cd ..
cp /users/pshannon/data/halo/microarrayXml/FeSO4-2004.07.07/feso4.ratio .
cp /users/pshannon/data/halo/microarrayXml/FeSO4-2004.07.07/feso4.lambda .

*--------------------------------------------------------------------------------
* concrete steps for creating cytoscape project from inferelator R output (7 jul 04)
write.table (influence.nw, 'influence.txt', sep='\t', quote=FALSE, col.names=NA)
top 10 lines put in
/users/pshannon/data/halo/biclusters/2004.07.07/unitTests/influence10.txt

487 influence.txt
10 influence10.txt

make proj:
tests the class ../InfluenceToCyProj.py, making sure it can extract a network,
node types, edge types, and edge weights from the influence file.
make cy:
runs the same unitTest, but with an influence file as command line argument,
and creates a cytoscape project fitting this bill:

sif=network.sif
noa=nodeTypes.noa
eda=weights.eda

manually, created static cytoscape project from these results in
/users/pshannon/tomcat/server1/webapps/halo/inferelator/try0
which can be run from db:8060/halo

(8 jul 04) todo -- from critique by rich, nitin and dave
- map cluster condition & member count control cluster node width & height
- add a list of member genes to cluster node attribute
- adapt tspace (or rmi replacement) so that broadcasting selected clusters
results in broadcasting the name of the genes which are the cluster members
- add a new plugin which, in the style of edge 'select or hide by attributes'
presents a slider allowing for select/hide by edge weight
*--------------------------------------------------------------------------------
* reading & translating inferelator output from rich (7 jul 04)
> load (file='inf_6-29_over0.5.PS.RData')
> ls ()
[1] "clusterStack"  "colMap"        "cv.err"        "gene.ids"
[5] "gene.names"    "influence.nw"  "knockIn"       "knockIn.names"
[9] "ratios"        "redExp"        "reg.infs"      "tau"

*----------------------------------------------------------------
#
# why 486 nodes?  which one belongs to which row?
> length (colnames (influence.nw))  -> 114
> colnames (influence.nw)
[1] "VNG2504g" "VNG0943c" "VNG2641h" "VNG2661g" "VNG0996g" "VNG1406g"
[7] "VNG0247c" "VNG1438h" "VNG2163h" "VNG2664g" "VNG2614h" "VNG5068g"
[13] "VNG0315g" "VNG0374g" "VNG2112c" "VNG2666g" "VNG0039h" "VNG0160g"
[19] "VNG1388h" "VNG1464g" "VNG1483c" "VNG0536g" "VNG0703h" "VNG5130h"
[25] "VNG0734g" "VNG5163g" "VNG1845c" "VNG0835g" "VNG0869g" "VNG0237h"
[31] "VNG1510c" "VNG1617h" "VNG5142g" "VNG1816g" "VNG5176c" "VNG6143h"
[37] "VNG2051g" "VNG1136g" "VNG1029c" "VNG1123g" "VNG2476c" "VNG1548c"
[43] "VNG0654c" "VNG5028g" "VNG5075c" "VNG5144h" "VNG6239g" "VNG6287h"
[49] "VNG0424c" "VNG1179c" "VNG2126c" "VNG0066h" "VNG2662g" "VNG5009h"
[55] "VNG0751c" "VNG0258h" "VNG0426g" "VNG0293h" "VNG1140g" "VNG1490h"
[61] "VNG2243g" "VNG0919g" "VNG1954h" "VNG2665g" "VNG2563h" "VNG0101g"
[67] "VNG6351g" "VNG1377g" "VNG6438g" "VNG0511h" "VNG5182g" "VNG0940g"
[73] "VNG2668g" "VNG1886c" "VNG1141g" "VNG0040c" "VNG0462c" "VNG0471c"
[79] "VNG1496g" "VNG6387h" "VNG6402h" "VNG1535g" "VNG6193h" "VNG5141g"
[85] "VNG1836g" "VNG2094g" "VNG1215g" "VNG0194h" "VNG2414h" "VNG1405c"
[91] "VNG1426h" "VNG0530g" "VNG2579g" "VNG0254g" "VNG0320h" "VNG2053g"
[97] "VNG6389g" "VNG0176h" "VNG0889g" "VNG0887g" "VNG0884g" "VNG0885g"
[103] "VNG0349g" "VNG0134g" "VNG0136g" "VNG0486g" "o2"       "light"
[109] "uv"       "gama"     "Fe"       "Mn"       "Zn"       "Cu"

no rownames:
> rownames (influence.nw) -> NULL
> plot (influence.nw [1,])  -> plots 114 points, all but 5 equal to 0:
3 above, 2 below

> influence.nw [1,] [abs (influence.nw [1,]) > 0]
> these are 'predictors' and transcription factors (of which there are 160 total)
> only 114 are listed in reg.infs, including 8 environmental conditions

VNG1548c   VNG6287h   VNG0194h   VNG2579g   VNG0320h
0.1352168  0.1404159 -0.1437422  0.1558062 -0.2165651

interpret: these 5 genes control cluster 1 synthesis, which
from clusterStack [[1]] contains  4 genes: "VNG6413h" "VNG2096g" "VNG6372h" "VNG6412h"
*----------------------------------------------------------------
# cv.err: rich says: "CV error for each node" or "error for each bicluster"
# why 486 nodes?  which one belongs to which row?

> length (cv.err) -> 486
> summary (cv.err)
Min.   1st Qu.    Median      Mean   3rd Qu.      Max.
0.0004739 0.0071150 0.0105100 0.0122300 0.0156800 0.0575800

*----------------------------------------------------------------
# ratios: log 10 ratios in 130 conditions for 2415 genes
#

*----------------------------------------------------------------
# ratios: log 10 ratios in 130 conditions for 2415 genes
#

*--------------------------------------------------------------------------------
* rich's notes on R data structure for cytoscape translation (7 jul 04)


here is the halo net. Inferred on the 130 conditions set.
I've not implemented the interactions version of the inferelator,
so this is early... also dave and I need to wrangle how much we
let the biclusters overlap and other such small but essential details.
BUT, a lot of this network is likely correct SO:

i did:
save (influence.nw, tau, cv.err, reg.infs, gene.ids, gene.names,ratios,
redExp, clusterStack, colMap, knockIn, knockIn.names,
file = "infResult_6-29_over0.5.VT.RData", compress = TRUE)

in R ... so load() will automatically decompress this when you read it
in.

I included a bit more than i needed too. Essential items have a
asterisks.   the data file has:

NETWORK(*):
influence.nw : biclusters (rows) X influences (cols)
matrix of weights (linear truncated functional form)
- is repress + is activate the numbers are the edge thickness

tau : this the vector of tau for each bicluster (see cluterStack)

ERROR FOR EACH BICLUSTER(*): cv.err : CV error for each node

GENE IDS / TF NAMES, ENV NAMES(*):
reg.infs : list of env and TF influences on transcription
colnames(influence.nw) give reg.infs
gene.ids
gene.names

EXPRESSION DATA(*):
ratios : the original data (for getting the level of the TF's, this
also has the environmental rows tacked on)
redExp: the expresion data (mean) mapped onto the biclusters.

BICLUSTER(*):
clusterStack : the biclusters :
clusterStack[[1]] -> clusterStack[[k]]
where k is in the object as clusterStack$k
clusterStack[[k]]${rows,cols, nrows, ncols, p.clust, resid, eval}

p.clust and e.val reffer to the motif finding
resid is the cluster coherence.

TIME SERIES:
colMap: who is in a time series?
for each col in the data we have
colMap[[p]]$isTs = TRUE/FALSE
colMap[[p]]$is1stLast = e,f,m,l
where e =3D eq, f =3D 1st time point in
time series, m = middle of ts, l = last time point
colMap$numTS = total number of seperate time series in this data set.

KNOCK OUTS:
knockIn : which conditions are these genes knocked-out In
knockIn.names : which genes are knocked out in one or more experiments
*--------------------------------------------------------------------------------
* write a R data frame or matrix to a tab-delimited file (7 jul 04)
write.table (ratios, 'ratios.txt', sep='\t', quote=FALSE, col.names=NA)
where ratios is a data frame
the title of the gene name colums is empty, but this is better than
non-existent, making it painful to parse -- which is the default.
*--------------------------------------------------------------------------------
* toggling zoom & select, in ChartPanel (29 jun 2004)

cd /users/pshannon/examples/jython/swing/jfreechart/xyplotInteractive
make: runs demo and test ScatterPlotter.py

cd /users/pshannon/src/jfreechart/ant
ant compile
after editing
/users/pshannon/src/jfreechart/src/org/jfree/chart/ChartPanel.java

todo:  xor'd rectangle not cleaned up during drag
once the first 'zoom' toggle is made, the drag-to-select
action no longer draws any kind of rubberband rectangle.

*--------------------------------------------------------------------------------
* mounting linux /users/pshannon on laptop book (29 oct 2008)

in finder, shared/isb-1/pshannon (with current windows password)
shows up as /Volumes/pshannon


*--------------------------------------------------------------------------------
* mounting smb:/users/pshannon as trickster:/users/pshannon  (29 jun 2004)

mount_smbfs -W isb -u pshannon -g isb -I isb-1.systemsbiology.net  \
//pshannon:1998leoLEO@ISB-1/PSHANNON /Volumes/netpshannon
after
I created user pshannon (uid=51036) and group isb (gid=4002)
/users/pshannon -> /Volumes/netpshannon

*--------------------------------------------------------------------------------
* mount_smbfs man page (9 nov 2004)


MOUNT_SMBFS(8)            BSD System Manager's Manual           MOUNT_SMBFS(8)

NAME
mount_smbfs - mounts a shared resource from an SMB file server

SYNOPSIS
mount_smbfs [-I host] [-M cmode[/smode]] [-N]
[-O cowner[:cgroup]/sowner[:sgroup]] [-R retrycount]
[-T timeout] [-U user] [-W workgroup] [-d mode] [-f mode]
[-g gid] [-h] [-n opt] [-u uid] //[workgroup;][user[
password]@] server[/share] path

DESCRIPTION
The mount_smbfs command mounts a share from a remote server using
SMB/CIFS protocol.

The options are:

-I host
Do not use NetBIOS name resolver and connect directly to host,
which can be either a valid DNS name or an IP address.

-M cmode[/smode]
Assign access rights to the newly created connection.

-N      Do not ask for a password.  At run time, mount_smbfs reads the
~/.nsmbrc file for additional configuration parameters and a
password.  If no password is found the mount_smbfs prompts for
it.

-O cowner[:cgroup]/sowner[:sgroup]
Assign owner/group attributes to the newly created connection.

-R retrycount
How many retries should be done before the SMB requester decides
to drop the connection.

-T timeout
Timeout in seconds for each request.

-U user
Specifies the user name to be used in the authentication request.

-W workgroup
Specifies the workgroup to be used in the authentication request.

-f mode, -d mode
Specify permissions that should be assigned to files and directo-
ries.  The values must be specified as octal numbers.  Default
value for the file mode is taken from mount point, default value
for the dir mode adds execute permission where the file mode
gives read permission.

Note that these permissions can differ from the rights granted by
SMB server.

-h      Prints a help message, much like the SYNOPSIS above.

-n opt  Set opt option to affect file name lookups.  opt can be one of
the following:

Value    Meaning

long     No long names.  Server supports only "8.3" format.

-u uid, -g gid
User id and group id assigned to files.  The default is owner and
group id from directory where the volume is mounted.

//[workgroup;][user[password]@] server[/share]
The mount_smbfs command will use server as the NetBIOS name of
remote computer, user as the remote user name and share as the
resource name on a remote server.  Workgroup and/or password may
be specified here.  If user is omitted the logged in user id will
be used.  Omitting share is an error when mount_smbfs is run from
the command line, otherwise a browsing dialogue is presented.

path    Path to mount point.

FILES
~/.nsmbrc      Keeps static parameters for connections and other informa-
tion.  See ./examples/dot.nsmbrc for details.

EXAMPLES
The following illustrate how to connect to an SMB server SAMBA as user
GUEST to mount PUBLIC:

mount_smbfs -I samba.mydomain.com //guest@samba/public /smb/public



*--------------------------------------------------------------------------------
* installing ant on trickster (29 jun 04)
fink failed, mysteriously
got apache-ant-1.6.1-bin.tar.gz from http://ant.apache.org
downloaded to   /Users/mpshannon/safariDownloads
cd /users/pshannon/src
tar xf ~/safariDownloads/apache-ant-1.6.1-bin.tar
added this to PATH:
/users/pshannon/src/apache-ant-1.6.1/bin
in both /users/pshannon/.profile and /Users/mpshannon/.profile
added these two lines:
export ANT_HOME=/users/pshannon/src/apache-ant-1.6.1
PATH=$PATH:$ANT_HOME/bin

*--------------------------------------------------------------------------------
* add mouse drag selection to jfreechart
test app is
cd /users/pshannon/examples/jython/swing/jfreechart/xyplotInteractive; make
code modification is in ChartPanel.java
need to:
erase xor'd box after done
find entities within the box, and their names
invent a clean change to the api.

*--------------------------------------------------------------------------------
* add new plot to existing plot window, in r (25 jun 04)
Look at help(curve). To add the results of any fit to an existing data
scatterplot, you can also use
lines(x.values, predict(your.model))


- if your x values are sorted by size. If not, use something like this:
x.order <- order (x.values)

lines (x.values[x.order], predict (your.model)[x.order])

*--------------------------------------------------------------------------------
* explore lambdas vs log10 ratios, halo manganese, in r (25 jun 04)

summary:  fun, but not very illuminating.

fit parabola to the data
y = ax^2 + bx + c

/users/pshannon/data/halo/microarrayXml/stat/lambdaVsRatio
cp -p  /users/pshannon/tomcat/server1/webapps/halo/data/manganese.ratio .
cp -p /users/pshannon/tomcat/server1/webapps/halo/data/manganese.lambda .
R>
ratios = read.table ("manganese.ratio", row.names=1, header=T, sep="\t")
lambdas = read.table ("manganese.lambda", row.names=1, header=T, sep="\t")
colnames (ratios) ->   "Mn_1_vs_C.sig" "Mn_2_vs_C.sig" "Mn_3_vs_C.sig"
colnames (lambdas) ->  "Mn_1_vs_C.sig" "Mn_2_vs_C.sig" "Mn_3_vs_C.sig"
boxplot (lambdas)  # box and whiskers plot
boxplot (lambdas$Mn_2_vs_C.sig)
plot (ratios$Mn_2_vs_C.sig, lambdas$Mn_2_vs_C.sig)

x = ratios$Mn_2_vs_C.sig
y = lambdas$Mn_2_vs_C.sig
model = lm (y ~ I (x^2))
yFit = as.vector (fitted.values (model))
plot (x,y)
points (x, yFit, col='red')
summary (model)
Call:
lm(formula = y ~ I(x^2))

Residuals:
Min        1Q    Median        3Q       Max
-92.50268  -1.46335   0.03161   0.48439  38.71814

Coefficients:
Estimate Std. Error t value Pr(>|t|)
(Intercept)   -0.1760     0.1272  -1.383    0.167
I(x^2)      1196.6820    10.8839 109.949   <2e-16 ***
---
Signif. codes:  0 `***' 0.001 `**' 0.01 `*' 0.05 `.' 0.1 ` ' 1

Residual standard error: 5.733 on 2398 degrees of freedom
Multiple R-Squared: 0.8345,	Adjusted R-squared: 0.8344
F-statistic: 1.209e+04 on 1 and 2398 DF,  p-value: < 2.2e-16

graphics.off ()

*--------------------------------------------------------------------------------
* (25 jun 04) good jython listbox class demo:
/users/pshannon/examples/jython/swing/listbox has classVersion.py
*--------------------------------------------------------------------------------
* (24 jun 04) ratios/lambda xy plotter for TreeDataBrowser
/users/pshannon/examples/jython/swing/listbox has classVersion.py,
ready to be called from the 'Plot' button in the TreeDataBrowser.
call this with a list of column names, plus 'all'
extend demo ScatterPlotter to take many data sets (for 'all') and
paint each one in a different color, with a legend.
*--------------------------------------------------------------------------------
* enhance Navigator to return multiple matching experiments (22 jun 04)
/users/pshannon/data/halo/microarrayXml/unitTests
make nav
make sure that two original tests (and the TreeDataBrowser) handle the new
result form of Navigator.findExperimentKeyForPerturbation (self, perturbationList)
(it is now a list of pairs, rather than just a pair)
*--------------------------------------------------------------------------------
* partial success in disabling JTree selection of non-leaf nodes (22 jun 04)
/users/pshannon/examples/jython/swing/tree
but not complete.  rather trying.
now I'll try to smarten up the Navigator so that non-leaf selection is meaningful,
returning multiple experiments
*--------------------------------------------------------------------------------
* working TreeDataBrowser (21 jun 04)
copied back to db at 8:45 pm and quickly tested
todo:
1)  Experiment.getSelectionAsAliases
seems to duplicate (without synchronizing data)
Experiment.getConditionSubset
choose one or the other, or support both, and update in ExperimentTest.py
2) label tabs as ratios or lambdas
3) create movie tab on command, instead of data tab
4) add a RServer button!


*--------------------------------------------------------------------------------
* exploring jython jtree for results of experiment navigator
cd /users/pshannon/data/halo/microarrayXml/unitTests
db.unitTests> make navigator
jython NavigatorTest.py
genetic
knockout
boa1
boa4
environmental
irradiation
gamma
metals
copper
zinc

cd /users/pshannon/examples/jython/swing/tree
make  [see rudimentary tree.  extend example to build from the above hash,
then move the code to microarrayXml]
*--------------------------------------------------------------------------------
* started building static simple perturbation tree (19 jun 04)
cd /users/pshannon/data/halo/microarrayXml/unitTests
make navigator
the last output is
genetic:knockout:boa1:
genetic:knockout:boa4:
environmental:metals:copper
environmental:metals:zinc
use this to build a JTree, with actual factor levels being the final leaves.
*--------------------------------------------------------------------------------
* experiment classification (19 jun 04)
trying to think this through from a perspective which includes mage & miame
(temporarily settled on using the current xml predicates to specify
experiment type, in the sense of

genetic:knockout:boa1:light X oxygen
genetic:knockout:boa4:light X oxygen
environmental:metals:copper
environmental:metals:zinc

with specific factor levels for the last named perturbation field
specified  in the condition elements


experiment type:
time course
dose repsonse

experimental context  (unchanging after experiment begins)
predicates:
genetic
environmental

experimental factors  (manipulated during experiment)
predicates:
genetic
environmental



constant factors

genetic
knockout
boa1
...
zim

environmental
metal
copper
zinc
manganese
iron
radiation
gamma
uv

variable factors
light
oxygen
metal concentration


factor: A factor of an experiment is a controlled independent
variable; a variable whose levels are set by the experimenter.

A factorial design is used to evaluate two or more factors
simultaneously. The treatments are combinations of levels of the
factors. The advantages of factorial designs over one-factor-at-a-time
experiments is that they are more efficient and they allow
interactions to be detected.



from miame mage:
http://www.mged.org/Workgroups/MIAME/MIAMEv1.1-MAGE-OntologyDraft2v1.0.htm#_Toc4303961

Experiment type (s): A controlled vocabulary that classify an experiment
MGED controlled vocabulary to be developed for ExperimentalDesign type

time course
dose response
comparison
disease vs normal
treated vs untreated
temperature shock,
gene knock out,
gene knock in (transgenic),
etc,

Experimental factor (s)
ExperimentalFactor (s) should be consistent with Type (s)
Biological factor
time
dose
genetic variation
(knock out, knock in)
compound
temperature

Methodological factor
Protocol difference (extraction, hybridization, labeling, scanning)

*--------------------------------------------------------------------------------
* refining xml and classes for Experiments, cont (18 jun 2004)
all tests run on these classes

/users/pshannon/data/halo/microarrayXml/2004.0618

Condition.py
Variable.py
DataSetDescription.py
Experiment.py
ExperimentXmlParser.py
MatrixCombiner.py
MatrixSlicer.py
HttpFileFetcher.py

with data files (in unitTests/) for gamma, copper, and zinc
datasets specify the pairing of ratio and lambda files within
the same experiment.


MatrixCombiner.createEmptyMatrix is a utility method for
filling in the case, i.e., where there is a missing lambdas
file when combining selected conditions from mutltiple experiments

unitTests/MultipleSlicedExperimentsCombinerTest.py

shows how to combine subsetted matrices into a single new pair
(ratios and lambdas)

renamed all this to

/users/pshannon/data/halo/microarrayXml/2004.0618

*--------------------------------------------------------------------------------
* yeast orf's to NP (18 jun 2004)
at martin's request, I looked to see if i had a script that would produce
this assignment.  it is not found in gene_association.sgd (from go)
a snapshot assignment table, which i produced somehow,  is in
/users/pshannon/data/yeast/np/yeastToNp.txt:   90106 Nov 18  2003
*--------------------------------------------------------------------------------
* refining xml and classes for Experiments (16 jun 2004)
accomodating multiple datasets per Experiment file in
/users/pshannon/data/halo/microarrayXml/unitTests
make matrixAssembler reads gamma.xml, with two datasets
MatrixAssembler.collapse () has both, but does not yet pass them sensibly
MatrixAssemblerTest.
to do:  enrich the api to return matrices by dataset type
- collect (say) all datasets into a hash, keyed by type, one matrix per type
- create submatrices and place them in that hash
- return keys (data set types) to client, and allow subsequent retrieval
of each matrix in turn.

then MatrixCombiner will have to distinguish among these several types
(now only lambda and ratio) when the final, combined matrices are created.
*--------------------------------------------------------------------------------
* create java webstart version of cy2 demo for nitin
did not work.  jar loader problems?  can't yet auto load yfiles.

for the db:8060 tomcat webserver
/users/pshannon/tomcat/server1/webapps/halo/cy2Demo

get all the databrowser files
(cd /users/pshannon/data/halo/cy2demo;
jar cvf dcb.jar `find csplugins -name "*.class" | egrep -v jpwork`)


*--------------------------------------------------------------------------------
* cy2 cytoscape2 options
--VT <view threshold number>   # networks with fewer nodes get view automatically
--JLD <directory>              # automatically load all jars in this directory
--JLW <url>                    # java webstart loads plugin jars from here
--JLL <url of file with urls   # java webstart loads plugin jars named here

*--------------------------------------------------------------------------------
* cy2 demo with condition chooser, for nitin (16 jun 2004)
/users/pshannon/data/halo/cy2demo/csplugins/trial/pshannon/newDataCube/py/cyDemo
subdirectory 'py' has all of the python code
run:
source ../../env
cat  ~/.cytoscape/cytoscape.props:
[this file will also be loaded if it (or a local copy) is specified via the props variable
in the project file]

#Cytoscape Property File
#Wed Jun 16 19:21:48 PDT 2004
viewType=3000
bioDataDirectory=http\://db.systemsbiology.net\:8080/cytoscape/annotation/halo/manifest
defaultSpeciesName=Halobacterium
viewThreshold=3000
plugin.1.load=DataBrowser

Trickster.cyDemo> make -n
java -Xmx1G cytoscape.CyMain -p project --VT 3000

cat project
#sif=network.sif
sif=100.sif
#sif=bug.sif
props=props
dataServer=http://db.systemsbiology.net:8080/cytoscape/annotation/halo/manifest
species=Halobacterium
noa=synonyms.noa
noa=organisms.noa
noa=moleculeType.noa
noa=sbeams.noa
vprops=vizmap.props

*--------------------------------------------------------------------------------
* cy2 demo with condition chooser, for nitin (15 jun 2004)
(did not quite work)
cy /users/amarkiel/cvsdir5/csplugins/trial/pshannon/newDataCube/cytoscape.jar
/users/pshannon/data/halo/cy2demo/csplugins/trial/pshannon/newDataCube
subdirectory 'py' has all of the python code
run:
java -jar /users/pshannon/data/halo/cy2demo/cytoscape.jar
load jar from plugin menu
error:
File "/users/pshannon/data/halo/cy2demo/csplugins/trial/pshannon/newDataCube/py/DataBrowser.py",
line 0, in __init__ , java.lang.NullPointerException
may be due to missing classes, since I didn't use rowan's new 'load from classpath' swich

*--------------------------------------------------------------------------------
* RUnit (14 jun 2004)
http://www.cran.r-project.org/src/contrib/Descriptions/RUnit.html

*--------------------------------------------------------------------------------
* explore data/condition chooser based on jtree (10 jun 2004)

*--------------------------------------------------------------------------------
* explore use of R for managing halo data
first:  can metadata be attache to a data frame?
from the R Language Definition:

Data frames are the R structures which most closely mimic the SAS or SPSS data
set, i.e., a "cases by variables" matrix of data.

A data frame is a list of vectors, factors, and/or matrices all having
the same length (the same number of rows in the case of matrices).  In
addition, a data frame generally has a 'names' attribute labelling
the variables, and a row.names attribute for labelling the cases.

A data frame can contain a list that is the same length as the other
components.  The list can contain elements of differing lengths thereby
providing a data structure for ragged arrays.  However, as of this writing,
such arrays are not generally handled correctly. (!)

cd /users/pshannon/examples/r/dataFrameWithMetadata
head -12 /users/pshannon/tomcat/server1/webapps/halo/data/copper.ratio > copper12.ratio
start R
f = 'bop12.ratio'
df = read.table (f, row.names=1, header=T, sep="\t")

--------- built-in dataframe attributes
attributes (df)
$names
[1] "bop__HO_D_vs_NRC.1" "bop__HO_L_vs_NRC.1" "bop__LO_D_vs_NRC.1"
[4] "bop__LO_L_vs_NRC.1"

$class
[1] "data.frame"

$row.names
[1] "VNG0001H" "VNG0002G" "VNG0003C" "VNG0005H" "VNG0006G" "VNG0008G"
[7] "VNG0009G" "VNG0011C" "VNG0013C" "VNG0014C" "VNG0015H"

attr (df, "names")
[1] "bop__HO_D_vs_NRC.1" "bop__HO_L_vs_NRC.1" "bop__LO_D_vs_NRC.1"
[4] "bop__LO_L_vs_NRC.1"


---------- assign custom column metadata attribute to df
columnMetadata = list (list (oxygen='High', illumination='Dark'),
list (oxygen='High', illumination='Light'),
list (oxygen='Low',  illumination='Dark'),
list (oxygen='Low',  illumination='Light'))
attr (df, 'columnMetadata') = columnMetadata

this got very confusing, so now I'll try to create a class which
has metadata for one variable:
name,    value,      units
------   --------    ----
oxygen   High/Low    NA

setClass ('variable', representation (name='character', value='character', units='character'))
v1 = new ('variable', name='oxygen', value='High')
setClass ('condition', representation (variables='list'))
col1 = new ('condition', variables = list (new ('variable', name='oxygen', value='High')))
col1 = new ('condition', variables = c (new ('variable', name='oxygen', value='High')))


*--------------------------------------------------------------------------------
* more cytoscape2: pseudoAnalysisPlugin, pyConsole (10 jun 2004)

in both cases, trouble loading multiple jars, some of which might be my
confusion.  andrew will embellish the --JLD command line option to
support not just one jar, but a colon-separated list of them.

/users/pshannon/cy2/projects/plugins/demos/pseudoDataAnalysis
/users/pshannon/cy2/projects/plugins/pyConsole

*--------------------------------------------------------------------------------
* try out cytoscape 2 (9 jun 2004)
got 5/21 version from
http://cytoscape.org/alpha.html

installed in ~/cy2
copied cytoscape jar to ~/jars/cy2.jar

test:  cd /users/pshannon/cy2/projects/halo/cyDemo; make
which executes this:
java -Xmx1G -jar /users/pshannon/jars/cy2.jar -p project \
--JLD /users/pshannon/cy2/myPlugins
*--------------------------------------------------------------------------------
* delivered adequate condition chooser to nitin, with knockout data (9 jun 2004)
non-jws test in /users/pshannon/data/halo/microarrayXml/cyDemo; make
load DataBrowserPlugin.jar (from python) in parent directory
installed as
5. Halobacterium NRC-1 network, new data browser (9 June 2004)
in the halo 8060 web page
*--------------------------------------------------------------------------------
* allow for multiple, deletable tabs in the new DataCubeBrowser (7 jun 04)
~/cy/csplugins/trial/pshannon/newDataCube/browsers/DataCubeBrowser.java
make sure that the 'delete' button is well-placed, and behaves properly
called from ~/data/halo/microarrayXml/DataBrowser.py#loadMoreSelectedConditions
*--------------------------------------------------------------------------------
* creating metadata xml for all halo experiments to date (7 jun 04)
[resuming from work interrupted on 2 jun]
working in
/users/pshannon/data/halo/allMicroarrayData
with file
'20040601_125035_22_strains.mrna' rec'd from nitin via email on 2 jun
copied to
/users/pshannon/data/halo/allMicroarrayData/raw/88conds, filename 'raw'
contents:  178 columns, 2401 rows
ratios and lambdas for 88 conditions, 2400 genes
make some hand edits to this, creating cooked.1
change all 750_ to VNG750C_
change all 1296_ to VNG1296C_
change all 2334_ to VNG2334C_
remove all '.sig'
change BOP to bop
rename 2nd column 'GENE'
delete the first column
remove ^M at the end of each line
change all O-D to O_D  (to provide consistent naming of conditions)
change all O-L to O_L  (to provide consistent naming of conditions)

head -1 cooked.1 | tr '\t' '\n' > junk
(this file -- all the column titles -- will be pasted into
util/splitIntoRatiosAndLambdas.py)

(after lengthy futzing around, i removed all ^M's from the cooked.1 file)
use '__' to delimit experiment name from experiment condition in all titles, by
adding a 'preferredTitles' array
then:
cd /users/pshannon/data/halo/allMicroarrayData/88conds
python util/splitIntoRatiosAndLambdas.py cooked.1
creates:
2401  213689 1279494 conds88.lambda
2401  213689 1373357 conds88.ratio


python util/splitIntoRatiosAndLambdas.py cooked.1
cp ../../marc/linearLayout/2004.06.06/cytoscape.props .
cy --matrix conds88.ratio --matrix conds88.lambda
everything looks good.

now -- split these into per-experiment files, creating metdata xml files along
the way.
cd /users/pshannon/data/halo/allMicroarrayData/88conds/ratios
python ../util/splitIntoExperimentMatrices.py ../conds88.ratio
hand check a few:
head zim.ratio
head VNG0750C.ratio
and make sure that the four values in the first row of each match those in
../cooked.1
ls -1 ratio >> run
edit run to look like this:
java cytoscape.cytoscape \
--matrix NRC-1.ratio \
--matrix VNG0750C.ratio \
--matrix VNG1296C.ratio \
--matrix VNG2334C.ratio \


cd /users/pshannon/data/halo/allMicroarrayData/88conds/lambdas
python ../util/splitIntoExperimentMatrices.py ../conds88.lambda
run  # see that all the matrices load okay, that there names are sensible,
# that they each have 4 columns

python ../util/createXmlFromMatrix.py ark.lambda
creates a pretty good start at an xml file, writing to stdout
ls -1 *.lambda > createAllXml
edit createAllXml so that it reads like this:
python ../util/createXmlFromMatrix.py NRC-1.lambda > NRC-1.lambda.xml
python ../util/createXmlFromMatrix.py VNG0750C.lambda > VNG0750C.lambda.xml
....

is this xml valid?
for x in *.xml; do msv ~/data/halo/microarrayXml/experiment.xsd  $x; done

i modified the uri in these files to read, eg,
<uri>http://db.systemsbiology.net:8060/halo/data/trial/crti2.lambda</uri>

cd /users/pshannon/tomcat/server1/webapps/halo/data/trial
cp -p ~/data/halo/allMicroarrayData/88conds/lambdas/*.xml .
cp -p ~/data/halo/allMicroarrayData/88conds/lambdas/*.lambda .

cd ../ratios
createAllXml
cp -p ~/data/halo/allMicroarrayData/88conds/ratios/*.xml .
cp -p ~/data/halo/allMicroarrayData/88conds/ratios/*.ratio .

added makefile to both
/users/pshannon/data/halo/allMicroarrayData/88conds/lambdas
ratios
*--------------------------------------------------------------------------------
* more chp-chip data from marc (6 jun 04)
following steps detail below '* new microarray pipeline data from marc (friday, 15 may 2004)'
for tbpEandtfbD.
1) extracted tfbG_tbpB.chip from email to ~/attachments
2) copied it to
/users/pshannon/data/halo/marc/linearLayout/2004.06.06/tfbG_tbpB.chip
3) head -1 tfbG_tbpB.chip | tr '\t' '\n'
GENE
DESCRIPT
tfbG_IP_vs_tfbG_wce.sig
tbpB_IP_vs_tbpB_wce.sig
tfbG_IP_vs_tfbG_wce.sig
tbpB_IP_vs_tbpB_wce.sig
NumSigConds
fold_change
plate_384
row_384
col_384
primer_forward_name
primer_forward_sequence
primer_reverse_name
primer_reverse_sequence
chromosome_start_position
chromosome_end_position
halo_span_source1
halo_span_source2
halo_flag_N
halo_flag_F
halo_gel_file
halo_gel_number
halo_gel_row
sample_number
regulatory_motif
sequence
plate_96
row_96
col_96
flag
4) 4635 rows
titles like this:
GENE
HS12I10
HS12I11
HS12I12
HS12I13
5) cp -p ../2004.05.15/createMatrices.py .
6) modified titles
*--------------------------------------------------------------------------------
*--------------------------------------------------------------------------------------------
* install latest tomcat 5.0 (3 jun 2004)
to get around mis-configured 4.1, discovered when i restarted db:8080
from http://apache.xtelli.net/jakarta/tomcat-5/v5.0.25/bin
got 10227073 Jun  3 10:06 jakarta-tomcat-5.0.25.tar.gz, put in /users/pshannon/tmp
mkdir ~/tomcat
cd tomcat
tar xvf ~/tmp/jakarta-tomcat-5.0.25.tar
cd /users/pshannon/tomcat/jakarta-tomcat-5.0.25/bin
grep 8080 ../conf/*.xml

catalina.sh run  # does not redirect stdout & stderr to logs/catalina.out

*--------------------------------------------------------------------------------------------
* tomcat 5, set up two web apps, with single authentication (3 jun 04)

create webapps/test[12]/WEB-INF/web.xml
in which these authentication settings are specified:
(the role-name value of 'accessTest' refers to an entry
in conf/tomcat-users.xml:

<role rolename="accessTest"/>
<user username="pshannon" password="leo" roles="accessTest"/>

test 1, for now, consists of just test1/index.html
here's test1's deployment spec
<web-app>

<security-constraint>
<display-name>Private Test1</display-name>
<web-resource-collection>
<web-resource-name>
test1
</web-resource-name>
<url-pattern>/</url-pattern>
</web-resource-collection>
<auth-constraint>
<role-name>accessTest</role-name>
</auth-constraint>
</security-constraint>

<login-config>
<auth-method>BASIC</auth-method>
<realm-name>Test1</realm-name>
</login-config>


if the singleSignOn valve element is disabled, two logins are required

the Engine element from conf/server.xml
<Engine defaultHost="localhost" name="Catalina">
<Host appBase="webapps" name="localhost">
<Logger className="org.apache.catalina.logger.FileLogger"
prefix="localhost_log."
suffix=".txt"
timestamp="true"/>
<Valve className="org.apache.catalina.authenticator.SingleSignOn" debug="3"/>
<Valve className="org.apache.catalina.valves.AccessLogValve"
fileDateFormat="yyyy-MM-dd"
prefix="localhost_access_log."
suffix=".txt"/>

<Context path="/test1"
docBase="/users/pshannon/tomcat/jakarta-tomcat-5.0.25/webapps/test1"
debug="3">
</Context>


<Context path="/test2"
docBase="/users/pshannon/tomcat/jakarta-tomcat-5.0.25/webapps/test2"
debug="0">
</Context>

<Context path="/cytoscape"
docBase="/users/pshannon/tomcat/jakarta-tomcat-5.0.25/webapps/cytoscape"
debug="0">
</Context>


</Host>

*--------------------------------------------------------------------------------------------
* permissions to run the tomcat manager app (3 jun 04)
granted to any user with role 'manager'
*--------------------------------------------------------------------------------------------
* container-managed security (3 jun 04)
specified in an application's (a context's) web.xml file.  see p41 of the ora book.
takes the place of apache .htaccess files
*--------------------------------------------------------------------------------------------
* tomcat access restriction (2 jun 04)

You can ask Catalina to check the IP address, or host name, on every
incoming request directed to the surrounding Engine, Host, or Context
element. The remote address or name will be checked against a
configured list of "accept" and/or "deny" filters, which are defined
using the Regular Expression syntax supported by the Jakarta Regexp
regular expression library. Requests that come from locations that are
not accepted will be rejected with an HTTP "Forbidden" error.  Example
filter declarations:

<Host name="localhost" ...>
...
<Valve className="org.apache.catalina.valves.RemoteHostValve"
allow="*.mycompany.com,www.yourcompany.com"/>
<Valve className="org.apache.catalina.valves.RemoteAddrValve"
deny="192.168.1.*"/>
...
</Host>




See Remote Address Filter  and Remote Host Filter for  more information about the configuration options that are supported.
*--------------------------------------------------------------------------------
* collect all of the latest halo mrna data (2 jun 04)
try again to collect the latest halo experimental data
1) rename column titles
'750' to 'VNG0750'
'BOP' to 'bop'
changed all VNGxxxx to VNGxxxxC   (for conserved gene)
2) deleted 2nd column
3) removed '.sig' from all titles
4) split ratios and lambdas
cp /users/pshannon/data/halo/marc/linearLayout/2004.05.15/createMatrices.py  \
splitIntoRatiosAndLambdas.py
5) split into separate experiment files
cd /local/tomcat/webapps/cytoscape/projects/static/halo/data/util/tmp
python ../splitIntoRatiosAndLambdas.py
creating:
1369447 Jun  2 17:05 2004-06-01.lambda
1369447 Jun  2 17:05 2004-06-01.ratio
6) create xml metadata companion files
*--------------------------------------------------------------------------------
* collect all of the latest halo mrna data (2 jun 04)
examining the rag-tag collection from previous weeks (halo/nrc1/default/*matrix*
and comparing to the latest file from nitin (which turned out to be the wrong one)

in /local/tomcat/webapps/cytoscape/projects/static/halo/data/orig/
after some hand-editing of big matrix files, and using the
work-in-progress
/local/tomcat/webapps/cytoscape/projects/static/halo/data/util/splitAndCreateXml.py
which parses, eg,
VNG0750.HO.D.vs.NRC-1, VNG0750.HO.L.vs.NRC-1, VNG0750.LO-D.vs.NRC-1, VNG0750.LO-L.vs.NRC-1
into
VNG0750: ['HO.D.vs.NRC-1', 'HO.L.vs.NRC-1', 'LO-D.vs.NRC-1', 'LO-L.vs.NRC-1']

got these results (which are illuminating, but not good enough to keep -- see next
log entry above)

>>> xc = Creator ('../orig/halo_gene_ko_HOLOLD_060204.cooked')
BOP: ['HO-D.vs.NRC-1', 'HO-L.vs.NRC-1', 'LO-D.vs.NRC-1', 'LO-L.vs.NRC-1']
NRC-1: ['HO-D.vs.NRC-1', 'HO-L.vs.NRC-1', 'LO-D.vs.NRC-1', 'LO-L.vs.NRC-1']
VNG0750: ['HO.D.vs.NRC-1', 'HO.L.vs.NRC-1', 'LO-D.vs.NRC-1', 'LO-L.vs.NRC-1']
VNG1296: ['HO.D.vs.NRC-1', 'HO.L.vs.NRC-1', 'LO.D.vs.NRC-1', 'LO.L.vs.NRC-1']
VNG2334: ['HO.D.vs.NRC-1', 'HO.L.vs.NRC-1', 'LO.D.vs.NRC-1', 'LO.L.vs.NRC-1']
afsQ2: ['HO-D.vs.NRC-1', 'HO-L.vs.NRC-1', 'LO-D.vs.NRC-1', 'LO-L.vs.NRC-1']
ark: ['HO-D.vs.NRC-1', 'HO.L.vs.NRC-1', 'LO-D.vs.NRC-1', 'LO-L.vs.NRC-1']
boa1: ['HO-D.vs.NRC-1', 'HO-L.vs.NRC-1', 'LO-D.vs.NRC-1', 'LO-L.vs.NRC-1']
boa4: ['HO-D.vs.NRC-1', 'HO-L.vs.NRC-1', 'LO-D.vs.NRC-1', 'LO-L.vs.NRC-1']
crti2: ['HO-D.vs.NRC-1', 'HO-L.vs.NRC-1', 'LO-D.vs.NRC-1', 'LO-L.vs.NRC-1']
htlD: ['HO-D.vs.NRC-1', 'HO-L.vs.NRC-1', 'LO-D.vs.NRC-1', 'LO-L.vs.NRC-1']
htr1: ['HO-D.vs.NRC-1', 'HO-L.vs.NRC-1', 'LO-D.vs.NRC-1', 'LO-L.vs.NRC-1']
htr2: ['HO-D.vs.NRC-1', 'HO-L.vs.NRC-1', 'LO-D.vs.NRC-1', 'LO-L.vs.NRC-1']
htr8: ['HO-D.vs.NRC-1', 'HO-L.vs.NRC-1', 'LO-D.vs.NRC-1', 'LO-L.vs.NRC-1']
kinA2: ['HO-D.vs.NRC-1', 'HO-L.vs.NRC-1', 'LO-D.vs.NRC-1', 'LO-L.vs.NRC-1']
phoR: ['HO-D.vs.NRC-1', 'HO-L.vs.NRC-1', 'LO-D.vs.NRC-1', 'LO-L.vs.NRC-1']
phr1: ['HO-D.vs.NRC-1', 'HO-L.vs.NRC-1', 'LO-D.vs.NRC-1', 'LO-L.vs.NRC-1']
phr1-and-2: ['HO-D.vs.NRC-1', 'HO-L.vs.NRC-1', 'LO-D.vs.NRC-1', 'LO-L.vs.NRC-1']
phr2: ['HO-D.vs.NRC-1', 'HO-L.vs.NRC-1', 'LO-D.vs.NRC-1', 'LO-L.vs.NRC-1']
sop2: ['HO-D.vs.NRC-1', 'HO-L.vs.NRC-1', 'LO-D.vs.NRC-1', 'LO-L.vs.NRC-1']
ura3: ['HO-D.vs.NRC-1', 'HO-L.vs.NRC-1', 'LO-D.vs.NRC-1', 'LO-L.vs.NRC-1']
zim: ['HO.D.vs.NRC-1', 'HO.L.vs.NRC-1', 'LO.D.vs.NRC-1', 'LO.L.vs.NRC-1']
>>> xc = Creator ('../orig/matrix-114.ratio')
BOP: ['HO.D.vs.NRC.1', 'HO.L.vs.NRC.1', 'LO.D.vs.NRC.1', 'LO.L.vs.NRC.1']
Cu: ['1.vs.c', '2.vs.c', '3.vs.c']
Fe: ['4.vs.c', '6.vs.c', '7.vs.c']
Mn: ['1.vs.c', '2.vs.c', '3.vs.c']
NRC: ['1.HO.D.vs.NRC.1', '1.HO.L.vs.NRC.1', '1.LO.D.vs.NRC.1', '1.LO.L.vs.NRC.1', '1.vs.NRC.1']
X750: ['HO.L.vs.NRC.1', 'LO.D.vs.NRC.1', 'LO.L.vs.NRC.1']
Zn: ['1.vs.c', '2.vs.c', '3.vs.c']
ark: ['HO.D.vs.NRC.1', 'HO.L.vs.NRC.1', 'LO.D.vs.NRC.1', 'LO.L.vs.NRC.1']
boa1: ['HO.D.vs.NRC.1', 'HO.L.vs.NRC.1', 'LO.D.vs.NRC.1', 'LO.L.vs.NRC.1']
boa4: ['HO.D.vs.NRC.1', 'HO.L.vs.NRC.1', 'LO.D.vs.NRC.1', 'LO.L.vs.NRC.1']
circadian: ['C60', 'D30', 'D60', 'L30', 'L60', 'X1', 'X2', 'X3', 'X4', 'X5',
'X6', 'X7', 'X8', 'X9', 'X10', 'X11', 'X12', 'X13', 'X14',
'X15', 'X16', 'X17', 'X18', 'X19', 'X20', 'X21', 'X22', 'X23', 'X24', 'X25']
crti2: ['HO.D.vs.NRC.1', 'HO.L.vs.NRC.1', 'LO.D.vs.NRC.1', 'LO.L.vs.NRC.1']
htlD: ['HO.D.vs.NRC.1', 'HO.L.vs.NRC.1', 'LO.D.vs.NRC.1', 'LO.L.vs.NRC.1']
htr1: ['HO.D.vs.NRC.1', 'HO.L.vs.NRC.1', 'LO.D.vs.NRC.1', 'LO.L.vs.NRC.1']
htr2: ['HO.D.vs.NRC.1', 'HO.L.vs.NRC.1', 'LO.D.vs.NRC.1', 'LO.L.vs.NRC.1']
htr8: ['HO.D.vs.NRC.1', 'HO.L.vs.NRC.1', 'LO.D.vs.NRC.1', 'LO.L.vs.NRC.1']
kinA2: ['HO.D.vs.NRC.1', 'HO.L.vs.NRC.1', 'LO.D.vs.NRC.1', 'LO.L.vs.NRC.1']
phoR: ['HO.D.vs.NRC.1', 'HO.L.vs.NRC.1', 'LO.D.vs.NRC.1', 'LO.L.vs.NRC.1']
phr1: ['HO.D.vs.NRC.1', 'LO.D.vs.NRC.1', 'LO.L.vs.NRC.1']
phr1-and-2: ['HO.D.vs.NRC.1', 'HO.L.vs.NRC.1', 'LO.D.vs.NRC.1', 'LO.L.vs.NRC.1']
phr2: ['HO.D.vs.NRC.1', 'HO.L.vs.NRC.1', 'LO.D.vs.NRC.1', 'LO.L.vs.NRC.1']
sop2: ['HO.D.vs.NRC.1', 'HO.L.vs.NRC.1', 'LO.D.vs.NRC.1', 'LO.L.vs.NRC.1']
ura3: ['HO.D.vs.NRC.1', 'HO.L.vs.NRC.1', 'LO.D.vs.NRC.1', 'LO.L.vs.NRC.1']


*--------------------------------------------------------------------------------
* split matrix-114 (ratios and lambdas) into separate experiments (1 jun 04)
/local/tomcat/webapps/cytoscape/projects/static/halo/data
batch file (in progress) splitAll
should make successive calls to splitter.py
*--------------------------------------------------------------------------------
* JSplitPane resizing by toggle button (28 may 2004)
/users/pshannon/examples/jython/swing/jsplitpane/test.py
*--------------------------------------------------------------------------------
* continue clean up of DataMatrixLens (27 may 2004)
after removing the rowTitlesTitle (eg, 'GENE') from the DataMatix
columnTitles, there is cleanup to do.
cd /users/pshannon/cy/csplugins/trial/pshannon/dataCube/unitTests
(cd ..; make) && make 1
see error:

.testColumnTitleLensing
titles 0 length: 4
titles0 [0]: cond0
titles0 [1]: cond0
titles0 [2]: cond1
titles0 [3]: cond2
F.testRowSelection_1

*--------------------------------------------------------------------------------
* change metal.xml? (description of 4 halo metal experiments) (20 may 2004)

even a redesigned Experiment.getSelectionAsAlias ()
fails to fix the problem with the metal.xml file, in which
4 experiments seem to be grouped as if they were one.

the problem comes when judging the inclusion of a condition in
the selection.  the rule is:

all conditions explicitly mentioned in the selection criteria
must be met, but

all conditions which do not include the selection criteria
are judged to meet the selection criteria.

with the 4 metal experiments, there are these choices:

selection choice (which of these conditions are selected?)
must be explicit:  if iron=2 is the sole selection criteria,
then every condition not exactly matching that is discarded

another approach:
one condition is 'metal' [zinc, copper, iron ...]
another is concentration
(this is like time & gamma -- see gamma.xml -- but differs
in that concentration amounts differ for each metal)

so how about this:  every experiment xml file can contain
only conditions factored completely into variableDefintions
and that the number of conditions must be exactly
product [condition-n range of values] as n varies
from 1 to number of variables

talk to nitin....


*--------------------------------------------------------------------------------
* finished MatrixCombiner.py prototype (19 may 2004)
this may eventually become part of the new DataMatrix class.
see /users/pshannon/cy/csplugins/trial/pshannon/dataCube/MatrixCombiner.py
and  unitTests/MatrixCombinerTest.py
in unitTests:  make 6
3 simpleMatrix*.txt files
*--------------------------------------------------------------------------------
* add password protection to the halo web site on db (18 may 2004)
eric suggests that i emulate changes he made to
/local/tomcat/jakarta-tomcat-4.1.18/server/webapps/manager/WEB-INF/web.xml
in
/local/tomcat/webapps/cytoscape/WEB-INF/web.xml


*--------------------------------------------------------------------------------
* (18 may 2004) jython exploration for combining multiple DataMatrices
/users/pshannon/cy/csplugins/trial/pshannon/dataCube/unitTests/explore.py
next up:  having determined row & column titles, now traverse the two
matrices and assign to the (new) third one, marking empty cells in some
appropriate way.
*--------------------------------------------------------------------------------
* (18 may 2004) import kegg xml files; w/ligand-reaction file, create cyto networks
modified from (7 may 2003) entry way below...

kelly asked for the prostaglandin and leukotriene metabolism pathway

cd /users/pshannon/data/import/kegg-to-cytoscape/example/2004-may

from http://www.genome.ad.jp/kegg/xml/map get map00590.xml

ftp'd reaction file from ftp://ftp.genome.ad.jp/pub/kegg/ligand/reaction
python keggToCytoscape.py
(has these lines:
reader = ReactionFileReader ("reaction")
reactions = reader.getReactions ()
pathway = Pathway ('map00590.xml')
)

produces these files:
network.sif
nodeTypes.noa

create project
sif=network.sif
noa=nodeTypes.noa

run
java cytoscape.cytoscape -p project



*--------------------------------------------------------------------------------
* add login and password to tomcat, for halo (17 may 2004)

http://db.systemsbiology.net:8080/admin/  user: 'admin' pw: 'NtnsBrn'):
*--------------------------------------------------------------------------------
* new microarray pipeline data from marc (friday, 15 may 2004)
has these columns:
GENE
DESCRIPT
tfbD_IP_vs_tfbD_wce.sig
tbpE_IP_vs_tbpE_wce.sig
tfbD_IP_vs_tfbD_wce.sig
tbpE_IP_vs_tbpE_wce.sig
NumSigConds
fold_change
plate_384
row_384
col_384
primer_forward_name
primer_forward_sequence
primer_reverse_name
primer_reverse_sequence
chromosome_start_position
chromosome_end_position
halo_span_source1
halo_span_source2
halo_flag_N
halo_flag_F
halo_gel_file
halo_gel_number
halo_gel_row
sample_number
regulatory_motif
sequence
plate_96
row_96
col_96
flag

with 4635 rows, having titles like:

GENE
HS12I10
HS12I11
HS12I12
HS12I13
HS12I14
....

created directory  /users/pshannon/data/halo/marc/linearLayout/2004.05.15
saved attachment to
/users/pshannon/data/halo/marc/linearLayout/2004.05.15/tbpEandtfbD.chip (1942749 May 15 16:02)

!! be sure to delete the last line in this file !!
NumSigGenes:	4635	4635	+Infinity

cp -p ../2004.04.30/createMatrices.py

modify createMatrices.py to import  /users/pshannon/lib/PipelineToDataMatrix.py
file = 'tbpEandtfbD.chip'
to create the ratios file, with better titles:

titlesToGrab    = ['primer_forward_name',
'tfbD_IP_vs_tfbD_wce.sig',
'tbpE_IP_vs_tbpE_wce.sig']

preferredTitles = ['Tile', 'tfbD_IP_vs_tfbD_wce', 'tbpE_IP_vs_tbpE_wce']


tokenizedLines = p2m.getAll ()
writeFile ('matrix.ratio', preferredTitles, titlesToGrab, tokenizedLines)

titlesToGrab    = ['primer_forward_name',
'tfbD_IP_vs_tfbD_wce.sig.dup',
'tbpE_IP_vs_tbpE_wce.sig.dup']

writeFile ('matrix.lambda', preferredTitles, titlesToGrab, tokenizedLines)


python createMatrices.py  (reads tbpEandtfbD.chip, produces matrix.ratio & matrix.lambda)
4636 matrix.lambda
4636 matrix.ratio
!! create this cytoscape.props:
plugin.0.load=csplugins.trial.pshannon.dataCube.DataCubePlugin
make sure both of these are readable:
java cytoscape.cytoscape --matrix matrix.ratio  --matrix matrix.lambda
this checks out.


*--------------------------------------------------------------------------------
* xerces/jdom version when working on roundpeak (15 may 04)
eventually traced to an obsolete version of either xerces or jdom, in
/home/pshannon/jars/cytoscape.jar, which was built from the unpacked
class files found at the isb, in
~/jars/aux/org
update those directories!
*--------------------------------------------------------------------------------
* column chooser evolves into data cube browser++ (14 may 2004)
/users/pshannon/data/halo/microarrayXml/gui.py
is now rather iTunes-like
next step is to embed a NewDataCubeBrowser in the lower left panel,
by making that class extend JPanel rathe rthan JDialog.
but
/users/pshannon/cy/csplugins/trial/pshannon/\
dataCube/browsers/NewDataCubeBrowser.java

does not yet compile

*--------------------------------------------------------------------------------
* dead simple use of JFileChooser (13 may 2004)
/users/pshannon/examples/jython/swing/fileChooser/go.py
*--------------------------------------------------------------------------------
* blend the itunesLikeExperimentalConditionChooser & the ExperimentXmlParser
working in /users/pshannon/data/halo/microarrayXml
*--------------------------------------------------------------------------------
* a jython/swing GUI for choosing conditions (12 may 2004)
/users/pshannon/examples/jython/swing/itunesLikeExperimentConditionChooser/go.py
this example
- uses nested JSplitPane's
- a toolbar
- scrollpane's galore
is a reasonable topological mimic of the iTunes application
*---------------------------------------------------------------------------------
* develop microarray xml schema (12 may 2004)

/users/pshannon/data/halo/microarrayXml
gamma.xml
experiment.xsd

(got this working after much fuss.  used po.mxl & po.xsd from
http://www.w3.org/TR/2001/REC-xmlschema-0-20010502/#DefnDeclars)

working from this, I created the two above files in
/users/pshannon/examples/xml/schema/haloExperiments

and at the end of the day, in
/users/pshannon/examples/xml/schema/haloExperiments

experiment.xsd:  schema for one full experiment
loadExperiments.py (see below)
ExperimentXmlParser.py: has 2 classes
Experiment
ExperimentXmlParser

and in unitTests/
ExperimentXmlParserTest.py
gamma.xml
metal.xml

loadExperiments.py has (for now) a hard-coded directory name
it reads all xml files in that directory, and prints out the
variable names, and their range of values (which are explicitly
stated in the xml file)


*-----------------------------------------------------------------------------------
* jython dual list box, prototype of x-y plotter controller (11 may 04)
~/examples/jython/swing/listbox/go.py
two listboxes, with one plot button, selection callback, using
MULTIPLE_INTERVAL_SELECTION on listbox #1
*-----------------------------------------------------------------------------------
* halo xml metadata format, attempt #2 xml (10 may 04)

<experiment name="gamma" environmental=true timeSeries=true>
<organism>
<species> Halobacterium NRC-1 </species>
<strain> wild type </strain>
</organism>

<perturbation name='cold shock'>
<value> 42 degrees C </value>
<value> room temperature </value>
<value> 42 degrees C </value>
</perturbation>

<perturbation name='nutrient shock'>
<value> complete medium </value>
<value> basal salts </value>
<value> complete medium</value>
</perturbation>

<variable name='gamma irradiation' control='true'>
<value>present</value>
<value>absetn</value>
</variable>

<variable name='time'
<value units='minutes'>0<value>
<value units='minutes'>30<value>
<value units='minutes'>60<value>
<value units='minutes'>90<value>
</variable>

<conditions>

<condition alias="C0" control="true">
<variable name='gamma irradiation' value='false'>
<variable name='time' value='0'>
</condition>

<condition alias="C30" control="true">
<variable name='gamma irradiation' value='false'>
<variable name='time' value='30'>
</condition>

<condition alias="C60" control="true">
<variable name='gamma irradiation' value='false'>
<variable name='time' value='60'>
</condition>

<condition alias="C90" control="true">
<variable name='gamma irradiation' value='false'>
<variable name='time' value='90'>
</condition>

<condition alias="G0" control="false">
<variable name='gamma irradiation' value='true'>
<variable name='time' value='0'>
</condition>

<condition alias="G30" control="false">
<variable name='gamma irradiation' value='true'>
<variable name='time' value='30'>
</condition>

<condition alias="G60" control="false">
<variable name='gamma irradiation' value='true'>
<variable name='time' value='60'>
</condition>

<condition alias="G90" control="false">
<variable name='gamma irradiation' value='true'>
<variable name='time' value='90'>
</condition>

</conditions>
</experiment>


<experiment name="metal" timeSeries="no" type="environmental">
<organism>Halobacterium NRC-1 </organism>
<factor> copper at 700, 850, 1000 micromoloar</factor>
<factor> iron at 0,2,4,6,7 millimolar</factor>
<factor> manganese at 800,1000,1500 micromolar</factor>
<factor> zinc at 5,10,20 micromolar</factor>
<conditions>
<condition alias='Fe_2_vs_C.sig'>Iron at 2 millimolar</condition>
<condition alias='Fe_4_vs_C.sig'>Iron at 4 millimolar</condition>
<condition alias='Fe_6_vs_C.sig'>Iron at 6 millimolar</condition>
<condition alias='Fe_7_vs_C.sig'>Iron at 7 millimolar</condition>
<condition alias='Cu_1_vs_C.sig'>Copper at 700 micromolar</condition>
<condition alias='Cu_2_vs_C.sig'>Copper at 850 micromolar</condition>
<condition alias='Cu_3_vs_C.sig'>Copper at 1000 micromolar</condition>
<condition alias='Mn_1_vs_C.sig'>Manganese at 800 micromolar</condition>
<condition alias='Mn_2_vs_C.sig'>Manganese at 1000 micromolar</condition>
<condition alias='Mn_3_vs_C.sig'>Manganese at 1500 micromolar</condition>
<condition alias='Zn_1_vs_C.sig'>Zinc at 5 micromolar</condition>
<condition alias='Zn_2_vs_C.sig'>Zinc at 10 micromolar</condition>
<condition alias='Zn_3_vs_C.sig'>Zinc at 20 micromolar</condition>
</conditions>
</experiment>

<experiment name="oxygen, light, knockouts" environmental=true genetic=true>

<organism>
<species> Halobacterium NRC-1 </species>
<strain> delta URA3 </strain>
</organism>

<variable name='oxygen'>
<value>high</value>
<value>low</value>
</variable>

<variable name='light'>
<value>light</value>
<value>dark</value>
</variable>

<variable name='knockout'>
<value>boa1</value>
<value>boa4</value>
<value>bop</value>
<value>crti2</value>
<value>htr1</value>
<value>htr2</value>
<value>htr8</value>
<value>kinA2</value>
<value>phoR</value>
<value>phr1</value>
<value>phr2</value>
<value>phr1 and phr2</value>
<value>sop2</value>
<value>ua3</value>
<value>VNG750C</value>
</variable>

<conditions>

<condition alias="750_HO_D_vs_NRC-1.clone">
<variable name='light' value='dark'>
<variable name='knockout' value='VNG750C'>
<variable name='oxygen' value='high'>
</condition>

<condition alias="750_HO_L_vs_NRC-1.clone">
</condition>

<condition alias="750_LO-D_vs_NRC-1.clone">
</condition>

<condition alias="750_LO-L_vs_NRC-1.clone">
</condition>

<condition alias="BOP_HO-D_vs_NRC-1.clone">
</condition>

<condition alias="BOP_HO-L_vs_NRC-1.clone">
</condition>

<condition alias="BOP_LO-D_vs_NRC-1.clone">
</condition>

<condition alias="BOP_LO-L_vs_NRC-1.clone">
</condition>

<condition alias="NRC-1_HO-D_vs_NRC-1.clone">
</condition>

<condition alias="NRC-1_HO-L_vs_NRC-1.clone">
</condition>

<condition alias="NRC-1_LO-D_vs_NRC-1.clone">
</condition>

<condition alias="NRC-1_LO-L_vs_NRC-1.clone">
</condition>

<condition alias="afsQ2_HO-D_vs_NRC-1.clone">
</condition>

<condition alias="afsQ2_HO-L_vs_NRC-1.clone">
</condition>

<condition alias="afsQ2_LO-D_vs_NRC-1.clone">
</condition>

<condition alias="afsQ2_LO-L_vs_NRC-1.clone">
</condition>

<condition alias="ak_HO-D_vs_NRC-1.clone">
</condition>

<condition alias="ak_HO_L_vs_NRC-1.clone">
</condition>

<condition alias="ak_LO-D_vs_NRC-1.clone">
</condition>

<condition alias="ak_LO-L_vs_NRC-1.clone">
</condition>

<condition alias="boa1_HO-D_vs_NRC-1.clone">
</condition>

<condition alias="boa1_HO-L_vs_NRC-1.clone">
</condition>

<condition alias="boa1_LO-D_vs_NRC-1.clone">
</condition>

<condition alias="boa1_LO-L_vs_NRC-1.clone">
</condition>

<condition alias="boa4_HO-D_vs_NRC-1.clone">
</condition>

<condition alias="boa4_HO-L_vs_NRC-1.clone">
</condition>

<condition alias="boa4_LO-D_vs_NRC-1.clone">
</condition>

<condition alias="boa4_LO-L_vs_NRC-1.clone">
</condition>

<condition alias="cti2_HO-D_vs_NRC-1.clone">
</condition>

<condition alias="cti2_HO-L_vs_NRC-1.clone">
</condition>

<condition alias="cti2_LO-D_vs_NRC-1.clone">
</condition>

<condition alias="cti2_LO-L_vs_NRC-1.clone">
</condition>

<condition alias="htlD_HO-D_vs_NRC-1.clone">
</condition>

<condition alias="htlD_HO-L_vs_NRC-1.clone">
</condition>

<condition alias="htlD_LO-D_vs_NRC-1.clone">
</condition>

<condition alias="htlD_LO-L_vs_NRC-1.clone">
</condition>

<condition alias="ht1_HO-D_vs_NRC-1.clone">
</condition>

<condition alias="ht1_HO-L_vs_NRC-1.clone">
</condition>

<condition alias="ht1_LO-D_vs_NRC-1.clone">
</condition>

<condition alias="ht1_LO-L_vs_NRC-1.clone">
</condition>

<condition alias="ht2_HO-D_vs_NRC-1.clone">
</condition>

<condition alias="ht2_HO-L_vs_NRC-1.clone">
</condition>

<condition alias="ht2_LO-D_vs_NRC-1.clone">
</condition>

<condition alias="ht2_LO-L_vs_NRC-1.clone">
</condition>

<condition alias="ht8_HO-D_vs_NRC-1.clone">
</condition>

<condition alias="ht8_HO-L_vs_NRC-1.clone">
</condition>

<condition alias="ht8_LO-D_vs_NRC-1.clone">
</condition>

<condition alias="ht8_LO-L_vs_NRC-1.clone">
</condition>

<condition alias="kinA2_HO-D_vs_NRC-1.clone">
</condition>

<condition alias="kinA2_HO-L_vs_NRC-1.clone">
</condition>

<condition alias="kinA2_LO-D_vs_NRC-1.clone">
</condition>

<condition alias="kinA2_LO-L_vs_NRC-1.clone">
</condition>

<condition alias="phoR_HO-D_vs_NRC-1.clone">
</condition>

<condition alias="phoR_HO-L_vs_NRC-1.clone">
</condition>

<condition alias="phoR_LO-D_vs_NRC-1.clone">
</condition>

<condition alias="phoR_LO-L_vs_NRC-1.clone">
</condition>

<condition alias="ph1_HO-D_vs_NRC-1.clone">
</condition>

<condition alias="ph1_HO-L_vs_NRC-1.clone">
</condition>

<condition alias="ph1_LO-D_vs_NRC-1.clone">
</condition>

<condition alias="ph1_LO-L_vs_NRC-1.clone">
</condition>

<condition alias="ph1_and_2_HO-D_vs_NRC-1.clone">
</condition>

<condition alias="ph1_and_2_HO-L_vs_NRC-1.clone">
</condition>

<condition alias="ph1_and_2_LO-D_vs_NRC-1.clone">
</condition>

<condition alias="ph1_and_2_LO-L_vs_NRC-1.clone">
</condition>

<condition alias="ph2_HO-D_vs_NRC-1.clone">
</condition>

<condition alias="ph2_HO-L_vs_NRC-1.clone">
</condition>

<condition alias="ph2_LO-D_vs_NRC-1.clone">
</condition>

<condition alias="ph2_LO-L_vs_NRC-1.clone">
</condition>

<condition alias="sop2_HO-D_vs_NRC-1.clone">
</condition>

<condition alias="sop2_HO-L_vs_NRC-1.clone">
</condition>

<condition alias="sop2_LO-D_vs_NRC-1.clone">
</condition>

<condition alias="sop2_LO-L_vs_NRC-1.clone">
</condition>

<condition alias="ua3_HO-D_vs_NRC-1.clone">
</condition>

<condition alias="ua3_HO-L_vs_NRC-1.clone">
</condition>

<condition alias="ua3_LO-D_vs_NRC-1.clone">
</condition>

<condition alias="ua3_LO-L_vs_NRC-1.clone">
</condition>


</conditions>
</experiment>

*--------------------------------------------------------------------------------------------------
* halo metadata format, attempt #1 (10 may 04)

grammar
---------
category=(environmental|knockout|...)
timeSeries=(yes|no)
control=(yes|no)
intervention=
intervention=
intervention=
time=



//
category=environmental
timeSeries=yes
control=yes
non-intervention=gamma irradiation
intervention=cold shock: 42oC-RT-42oC
intervention=nutrient Shock: Complete medium-Basal Salts-Complete medium
time=0 minutes
//
category=environmental
timeSeries=yes
control=no
intervention=gamma irradiation
intervention=cold shock: 42oC-RT-42oC
intervention=nutrient Shock: Complete medium-Basal Salts-Complete medium
time=0 minutes
//
category=environmental
timeSeries=yes
control=no
intervention=gamma irradiation
intervention=cold shock: 42oC-RT-42oC
intervention=nutrient Shock: Complete medium-Basal Salts-Complete medium
time=30 minutes
//
category=environmental
timeSeries=yes
control=no
intervention=gamma irradiation
intervention=cold shock: 42oC-RT-42oC
intervention=nutrient Shock: Complete medium-Basal Salts-Complete medium
time=60 minutes
//
category=environmental
category=knockout
type=intervention
perturbation=Genetic=Knockout:Gene=VNG0750C
perturbation=Environmental Factor=Oxygen:Concentration=High
perturbation=Environmental Factor-Light=Concentration=High
alias:750_HO_L_vs_NRC-1
//
category=Environmental response
alias=Fe_2_vs_C.sig
type=intervetion
Perturbation 1: Environmental
Factor: Metals
Sub-factor: Iron Sulfate (FeSO4)
Concentration: 2mM

Fe_4_vs_C.sig
Perturbation 1: Environmental
Factor: Metals
Sub-factor: Iron Sulfate (FeSO4)
Concentration: 4mM

*--------------------------------------------------------------------------------------------------
* halo gamma radiation, new pipeline file (10 may 04)
copied PipelineToMatrix.py to ~/lib
copied createMatrix.py from ~/data/halo/marc/linearLayout/2004.04.30 to
gamma
in that program, corrected 'titlesToGrab' to be the names of the columns
(this produces file gamma.ratio) and then reassiged 'titlesToGrab' to
be those same names with '.dup' appended to all -- that is the suffix
that PipelineToMatrix.py adds to the lambda column names, so that they
are unique.  the parallel array 'preferredTitles' is explicit and complete,
so that column names in both resulting files are identical.

nitin's comments

This is the data for the halobacterium gamma repair microarrays.  When
you get a chance can I have a webstart with all of the halo data,
including UV, metals and gamma?  The format is the same as for the .mrna
files, i.e. with the following columns in the given order

GENE   DESCRIPTION   RATIOS            LAMBDAS.
*--------------------------------------------------------------------------------------------------
* halo gamma radiation, metadata (10 may 04)

All "C" columns are controls for the overall "Gamma repair" group and
the "G" columns are the experiments.  The numbers after a C or G
indicate the number of minutes subsequent to irradiation.

Therefore for C0:
Main category: Gamma repair
Type1: Control
Type2: Time series
Perturbation1: Cold shock: 42oC-RT-42oC
Perturbation2: Nutrient Shock: Complete medium-Basal Salts-Complete medium
Time: 0 minutes
And for G0

Main category: Gamma repair
Type1: Experimental
Type2: Time series
Perturbation1: Cold shock: 42oC-RT-42oC
Perturbation2: Nutrient Shock: Complete medium-Basal Salts-Complete medium
Perturbation3: Gamma irradiation
Time: 0 minutes

I realize we are still figuring out the meta-information concept and you
may have a better idea of this than I do.  I am copying in this
information so we can keep thinking of what might be the most efficient
format.
*--------------------------------------------------------------------------------------------------
* jython, 2d plotter, prototype for ratios vs lambdas, interactive hyperbola plotter (10 may 04)
/users/pshannon/examples/jython/swing/jfreechart/xyplot/
jython; execfile ('go.py')
plots x,y pairs with names attached, mouse selection supported.
*--------------------------------------------------------------------------------------------------
* jython, embedded interpreter, from gui to gui (7 may 2004)

example 1: /users/pshannon/examples/jython/jythoness_examples/myEmbed/panel

the python script adds buttons (within a panel) to the parent pure-java application
a text field is pre-loaded with "e.add (TPanel ())", which is interpreted and the buttons are added

example 2: /users/pshannon/examples/jython/jythoness_examples/myEmbed/frame

the python script adds buttons in a new, independent JFrame
a text field is pre-loaded with "t = TPanel ())", which is interpreted and the new frame opesn
*--------------------------------------------------------------------------------------------------
* jython, create swing module, load from elsewhere (7 may 2004)
by example:
cd /users/pshannon/examples/jython/displayImage
mkdir img
in img, create:
__init__.py
go.py   (which defines JFrame subclass called 'Counter' with no-args ctor)
import sys
sys.path  (make sure that the current directory -- also the parent of 'img'
is in the path)

>>> import img.go
>>> c = img.go.Counter ()
-- or --
>>> from img.go import *
>>> c2 = Counter ()

in prose:

a module is a file of python soure code

it has a path   grandparent.parent.filename(.py)

the grandparent directory must be -in- a directory named in sys.path

all the variables (including functions and classes) found in the module
are evaluated when the module is imported
*--------------------------------------------------------------------------------------------------
* jython essentials, from ora (7 may 2004)
http://www.oreilly.com/catalog/jythoness/
put 13 chapters of examples in /users/pshannon/examples/jython/jythoness_examples
*--------------------------------------------------------------------------------------------------
* jython & image display (5 may 2004)
many fruitless hours trying to mimic
/users/pshannon/examples/java/2d/tutorial/loadImage/ImageViewer
in jython
*--------------------------------------------------------------------------------------------------
* Rserve (4 may 2004)
(once installed, start daemon like this:   R CMD Rserve)
got Rserve_0.3-10.tar.gz from http://stats.math.uni-augsburg.de/Rserve/doc.shtml
put it in /users/pshannon/src/r
su
R CMD INSTALL Rserve_0.3-10.tar.gz
success
test:

Trickser> R CMD Rserve
...
Rserv started in daemon mode.
Trickster.r>

put /users/pshannon/jars/JRclient-RE321.jar
in CLASSPATH
start jython
from org.rosuda.JRclient import *
c = Rconnection ()
c.eval ("rnorm (3)")
[REAL* (-0.8422375814992669, -0.9822571596554017, 0.4191461134959869)]
c.eval ("R.version.string") --> [STRING "R version 1.9.0, 2004-04-12"]
len (rc.eval ('rnorm (5)').getContent ()) --> 5

to kill Rserve:  ps -U pshannon
*--------------------------------------------------------------------------------------------------
* halo pcr/genes/insertion elements all working pretty well
cd /users/pshannon/data/halo/marc/linearLayout/2004.04.30/
make
cd cy
make
todo:
1) create vizmap for expression ratio (which is on tiles)
2) ask marc how to get pNRC200 tiles into the beginning of pNRC100


*--------------------------------------------------------------------------------------------------
* new microarray pipeline data from marc (friday, 30 apr 2004)
saved attachment to
/users/pshannon/data/halo/marc/linearLayout/2004.04.30/batcmyc.chip  (1993756 30 Apr 17:21)
!! be sure to delete the last line in this file !!
NumSigGenes:	4635	4635	+Infinity

created directory  /users/pshannon/data/halo/marc/linearLayout/2004.04.30
cp -p ../2004.04.05/createMatrices.py
cp -p ../2004.04.05/PipelineToDataMatrix.py .
modify createMatrices.py:
file = 'batcmyc.chip'
#  from the data file         to be used in the matrix files
#  ------------------         -------------------------------
# primer_forward_name                  Tile
# bat_vs_bat.sig                       bat_vs_bat
# cmyc1_vs_cmyc1.sig                   cmyc1_vs_cmyc1

titlesToGrab    = ['primer_forward_name', 'bat_vs_bat.sig', 'cmyc1_vs_cmyc1.sig']
preferredTitles = ['Tile', 'bat_vs_bat', 'cmyc1_vs_cmyc1']

python createMatrices.py  (reads batcmyc.chip, produces matrix.ratio & matrix.lambda)
4636 matrix.lambda
4636 matrix.ratio
create this cytoscape.props:
plugin.0.load=csplugins.trial.pshannon.dataCube.DataCubePlugin
make sure both of these are readable:
java cytoscape.cytoscape --matrix matrix.ratio  --matrix matrix.lambda
this checks out.

todo: next up, generate the full tiles, genes, and insertion element map
*--------------------------------------------------------------------------------------------------
* towards a new interface for the DataMatrix class (friday, 30 apr 2004)  david's comments

java.util.Vector getDataMatrix(java.lang.String matrixName):
Get the values in the matrix as a Vector of Vectors (indexed by row)

java.util.Hashtable getDataMatrixAsColumns (java.lang.StringmatrixName)
Return the entire named data matrix, indexed by column names

java.util.Hashtable getDataMatrixAsRows(java.lang.String matrixName)
Return the entire named data matrix, indexed by row names

java.util.Vector getDataMatrixColumn( java.lang.String matrixName,  java.lang.String colName)
Return the values in the given named column for the given named matrix

java.util.Hashtable getDataMatrixColumns (java.lang.String matrixName,  java.util.Vector colNames)
Get the values in the given named matrix columns for the given named matrix

java.util.Vector getDataMatrixColumnTitles(java.lang.String matrixName)
Get the column titles for the given named data matrix

java.util.Vector getDataMatrixNames ()
Get the names of the available data matrices

java.util.Vector getDataMatrixRow (java.lang.String matrixName,  java.lang.String rowName)
Get the values in the given named matrix row in the given named data matrix

java.util.Hashtable getDataMatrixRows (java.lang.String matrixName,  java.util.Vector rowNames)
Get the values in the given named matrix rows in the given named data matrix

java.util.Vector getDataMatrixRowTitles (java.lang.String matrixName)  getDataMatrixRowTitles
Get the row titles for the given named data matrix

double getDataMatrixValue(java.lang.StringmatrixName,  java.lang.String rowName,  java.lang.String colName)
Get the value in the named matrix at the given named row,column coordinate
*--------------------------------------------------------------------------------------------------
* halo submatrix cluster selection test directories (30 apr 2004)

browserOnlyTest:  uses jython to run a data matrix browser w/o cytoscape
tinyTest:  small network (37 nodes), 3 disjoint clusters
fullTest:  270 clusters over 10k interactions, 2400+ genes, in 114 conditions

many bugs fixed.
*--------------------------------------------------------------------------------------------------
* cluster selection bug (29 apr 2004)
[this turned out to be caused mostly by selecting rows in matrices hidden behind the
top, visible one. now selection is restricted to the top visible matrix]

reproduced in
/users/pshannon/cy/csplugins/trial/pshannon/dataCube/demo/haloClusters/try0
make 37
load clusters37.txt
choose cluster 1, which has 30 genes and 3 conditions
'Create Matrix from Selection'  -- make new tab labeled 'c1'
switch to that tab
select next cluster, 2, generating exception:
cluster: 2: 0.222, 0.0222 5x3
apple.awt.EventQueueExceptionHandler Caught Throwable :
java.lang.ArrayIndexOutOfBoundsException: 10
at csplugins.trial.pshannon.dataCube.browsers.\
DataCubeBrowser$TableSelectionListener.valueChanged(DataCubeBrowser.java:685)
at javax.swing.DefaultListSelectionModel.fireValueChanged(DefaultListSelectionModel.java:187)
at javax.swing.DefaultListSelectionModel.fireValueChanged(DefaultListSelectionModel.java:167)
at javax.swing.DefaultListSelectionModel.fireValueChanged(DefaultListSelectionModel.java:214)
at javax.swing.DefaultListSelectionModel.changeSelection(DefaultListSelectionModel.java:402)
at javax.swing.DefaultListSelectionModel.changeSelection(DefaultListSelectionModel.java:411)
at javax.swing.DefaultListSelectionModel.addSelectionInterval(DefaultListSelectionModel.java:456)
at csplugins.trial.pshannon.dataCube.browsers.DataCubeBrowser.selectRowsByName(DataCubeBrowser.java:756)
at csplugins.trial.pshannon.dataCube.browsers.DataCubeBrowser.selectRowsByName(DataCubeBrowser.java:743)
at csplugins.trial.pshannon.dataCube.browsers.\
SubMatrixSelectorDialog$ListboxSelectionListener.valueChanged(SubMatrixSelectorDialog.java:138)

*--------------------------------------------------------------------------------------------------
* halo microarray data sets (29 apr 2004)
matrix-27.ratio/lambda:  from 2004.03.05, titles
['GENE', '4_vs_R', '2_vs_R', '21_vs_R', '3_vs_R', '18_vs_R', '17_vs_R',
'10_vs_R', '20_vs_R', '13_vs_R', '12_vs_R', '8_vs_R', '24_vs_R', '6_vs_R',
'23_vs_R', '9_vs_R', '19_vs_R', '14_vs_R', '1_vs_R', '5_vs_R', '22_vs_R',
'25_vs_R', '15_vs_R', '7_vs_R', '11_vs_R', '16_vs_R', '']

uvRepair.ratio/lambda:  from 2004.04.22 (or earlier), titles:
['GENE', 'C60', 'D30', 'D60', 'L30', 'L60', '']

haloMetal.ratio/lambda:  from 2004.04.21, titles:
['GENE', 'Fe_2_vs_C.sig', 'Fe_4_vs_C.sig', 'Fe_6_vs_C.sig', 'Fe_7_vs_C.sig',
'Cu_1_vs_C.sig', 'Cu_2_vs_C.sig', 'Cu_3_vs_C.sig', 'Mn_1_vs_C.sig',
'Mn_2_vs_C.sig', 'Mn_3_vs_C.sig', 'Zn_1_vs_C.sig', 'Zn_2_vs_C.sig', 'Zn_3_vs_C.sig', '']

haloOxygen.ratio/lambda:  from 2004.04.21, titles:
['GENE', '750_HO_D_vs_NRC-1.clone', '750_HO_L_vs_NRC-1.clone', '750_LO-D_vs_NRC-1.clone',
'750_LO-L_vs_NRC-1.clone', 'BOP_HO-D_vs_NRC-1.clone', 'BOP_HO-L_vs_NRC-1.clone',
'BOP_LO-D_vs_NRC-1.clone', 'BOP_LO-L_vs_NRC-1.clone', 'NRC-1_HO-D_vs_NRC-1.clone',
'NRC-1_HO-L_vs_NRC-1.clone', 'NRC-1_LO-D_vs_NRC-1.clone', 'NRC-1_LO-L_vs_NRC-1.clone',
'afsQ2_HO-D_vs_NRC-1.clone', 'afsQ2_HO-L_vs_NRC-1.clone', 'afsQ2_LO-D_vs_NRC-1.clone',
'afsQ2_LO-L_vs_NRC-1.clone', 'ak_HO-D_vs_NRC-1.clone', 'ak_HO_L_vs_NRC-1.clone',
'ak_LO-D_vs_NRC-1.clone', 'ak_LO-L_vs_NRC-1.clone', 'boa1_HO-D_vs_NRC-1.clone',
'boa1_HO-L_vs_NRC-1.clone', 'boa1_LO-D_vs_NRC-1.clone', 'boa1_LO-L_vs_NRC-1.clone',
'boa4_HO-D_vs_NRC-1.clone', 'boa4_HO-L_vs_NRC-1.clone', 'boa4_LO-D_vs_NRC-1.clone',
'boa4_LO-L_vs_NRC-1.clone', 'cti2_HO-D_vs_NRC-1.clone', 'cti2_HO-L_vs_NRC-1.clone',
'cti2_LO-D_vs_NRC-1.clone', 'cti2_LO-L_vs_NRC-1.clone', 'htlD_HO-D_vs_NRC-1.clone',
'htlD_HO-L_vs_NRC-1.clone', 'htlD_LO-D_vs_NRC-1.clone', 'htlD_LO-L_vs_NRC-1.clone',
'ht1_HO-D_vs_NRC-1.clone', 'ht1_HO-L_vs_NRC-1.clone', 'ht1_LO-D_vs_NRC-1.clone',
'ht1_LO-L_vs_NRC-1.clone', 'ht2_HO-D_vs_NRC-1.clone', 'ht2_HO-L_vs_NRC-1.clone',
'ht2_LO-D_vs_NRC-1.clone', 'ht2_LO-L_vs_NRC-1.clone', 'ht8_HO-D_vs_NRC-1.clone',
'ht8_HO-L_vs_NRC-1.clone', 'ht8_LO-D_vs_NRC-1.clone', 'ht8_LO-L_vs_NRC-1.clone',
'kinA2_HO-D_vs_NRC-1.clone', 'kinA2_HO-L_vs_NRC-1.clone', 'kinA2_LO-D_vs_NRC-1.clone',
'kinA2_LO-L_vs_NRC-1.clone', 'phoR_HO-D_vs_NRC-1.clone', 'phoR_HO-L_vs_NRC-1.clone',
'phoR_LO-D_vs_NRC-1.clone', 'phoR_LO-L_vs_NRC-1.clone', 'ph1_HO-D_vs_NRC-1.clone',
'ph1_HO-L_vs_NRC-1.clone', 'ph1_LO-D_vs_NRC-1.clone', 'ph1_LO-L_vs_NRC-1.clone',
'ph1_and_2_HO-D_vs_NRC-1.clone', 'ph1_and_2_HO-L_vs_NRC-1.clone', 'ph1_and_2_LO-D_vs_NRC-1.clone',
'ph1_and_2_LO-L_vs_NRC-1.clone', 'ph2_HO-D_vs_NRC-1.clone', 'ph2_HO-L_vs_NRC-1.clone',
'ph2_LO-D_vs_NRC-1.clone', 'ph2_LO-L_vs_NRC-1.clone', 'sop2_HO-D_vs_NRC-1.clone',
'sop2_HO-L_vs_NRC-1.clone', 'sop2_LO-D_vs_NRC-1.clone', 'sop2_LO-L_vs_NRC-1.clone',
'ua3_HO-D_vs_NRC-1.clone', 'ua3_HO-L_vs_NRC-1.clone', 'ua3_LO-D_vs_NRC-1.clone',
'ua3_LO-L_vs_NRC-1.clone', '']

matrix-114.ratio/lambda:  from rich, used for his bi-clustering, rec'd 2004.04.23, titles
['GENE', 'C60', 'D30', 'D60', 'L30', 'L60', 'X1', 'X2', 'X3', 'X4', 'X5', 'X6', 'X7',
'X8', 'X9', 'X10', 'X11', 'X12', 'X13', 'X14', 'X15', 'X16', 'X17', 'X18', 'X19',
'X20', 'X21', 'X22', 'X23', 'X24', 'X25', 'Fe.4.vs.c', 'Fe.6.vs.c', 'Fe.7.vs.c',
'Cu.1.vs.c', 'Cu.2.vs.c', 'Cu.3.vs.c', 'Mn.1.vs.c', 'Mn.2.vs.c', 'Mn.3.vs.c', 'Zn.1.vs.c',
'Zn.2.vs.c', 'Zn.3.vs.c', 'X750.HO.L.vs.NRC.1', 'X750.LO.D.vs.NRC.1', 'X750.LO.L.vs.NRC.1',
'BOP.HO.D.vs.NRC.1', 'BOP.HO.L.vs.NRC.1', 'BOP.LO.D.vs.NRC.1', 'BOP.LO.L.vs.NRC.1',
'NRC.1.HO.D.vs.NRC.1', 'NRC.1.HO.L.vs.NRC.1', 'NRC.1.LO.D.vs.NRC.1', 'NRC.1.LO.L.vs.NRC.1',
'NRC.1.vs.NRC.1', 'ark.HO.D.vs.NRC.1', 'ark.HO.L.vs.NRC.1', 'ark.LO.D.vs.NRC.1', 'ark.LO.L.vs.NRC.1',
'boa1.HO.D.vs.NRC.1', 'boa1.HO.L.vs.NRC.1', 'boa1.LO.D.vs.NRC.1', 'boa1.LO.L.vs.NRC.1',
'boa4.HO.D.vs.NRC.1', 'boa4.HO.L.vs.NRC.1', 'boa4.LO.D.vs.NRC.1', 'boa4.LO.L.vs.NRC.1',
'crti2.HO.D.vs.NRC.1', 'crti2.HO.L.vs.NRC.1', 'crti2.LO.D.vs.NRC.1', 'crti2.LO.L.vs.NRC.1',
'htlD.HO.D.vs.NRC.1', 'htlD.HO.L.vs.NRC.1', 'htlD.LO.D.vs.NRC.1', 'htlD.LO.L.vs.NRC.1',
'htr1.HO.D.vs.NRC.1', 'htr1.HO.L.vs.NRC.1', 'htr1.LO.D.vs.NRC.1', 'htr1.LO.L.vs.NRC.1',
'htr2.HO.D.vs.NRC.1', 'htr2.HO.L.vs.NRC.1', 'htr2.LO.D.vs.NRC.1', 'htr2.LO.L.vs.NRC.1',
'htr8.HO.D.vs.NRC.1', 'htr8.HO.L.vs.NRC.1', 'htr8.LO.D.vs.NRC.1', 'htr8.LO.L.vs.NRC.1',
'kinA2.HO.D.vs.NRC.1', 'kinA2.HO.L.vs.NRC.1', 'kinA2.LO.D.vs.NRC.1', 'kinA2.LO.L.vs.NRC.1',
'phoR.HO.D.vs.NRC.1', 'phoR.HO.L.vs.NRC.1', 'phoR.LO.D.vs.NRC.1', 'phoR.LO.L.vs.NRC.1',
'phr1.HO.D.vs.NRC.1', 'phr1.LO.D.vs.NRC.1', 'phr1.LO.L.vs.NRC.1', 'phr1.and.2.HO.D.vs.NRC.1',
'phr1.and.2.HO.L.vs.NRC.1', 'phr1.and.2.LO.D.vs.NRC.1', 'phr1.and.2.LO.L.vs.NRC.1',
'phr2.HO.D.vs.NRC.1', 'phr2.HO.L.vs.NRC.1', 'phr2.LO.D.vs.NRC.1', 'phr2.LO.L.vs.NRC.1',
'sop2.HO.D.vs.NRC.1', 'sop2.HO.L.vs.NRC.1', 'sop2.LO.D.vs.NRC.1', 'sop2.LO.L.vs.NRC.1',
'ura3.HO.D.vs.NRC.1', 'ura3.HO.L.vs.NRC.1', 'ura3.LO.D.vs.NRC.1', 'ura3.LO.L.vs.NRC.1']

bigClusters27.txt: development location:
cd  /users/pshannon/cy/csplugins/trial/pshannon/dataCube/demo/haloClusters/try1; make

*--------------------------------------------------------------------------------------------------
* nitin's metadata for experimental data (28 apr 2004)
see how an interface for these can be added to the DataCubeBrowser

750_HO_L_vs_NRC-1
Perturbation 1: Genetic
Type: Knockout
Gene: VNG0750C
Perturbation 2: Environmental
Factor: Oxygen
Concentration: High
Perturbation 3: Environmental
Factor: Light
Concentration: High

750_LO_L_vs_NRC-1
Perturbation 1: Genetic
Type: Knockout
Gene: VNG0750C
Perturbation 2: Environmental
Factor: Oxygen
Concentration: Low
Perturbation 3: Environmental
Factor: Light
Concentration: High

750_HO_D_vs_NRC-1
Perturbation 1: Genetic
Type: Knockout
Gene: VNG0750C
Perturbation 2: Environmental
Factor: Oxygen
Concentration: High
Perturbation 3: Environmental
Factor: Light
Concentration: Low

750_LO_D_vs_NRC-1
Perturbation 1: Genetic
Type: Knockout
Gene: VNG0750C
Perturbation 2: Environmental
Factor: Oxygen
Concentration: Low
Perturbation 3: Environmental
Factor: Light
Concentration: low



Fe_2_vs_C.sig
Perturbation 1: Environmental
Factor: Metals
Sub-factor: Iron Sulfate (FeSO4)
Concentration: 2mM

Fe_4_vs_C.sig
Perturbation 1: Environmental
Factor: Metals
Sub-factor: Iron Sulfate (FeSO4)
Concentration: 4mM

Fe_6_vs_C.sig
Perturbation 1: Environmental
Factor: Metals
Sub-factor: Iron Sulfate (FeSO4)
Concentration: 6mM

Fe_7_vs_C.sig
Perturbation 1: Environmental
Factor: Metals
Sub-factor: Iron Sulfate (FeSO4)
Concentration: 7mM

D30
Perturbation 1: Environmental
Factor: Ultraviolet radiation
Concentration: 200J/m2
Sub-factor: Light
Concentration: Low
Time: 30 minutes


D60
Perturbation 1: Environmental
Factor: Ultraviolet radiation
Concentration: 200J/m2
Sub-factor: Light
Concentration: Low
Time: 60 minutes

L30
Perturbation 1: Environmental
Factor: Ultraviolet radiation
Concentration: 200J/m2
Sub-factor: Light
Concentration: High
Time: 30 minutes

L60
Perturbation 1: Environmental
Factor: Ultraviolet radiation
Concentration: 200J/m2
Sub-factor: Light
Concentration: high
Time: 60 minutes


C60
Perturbation 1: Environmental
Factor: Ultraviolet radiation
Concentration: 0J/m2
Sub-factor: Light
Concentration: high
Time: 60 minutes


*-----------------------------------------------------------------------------------
* todo, halo (27 apr 2004)
data matrix correlation finder:  make +/-/both options on the gui
*-----------------------------------------------------------------------------------
* todo
in /users/pshannon/cy/csplugins/trial/pshannon/dataCube/browsers/DataCubeBrowser, line 433,
this println shows that the data matrix lens is returning 7 rows, not the 3 I had manually
selected.  see why....


System.out.println ("number of selected row titles: " + lens.getSelectedRowTitles().length);
the
number of matrices read: 1
browse matrices
matrix column count: 5
matrix column title count: 6
>>> new matrix size: 3 x 5
number of selected row titles: 7
apple.awt.EventQueueExceptionHandler Caught Throwable :
java.lang.ArrayIndexOutOfBoundsException: 3
at csplugins.trial.pshannon.dataCube.DataMatrix.get(DataMatrix.java:87)
at csplugins.trial.pshannon.dataCube.DataMatrix.toString(DataMatrix.java:136)
at csplugins.trial.pshannon.dataCube.browsers.DataCubeBrowser$CreateNewMatrixFromSelection.actionPerformed(DataCubeBrowser.java:438)
at javax.swing.AbstractButton.fireActionPerformed(AbstractButton.java:1819)
at javax.swing.AbstractButton$ForwardActionEvents.actionPerformed(AbstractButton.java:1872)
at javax.swing.DefaultButtonModel.fireActionPerformed(DefaultButtonModel.java:420)
at javax.swing.DefaultButtonModel.setPressed(DefaultButtonModel.java:258)
at javax.swing.plaf.basic.BasicButtonListener.mouseReleased(BasicButtonListener.java:247)
at java.awt.Component.processMouseEvent(Component.java:5100)
at java.awt.Component.processEvent(Component.java:4897)
at java.awt.Container.processEvent(Container.java:1569)
*-----------------------------------------------------------------------------------
* (26 apr 2004) keggwib crontest failed
the 5:38 am cront test failed
38 5 * * * (cd /local/tomcat/webapps/cytoscape/projects/dynamic/keggwbi/halo/execTests;\
/tools/bin/python crontest.py verbose)
this seems to be caused by the expired cached pathway map at kegg, produced yesterday afternoon (sunday) in
the cron job
http://www.genome.ad.jp/kegg-bin/mark_pathway_www?22441/hal00010.args
the fresh (and working) url is
http://www.genome.ad.jp/kegg-bin/mark_pathway_www?8304/hal00010.args
proposed solution:  reschedule the jog
04 16 * * * (cd /local/tomcat/webapps/cytoscape/projects/dynamic/keggwbi/halo;/tools/bin/python \
createStaticBrowsingList.py > static.html)
to run, not at 16:04, but at 4:04 (am!)
cd /local/tomcat/webapps/cytoscape/crontests
crontab crontab
*-----------------------------------------------------------------------------------
* (23 apr 2004) build a cy project for biaoyang
started with his pd interactions
added hprd with david's plugin (also got synonyms)  user ISBuser, ISBpass
saved as project:
/users/pshannon/data/blin/2004.04.23/afterHprd
created makefile there.
some vizmapping done
needs mpss data, locus links, ...
*-----------------------------------------------------------------------------------
* (23 apr 2004) create small halo test project for cluster selecting
/users/pshannon/cy/csplugins/trial/pshannon/dataCube/demo/haloClusters/try1
*-----------------------------------------------------------------------------------
* (23 apr 2004) create full expression matrix from Rich's RData
working in:    /users/pshannon/data/halo/biclusters/2004.04.23
file:          clust.rat.lam.RData
described by rich (email, 20 apr 2004):
here is a RData save with:
clusterStack (the list of clusters)
ratios
lambdas
load ("clust.rat.lam.RData")
length (ratios) ->  242046
dim (ratios) ->  2142  113
write.table (ratios, file='matrix.ratios', quote=F, sep="\t", col.names=NA)
write.table (lambdas, file='matrix.lambdas', quote=F, sep="\t", col.names=NA)
'col.names' parameter ensures a blank column heading at (0,0)
removed '.rat' and '.lam' title suffixes from each file, row 1, as needed.
*-----------------------------------------------------------------------------------
* (22 apr 2004)
todo: the lookup servlet/python combo is vastly inefficient.  it seems
to write (and/or read) one selection at a time from the tspace.
run halo/yeast demo, and watch stdout.

/users/pshannon/demos/haloYeastDipCogEnsemble
two subdirectories: halo, yeast
type 'make' in the parent directory, and two cytoscapes are started
make sure that a tspace is working first.

*-----------------------------------------------------------------------------------
* (22 apr 2004) try parsing rich's cluster file using java String.split ()
my attempt at java regex fell a little flat (see just below)

manual modifications to rich's data format:
- remove introductory lines, so that file now starts with cluster 1
- add 'cluster: ' at the beginning of each cluster header line so
that it looks like this:

cluster: 1	resid:	0.02838043	rowVar:	0.01235262

code:
/users/pshannon/cy/csplugins/trial/pshannon/dataCube/SubMatrixClusterReader.java
with unitTest
data:
/users/pshannon/data/halo/biclusters/2004.04.20/raw, looks like

cluster: 1	resid:	0.02838043	rowVar:	0.01235262
10	VNG6413h	VNG2386c	VNG2096g	...
111	C60.rat	D30.rat	D60.rat	L30.rat....

cluster: 2	resid:	0.03446423	rowVar:	0.01284790
38	VNG2632g	VNG0626g	...
112	C60.rat	D30.rat	D60.rat	L30.rat	L60.rat	....

cluster: 3	resid:	0.03119853	rowVar:	0.01472714

in /users/pshannon/cy/csplugins/trial/pshannon/dataCube/unitTests
SubMatrixClusterReaderTest.java
SubMatrixClusterTest.java
establish that two sample files, one of 3 clusters, the other of 270
(rich bonneau's first offering, of halo data on which he ran his R bi-clustering
program) are each available.
*-----------------------------------------------------------------------------------
* (22 apr 2004) DataCubeBrowser SubMatrixSelectorDialog now reads in a cluster file
demo in /users/pshannon/cy/csplugins/trial/pshannon/dataCube/demo/haloClusters/try0
next up:
read Rich's data into a cytoscape matrix
add methods to DataCubeBrowser to support selection
*-----------------------------------------------------------------------------------
* (22 apr 2004) java regex experiments
figure out java regexes (using jython?) based on problem reading clusters
in /users/pshannon/cy/csplugins/trial/pshannon/dataCube/SubMatrixClusterReader.java
some progress towards understanding java regex in
/users/pshannon/examples/java/regex/demo.java -- a unit test program
but I got completely hung on trying to do a non-consuming match in 'textFindRegex3'.
now, try using split on 'Cluster' instead....
*-----------------------------------------------------------------------------------
* (21 apr 2004) cytoscape plugin to selected submatrices in the DataCubeBrowser
made (temporary?) change to DataCubeBrowser so that it creates a button
for a new inner class, SubMatrixSelectorAction, which in turn creates
a new SubMatrixSelectorDialog, a dialog with a menubar containing file->load clusters
option, and a listbox, whose selections will be sent back to the DataCubeBrowser

*-----------------------------------------------------------------------------------
* (20 apr 2004) installed R on trickster
http://cran.r-project.org/
clicked on link to R.dmg
after install, and to create a command line version, do something like this:
as root, cd /usr/local/bin
ln -s /Library/Frameworks/R.framework/Resources/bin/R /usr/local/bin/R
added /usr/local/bin to path
works
*-----------------------------------------------------------------------------------
* (20 apr 2004) halo microarray data files from nitin, metals and ????
/users/pshannon/data/halo/metals

data/halo/marc/linearLayout/2004.04.05/unitTest/PipelineToDataMatrixTest.py
data/halo/marc/linearLayout/2004.04.05/PipelineToDataMatrix.py
*-----------------------------------------------------------------------------------
* (21 apr 2004) general purpose PipelineToDataMatrix class
/users/pshannon/lib/python/PipelineToDataMatrix.py
/users/pshannon/lib/python/unitTests/PipelineToDataMatrixTest.py
to use, write a little script like this, to keep in the project directory
associated with the raw file (and any subsequent manipulations)

import sys
sys.path.append ("..")
from PipelineToDataMatrix import *
p2d = PipelineToDataMatrix ('halo_metal_response.mrna')
matrix1 = p2d.getMatrixOne ()
matrix2 = p2d.getMatrixTwo ()

f1 = open ('haloMetal.ratios', 'w')
for line in matrix1:
for token in line:
f1.write ('%s\t' % (token)
f1.write ('\n')

f2 = open ('haloMetal.ratios', 'w')
for line in matrix2:
for token in line:
f2.write ('%s\t' % (token)
f2.write ('\n')
*-----------------------------------------------------------------------------------
* (20 apr 2004) trying out dan's SharedDataPlugin
/users/pshannon/cy/csplugins/sharedData/
the 'current data' browser needs a horizontal scrollbar
added colt.jar to get the inverter demo to work
*-----------------------------------------------------------------------------------
* (20 apr 2004) looked at dan's first treatment of blin's spreadsheets
in $H/data/blin/dan.2004.04.20/
see readme.txt
*-----------------------------------------------------------------------------------
* (20 apr 2004) parse rich's bicluster data

/users/pshannon/data/halo/biclusters/2004.04.20/raw
modified raw (an attachment from rich sent on 04.19) so that each 'cluster
header line' looks like this (i add 'cluster: '):
cluster: 1	resid:	0.02838043	rowVar:	0.01235262

simple python script 'reformat.py' reads these files
*-----------------------------------------------------------------------------------
* (19 apr 2004) create sample halo/dip-yeast cog homology ensemble

/users/pshannon/demos/haloYeastDipCogEnsemble
two subdirectories: halo, yeast
type 'make' in the parent directory, and two cytoscapes are started
make sure that a tspace is working first.


*-----------------------------------------------------------------------------------
* (17 apr 2004) get latest dip network covert to cytoscape project
db: /users/pshannon/data/import/dip/yeast
http://dip.doe-mbi.ucla.edu/dip/Download.cgi
only the 'core' dataset seems to be available in xin format for yeast
in /users/pshannon/data/import/dip/yeast:
2306327 Apr 17 20:17 ScereCR20040404.xin
mkdir 2004.04.17
cd 2004.04.17
python ../../scripts/xmlToCytoscape.py  ../ScereCR20040404.xin ../synonyms.dip
/users/pshannon/data/import/dip/yeast/2004.04.17:
Apr 17 20:25 edgeClass.eda
Apr 17 20:25 evidenceCount.eda
Apr 17 20:25 evidence.eda
Apr 17 20:25 evidenceWithPubmed.eda
Apr 17 20:25 experimentScale.eda
Apr 17 20:25 network.sif
Apr 17 20:25 pubmed.eda
copied all this to /local/tomcat/webapps/cytoscape/projects/static/dip/2004.04.17
got project, makefile, and jnlp file from next door:  ../2003.04.08
*-----------------------------------------------------------------------------------
* (17 apr 2004) new cog run:  find shared cogs for halo and yeast
/users/pshannon/data/import.old/cogs
getHalobacYeast > yeastAndHalobacterium.cogs
cat yeastAndHalobacterium.cogs | awk '{print "getPartners " $1}' > getAllPartners
getAllPartners > allPartners.xml &
grep -c 'cog id' allPartners.xml  -> 560
wc -l allPartners.xml ->  4197
parse these data so they can be read by
new class in /local/tomcat/webapps/cytoscape/projects/lookup/haloYeastCogs
HaloYeastCogTranslator.py
(has a nice & simple example of python regex use)
testing with sample.xml
python HaloYeastCogTranslatorTest.py
fills in two maps, of single gene to array of cog-partner genes
---------------- halo to yeast
VNG2321G: ['YIR042c']
VNG2078G: ['YIR042c']
VNG0486G: ['YIR042c']
VNG6312G: ['YDR341c', 'YHR091c']
VNG0872G: ['YDR242w', 'YMR293c', 'YBR208c_1']
VNG0487H: ['YIR042c']
VNG6213G: ['YIR042c']
VNG0461G: ['YCR024c', 'YHR019c', 'YLL018c']
VNG0345G: ['YBL080c']
VNG2283G: ['YOR335c']
---------------- yeast to halo
YIR042c: ['VNG0486G', 'VNG0487H', 'VNG2078G', 'VNG2321G', 'VNG6213G']
YOR335c: ['VNG2283G']
YDR341c: ['VNG6312G']
YHR019c: ['VNG0461G']
YBL080c: ['VNG0345G']
YLL018c: ['VNG0461G']
YBR208c_1: ['VNG0872G']
YCR024c: ['VNG0461G']
YHR091c: ['VNG6312G']
YDR242w: ['VNG0872G']
YMR293c: ['VNG0872G']

next up:  test with full allPartners.xml file
test with small yeast & halo network
make web start with full networks for both organisms (dip for yeast)a


*-----------------------------------------------------------------------------------
* (17 apr 2004) old notes on finding shared cogs for halo and yeast
found /users/pshannon/data/import.old/cogs from feb 2002, still functional
crib sheet (11 jan 2002)
mkdir `date +%Y.%h.%d`
cd `date +%Y.%h.%d`
../getHalobacYeast > yeastAndHalobacterium.cogs
cat yeastAndHalobacterium.cogs | awk '{print "../getPartners " $1}' > getAllPartners
chmod 755 getAllPartners
getAllPartners > allPartners.xml &
tail -f allPartners.xml
(when done, add xml header and footer:
<?xml version="1.0"?>
<!DOCTYPE cogs SYSTEM "../cogPartners.dtd">
<cogs>
....
</cogs>
validate allPartners.xml
cd ..
java deduceBindingCogPairs ~/work/org/isb/data/import/ypdOrfAndGenes/synonyms.xml \
~/work/org/isb/data/import/bind/2002.01.08/canonicalPairs.xml \
~/work/org/isb/data/import/cogs/2002.01.09/allPartners.xml > `date +%Y.%h.%d`/cogPairs

geneToCogMap size: 2566
found 17391 gene synonyms...
found 5650 binding pairs...
cog matches: 326
*-----------------------------------------------------------------------------------
* (16 apr 2004)
halo todo: in keggwbi, looking at a rewritten kegg pathway map, leading to
halo todo: an sbeams search by ec number, include search of nrc-1 also

halo todo: create a yeast network listener for nrc-1 which uses cogs for mapping
halo todo: publication search on selected nodes.  popup a dialog which offers choices:
- use synonyms?
- use orthologs?
- limit search by time (e.g., papers published in the last week)
- webby tricks:  insert checkboxes for selection among those displayed
on 'go' offer a chance to enter notes, then save
this information
- provide browser for previous, saved results

*-----------------------------------------------------------------------------------
* (15 apr 2004) getting back to marc's replicon-separated pcr tile display
/users/pshannon/data/halo/marc/linearLayout/src/unitTests
make tiles
looks like 'testSegregateReplicons' is a not-yet-used method
intended to separate the replicions on display.
*-----------------------------------------------------------------------------------
* (15 apr 2004) added javascript, legends, and better title to keggwbi pages
db:/local/tomcat/webapps/cytoscape/projects/dynamic/keggwbi/halo
createStaticBrowsingList.py   uses java script
KeggRewriter.py adds button legend (explaining red & green in kegg nodes)
and rewrites the title to include 'comparative metabolic reconstruction ...'
*-----------------------------------------------------------------------------------
* (14 apr 2004) proposal to nitin on creating new matrices on the fly
we need to be able to create custom matrices, built up by
selecting elements from data already loaded into cytoscape.

to make this convenient, all data matrices need to have a
(usually hierarchical) categorization.  this categorization
might be in an optional header in the data file, or it might
be assigned after the data is already in cytoscape.

data can be categorized to any level.  two examples, in which
'::' separates successive levels:

category=halo::uv repair::experiment 1
category=metals:iron::sulfate::time course #1

suggestion (16 apr 2004): always have an organism as the category root

the categorization could be extended to include columns and rows,
producing vectors, or even a scalar:

halo:uv repair:experiment 1:2 hours -> (a column of data, a vector)
halo:uv repair:experiment 1:bop -> (a row of data, also a vector)
halo:uv repair:experiment 1:bop:2 hours -> (a single cell, a scalar)

we want to allow the user to browse through the data.  we can  present
a browser rather like a windows or mac directory browser, and the
user can select some or all of the contents at any level.  this
selection can then be made into a matrix, and added to the current
collection of matrices  visible in the data cube browser.
*-----------------------------------------------------------------------------------
* (13 apr 2004) halo keggwbi now settled down
servlet: at http://db/cytoscape/keggwbi-hm
static version
http://db.systemsbiology.net/cytoscape/projects/dynamic/keggwbi/halo/static.html
(static only in the sense that initial retrieval of all
sbeams hm EC's, and their submission to KEGG, are skipped; instead,
the kegg results page is displayed, created every morning by
createStaticBrowsingList.py
in   /local/tomcat/webapps/cytoscape/projects/dynamic/keggwbi/halo)
crontest:
04 16 * * *
(cd /local/tomcat/webapps/cytoscape/projects/dynamic/keggwbi/halo;
/tools/bin/python createStaticBrowsingList.py > static.html)
*-----------------------------------------------------------------------------------
* (12 apr 2004) small keggwbi problems

1) glycolysis 5.3.1.1 is green (present in halo) but has no border (present
in hm).  this fails only with big search:  searching 5311 alone in
KEGG gets a green, red-bordered box

For the first pathway -glycolysis and gluconeogenesis- enzyme 5.3.1.1
(right next to "Photosynthesis" in the chart)) does not have a red
border (as it should) -but when you click on the box it takes you to the
correct entry in the SBEAMS table.

fixed: see 4) below

2) modify each kegg pathway map as it gets wbi'd.  by example, change

Glycolysis / Gluconeogenesis - Halobacterium sp.
to
Glycolysis / Gluconeogenesis - Comparative metabolic reconstruction
of  Halobacterium NRC-1 & Haloarcula marismortui

3) add popup window in top right corner which explains the meaning of
the different colored rectangles:
green:  present in nrc-1
red:    matches an ec number supplied in the search box

4) missing hm genes [fixed (13 apr): upped maxRows in SbeamsEcRetriever to 50000]
ec 5.4.2.4
rrnAC2859, gpmB, 5.4.2.4; 5.4.2.1, Phosphoglycerate mutase
ec 3.6.1.7
rnAC1167 acyP 3.6.1.7 Acylphosphatase
both of these are present in hal00010, glycolysis/glucogenesis
both are known to sbeams, and appear in the 'browse the proteome' page
(both fail to find anything when, on the 'browse' page, you click
'View Domain Hits'
*-----------------------------------------------------------------------------------
* (11 apr 2004) todo: for static kegg pathways display, remove sbeams assignment option
done
*-----------------------------------------------------------------------------------
* (11 apr 2004) todo: automate the manual part of 'make kegg'
in /local/tomcat/webapps/cytoscape/projects/dynamic/keggwbi/unitTests
use a ClientForm ExecTest (see ../execTests/ExecTest.py) to
make this target fully automated.  right now, an up-to-date kegg temporary
url must be created manually in a browser
*-----------------------------------------------------------------------------------
* (11 apr 2004)
first draft of cytoscape/isb plugin website:
http://db.systemsbiology.net/cytoscape/plugins/
*-----------------------------------------------------------------------------------
* next: continue working on keggwbi cleanup:

/local/tomcat/webapps/cytoscape/projects/dynamic/keggwbi/main.py
called out of servlet: http://db/cytoscape/helper  (which needs a new name)
*-----------------------------------------------------------------------------------
* (9 apr 2004) fix keggwbi servlet, create semi-static form

/local/tomcat/webapps/cytoscape/projects/dynamic/keggwbi/execTests
File "ExecTest.py", line 96, in testDoKeggSearchFromSbeamsUsingServlet
assert (pathwayCount > 100)          # found 120 pathways on (16 jan 2004)
this failure is due to the inclusion of a number of lines of html, even in
the tsv resultset. the error provided a good occasion to revamp & rethink
the classes involved in this wbi:
SbeamsEcRetriever:  has a method which gets all EC numbers identified
for hm; another method, when given an EC number,
returns all the genes with that assignment
KeggRewriter: this existed before, and will be refurbished
main.py:  the old version was renamed, and the new one is making use
of SbeamsEcRetriever, rather than doing that directly
unitTests:
KeggRewriterTest.py
SbeamsEcRetrieverTest.py


*-----------------------------------------------------------------------------------
* (9 apr 2004) sbeams.noa for hm cytoscape
created /local/tomcat/webapps/cytoscape/projects/static/halo/haloarcula\
/genomePaper2004/sbeams.noa
using /users/pshannon/data/halo/hm/createSbeamsUrls/createLinks.py
beginning with csv result set from sbeams, obtained by query
https://db.systemsbiology.net/sbeams/cgi/ProteinStructure/GetDomainHits
*----------------------------------------------------------------------------------
* (19 mar 2004) lookup: a servlet/python combo to support ensemble window translations
servlet is /local/tomcat/webapps/cytoscape/WEB-INF/classes/lookup.java
calls dispatcher.py in /local/tomcat/webapps/cytoscape/projects/lookup
which branches on mode argument (in url) to construct a specific translator
translator = EchoTranslator ()
translator = UpCaseEchoTranslator ()
translator = HomologyTranslator (args)

and then calls
result = translator.lookup (name)
if (result):
print '%s=%s' % (name, translator.lookup (name))

do a two cytoscape test:
on db, with tspaces jars in classpath (which they are by default for me)
in one shell java:  com.ibm.tspaces.server.TSServer
in another shell:
cd /users/pshannon/cy/csplugins/trial/pshannon/coord
make test0   (one cy is human, the other is mouse; select & broadcast)
*----------------------------------------------------------------------------------
* (7 may 2003) import  kegg xml files; w/ligand-reaction file, create cyto networks
http://www.genome.ad.jp/kegg/xml/map/
save all these xml files to

~/data/import/kegg-kgml/xml   (114 files)
cd ~/data/import/kegg-kgml/py/samples (argh!)
for i in ../../xml/*.xml; do
echo -------------------------------- $i;
python keggToCytoscape.py ../../reaction $i;
done

slip over to db, cd /local/tomcat/webapps/cytoscape/networks/kegg
cp -prv ~pshannon/data/import/kegg-kgml/py/samples/map* .
*--------------------------------------------------------------------------------
* grab tips

command-shift-4: grap window or screen (space bar toggles, saves to desktop)
ctrl-shift-command-4: drag select, save to clipboard  (ctrl --> clipboard)


* end grab tips
*--------------------------------------------------------------------------------
* macos tips
----  screen capture, screenshot tips, screen grab, grab tips
command-shift-4

click & drag mouse cursor, release, find pdf on desktop
use space bar to toggle back & forth between one window & screen
add control key to save to clipboard rather than file

more control: Applications -> Utilities -> Grab

---- mount unix file system
mount_smbfs -W isb -u pshannon -g isb -I isb-1.systemsbiology.net  //pshannon:duva*1998*leo@ISB-1/PSHANNON \
/Volumes/netpshannon


----- use the correct version of gcc
I needed to re-install GNU Prolog on Mac OS X 10.4.1 (Tiger). It appears that it does not compile with gcc 4.0 (the default compiler on Tiger).
This is the current workaround on the DarwinPorts portfile for GNU Prolog: use gcc 3.3 instead of the default gcc 4.0. However, there is
no need to manually replacing/changing soft links. Apple provides a command that allows you to set the default version of the gcc compiler. Just type:

% man gcc_select

to learn how to use it.

---- darwinports, how to call
port search 'graphviz'



* end macos tips
*--------------------------------------------------------------------------------
* jess tips

--- command
alias jess to 'java -Xmx1G -cp ~/jars/jess.jar jess.Main $*'
--- interactively load & execute a clp file
Jess> (batch shoppingCart.clp)   # no quotes needed


* ending jess tips
*--------------------------------------------------------------------------------
* gaggle tips

--- from dan, starting the boss offline, from the command line

javaws -offline http://gaggle.systemsbiology.net/2007-04/boss.jnlp

In order for this to work, you first have to have the boss app in the
cache, so you have to launch the boss while you are online, from the
"Gaggle Boss" link at
http://gaggle.systemsbiology.net/2007-04/blankslate.php

You can also change the URL as follows:

javaws -offline http://gaggle.systemsbiology.net/2007-04/minimizedBoss.jnlp

That will launch the minimized boss (the one that is autostarted by
geese)--users are more likely to already have that one in their local cache.

--- dan on running the boss offline

Java Web Start caches applications on the client side, and apps with the
<offline-allowed/> tag (such as the Boss) can be run from the local
cache without needing a network connection.

So, assuming your user is online at least some of the time, they can
download the boss and then run it when they are offline.

The trick is to be sure and start the boss first, otherwise Gaggle will
try and start it by going online (if setAutoStartBoss is true in
RmiGaggleConnector, which it is by default).

I should probably revisit the way the boss is auto-started, to
accomodate use cases like this. Perhaps I could check the cache first
before trying to launch the boss from the internet.

Anyway....here's how you do the above:

Windows:
Control Panel/Java
On the "General" tab, at the bottom under "Temporary Internet Files":
Click "View"
Look for "Gaggle Boss" in the list of apps, right-click it and choose
"Run Offline".


Mac:
Applications/Utilities/Java/Java Web Start
look for "Gaggle Boss" in the list of downloaded apps.
Right-click (or control-click) on it and choose "Run Offline".

--- proposed 'private commands' twixt R and cygoose  (20 aug 2007)
broadcast (c ('cmd', 'clearSelection'))
broadcast (c ('A', 'C'))
broadcast (c ('cmd', 'invertSelection'))
broadcast (c ('cmd', 'hideSelection'))

# debug control

broadcast (c ('cmd', 'debugOn'))
broadcast (c ('cmd', 'debugOff'))

# might want this next command, so R can tell the cygoose who the
# targetGoose should be for subsequent broadcasts

broadcast (c ('cmd', 'setTargetGoose', 'R'))   # who to send.  note this is the only cmd with a parameter
# other than the command name


# here are some possible  debugging commands:
broadcast (c ('cmd', 'broadcastSelectionAsList'))
broadcast (c ('cmd', 'broadcastSelectionAsNetwork'))
broadcast (c ('cmd', 'broadcastSelectionAsMatrix'))
broadcast (c ('cmd', 'broadcastSelectionAsMap'))



--- broadcast a hash map from R to cytoscape (for example)

makeMap = function (names, values) {
map = new.env ()
for (i in 1:length (names))
assign (names [i], values [i], env=map)
return (map)
}
map = makeMap (orfs, rep ("phosphoprotein", length (orfs)))
broadcast (map, 'nodeType')

---- give a cy goose a custom name
(in, eg, ControlPanel.java ctor):
myName = discoverGooseName (cw.getConfiguration().getArgs ());
[this method needs to be present also; see
org/systemsbiology/gaggle/geese/cy/inferelator/ControlPanel.java]
in jnlp file, add
<argument>--gooseName</argument>
<argument>biclusters</argument>


---- create annotation for gaggle boss search tab plugin
need 3 colums, tab delimited, no title line
canonicalName\tgeneSybmol\tfunction
example for yeast:
~/data/yeast/gaggled-bicluster/annotation
python extract.py > sgd.tsv
scp sgd.tsv db:/net/dblocal/wwwspecial/gaggle/projects/yeast/2005-10/annotation
*--------------------------------------------------------------------------------
* web tips

---- entrez gene urls
http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?db=gene&cmd=Retrieve&dopt=Graphics&list_uids=XXXXX
---- t1db gene urls
http://t1dbase.org/cgi-bin/gene_overview.cgi?gene_id

*--------------------------------------------------------------------------------
* bioconductor tips

(from burak)
source ("http://www.bioconductor.org/getBioC.R")
getBioC ()
library (affy)

load ("ale1ExprSet")
summary (ale1)
slotNames (ale1)
mat <- exprs (ale1)
dim (mat)
phenoData
phenoData (ale1)
pData (ale1)
head (mat)
slots (ale1$phenoData)
slot (ale1$phenoData)
slotNames (ale1$phenoData)
slotNames (ale1@phenoData)
varLabels (ale1@phenoData)
varMetaData (ale1@phenoData)
varMetadata (ale1@phenoData)

* ending bioconductor tips
*--------------------------------------------------------------------------------
* apache tips

------ locations for mac osx 10.4, panther
configuration is in /etc/httpd/httpd.conf
access log: /private/var/log/httpd/access_log
html found in DocumentRoot "/usr/local/htdocs"

------ set server name, so that relative links are absolutized by the server
for mac osx 10.4, panther,
in   /etc/httpd/httpd.conf, enable this line, with proper local value:
ServerName sewardpark.net

------ per-directory password protection
cd to the directory you want to protect
create, for example, .htaccess:

AuthName "Halobacterium"
AuthType Basic
AuthUserFile /net/dblocal/wwwspecial/gaggle/halo/.htpasswd
Require valid-user

now create the password file:

htpasswd -c /net/dblocal/wwwspecial/gaggle/halo/.htpasswd halo  (will prompt for password)

*--------------------------------------------------------------------------------
* mev tricks  (tigr mev, tmev)
trickster, ~/src/mev/ant_build_script, type 'ant'
the main program seems to be org.tigr.microarray.mev.TMEV
this puts 8 jars into ~/src/mev/lib, of which mev-base.jar seems to have the main class

org/tigr/microarray/mev/file/StanfordFileLoader.java has method
public Vector loadStanfordExpressionFile(File f) throws IOException
which the goose needs to emulate.
(StanfordFileLoader extends abstract class ExpressionFileLoader, and implements
public abstract ISlideData loadExpressionFile (File f) throws IOException;
which is called by mev/file/SuperExpressionFileLoader.run () which
data = selectedFileLoader.loadExpressionFiles();
dataType = IData.DATA_TYPE_RATIO_ONLY;
viewer.fireDataLoaded(toISlideDataArray(data), dataType);  (viewer is of type MultipleArrayViewer)
)



it looks like org/tigr/microarray/mev/file/SuperExpressionFileLoader, in method run (),
calls
viewer.fireDataLoaded (toISlideDataArray (data), dataType);
where  data is obtained
data = selectedFileLoader.loadExpressionFiles();
in our case, the loader is the StanfordFileLoader
and data is a Vector converted from an array of ISlideData [experimentCount]
so the GaggledMev can return a vector of length 1, whose single element
is an ISlideData object.
SlideData.java might be the simplest version of this:
~/src/mev/devel/source/org/tigr/microarray/mev/SlideData.java
with a ctor:
public SlideData(int rows, int columns) {


where viewer is a org/tigr/microarray/mev/MultipleArrayViewer.java

the main program has these calls:

Manager manager = new Manager ();
Manager.createNewMultipleArrayViewer();

*--------------------------------------------------------------------------------
* httpunit tips

---- turn off java scripting
HttpUnitOptions.setScriptingEnabled (false);

---- doGet, with simple check of text response:
public void testAlive () throws Exception {
System.out.println ("testAlive");
HttpUnitOptions.setScriptingEnabled (false);
WebConversation wc = new WebConversation ();
WebRequest wreq = new GetMethodWebRequest (url + "?test");
WebResponse wresp = wc.getResponse (wreq);
String response = wresp.getText ();
assertTrue (response.indexOf ("hello from FwbRpcImpl.doGet ()") >= 0);
}

---- basic sequence to get, fill in, and submit a form
wc = WebConversation ()
request =  GetMethodWebRequest ('http://www.ncbi.nlm.nih.gov/BLAST/Blast.cgi')
response = self.wc.getResponse (request);
forms = response.getForms ();  # just 1
form = forms [0]
parameterNames = form.getParameterNames ()
form.setParameter ('QUERY', someAminoAcidSequence)
form.submit ()

--- example program to test a file upload servlet
mink, cd /Users/paulshannon/examples/java/httpunit/uploadForm

import com.meterware.httpunit.*;
import java.io.File;
public class go {
static public void main (String [] args) throws Exception {
WebConversation wc = new WebConversation();
String url = "http://localhost:8080/upload/go";
WebResponse response = wc.getResponse (url);
System.out.println ("text: " + response.getText ());
WebForm [] forms = response.getForms (); // just 1
WebForm form = forms [0];
String [] parameterNames = form.getParameterNames ();
System.out.println ("number of parameter names: " + parameterNames.length);
for (int i=0; i < parameterNames.length; i++)
System.out.println ("   " + parameterNames [i]);
form.setParameter ("fileName", new File ("go.java"));
WebResponse searchResponse = form.submit ();
System.out.println ("search response: " + searchResponse.getText ());
} // main
} // class go





*--------------------------------------------------------------------------------
* date tips, format time tips

format(Sys.time(), "%a.%b.%d.%Y-%H:%M:%S")  # "Fri.Dec.20.2013-13:43:33"

filename = sprintf ('node.position.%s.RData', format (Sys.time(), "%a.%b.%d.%Y-%H:%M:%S"))
for timestamping files:   date +%Y%b%e-%H%M  -> 2007Jan13-0520
default, explicitly:     date +'%a %b %e %H:%M:%S %Z %Y'  ->    Sat Jan 13 05:22:34 PST 2007
mv fwb.tar fwb-`hostname -s`-`date +%Y-%m-%e-%H%M`.tar    ->    fwb-aphelion-2007-01-13-0534.tar

*--------------------------------------------------------------------------------
* java tips

---- get full list of environment variables
Map <String, String> variables = System.getenv();
for (Map.Entry<String, String> entry: variables.entrySet ()) {
String name = entry.getKey ();
String value = entry.getValue ();
System.out.println (name + "=" + value);
}

----- return the current directory, cwd, pwd
import java.io.File;
public class CurrentDir {
public static void main (String args[]) {
File dir1 = new File (".");
File dir2 = new File ("..");
try {
System.out.println ("Current dir : " + dir1.getCanonicalPath());
System.out.println ("Parent  dir : " + dir2.getCanonicalPath());
}
catch(Exception e) {
e.printStackTrace();
}
}
}
----- file pathname delimitors, regex, pattern, windows, \\\\
String [] filenames = new String [] {"C:\\Documents and Settings\\Owner\\Desktop\\targetedBoth.txt",
"/Users/mpshannon/tmp/brca/targetedBoth.txt"};
Pattern backslash = Pattern.compile ("\\\\");
Pattern forwardslash = Pattern.compile ("/");
Pattern delimitor;

for (int i=0; i < filenames.length; i++) {
String f = filenames [i];
System.out.println ("------------------------------- " + f);
delimitor = forwardslash;
if (f.indexOf ("\\") >= 0) {
System.out.println ("backslash");
delimitor = backslash;
}
String [] tokens = f.split (delimitor.pattern ());
for (int j=0; j < tokens.length; j++)
System.out.println ("   token " + j + ": " + tokens [j]);
System.out.println (" >>> result: " + tokens [tokens.length - 1]);
} // for i


----- threaded exec, run child program
aphelion, cd ~/examples/java/execThreaded
Exec.java, with unit test for short- & long-running command

----- rename file, to temporary name
aphelion, cd ~/examples/java/renameFile; make
File file = new File (originalName);
File directory = new File (".");
File file2 = File.createTempFile ("test", null, directory);
boolean success = file.renameTo (file2);



----- JNI signatures
Table 3-2 Java VM Type Signatures
Type Signature
Java Type
Z boolean
B byte
C char
S short
I int
J long
F float
D double
L fully-qualified-class ; fully-qualified-class
[type type[]
(arg-types) ret-type  method type

For example, the Java method:

long f (int n, String s, int[] arr);
has the following type signature:

(ILjava/lang/String;[I)J


----- introspection, class type, isarray, array component type
Class objClass = obj.getClass ();
boolean ia =
if (objClass.isArray ())
Class componentType = objClass.getComponentType();


----- run time consuming tasks in another thread: the manual approach
Runnable timeConsumingRunnable = new Runnable () {
public void run ()  {
// time-consuming code called here
// do all gui operations on the edt (event-dispatch thread)
SwingUtilities.invokeLater (new Runnable () {
public void run () {
// Update UI
}};);
} // timeConsumingRunnable.run
};  // timeConsumingRunnable.ctor
new Thread (timeConsumingRunnable).start(); // now call it

----- run time consuming tasks by subclassing SwingWorker
SwingWorker aWorker = new SwingWorker () {
public Object construct () {
// time-consuming code called here
return null;
}
public void finished () {// called for us on the edt
// update ui here
}
} // aWorker
aWorker.start ();

----- simulate a time-consuming task
(from http://www.javaworld.com/javaworld/jw-06-2003/jw-0606-swingworker.html)
int sleepTime = (new Random().nextInt(4) + 1) * 1000;
Thread.currentThread().sleep (sleepTime)

----- create the gui of a swing app on the event dispatching thread (edt)
SwingUtilities.invokeLater (new Runnable () {public void run () {createGui ();}});

----- look and feel, for all ui elements
try {
UIManager.setLookAndFeel (UIManager.getCrossPlatformLookAndFeelClassName());
//UIManager.setLookAndFeel ("com.sun.java.swing.plaf.motif.MotifLookAndFeel");
//UIManager.setLookAndFeel ("com.sun.java.swing.plaf.windows.WindowsLookAndFeel");
}
catch (Exception ex0) {
ex0.printStackTrace ();
}

----- for JTabbedPane only
import javax.swing.plaf.basic.BasicTabbedPaneUI;
tabbedPanel.setUI (new BasicTabbedPaneUI ());

----- jprogressbar demo
trickster:~/examples/java/progressBar/reformattedByMe

----- jradiobutton, radio buttons
ButtonGroup radioButtonGroup = new ButtonGroup ();
JRadioButton dnaButton = new JRadioButton ("DNA");
JRadioButton aminoAcidButton = new JRadioButton ("aa");
dnaButton.setSelected (true);
radioButtonGroup.add (dnaButton);
radioButtonGroup.add (aminoAcidButton);
controlPanel.add (dnaButton);
controlPanel.add (aminoAcidButton);

dnaButton.addActionListener (new ActionListener () {
public void actionPerformed (ActionEvent e) {
sequenceType = e.getActionCommand ();  // 'DNA'
}});

aminoAcidButton.addActionListener (new ActionListener () {
public void actionPerformed (ActionEvent e) {
sequenceType = e.getActionCommand (); // 'aa'
}});

----- html renderers
Even on windows, we found that smaller HTML files were all that the
JEditorPane would render properly - and it did seem to be a combination
of HTML complexity and file length...
We ended up switching to the JDIC browser on windows, and Dimitry's
webkit on OSX...

JEditorPane only supports 3.2

----- static initialize 2d String array
static String [][] s2d = {{"aaaa", "aaaaa"},
{"bbbb", "BBBBB"}};

----- static initialize HashMap
// put this in the variable declaration part of a class; it
// gets executed once upon loading of the class  (i think)
static HashMap hash = new HashMap();
static {
hash.put ("aaaa", "AAAA");
hash.put ("bbbb", "BBBB");
}


----- mac os java 1.5, release 4
http://lists.apple.com/archives/java-dev/2005/Sep/msg00529.html

----- reflection, class loading, jni, loading native libraries, etc.

That's exactly why I would NOT recommend using reflection.

When a class is loaded, the class-loader may also load classes it refers
to.  Worse, when a class is loaded, all its static initializers are
executed (and recursively for all classes it references, as needed).  This
can have very serious consequences indeed.  As a simple example, many
classes with JNI libs will load those libs in a static initializer.  If
there isn't a native lib for your platform, you're stuck: you can't reflect
on the class because you can't get it fully loaded.

My advice is to not use reflection because of the class-loading side-effects.

Instead, read up on the class-file format, to understand the principles,
then read existing code, like from Harold's "Java Secrets", to understand
how the code is embodying those principles.  Once you have sufficient
understanding, modify the code to do exactly what you want.

Or if you've used exec() before and know how to use it well, it would
probably be simpler to exec 'javap'.  You wouldn't learn nearly as much
about class-files, but you would learn a lot about what it takes to exec()
a process under cross-platform conditions.  Both have value, so maybe you
want to try it both ways.

Or just use Jaree, if you're not doing it for the learning potential.


---- read from jar files
two different approaches, both work (17 aug 2005), tested in
trickster: ~/examples/java/textReaderFactory/JarTextFileReader.java
the filename should have "/" for jar root absolute names
or no leading "/" if an absolute path is desired, relative
to the class whose loader is used

public int newread () throws IOException  {
InputStream is = this.getClass().getClassLoader().getResourceAsStream(filename);
reader = new InputStreamReader (is);
char [] cBuffer = new char [1024];
int bytesRead;
while ((bytesRead = reader.read (cBuffer, 0, 1024)) != -1)
sb.append (new String (cBuffer, 0, bytesRead));
return sb.length ();
} // read

public int read () throws IOException  {
ClassLoader cl = this.getClass().getClassLoader();
URL url = cl.getResource (filename);
JarURLConnection juc = (JarURLConnection) url.openConnection ();
JarFile jarFile = juc.getJarFile();
InputStream is = jarFile.getInputStream (jarFile.getJarEntry (filename));
reader = new InputStreamReader (is);
char [] cBuffer = new char [1024];
int bytesRead;
while ((bytesRead = reader.read (cBuffer, 0, 1024)) != -1)
sb.append (new String (cBuffer, 0, bytesRead));
return sb.length ();
} // read


---- arraycopy
double [] data = ....
for (int r=0; r < rowCount; r++) {
double [] rowValues = new double [columnCount];
int fromPosition = r * columnCount;
int toPosition = 0;
System.arraycopy (data, fromPosition, rowValues, 0, columnCount);
matrix.set (r, rowValues)



---- memory profilers
JProfileer
YourKit
Shark
hprof: I have found you can get it to generate snapshot type statistic updates by
issuing a kill -QUIT ### where ### is the pid, the same deal as for a console stack crawl.

---- tool tip latency, assignment

ToolTipManager.sharedInstance().setInitialDelay (0);
c.setToolTipText ("");    // set the tooltip for some component

---- conditional assignment

names [i] = (value == null) ? "" : value;

---- put a JTextArea component in a scrollpane, with scrollbars always visible
(works for listboxes [JList] as well)
textArea = new JTextArea ();
JScrollPane scrollPane = new JScrollPane (textArea);
scrollPane.setVerticalScrollBarPolicy (JScrollPane.VERTICAL_SCROLLBAR_ALWAYS);
scrollPane.setHorizontalScrollBarPolicy (JScrollPane.HORIZONTAL_SCROLLBAR_ALWAYS);
mainPanel.setBorder (createBorder ());
mainPanel.add (scrollPane, BorderLayout.CENTER);

HORIZONTAL_SCROLLBAR_ALWAYS
HORIZONTAL_SCROLLBAR_AS_NEEDED
HORIZONTAL_SCROLLBAR_NEVER
VERTICAL_SCROLLBAR_ALWAYS
VERTICAL_SCROLLBAR_AS_NEEDED
VERTICAL_SCROLLBAR_NEVER

---- createBorder

import javax.swing.border.*;
private Border createBorder () {
int right  = 10;
int left   = 10;
int top    = 10;
int bottom = 10;
return new EmptyBorder (top, left, bottom, right);

private Border createBorder () {
Border raisedBevelBorder = BorderFactory.createRaisedBevelBorder ();
Border loweredBevelBorder = BorderFactory.createLoweredBevelBorder ();
Border compoundBorder = BorderFactory.createCompoundBorder (raisedBevelBorder, loweredBevelBorder);
return compoundBorder;
}

---- examine class files

javap -public GuiBoss_Stub
Compiled from null
public final class csplugins.isb.pshannon.gaggle.GuiBoss_Stub
extends java.rmi.server.RemoteStub
implements csplugins.isb.pshannon.gaggle.Boss, java.rmi.Remote {
public csplugins.isb.pshannon.gaggle.GuiBoss_Stub();
public csplugins.isb.pshannon.gaggle.GuiBoss_Stub(java.rmi.server.RemoteRef);
public void broadcast(csplugins.isb.pshannon.experiment.datamatrix.LensedDataMatrix); throws ...
public void broadcast(csplugins.isb.pshannon.experiment.datamatrix.LensedDataMatrix[]); throws ..
public void broadcastAttributes(java.lang.String,java.util.HashMap); throws ...
public void broadcastCluster(java.lang.String,java.lang.String[],java.lang.String[]); throws ...
public void cleanUpOnExit(java.lang.String); throws ...
public java.lang.String register(csplugins.isb.pshannon.gaggle.DeafGoose); throws ...
public java.lang.String register(csplugins.isb.pshannon.gaggle.Goose); throws ...
public void select(java.lang.String,java.lang.String[]); throws ...
}

--- hash contains
if (hashMap.containsKey (someKey)) ...
if (hashMap.containsValue (someValue)) ...

--- collection conversions: hash keys and ArrayList to arrays

String [] hashMapKeys = (String []) hashMap.keySet().toArray (new String [0]);
String [] list = (String []) arrayList.toArray (new String [0]);

--- vector to string array

String [] criteria = (String[]) tokenVector.toArray (new String [0]);

--- array equality

String [] result = (String []) list.toArray (new String [0]);
String [] expected = new String [] {"gamma irradiation", "time"};
String [] actual = e.getVariableNames ();

return new int [] {targetMatrixRow, targetMatrixColumn};

import java.util.Arrays;

Arrays.sort (expected);
Arrays.sort (actual);
assertTrue (Arrays.equals (expected, actual));

--- array search:  (the array must be "natural sort order")

assertTrue (experimentNames.length > 0);
Arrays.sort (experimentNames);
assertTrue (Arrays.binarySearch (experimentNames, "sample.xml") >= 0);

simple error message dialog:
JOptionPane.showMessageDialog (cw.getMainFrame (), "Could not connect to gaggle");
simple yes/no message dialog
int dialogResult = JOptionPane.showConfirmDialog (cw.getMainFrame (),
"Gaggle Boss not found.  Proceed ungaggled?",
"title", JOptionPane.YES_NO_OPTION);
if (dialogResult == JOptionPane.YES_OPTION)
System.exit (0);



--- borders:
import javax.swing.border.*;
jpanel.setBorder (BorderFactory.createEmptyBorder (top, left, bottom, right);
Border raisedBevelBorder = BorderFactory.createRaisedBevelBorder ();
Border loweredBevelBorder = BorderFactory.createLoweredBevelBorder ();
textArea = new JTextArea ();
textArea.setBorder (BorderFactory.createCompoundBorder (raisedBevelBorder, loweredBevelBorder));


editable jtable text cell:
good example in ~/work/org/systemsbiology/gaggle/devbed/MovieControllerDialog
this and related files will probably move to csplugins/isb/pshannon/experiment/gui

-- format double with 4 decimal places
DecimalFormat df = new DecimalFormat ();
StringBuffer sb = df.format (currentValue, new StringBuffer (), new FieldPosition (4));

-- change font on a label

JLabel label = new JLabel ("Enable Live Update");
f = label.getFont();
lblFont = new Font (f.getFontName(), f.getStyle(),9);
label.setFont (lblFont);

-- create list from array
ArrayList list = new ArrayList (Arrays.asList (lens.getRowTitles ()));

-- add action to a jbutton
xButton = new JButton ("X");
xButton.setToolTipText ("some description");
xButton.addActionListener (new ActionListener () {
public void actionPerformed (ActionEvent e) {
// call or do something here;
}});

--- radio buttons
ButtonGroup radioButtonGroup = new ButtonGroup ();
JRadioButton dnaButton = new JRadioButton ("DNA");
JRadioButton aaButton = new JRadioButton ("aa");
aaButton.setSelected (true);
radioButtonGroup.add (dnaButton);
radioButtonGroup.add (aaButton);
somePanel.add (dnaButton);
somePanel.add (aaButton);



--- carriage return (enter) in a text field leads to action:
someTextField.addKeyListener (new KeyAdapter () {
public void keyPressed (KeyEvent e) {
if (e.getKeyText (e.getKeyCode()).equals ("Enter")) someAction ();}});

--- timing
long startTime, endTime, duration;
startTime = System.currentTimeMillis ()
endTime = System.currentTimeMillis ();
duration = endTime - startTime;

--- branch on os
String osName = System.getProperties().getProperty("os.name").toLowerCase ();
if (osName.indexOf ("windows") >= 0) ....


--- create a scrollable text area

frame = new JFrame (name);
JPanel outerPanel = new JPanel ();
frame.getContentPane().add (outerPanel);

outerPanel.setBorder (BorderFactory.createEmptyBorder (10, 10, 10, 10));
outerPanel.setLayout (new BorderLayout ());
JToolBar toolbar = createToolBar ();
toolbar.setFloatable (false);
outerPanel.add (toolbar, BorderLayout.NORTH);
textArea = new JTextArea ();
JScrollPane scrollPane = new JScrollPane (textArea);
scrollPane.setPreferredSize (new Dimension (300,300));
scrollPane.setVerticalScrollBarPolicy (JScrollPane.VERTICAL_SCROLLBAR_ALWAYS);
outerPanel.add (scrollPane, BorderLayout.CENTER);
frame.pack ();
frame.setSize (300, 300);
MiscUtil.placeInCenter (frame);
frame.setVisible (true);

--- get a directory listing (in jython)
from java.io import *
f = File ('.')
fileObjects = f.listFiles ()
filenames = f.list ()


------------  on iMac at home, so that rJava picks up java 1.5
cd /System/Library/Frameworks/JavaVM.framework/Versions
lrwxr-xr-x    1 root  wheel    1 May 14 10:19 Current -> A
lrwxr-xr-x    1 root  wheel    5 May 14 10:19 CurrentJDK -> 1.4.2
sudo rm CurrentJDK
sudo ln -s 1.5.0 CurrentJDK


----------- use java 1.5 on mac os x 10.4.1

(from http://wiki.java.net/bin/view/Mac/HowDoISwitchToJava15)

Follow these steps to modify projects for use with J2SE 5.0:

Target Settings: Double click the target to edit and provide
/System/Library/Frameworks/JavaVM.framework/Versions/1.5/Commands/javac as the value
for the JAVA_COMPILER build setting. Change the Target VM Version and

Executable Settings: Double click the executable named java and enter /System/Library/ Frameworks/JavaVM.framework/Versions/1.5/Commands/java as the Executable Path in the General tab of Executable info.
Applet Development: Double click the executable named appletviewer and enter /System/ Library/Frameworks/JavaVM.framework/Versions/1.5/Commands/ appletviewer as the Executable Path in the General tab of Executable info.
For developers using the command line simply define your JAVA_HOME environment var as needed and call the correct java tools (consider modifying your path for that).

Normally JAVA_HOME points at /Library/Java/Home which is a link to the 1.4.2 home directory listed below. You could redirect it as needed to one of the following (on Tiger).
/System/Library/Frameworks/JavaVM.framework/Versions/1.3.1/Home
/System/Library/Frameworks/JavaVM.framework/Versions/1.4.2/Home
/System/Library/Frameworks/JavaVM.framework/Versions/1.5.0/Home

I leave the use of correct java commands to the reader but consider
simply prepending to your path the bin directory from the home
directory (or Commands one level up) of the JVM you want to use.

You could set all this up as a simple shell script, function or alias.

------- change to 1.5 on home iMac (25 jun 2005)
PATH=/System/Library/Frameworks/JavaVM.framework/Versions/1.5.0/Home/bin:$PATH
seems to work fine.


-------- handle os-provided close-window button
mainFrame.setDefaultCloseOperation (WindowConstants.EXIT_ON_CLOSE);
mainFrame.setDefaultCloseOperation (WindowConstants.DISPOSE_ON_CLOSE);

--------- using DefaultListModel with JList
* create model and listbox:
DefaultListModel model = new DefaultListModel ();
for (int i=0; i < listData.length; i++)
model.add (i, listData [i]);
listbox = new JList (model);

* get current contents of list:
DefaultListModel model = (DefaultListModel) listbox.getModel ();
Object [] tmp = model.toArray ();
ArrayList nameList = new ArrayList ();
for (int i=0; i < tmp.length; i++) {
System.out.println (tmp [i] + "   " + tmp [i].getClass());
nameList.add (tmp [i]);
}

return (String []) nameList.toArray (new String [0]);

* respond to selections
class ListboxSelectionListener implements ListSelectionListener {
public void valueChanged (ListSelectionEvent e) {
if (e.getValueIsAdjusting ()) return;
ListSelectionModel lsm = (ListSelectionModel) e.getSource();
currentSelection = new ArrayList ();
if (!lsm.isSelectionEmpty()) {
int minIndex = lsm.getMinSelectionIndex ();
int maxIndex = lsm.getMaxSelectionIndex ();
for (int i = minIndex; i <= maxIndex; i++) {
if (lsm.isSelectedIndex (i))
currentSelection.add (listData [i]);
} // for i
} // if !empty
} // valueChanged
} // inner class ListboxSelectionListener

* end java tips
*--------------------------------------------------------------------------------
* junit tips: trigger text input

   QUnit.test("gbmPathways searchBox", function(assert){
     assert.equal(cyGbm.filter("node:selected").length, 0);
     assert.equal($("#gbmPathwaysSendSelectionMenu").prop("disabled"), true);
     var box = $("#gbmPathwaysSearchBox");
     box.val("pik");  // user lower case to test case insensitivity
     box.trigger(jQuery.Event("keydown", {which: 13}))
     assert.equal(cyGbm.filter("node:selected").length, 9);
     assert.equal($("#gbmPathwaysSendSelectionMenu").prop("disabled"), false);
     testZoomSelected();
     });


*--------------------------------------------------------------------------------
* junit tips

---- minimal program
aphelion, cd ~/examples/java/junit; make

import junit.framework.*;
import junit.textui.TestRunner;
public class go extends TestCase {
public void test0 () throws Exception  {assertTrue (0 == 0);}
public static void main (String [] args)  {TestRunner.run (new TestSuite (go.class));}
}


*--------------------------------------------------------------------------------
* javadoc tips
---  @see  (30 aug 2002)
/**
* create a table in a tab for every attribute; each table has 3 columns:  canonical name,
* common name, attribute. note that canonical and common names are, strictly speaking,
* themselves attributes, but since they appear in every tabbed table, they do not
* get their own tabbed table.  furthermore, cytoscape.props may contain a list of
* other attribute types to ignore.
*
* @see cytoscape.GraphObjAttributes#setType(String,String)
*
*/
----  as a make target (30 aug 2002)
doc:
javadoc \
-source 1.4 \
-d ./htdocs\
-private \
-overview ./overview.html \
-sourcepath .. \
cytoscape.data \
cytoscape   \
cytoscape.data.unitTests \
cytoscape.data.readers \
cytoscape.data.readers.unitTests \
cytoscape.dialogs \
cytoscape.unitTests \
cytoscape.layout \
cytoscape.vizmap \
cytoscape.vizmap.unitTests \
-link http://java.sun.com/j2se/1.4/docs/api \
-windowtitle cytoscape \
-doctitle "cytoscape"

* end javadoc tips
*-------------------------------------------------------------------------------------------------------
* javap -s -p <className>  (but leave off the .class) (4 nov 2004)
prints out signatures:
javap -s -p MutableList
Compiled from "MutableList.java"
public class csplugins.isb.pshannon.experiment.gui.MutableList extends javax.swing.JList{

java.util.Vector originalValues;
Signature: Ljava/util/Vector;

java.util.Vector originalNames;
Signature: Ljava/util/Vector;

java.util.Hashtable nameMap;
Signature: Ljava/util/Hashtable;

java.util.Hashtable indexMap;
Signature: Ljava/util/Hashtable;

csplugins.isb.pshannon.experiment.gui.MutableList();
Signature: ()V

csplugins.isb.pshannon.experiment.gui.MutableList(java.lang.Object[]);
Signature: ([Ljava/lang/Object;)V

public java.util.Vector getOriginalValues();
Signature: ()Ljava/util/Vector;

public void setOriginalValues(java.util.Vector);
Signature: (Ljava/util/Vector;)V

public java.lang.String getOriginalName(java.lang.String);
Signature: (Ljava/lang/String;)Ljava/lang/String;

public void changeList(java.lang.Object[]);
Signature: ([Ljava/lang/Object;)V

public int getIndex(java.lang.String);
Signature: (Ljava/lang/String;)I

public javax.swing.DefaultListModel getContents();
Signature: ()Ljavax/swing/DefaultListModel;
}



Java VM Type Signatures

Signature        Java Programming Language Type
Z       boolean
B       byte
C       char
S       short
I       int
J       long
F       float
D       double
L fully-qualified-class;         fully-qualified-class
[ type  type[]
( arg-types ) ret-type   method type
For example, the Prompt.getLine method has the signature:

(Ljava/lang/String;)Ljava/lang/String;
Prompt.getLine takes one parameter, a Java String object, and the method type is also String.
The Callbacks.main method has the signature:
([Ljava/lang/String;)V

see http://java.sun.com/j2se/1.5.0/docs/guide/jni/spec/types.html 'jni types and data structures'

*--------------------------------------------------------------------------------
* jython tips

-- expanded ~/bin/jython script to grab swipl library; rearranged script for readability:
"/System/Library/Frameworks/JavaVM.framework/Versions/1.5.0/Home/bin/java" \
-Xmx1G \
-Dpython.home="/Users/pshannon/src/jython" \
-Djava.library.path="/opt/local/lib/swipl-5.6.6/lib/powerpc-darwin8.4.0" \
-classpath "/Users/pshannon/src/jython/jython.jar:$CLASSPATH" \
"org.python.util.jython" \
"$@"


-- learning the methods defined on an object
dir  returns a list of methods and attributes in an object
dir (boss) If dir() doesn't reveal an object's methods, add ".__class__" to get a closer look.
dir (boss.__class__)

-- calling methods in your superclass
In Python, if I want to call the foo method in my superclass, I use the form:
SuperClass.foo(self)

This works with the majority of methods, but protected methods cannot
be called from subclasses in this way. Instead you have to use the
"self.super__foo()" call style.

----- importing, dir, __dict__

>>> import org.rosuda.JRclient as r
>>> dir (r)
['RBool', 'REXP', 'RFactor', ...]
>>> print r.__dict__ {'REXP': <jclass org.rosuda.JRclient.REXP at 8128340>,
'__name__': 'org.rosuda.JRclient',
'RBool': <jclass org.rosuda.JRclient.RBool at 12929851>,
..}

when a classpath entry is not previously known, the python.path variable
can help:

jython -Dpython.path=/users/pshannon/jars/dataMatrixExtra
or
jython -Dpython.path=DataMatrixPlugin.jar
import org.rosuda.JRclient as r
dir (r)
['RBool', 'REXP', ...]
this appends the expanded path for DataMatrixPlugin.jar to sys.path
does runtime-editing of sys.path allow an import also?  yes!




-----  to make a jar:
jar:
jythonc --core --jar metaDataEditor.jar MetaDataEditor.py

when a module fails to import, like this:
from org.systemsbiology.gaggle import *
in preparation for a reference like this:
class ControlPanel (JFrame, WindowListener, ActionListener, Goose):
with error message:
ImportError: No module named systemsbiology
this seems to help:
sys.add_package ('org.systemsbiology.gaggle')
import org.systemsbiology.gaggle as gaggle
class ControlPanel (JFrame, WindowListener, ActionListener, gaggle.Goose):


----- to create a java array, suitable for passing to a java method
>>> from jarray import *
>>> zeros (10, 'z')
array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0], boolean)

used with y.algo.GraphConnectivity, from a cytoscape jyconsole plugin
g = cw.getGraph ()   # 'cw' is set by the plugin on the java side
nodes = g.getNodeArray ()
result = zeros (len (nodes), 'z')   # 'z' is code for boolean type
# see www.jython.org/docs/jarray.html
directed = 0
reachable (g, nodes, directed, result)
result ->  [1,1,0,1,0,0,0,1,0,1,1,1,0,1,1,0,1,0,1,0,0,0,0,0,0,0]

---- mimic python's dict.keys ()
keys = [x for x in widgets.keySet()]

* end jython tips
*--------------------------------------------------------------------------------
* cytoscape tips, cy tips

--- zoomed out thresholds
Cytoscape automatically adjusts graphic details as you zoom for performance
reasons, but you can override this by selecting View>Show Graphics Details.

You can also adjust the automatic thresholds in Edit>Preferences>Properties.
Locate the render.* properties.


---  'Java heap space' error
remedy:  java -Xms5m -Xmx15m MyApp

------ node attibute value is a list
nodeName = (value1::value2::value3)
------ assign data server in a webstart project file
dataServer=http://db.systemsbiology.net:8080/cytoscape/annotation/fly/manifest-cg

------ set visual style to be used on startup
in props file:   visualStyle=Prolinks

------ set layout to be used on startup
in props file:  defaultLayoutStrategy=hierarchical

------ ensure that nodes are always fully rendered, despite the zoom
import y.view.*;
View view = cytoscapeWindow.getGraph().getCurrentView();
if (view instanceof Graph2DView) {
Graph2DView g2dv = (Graph2DView) view;
g2dv.setPaintDetailThreshold(0.0);      // You only need to do this once
}

---- jnlp file argument to set cytoscape gooseName

<application-desc>
<argument>--gooseName</argument>
<argument>biclusters 2005/06/01</argument>
</application-desc>

----- build a new jar from the common/cvsdir4 tree
trickster: cd /Users/mpshannon/work/cytoscape
ant jar
cd build
jarsigner -keystore ~/.keystore  -storepass cytokey cytoscape.jar cytoscape
cp -p cytoscape.jar <whereever you need it>

------ standard steps for using the cytoscape 1.1 utility panel:

JPanel utilityPanel = cw.getUtilityPanel ();
utilityPanel.setBorder (BorderFactory.createCompoundBorder (
BorderFactory.createRaisedBevelBorder (),
BorderFactory.createLoweredBevelBorder ()));

utilityPanel.add (new ControlPanel (cw));
cw.getMainFrame().pack ();
org.systemsbiology.gaggle.util.MiscUtil.placeInCenter (cw.getMainFrame ());


*--------------------------------------------------------------------------------
* yfiles tricks, yfiles tips

used with y.algo.GraphConnectivity, from a cytoscape jyconsole plugin
g = cw.getGraph ()   # 'cw' is set by the plugin on the java side
nodes = g.getNodeArray ()
result = zerosimp (len (nodes), 'z')   # 'z' is code for boolean type
# see www.jython.org/docs/jarray.html
directed = 0
reachable (g, nodes, directed, result)
result ->  [1,1,0,1,0,0,0,1,0,1,1,1,0,1,1,0,1,0,1,0,0,0,0,0,0,0]


--- set font size
[see ~/s/work/gaggle/yed/Yed.java]

int newSize;
try {newSize = Integer.parseInt (value);}
catch (NumberFormatException nfe) {
System.err.println ("error parsing string to int for node font size: " + value);
return;
}
System.out.println ("setting new font size on " + node + ": " + newSize);
NodeLabel label = g2d.getRealizer (node).getLabel();
label.setFontSize (newSize);



*------------------------------------------------------------------------------------------------------------------------
* python tips dict, hash, initialize

x = {'ahc_5148': '/proj/famgen/studies/ahc/analysis/ahc_5148/genotype.csv'}
or
x = {}
x ['ahc_5148'] = '/proj/famgen/studies/ahc/analysis/ahc_5148/genotype.csv'

x.keys () # ['ahc_5148']

*------------------------------------------------------------------------------------------------------------------------
* python tips obtain or update module

*------------------------------------------------------------------------------------------------------------------------
* python tips


---- csv module, tsv
cd ~/s/data/isb/vt/gwtDemo/
import csv
sampleFile = 'mouseSmall.tsv'
reader = csv.reader (open (sampleFile), dialect='excel-tab')
header = reader.next ()
print ('----- header: %s' % header)
for row in reader:
print row

---- what names does a module define?
dir (g.class)

--- what variables are defined?
dir ()   # variables, modules and functions
# does not list the names of built-in functions and variables. If you want a list of those,
# they are defined in the standard module __builtin__ :
>>> import __builtin__
>>> dir(__builtin__)

---- flow control
pass: a nop; blank lines are not legal
break: fall through loop
continue: on next iteration through the loop

---- escape single quote in quoted string, suitable for prolog rule

term = term.replace ("'", "\\\'")
changes  'de novo' protein folding
to  \'de novo\' protein folding

python xml tips

----- use regex to find elements, then xml parser to find child nodes:
import sys, re
from xml.dom.minidom import parseString

regex = '(<Hit>.*?<\/Hit>)'
regexCompiled = re.compile (regex, re.DOTALL|re.M)
matches = re.findall (regexCompiled, text)
for match in matches [:1]:
doc = parseString (match)
id = doc.getElementsByTagName ('Hit_id')[0]
print id.childNodes[0].nodeValue


------
os.environ ['HOME']

--- open a file for writing
f = open ('junk.txt', 'w')
f.write ('hello junk\n')
f.close ()

------ sleep
from time import sleep
sleep (2)

------ xml parsing
from xml.dom.minidom import parseString
f = 'pfi1785w.aa.xml'
text = open(f).read()
doc = parseString (text)
hits = doc.getElementsByTagName ('Hit')
print 'hit count: %d' % len (hits)  --> 13

hits[0].attributes.keys ()        # all the attribute names
hits[0].attributes.values ()      # all the attribute values
hits[0].getAttribute ('attName')  # a specific attribute value


-- <element>.getElementsByTagame ('someTagName')
finds all nested elements with that name, regardless of depth

-- explore an unknown (or little understood) xml element hierarchy
from xml.dom.minidom import *
f = '../../fromLukas-2006.10.03/profile_group/profile_group_APML_0.apml'
text = open(f).read()
doc = parseString (text)
[str (x.nodeName) for x in doc.childNodes] -> ['apml']
[str (x.nodeName) for x in doc.childNodes[0].childNodes]
--> ['#text', 'dataProcessing', '#text', 'data', '#text']
[str (x.nodeName) for x in doc.childNodes[0].childNodes[3].childNodes]
--> ['#text', 'PROFILE_GROUP', '#text']
[str (x.nodeName) for x in doc.childNodes[0].childNodes[3].childNodes[1].childNodes]
--> ['MAIN_CLUSTER_PROFILE', 'TARGET_PROFILE', 'SELECTED_CLUSTER_PROFILES', 'PROTEIN_GROUPS',
'PEPTIDE_GROUPS', 'MS1_FEATURE_MEMBERS']   ## '#text' elements removed


-- get immediate children by name
kids = self.root.childNodes
nameElement = None
for kid in kids:
if (kid.nodeName == 'names'):
nameElement = kid

-- ascii from unicode (from http://www.network-theory.co.uk/docs/pytut/tut_17.html)
s = u'Replication factor C1'
str (s) --> 'Replication factor C1'

-- extract text from an element
sampleText: <fullName>in vitro</fullName>

experiment.getElementsByTagName ('fullName')[0].childNodes[0].nodeValue

-- get attribute
sample text:  <secondaryRef db="entrezgene" dbAc="MI:0477" id="55859"/>

xrefs = interactor.getElementsByTagName ('secondaryRef')
geneID = None
for xref in xrefs:
db = xref.getAttribute ('db')
if (db == 'entrezgene'):
geneID = xref.getAttribute ('id')

------ detect control characters:
from curses.ascii import *
for c in s:
if (not isctrl (c)):
print c


------ smtp
see examples/python/smtp/mail.py

------ date and time
from time import *
timeStampSuffix = strftime ('%Y.%m.%d.%H%M')  --> '2006.04.21.0940'

------ call from command line, and return:
python -c "print 'SSSS'.lower()"     ---> 'ssss'

------ delete regexes
import re
s = 'signal transduction (GO:0007165);'
regex = ' \(GO:.*?\);'
regexCompiled = re.compile (regex, re.DOTALL|re.M)
s = re.sub (regexCompiled, '', s)

------ regex special characters
.      (Dot.) In the default mode, this matches any character except a newline. If the DOTALL flag has been specified, this matches any character including a newline.
^     (Caret.) Matches the start of the string, and in MULTILINE mode also matches immediately after each newline.
$      Matches the end of the string or just before the newline at the end of the string, and in MULTILINE mode also matches before a newline. foo
matches both 'foo' and 'foobar', while the regular expression foo$ matches only 'foo'. More interestingly, searching for foo.$ in 'foo1\nfoo2\n'
matches 'foo2' normally, but 'foo1' in MULTILINE mode.
*     Causes the resulting RE to match 0 or more repetitions of the preceding RE, as many repetitions as are possible. ab* will match 'a', 'ab', or 'a' followed by any number of 'b's.
+     Causes the resulting RE to match 1 or more repetitions of the preceding RE. ab+ will match 'a' followed by any non-zero number of 'b's; it will not match just 'a'.
?     Causes the resulting RE to match 0 or 1 repetitions of the preceding RE. ab? will match either 'a' or 'ab'.
*?, +?, ??      The *, +, and ? qualifiers are all greedy; they match as much text as possible. Sometimes this behaviour isn't desired; if the RE <.*> is matched
against '<H1>title</H1>', it will match the entire string, and not just '<H1>'. Adding ? after the qualifier makes it perform the match in non-greedy or
minimal fashion; as few characters as possible will be matched. Using .*? in the previous expression will match only '<H1>'.
{m}     Specifies that exactly m copies of the previous RE should be matched; fewer matches cause the entire RE not to match. For example, a{6} will match exactly six a characters, but not five.
{m,n}   Causes the resulting RE to match from m to n repetitions of the preceding RE, attempting to match as many repetitions as possible. For example, a{3,5} will
match from 3 to 5 a characters. Omitting m specifies a lower bound of zero, and omitting n specifies an infinite upper bound. As an example, a{4,}b will
match aaaab or a thousand a characters followed by a b, but not aaab. The comma may not be omitted or the modifier would be confused with the previously described form.
{m,n}?  Causes the resulting RE to match from m to n repetitions of the preceding RE, attempting to match as few repetitions as possible. This is the non-greedy
version of the previous qualifier. For example, on the 6-character string 'aaaaaa', a{3,5} will match 5 a characters, while a{3,5}? will only match 3 characters.
\    Either escapes special characters (permitting you to match characters like *, ?, and so forth), or signals a special sequence; special sequences are discussed below.

If you're not using a raw string to express the pattern, remember that Python also uses the backslash as an escape sequence in
string literals; if the escape sequence isn't recognized by Python's parser, the backslash and subsequent character are
included in the resulting string. However, if Python would recognize the resulting sequence, the backslash should be repeated
twice. This is complicated and hard to understand, so it's highly recommended that you use raw strings for all but the
simplest expressions.

[]  Used to indicate a set of characters. Characters can be listed individually, or a range of characters can be indicated by
giving two characters and separating them by a -. Special characters are not active inside sets. For example, [akm$] will match
any of the characters a, k, m, or $; [a-z] will match any lowercase letter, and [a-zA-Z0-9] matches any letter or
digit. Character classes such as \w or \S (defined below) are also acceptable inside a range. If you want to include a ] or a -
inside a set, precede it with a backslash, or place it as the first character. The pattern []] will match ']', for example.

You can match the characters not within a range by complementing the set. This is indicated by including a ^ as the first character of the set; ^ elsewhere will simply
match the ^ character. For example, [^5] will match any character except 5, and [^^] will match any character except ^.

| A|B, where A and B can be arbitrary REs, creates a regular expression that will match either A or B. An arbitrary number of
REs can be separated by the | in this way. This can be used inside groups (see below) as well. As the target string is
scanned, REs separated by | are tried from left to right. When one pattern completely matches, that branch is accepted. This
means that once A matches, B will not be tested further, even if it would produce a longer overall match. In other words,
the | operator is never greedy. To match a literal |, use \|, or enclose it inside a character class, as in [|].

(...)  Matches whatever regular expression is inside the parentheses, and indicates the start and end of a group; the contents
of a group can be retrieved after a match has been performed, and can be matched later in the string with the \number special
sequence, described below. To match the literals ( or ), use \( or \), or enclose them inside a character class: [(] [)].

(?...)  This is an extension notation (a ? following a ( is not meaningful otherwise). The first character after the ?
determines what the meaning and further syntax of the construct is. Extensions usually do not create a new group;
(?P<name>...) is the only exception to this rule. Following are the currently supported extensions.

(?iLmsux) (One or more letters from the set i, L, m, s, u, x.) The group matches the empty string; the letters set the
corresponding flags (re.I, re.L, re.M, re.S, re.U, re.X) for the entire regular expression. This is useful if you wish to
include the flags as part of the regular expression, instead of passing a flag argument to the compile() function.

Note that the (?x) flag changes how the expression is parsed. It should be used first in the expression string, or after one
or more whitespace characters. If there are non-whitespace characters before the flag, the results are undefined.

(?:...)  A non-grouping version of regular parentheses. Matches whatever regular expression is inside the parentheses, but the
substring matched by the group cannot be retrieved after performing a match or referenced later in the pattern.

(?P<name>...)  Similar to regular parentheses, but the substring matched by the group is accessible via the symbolic group name
name. Group names must be valid Python identifiers, and each group name must be defined only once within a regular
expression. A symbolic group is also a numbered group, just as if the group were not named. So the group named 'id' in the
example above can also be referenced as the numbered group 1.

For example, if the pattern is (?P<id>[a-zA-Z_]\w*), the group can be referenced by its name in arguments to methods of match
objects, such as m.group('id') or m.end('id'), and also by name in pattern text (for example, (?P=id)) and replacement text
(such as \g<id>).

(?P=name)  Matches whatever text was matched by the earlier group named name.

(?#...)   A comment; the contents of the parentheses are simply ignored.
(?=...)   Matches if ... matches next, but doesn't consume any of the string. This
(?!...)   Matches if ... doesn't match next. This is a negative lookahead assertion. For example, Isaac (?!Asimov) will match 'Isaac ' only if it's not followed by 'Asimov'.

(?<=...)  Matches if the current position in the string is preceded by a match for ... that ends at the current position. This
is called a positive lookbehind assertion. (?<=abc)def will find a match in "abcdef", since the lookbehind will back up 3
characters and check if the contained pattern matches. The contained pattern must only match strings of some fixed length,
meaning that abc or a|b are allowed, but a* and a{3,4} are not. Note that patterns which start with positive lookbehind
assertions will never match at the beginning of the string being searched; you will most likely want to use the search()
function rather than the match() function:

>>> import re
>>> m = re.search('(?<=abc)def', 'abcdef')
>>> m.group(0)  #       'def'

This example looks for a word following a hyphen:

>>> m = re.search('(?<=-)\w+', 'spam-egg')
>>> m.group(0)  #  'egg'

(?<!...)  Matches if the current position in the string is not preceded by a match for .... This is called a negative
lookbehind assertion. Similar to positive lookbehind assertions, the contained pattern must only match strings of some fixed
length. Patterns which start with negative lookbehind assertions may match at the beginning of the string being searched.

(?(id/name)yes-pattern|no-pattern) Will try to match with yes-pattern if the group with given id or name exists, and with
no-pattern if it doesn't. |no-pattern is optional and can be omitted. For example, (<)?(\w+@\w+(?:\.\w+)+)(?(1)>) is a poor
email matching pattern, which will match with '<user@host.com>' as well as 'user@host.com', but not with '<user@host.com'. New
in version 2.4.

The special sequences consist of "\" and a character from the list below. If the ordinary character is not on the list, then
the resulting RE will match the second character. For example, \$ matches the character "$".

\number Matches the contents of the group of the same number. Groups are numbered starting from 1. For example, (.+) \1
matches 'the the' or '55 55', but not 'the end' (note the space after the group). This special sequence can only be used to
match one of the first 99 groups. If the first digit of number is 0, or number is 3 octal digits long, it will not be
interpreted as a group match, but as the character with octal value number. Inside the "[" and "]" of a character class, all
numeric escapes are treated as characters.

\A   Matches only at the start of the string.

\b Matches the empty string, but only at the beginning or end of a word. A word is defined as a sequence of alphanumeric or
underscore characters, so the end of a word is indicated by whitespace or a non-alphanumeric, non-underscore character. Note
that \b is defined as the boundary between \w and \ W, so the precise set of characters deemed to be alphanumeric depends on
the values of the UNICODE and LOCALE flags. Inside a character range, \b represents the backspace character, for compatibility
with Python's string literals.

\B Matches the empty string, but only when it is not at the beginning or end of a word. This is just the opposite of \ b, so
is also subject to the settings of LOCALE and UNICODE.

\d When the UNICODE flag is not specified, matches any decimal digit; this is equivalent to the set [0-9]. With UNICODE, it
will match whatever is classified as a digit in the Unicode character properties database.

\D When the UNICODE flag is not specified, matches any non-digit character; this is equivalent to the set [^0-9]. With
UNICODE, it will match anything other than character marked as digits in the Unicode character properties database.

\s When the LOCALE and UNICODE flags are not specified, matches any whitespace character; this is equivalent to the set
[\t\n\r\f\v]. With LOCALE, it will match this set plus whatever characters are defined as space for the current locale. If
UNICODE is set, this will match the characters [ \t\n\r\f\v] plus whatever is classified as space in the Unicode character
properties database.

\S When the LOCALE and UNICODE flags are not specified, matches any non-whitespace character; this is equivalent to the set
[^\t\n\r\f\v] With LOCALE, it will match any character not in this set, and not defined as space in the current locale. If
UNICODE is set, this will match anything other than [ \t\n\r\f\v] and characters marked as space in the Unicode character
properties database.

\w When the LOCALE and UNICODE flags are not specified, matches any alphanumeric character and the underscore; this is
equivalent to the set [a-zA-Z0-9_]. With LOCALE, it will match the set [0-9_] plus whatever characters are defined as
alphanumeric for the current locale. If UNICODE is set, this will match the characters [0-9_] plus whatever is classified as
alphanumeric in the Unicode character properties database.

\W When the LOCALE and UNICODE flags are not specified, matches any non-alphanumeric character; this is equivalent to the set
[^a-zA-Z0-9_]. With LOCALE, it will match any character not in the set [0-9_], and not defined as alphanumeric for the current
locale. If UNICODE is set, this will match anything other than [0-9_] and characters marked as alphanumeric in the Unicode
character properties database.

\Z   Matches only at the end of the string.

Most of the standard escapes supported by Python string literals are also accepted by the regular expression parser:
\a      \b      \f      \n     \r      \t      \v      \x    \\
Octal escapes are included in a limited form: If the first digit is a 0, or if there are three octal digits, it is considered an
octal escape. Otherwise, it is a group reference. As for string literals, octal escapes are always at most three digits in length.



------ find patterns regexes
import re
s = 'Factor "HLHm5"; Target "ac"; PMID "8078474"; FPID "003024"
regex = 'Factor \"(.*?)\"'
regexCompiled = re.compile (regex, re.DOTALL|re.M)
matches = re.findall (regexCompiled, s)
for match in matches:
print match

------ read xml elements (useful when big file (>50M) parsing is way too slow)
aphelion, cd /Users/mpshannon/data/sbri/davidSimpson/biomarkers/protXml/cy046

regex = '(<protein_group .*?<\/protein_group>)'
regexCompiled = re.compile (regex, re.DOTALL|re.M)
matches = re.findall (regexCompiled, text)
print 'match count: %d' % len (matches)
for match in matches:
print 'size: %d' % len (match)

------ indexed for loop
for i in range (5):
print i


------ delete the last empty string in a list of strings:

if (result [len (result) - 1].strip() == ''):
del result [len (result) - 1]

--- find and delete an element
x = ['a', 'b', 'c']
x.index ('a')     # 0
del x [0]         #  x ['b', 'c']

--- find substring
'aaasdasdfa'.find ('a')   ---> 0
'aaasdasdfa'.find ('leo') --> -1

--- random numbers
from random import *
int (random () * 100)  --> 88

------ python regex to parse across multiple lines, from kegg reaction file
import re

text = \
"""ENTRY       R00146                      Reaction
DEFINITION  alpha-Amino acid + H2O + NADP+ <=> 2-Oxo acid + NH3 + NADPH + H+
EQUATION    C05167 + C00001 + C00006 <=> C00161 + C00014 + C00005 + C00080
RPAIR       RP: A00068  C00161_C05167 main
PATHWAY     PATH: rn00910  Nitrogen metabolism
ENZYME      1.4.1.1         1.4.1.2         1.4.1.3         1.4.1.4
1.4.1.5         1.4.1.7         1.4.1.8         1.4.1.9
1.4.1.10        1.4.1.12        1.4.1.15        1.4.1.19
1.4.1.20
COMMENT     general reaction, NADH(see R00145)
"""

regex = "^(\w+) (.*?)(?=^\w)"  # last () contains non-consuming match against next line
# which starts with a character

regexCompiled = re.compile (regex, re.DOTALL|re.MULTILINE);
matches = re.findall (regexCompiled, text)
print 'match count: %d' % len (matches)

m = 0
for match in matches:
print '%d) (%d) >%s<' % (m, len (match), match)
m += 1

------- non-consuming match: another example
# find all term elements, in this case, 4-6 lines like this:
#   term: 'de novo' IMP biosynthetic process
#   goid: GO:0006189
#   definition: The chemical reactions and pathways resulting in the formation of IMP, inosine
#               monophosphate, beginning with the synthesis of a purine ring from simpler precursors.
#   definition_reference: GOC:mah
#   definition_reference: ISBN:0716720094

regex = "term: (.*?)(?=^term:|$)"    # '$' matches end of text, captures last regex in the text

-------  list comprehensions

xmlFiles = [f for f in candidates if f.count ('.xml') > 0]

where candidates might be
['ExperimentXmlParserTest.pyc', 'ExperimentXmlParserTest.py',
'gamma.xml', 'metal.xml']

and xmlFiles becomes

['gamma.xml', 'metal.xml']

and with a function call:

[x.capitalize () for x in dirs if x.count ('.xml') > 0]
['Gamma.xml', 'Metal.xml']

# retrived is an array of objects, each of which has a 'getAlias' method

print 'aliases: %s' % [a.getAlias () for a in retrieved]


a simpler list construction, useful for converting arrays returned
to jython from java:

NaN = Double.NaN
expected = [-1.2, -8.0, -32.3333, NaN, NaN, NaN]
actual = [e for e in result.get ('b')]
assert (actual == expected)

assert that all filenames in a list have a specified substring:

assert ([filename.count ('.xml') for filename in xmlFileNames].count (0) == 0)

x = [10, 11, 12]
print ['%s' % e for e in x]   -->  ['10', '11', '12']

--------- run on the command line

python -c "print len (open ('matrix.lambdas').read().split ('\n')[0].split('\t'))"

--------- execute commands
import os
simple, with results to stdout, returns status code
os.system ('/bin/ls -l static.html')
more useful (and complicated)
cmd = '/usr/bin/cvs status *.java *.py makefile | grep ^F'
(stdin, stdout, stderr) = os.popen3 (cmd)
out = stdout.read ()
err = stderr.read ()

--------- directory listing, current directory, change directory, cd, mkdir, copy
import shutil
import os
import os.path
jarFiles = [x for x in os.listdir ('.') if x.find ('.jar') > 0]
os.getcwd () --> '/Users/mpshannon/examples/python'
os.path.isdir ('aaa')  ....
os.chdir ('aaa')
os.rmdir ('junkkkkkk')
suffix = strftime ('%Y-%m-%d')
directoryName = '/users/pshannon/work/r/gaggleTest-package-%s' % suffix
if (not os.path.exists (directoryName)):
os.mkdir (directoryName)
shutil.copyfile ('a', 'b')
--------- not-so-dangerous directory delete, one level deep
dirName = 'test'
files = os.listdir (dirName)
for file in files:
os.remove ('%s/%s' % (dirName, file)
os.rmdir (dirName)

--------- dangerous recursive delete
for root, dirs, files in os.walk(top, topdown=False):
for name in files:
os.remove (os.path.join(root, name))
for name in dirs:
os.rmdir (os.path.join(root, name))

--------- subclass from a java class
from org.rosuda.JGR import *
from csplugins.isb.pshannon.gaggle import *

class GJGR (JGR, Goose):         # GJGR extends JGR, implements Goose

def __init__ (self):
JGR.__init__ (self)          # call the super class constructore

def hide (self):
JFrame.setVisible (self, 0) # call a super class method (JGR is a grandchild of JFrame)

-------- parse xml: read a (may 2005) metdata xml file, find out many variables in each condition
from xml.dom.minidom import parseString
import os
f = '/users/pshannon/halo/data/oxygenTimeSeries.xml'
os.system ('/bin/ls -l %s' % f)     # make sure the file is truly there
text = open(f).read()
doc = parseString (text)
conditions = doc.getElementsByTagName ('condition')
for cond in conditions:
variables = cond.getElementsByTagName ('variable')
print '%s has %d variables' % (cond, len (variables))

----- parse xml: read an interact file, get the search_hits, and their attributes
searchHits = doc.getElementsByTagName ('search_hit')
print 'hits: %d' % len (searchHits)
for hit in searchHits [:5]:
print hit.attributes.keys ()
print hit.attributes.values ()
print hit.getAttribute ('protein')
keys = hit.attributes.keys ()
for key in keys:
attribute = hit.attributes [key]
print '%s: %s' % (attribute.name, attribute.value)


-------- array slicing, from end, used to write tabs at all but last token
columns = [0, 18, 19, 20, 21, 22, 23, 24, 25]
for c in columns:
sys.stdout.write ('%s' % tokens [c])
if (c in columns [:-1]):
sys.stdout.write ('\t')
sys.stdout.write ('\n')

------- exception
try:
if (m == 1):
sys.stderr.write ('M pd gene')
except Exception, inst:
print type (inst)             # <type 'instance'>
print inst                    # undefined entity: line 14, column 7
print inst.args               # ('undefined entity: line 14, column 7',)


------ modify module search path
see http://www.python.org/doc/2.4.2/inst/search-path.html
options:
1) change site.py
2) define personal PYTHONPATH (this is from trickster:~/.profile)

export PYTHONPATH="/Users/mpshannon/src/py/fpconst-0.7.2"
PYTHONPATH=$PYTHONPATH:"/Users/mpshannon/src/py/PyXML-0.8.4"
PYTHONPATH=$PYTHONPATH:"/Users/mpshannon/src/py/SOAPpy-0.12.0"


----- for loop, using index, not 'seq' but 'range':
x = [8, 9, 10]
for i in range (len (x)):
print x [i]

--- concatenate lists
x = [8, 9, 10]
y = [3, 4, 5]
x + y        --> [8, 9, 10, 3, 4, 5]
x += y      (x:  [8, 9, 10, 3, 4, 5]
x.append (y) --> [8, 9, 10, [3, 4, 5]]


--- substring
'asdfsdfasdfasdf'[1:4] --> 'sdf'

* end python tips
*--------------------------------------------------------------------------------
* jar tricks
--- to sign a jar:

jarsigner -keystore /users/pshannon/.keystore  \
-storepass cytokey TreeDataBrowserPlugin.jar cytoscape

--- to specify a main class (needed for java webstart)
create a file (eg, 'jar.manifest') with these contents:

Main-Class: cytoscape.cytoscape

put this manifest into the jar:

jar cmf jar.manifest <your.jar>

--- is a jar signed?
jarsigner -verify -verbose -certs xxx.jar

* jarsigner tips

-----  the signer certificate has expired (8 nov 2005)
mv .jarkey .jarkey-2005-08-08
keytool -genkey -alias gaggle -keystore .jarkey -validity 36500     (100 years)

-----  new java 1.5 key file (8 aug 2005) on trickster
created 1277 Aug  8 15:21 /Users/mpshannon/.jarkey
use it with ~/bin/sign15:
jarsigner -keystore /users/mpshannon/.jarkey -storepass honker $1 gaggle
created thus:
keytool -genkey -alias gaggle -keystore .jarkey
Enter keystore password:  honker
What is your first and last name?  Paul Shannon
What is the name of your organizational unit?   Halo Research Group
What is the name of your organization?  ISB
What is the name of your City or Locality?  Seattle
What is the name of your State or Province?  Washington
What is the two-letter country code for this unit?  US
RETURN if same as keystore password:  [honker]



original, and longstanding keystore (2002-2005)
in home directory, create key:

keytool -genkey -alias cytoscape
Enter keystore password:  cytokey
What is your first and last name?   Paul Shannon
What is the name of your organizational unit?  Computational Biology
What is the name of your organization?  Institute for Systems Biology
What is the name of your City or Locality?  Seattle
What is the name of your State or Province?  WA
What is the two-letter country code for this unit?  US
Is CN=Paul Shannon, OU=Computational Biology, O=Institute for Systems Biology, L=Seattle, ST=WA, C=US correct?  yes

sign any jar:

jarsigner -keystore /users/pshannon/.keystore  -storepass cytokey cytoscape.jar cytoscape


new keystore and key (mar 2005)
hazel.gaggle> keytool -genkey -alias gaggle -keystore .jarkey
Enter keystore password:  fiddle
What is your first and last name?  Paul Shannon
What is the name of your organizational unit? Halo Research Group
What is the name of your organization?  ISB
What is the name of your City or Locality? Seattle
What is the name of your State or Province?  Washington
What is the two-letter country code for this unit?   US
Enter key password for <gaggle>  fiddle

hazel.gaggle> dir .jarkey
-rw-r--r--  1 pshannon isb 1277 Mar 24 12:38 .jarkey

use it:

jarsigner -keystore .jarkey -storepass fiddle boss.jar gaggle


-------- check signatures on a jar.  see /users/pshannon/bin/jarcheck
which has these contents:
jarsigner -verify -verbose -certs $1 | grep "X.509" | sort | uniq


*--------------------------------------------------------------------------------
Trickster.jars> cat jar.manifest
Main-Class: cytoscape.cytoscape
*--------------------------------------------------------------------------------
* find tips

-type t

d: directory

-regex pattern
To match a file named ``./foo/xyzzy'', you can use the regular expression
``.*/[xyz]*'' or ``.*/foo/.*'', but not ``xyzzy'' or ``/foo/''.


--- by age
find -newer <some file>


* end find tips
*--------------------------------------------------------------------------------
* cut tips

bobama, from this:
chr1,11456,C,nnbbbbnn,N,,N,,G,0.000015,G,0.000015,G,0.000015,G,0.000015,N,,N,
chr1,11507,A,nnnnbbab,N,,N,,N,,N,,G,0.003906,G,0.003906,A,0.095997,G,0.095997
chr1,11541,A,nnbbbbaa,N,,N,,T,0.003906,T,0.003906,T,0.000015,T,0.000015,A,,A,
chr1,12197,G,nnbbnnnn,N,,N,,C,0.000015,C,0.000015,N,,N,,N,,N,
chr1,14906,A,nnaaabnn,N,,N,,A,,A,,A,0.004520,G,0.004520,N,,N,

to this:
head -20 /proj/famgen/studies/lung_cancer/analysis/genotype.csv | tail -5 | cut --delimiter="," -f -4
chr1,11456,C,nnbbbbnn
chr1,11507,A,nnnnbbab
chr1,11541,A,nnbbbbaa
chr1,12197,G,nnbbnnnn
chr1,14906,A,nnaaabnn

*--------------------------------------------------------------------------------
* bash tips

---- redirection
# Redirect standard out and standard error separately
cmd >stdout-redirect 2>stderr-redirect

# Redirect standard error and out together
cmd >stdout-redirect 2>&1


# Merge standard error with standard out and pipe
cmd 2>&1 |cmd2

---- loops
while [ 1 ]; do date; sleep 1; done

for loop
for i in *.jar; do echo $i; done

another for loop:
for j in *.jar; do echo ------------ $j;  /users/pshannon/bin/jarcheck $j; done


---- traverse command line arguments
# see   /Users/mpshannon/examples/bash/iterateOverCommandLineArguments

echo "number of args: " $#
echo "args: " $*
index=1
for arg in $*
do
echo "arg #$index = $arg"
let "index+=1"
done


*--------------------------------------------------------------------------------
* emacs tips

--- show-paren-mode
--- tabs in fundamental mode
problem:  sometimes extra tabs are added to try to align with preceeding line structure
sometimes spaces are added
this seems to help:  (global-set-key "\C-i" 'self-insert-command)

--- printing
print-region
see http://comments.gmane.org/gmane.emacs.macintosh.osx/1359
ps-spool-region-with-faces    # creates buffer *PostScript*

---- line wrap toggle
esc-x toggle-truncate-lines

---- rectangle
copy to register      ^xrr [prompt for single character register name]
insert from register  ^xri [prompt for single character register name]

--- named macros, emacs:

~/emacs/macros

contents as of (25 may 2011)
(fset 'rtips
"\C-s r tips\C-a\C-@\C-s\C-s\C-s\C-n\C-a\C-x\C-x\C-xnn")
(fset 'rlr
"q ('no')\C-m\C-[xR\C-m\C-msource ('test.R')\C-mrun.tests ()\C-m")


---- name & save a kbd macro, keyboard macro
esc-x name-last-kbd-macro
open file ~/emacs/macros
esc-x insert-kbd-macro <CR> name <CR>
save file

to run named macro:  just like a command:  esc-x <macro name>

---- fix the backspace key
(global-set-key "" 'delete-backward-char)

---- ! runs the command dired-do-shell-command
(dired-do-shell-command COMMAND &optional ARG FILE-LIST)
example: scp file to home computer, from trickster
mark files in dired mode (or work on file on current line)
! (prompts '! on <file>' scp ? $RPK/in

Run a shell command COMMAND on the marked files.
If no files are marked or a specific numeric prefix arg is given,
the next ARG files are used.  Just M-x universal-argument means the current file.
The prompt mentions the file(s) or the marker, as appropriate.

If there is output, it goes to a separate buffer.

Normally the command is run on each file individually.
However, if there is a `*' in the command then it is run
just once with the entire file list substituted there.

If there is no `*', but a `?' in the command then it is still run
on each file individually but with the filename substituted there
instead of at the end of the command.

No automatic redisplay of dired buffers is attempted, as there's no
telling what files the command may have changed.  Type
l to redisplay the marked files.

The shell command has the top level directory as working directory, so
output files usually are created there instead of in a subdir.


---- where are packages loaded from?
The following command adds your ~/emacs directory to the existing load path:
(setq load-path (cons "~/emacs" load-path))

esc-x describe-variable [load-path]

("/users/mpshannon/elisp/ess-5.2.8/lisp/"
"/users/mpshannon/elisp/"
"/usr/share/emacs/21.2/site-lisp"
"/usr/share/emacs/site-lisp"
"/usr/share/emacs/21.2/leim"
"/usr/share/emacs/21.2/lisp"
"/usr/share/emacs/21.2/lisp/toolbar"
"/usr/share/emacs/21.2/lisp/textmodes"
"/usr/share/emacs/21.2/lisp/progmodes"
"/usr/share/emacs/21.2/lisp/play"
"/usr/share/emacs/21.2/lisp/obsolete"
"/usr/share/emacs/21.2/lisp/net"
"/usr/share/emacs/21.2/lisp/mail"
"/usr/share/emacs/21.2/lisp/language"
"/usr/share/emacs/21.2/lisp/international"
"/usr/share/emacs/21.2/lisp/gnus"
"/usr/share/emacs/21.2/lisp/eshell"
"/usr/share/emacs/21.2/lisp/emulation"
"/usr/share/emacs/21.2/lisp/emacs-lisp"
"/usr/share/emacs/21.2/lisp/calendar")





---- edit last keyboard macro
^x^k

---- aquamacs, for osx
http://home.att.ne.jp/alpha/z123/emacs-mac-e.html
apparently not this one: http://www.apple.com/downloads/macosx/productivity_tools/aquamacsemacs.htmls

---- in shell buffer, restore directory sanity
esc-x dirs

---- dired-do-chmod:  'M'

if emacs shell has lost sense of the current directory, restore that sense with esc-x dirs

narrow
narrow-to-defun
narrow-to-page
narrow-to-region: ^x-n-n
py-narrow-to-defun
widen: ^x-n-w

recursive dired
esc-0 ^x-d   (shows current switches for ls, allows for new ones: enter '-lR')

list processes in a buffer
meta-x list-processes

---- dired-do-shell-command, include filename in command
! jar tvf * | grep MetaData.class     # the '*' is a place holder for the selected file

---- see dos ^M eol characters
manipulate variable 'inhibit-eol-conversion'
M-X set-variable<RET> inhibit-eol-conversion<RET> t<RET>
To make it permanent put (setq-default inhibit-eol-conversion t) in your .emacs file.

--- control font colors
in ~/.emacs:  (global-font-lock-mode -1)


--- outline-mode

distinguishes between different header levels and the plain text. The default mechanism uses asterisks to determine header levels.
[from     http://www.emacswiki.org/cgi-bin/wiki?OutlineMode]

* Very important
** Less important
*** A detail
And the rest is text
between the headers.

You can then use Headings, Show, and Hide menus to selectively show parts of the text, or the following keys:

* C-c C-a show all
* C-c C-t show only the headings
* C-c C-s show subtree at cursor location
* C-c C-d hide subtree at cursor location

outline-regexp is a variable defined in `outline.el', Its value is "[*\f]+"
Any line whose beginning matches this regexp is considered to start a heading.
Note that Outline mode only checks this regexp at the start of a line,
so the regexp need not (and usually does not) start with `^'.
The recommended way to set this is with a Local Variables: list


* emacs tips
*--------------------------------------------------------------------------------
* tspace tips

multi-tuple unpacking (4 oct 2004)

// get all the tuples which match (Client.class, name(any String))
// put the names into a list as the value of the hash key "client"

Tuple clientTemplate = new Tuple (new Field (TSpaceGaggleBusClient.class), new Field (String.class));
Tuple clientsTuple = currentAppsTSpace.scan (clientTemplate);
ArrayList clientNames = new ArrayList ();
for (int i=0; i < clientsTuple.numberOfFields (); i++) {
Tuple t = (Tuple) clientsTuple.getField (i).getValue ();
String clientName = (String) t.getField (1).getValue ();
clientNames.add (clientName);
}
result.put ("client",  (String []) clientNames.toArray (new String [0]));
*--------------------------------------------------------------------------------
* ps tricks
on trickster:
ps -xwU pshannon
x: include processed w/o a terminal
w: wide
ww: really wide
U pshannon: processes belonging to me
*--------------------------------------------------------------------------------
* find tricks
all files modified more than 2 years ago:
find -mtime +730
all files modified exactly 2 years ago:
find -mtime 730
all files modified less than 1 day ago
find -mtime 1
all files modified less than 30 minutes ago
find -mmin -30

limit depth of search to only the explicitly named directory:
-maxdepth 1

all directories except those names CVS
find . -type d \! -name CVS

*--------------------------------------------------------------------------------
* dmv tips

---- how are common names found?

org.systemsbiology.gaggle.experiment.gui.MatrixSpreadSheet provides a button
which changes row names to gene symbol names (common names).  where is this
info obtained?

1) MatrixSpreadSheet calls matrix.getSpecies (), and passes that name to
org/systemsbiology/gaggle/util/NameHelperFactory, which constructs and
returns a NameHelper object:

if (canonicalSpeciesName.equals ("Halobacterium sp."))
serverUri = "http://db.systemsbiology.net/cytoscape/annotation/halo/manifest";
else if (canonicalSpeciesName.equals ("Helicobacter pylori"))
serverUri = "http://db.systemsbiology.net/cytoscape/annotation/hpy/manifest";
else if (canonicalSpeciesName.equals ("Homo sapiens"))
serverUri = "http://db.systemsbiology.net/cytoscape/annotation/human/manifest";
else if (canonicalSpeciesName.equals ("Mus musculus"))
serverUri = "http://db.systemsbiology.net/cytoscape/annotation/mouse/manifest";
else if (canonicalSpeciesName.equals ("Drosophila melanogaster"))
serverUri = "http://db.systemsbiology.net/cytoscape/annotation/fly/manifest-cg";
else if (canonicalSpeciesName.equals ("Saccharomyces cerevisiae"))
serverUri = "http://db.systemsbiology.net/cytoscape/annotation/yeast/manifest";
else
recognizedSpecies = false;


if (recognizedSpecies) {
try {
bioDataServer = new BioDataServer (serverUri);
}
catch (Exception e) {
System.err.println ("Exception creating biodataserver for species '" + species + "'");
e.printStackTrace();
}
}

return new NameHelper (canonicalSpeciesName, bioDataServer);
the species mapping, and canonical<-->common mappings for each organism, are tested in
org/systemsbiology/gaggle/util/unitTests/NameHelperTest.java

---- metadata xml sample

<?xml version="1.0"?>

<experiment name="Myc Timecourse" date="2003-05-01" >
<predicate category="species" value="Drosophila melanogaster"/>
<predicate category="perturbation" value="Myc"/>
<link type="journalArticle" url="http://www.genesdev.org/cgi/content/abstract/17/9/1101" />
<dataset status="primary" type="ratios">
<uri> myc.ratios </uri>
</dataset>
<dataset status="derived" type="pvals">
<uri> myc.pvals </uri>
</dataset>
<condition alias = "myc07">
<variable name="time" value="07" units="hours"/>
</condition>
</experiment>


---- validate with
msv  /users/mpshannon/data/halo/microarrayXml/experiment.xsd xxx.xml

*--------------------------------------------------------------------------------
* javaws tips, java webstart tips,  jws tips

----- start other jws apps from an initial jws app
from the unofficial jws/jnlp faq (http://www.vamphq.com/download/jwsfaq.pdf)
An alternative is starting Web Start yourself using Runtime.exec. You can find out where Web Start
hides away on your user's disk using the javax.home property.


---- jnlp file argument to set cytoscape gooseName

<application-desc>
<argument>--gooseName</argument>
<argument>biclusters 2005/06/01</argument>
</application-desc>


--- get jws app name visible in mac doc (also, in option-tab finder?)
> The title of our JWS app doesn't show up in the dock although it
> does show in the title bar as the application menu title. The dock
> icon just says "java". Is there something special we need to do?

You have just to pass your title in the java arguments with the
special option "-Xdoxk:name" like that :

java -Xdock:name='your name'  <other options> <your.MainClass>

---- windows webstart cache:
c:\Documents and Settings\<user>\Application Data\Sun\Java\Deployment\cache

---- mulitply signed jars in the same jnlp
http://java.sun.com/j2se/1.5.0/docs/guide/javaws/developersguide/faq.html#213
----   cache on mac osx
/Users/mpshannon/Library/Caches/Java Web Start/cache/http

----  <nativelib> element in a jnlp file:
sample application described at http://java.sun.com/developer/releases/javawebstart/

---- debug from command line
To see what your Web Start copy uses under the hood turn on the
environment variable JAVAWS_TRACE_NATIVE=1 and fire off Web Start on
the command line e.g.
javaws.exehttp://java.sun.com/products/javawebstart/apps/notepad.jnlp
Web Start will popup a message box that shows you the full command line that you
can use to kick off your app for debugging.
on trickster:
/Applications/Utilities/Java/Java\ Web\ Start.app/Contents/MacOS/Java\ Web\ Start \
http://db/cytoscape/gaggle/jaguar/jaguar.jnlp

Java Web Start 1.4.2 Launching:
/System/Library/Frameworks/JavaVM.framework/Versions/1.4.2/Home/bin/java
-classpath /Applications/Utilities/Java/Java Web
Start.app/Contents/MacOS/javaws.jar
-Djnlpx.home=/Applications/Utilities/Java/Java Web
Start.app/Contents/MacOS -Djnlpx.splashport=-1
-Djnlpx.jvm=/System/Library/Frameworks/JavaVM.framework/Versions/1.4.2/Home/bin/java
-Djnlpx.remove=false
-Djava.security.policy=file:/Applications/Utilities/Java/Java Web
Start.app/Contents/MacOS/javaws.policy -DtrustProxy=true
-Djnlpx.heapsize=NULL,NULL
-Djnlpx.deployment.system.home=/Applications/Utilities/Java/Java Web
Start.app/Contents/MacOS
-Djnlpx.deployment.user.home=/Users/mpshannon/Library/Caches/Java Web
Start -Xdock:name=Java Web Start
-Djava.library.path=/Applications/Utilities/Java/Java Web
Start.app/Contents/MacOS/../../Contents/Resources/Java/
com.sun.javaws.Main http://db/cytoscape/gaggle/jaguar/jaguar.jnlp

but nothing seemed to run....
*--------------------------------------------------------------------------------
* cvs tricks

---- create new cvs repository from ucsd, cvsdir4

export CVSROOT=:ext:pshannon@bordeaux.ucsd.edu:/common/cvsdir4
export CVS_RSH=ssh

ssh-keygen -t rsa -b 1024
creates two files in ~/.ssh

-rw-------    1 pshannon isb           883 Dec 20 13:33 id_rsa
-rw-r--r--    1 pshannon isb           243 Dec 20 13:33 id_rsa.pub

take current host's entry in id_rsa.pub, and put it in target host's
.ssh/authorized_keys

test out with 'ssh bordeaux.ucsd.edu date'




---- find out which files in a directory are unknown to cvs

trickster:~/bin/cvsUnknown:
cvs status * 2>&1| grep ^F | egrep -v "(.class|.jar)" | grep -i unknown

*--------------------------------------------------------------------------------
* ant tricks
ant -projecthelp    # lists the main targets, with brief explanations

*--------------------------------------------------------------------------------
* make tricks (dec 2004)

---  specify suffix rules for making (and validating) xml from '.rml', using m4

.SUFFIXES: .rml .xml
.rml.xml:
m4 $< > $@
msv experiment.xsd $@


INPUT = feso4.xml \
iron.xml \

default: $(INPUT)

---   Give  variables taken  from the environment precedence over vari ables from makefiles.
-e

make deploy -n
scp boss.jar db:/local/tomcat/webapps/cytoscape/gaggle/testJars

export DEPLOY=/users/pshannon/tmp
make deploy -e -n
scp boss.jar /users/pshannon/tmp

*--------------------------------------------------------------------------------
* entrez, pubmed, medline, ncbi tips, eutil tips, eutils tips, gene_info tips

--- get gene.summaries, gene summary, gene summaries
from ~/s/rcy/paper/go.R, run (21)
gene.summaries <<- list ()
for (gene in gene.ids) {
printf ('--- building text for %s', gene)
s = sprintf ('geneID: %s  %s', gene, get (gene, org.Hs.egSYMBOL))
s = paste (s, desc (gene), sep ='\n')
s = paste (s, gene.summary (gene), sep='\n')
lines = strwrap (s, 50)
s = paste (lines, collapse='<br>')
s = paste ('<html>', s, '</html>')
gene.summaries [gene] <<- s
} # for gene


--- python api
http://www.dalkescientific.com/EUtils/
http://www.dalkescientific.com/writings/diary/archive/2005/09/30/using_eutils.html

--- gene_info
ftp://ftp.ncbi.nlm.nih.gov/gene/DATA/gene_info.gz  (a manual ftp seems to work best)
cat gene_info.human.2007-dec-21 | awk -F'\t' '{print $2 "\t" $3}' > gene_info.human-2007-dec-21.idSymbolOnly.tsv

--- eutils, etc
entrez programming utilities:  http://eutils.ncbi.nlm.nih.gov/entrez/query/static/eutils_help.html
http://www.ncbi.nlm.nih.gov/entrez/query/static/help/genehelp.html
eutils via soap: http://eutils.ncbi.nlm.nih.gov/entrez/query/static/esoap_help.html

--- guidelines:
http://eutils.ncbi.nlm.nih.gov/entrez/query/static/eutils_help.html#UserSystemRequirements
User Requirements
Do not overload NCBI's systems. Users intending to send numerous queries and/or retrieve large numbers
of records from Entrez should comply with the following:

* Run retrieval scripts on weekends or between 9 pm and 5 am Eastern Time weekdays for any series of more than 100 requests.
* Send E-utilities requests to http://eutils.ncbi.nlm.nih.gov, not the standard NCBI Web address.
* Make no more than one request every 3 seconds.
* Use the URL parameter email, and tool for distributed software, so that we can track your project and contact you if there is a problem.
* NCBI's Disclaimer and Copyright notice must be evident to users of your service.  NLM does not claim the copyright on
the abstracts in PubMed; however, journal publishers or authors may. NLM provides no legal advice concerning
distribution of copyrighted materials, consult your legal counsel.



--- get abstract, plain text, for pmid
curl 'http://eutils.ncbi.nlm.nih.gov/entrez/eutils/efetch.fcgi?db=pubmed&id=14574415&retmode=text&rettype=abstract'


--- python interface to ncbi soap
http://www.dalkescientific.com/EUtils/

see the 3d structure of  a homolog of
vng2283G (alaS) Alaynyl-tRNA synthetase has official name 'Alanine--tRNA ligase'

http://www.ncbi.nlm.nih.gov/Structure/mmdb/mmdbsrv.cgi?form=6&db=t&Dopt=s&uid=30406

--- summary view of multiple genes at entrez
http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=PureSearch&db=gene&details_term=2153,23039,20745

--- summary view of multiple proteins at entrez
http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=PureSearch&db=protein&details_term=AAB22835.1,AAV33124.1,AAN36772.1


more elaborately, as provided by an ncbi  'url' button
...&details_term=2153%5BUID%5D%20OR%2023039%5BUID%5D%20OR%20733%5BUID%5D

--- taxonomy id, organism, species
mouse: 10090
human:  9606

--- try to concoct an extrez url that returns multiple abstracts (or the like)
single pmid:
http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&db=PubMed&list_uids=12081471&dopt=Abstract
multiple:
http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=PureSearch&db=PubMed&details_term=10631996,12795606,9195888
*--------------------------------------------------------------------------------
* ncbi eutils tips
help: http://eutils.ncbi.nlm.nih.gov/entrez/query/static/eutils_help.html
Application 7: Entrez TBLASTX

I want to download all mRNAs from green plants that are related at the
protein level to human NM_001126, in flatfile format.  Motivation: For
finding distant homologs, protein BLAST searches are generally more
sensi- tive than nucleotide BLAST searches. In this specific case, a
nucleotide BLAST search finds no significant matches to NM_001126 from
green plants, while TBLASTX will find several homolo- gous
sequences. However, TBLASTX is the most time-consuming version of
BLAST, and there- fore using the pre-computed results in Entrez saves
significant computing time.

Programming Utilities (eUtils)

Solution: Use ESearch to retrieve the record for NM_001126, and then use ELink to find the
linked protein sequence. Then use ELink again to find all related sequences to that protein, and
then use ELink a third time to find all nucleotide records linked to those related proteins and then
limit them to mRNAs from green plants. Finally, download the formatted data with EFetch.

base url: http://www.ncbi.nlm.nih.gov/entrez/eutils/


URL 1: http://www.ncbi.nlm.nih.gov/entrez/eutils/esearch.fcgi?db=nucleotide&term=NM_001126  --> 34577062
Result: Find GI = 4557270.

URL 2:http://www.ncbi.nlm.nih.gov/entrez/eutils/elink.fcgi?dbfrom=nucleotide&db=protein&id=4557270
URL 2:  http://www.ncbi.nlm.nih.gov/entrez/eutils/elink.fcgi?dbfrom=nucleotide&db=protein&id=34577062  --> 34577063
Result:   Find GI = 4557271.

URL 3:  http://www.ncbi.nlm.nih.gov/entrez/eutils/elink.fcgi?dbfrom=protein&db=protein&id=4557271
URL 3:  http://www.ncbi.nlm.nih.gov/entrez/eutils/elink.fcgi?dbfrom=protein&db=protein&id=34577063
Result:   Extract the 507 GI numbers into $gi_list1, and if desired, the raw BLAST scores
reported by ELink into @scores

URL 4:  elink.fcgi?dbfrom=protein&db=nucleotide&id=$gi_list1&term=biomol+mrna[properties]
+AND+viridiplantae[organism]
Result:   Extract the 7 GI numbers into $gi_list2

URL 5:  efetch.fcgi?db=nucleotide&WebEnv=$Webenv2&query_key=$key2&rettype=gb
Result:   Download the 7 plant mRNAs, none of which are found using Related Sequences to
NM_001126


*--------------------------------------------------------------------------------
* find blast matches from ncbi, to create facts for prolog (10 jan 2006)
VNG6098H
best approach seems to be BLink -- get precomputed blast links.  does not seem
to have a programmatic interface...
use biobar, ncbi protein search, choose BLink (on right margin)
vng6119h (a long gene in the ISH7_4, along with vng6120h)

ortholog(vng6119h, vng6007h, 3187,

*--------------------------------------------------------------------------------
* pfam tricks, pfam tips
--- view the main page for a pfam domain, give a pfam id (ie, from sbeams)
http://www.sanger.ac.uk/cgi-bin/Pfam/getacc?PF03485
*--------------------------------------------------------------------------------
* jess tricks, jess tips

--- declare, assign, dereference
(deftemplate person (slot name) (slot age))
(assert (person (name "Leo Duva Shannon") (age 6))) -> <Fact-1>
(bind ?leo (fact-id 1))  -> <Fact-1>
(fact-slot-value ?leo age)  -> 6
(fact-slot-value ?leo name) -> "Leo Duva Shannon"
Jess>
(bind ?leo
--- edit cycle; reload, reset, run:
(batch rules.clp) (reset) (run)

--- match a slot explicitly, print another slot's value
(defrule pfam00015
(pfamHit (geneSymbol ?gs)
(pfamID PF00015))
=>
(printout t ?gs " has PF00015  " crlf))

*--------------------------------------------------------------------------------
* tomcat tricks, tomcat tips
--- add a manager to a newly-installed tomcat
add these two lines to /usr/local/tomcat/conf/tomcat-users.xml
<role rolename="manager"/>
<user username="mgr" password="mgr" roles="tomcat,manager"/>

*--------------------------------------------------------------------------------
* rcurl tips

--- pathway commons example, ~/s/examples/R/pathwayCommonsWithRCurl/go.R

if (0 %in% levels) {
uri = "http://www.pathwaycommons.org/pc/webservice.do?cmd=get_pathways&version=2.0&q=SHH&input_id_type=GENE_SYMBOL"
if (!exists ('txt.pw')) {
txt.pw <<- getURL (uri)
txt.pw <<- sub ('\r\n', '', txt.pw)
}
lines = strsplit (strsplit (txt.pw, '\n')[[1]], '\t')
template.row = list (gene='dummy', pathway='', source='', cpathid='')
tbl.pathways <<- data.frame (template.row, stringsAsFactors=FALSE)
max.lines = 3
#max.lines = length (lines)
for (i in 2:length (lines)) {
if (length (lines [[i]] == 4))
tbl.pathways <<- rbind (tbl.pathways, lines [[i]])
} # for i
colnames (tbl.pathways) <<- lines [[1]]
tbl.pathways <<- tbl.pathways [-1,]
}


martin morgan, bioc, 13 sep 2009

I think you want to end up using

getURL("http://api-url", ...)

where ... are arguments that capture the command line --data @genes.xml.
The place to look for ... is in the 'man' page for curl_easy_setopt,
where an option like CURLOPT_READFUNCTION becomes a named argument
'readfunction'. I'd guess perhaps

reader <- function(file) {
function() paste(readLines(file), collapse="\n")
}

res <- getURL("http://api-url", readfunction=reader("genes.xml"))

If the return value is XML or HTML, you might then

xml <- xmlTreeParse(res, useInternal=TRUE)

and the query xml with the xpath language, described here
http://www.w3.org/TR/xpath, especially section 2.5, abbreviated syntax.


* end rcurl tips
*------------------------------------------------------------------------------------------------------------------------
* keggsoap  tips

--- R (11 jan 2008)

library (KEGGSOAP)   # may need to update XML, SSOAP, RCurl also
get.genes.by.pathway("path:sce00061")   "sce:YBR026C" "sce:YER061C" "sce:YKL182W" "sce:YNR016C" "sce:YPL231W"
domains = get.motifs.by.gene ("sce:YBR026C", "pfam")

--- find out soap methods
for key in kegg.methods.keys():
print key

kegg.get_ko_by_gene('hal:VNG2208G') -> ['ko:K01867']
kegg.get_definition_by_gene ('hal:VNG2208G') -> 'tryptophanyl-tRNA synthetase'

(see sample script trickster:~/src/keggSoap/samples/pathwayGenes.py'
kegg.get_genes_by_pathway ('path:hal00230')  # use 'map' for generic pathway
kegg.get_linked_pathways ('path:hal00230')   # returns 10 pathways
kegg.get_pathways_by_genes (['hal:VNG2331G'])
kegg.get_ko_by_gene ('hal:vng2650G') -> ['ko:K00003']
kegg.get_motifs_by_gene ('eco:b0002', 'pfam') generates ArrayStoreException
kegg.get_ko_by_gene ('hal:VNG2331G') -> ['ko:K02302']
kegg.get_ko_members ('ko:K02302') -> long list of, eg, ece:Z4729', 'ecj:JW3331', 'eco:b3368'

*--------------------------------------------------------------------------------
* jws tips, java web start tips, jnlp tips

---- how to serve jars with conflicting signatures:

1) This simply removes the original certificate so you can sign it like
every other jar when you run the ant build tasks. Open the jhall.jar(in
cytoscape/lib) with WinZip (or similar app) and delete .dsa and .sf file
from the jar file. This will delete the original certificate.

2) This second method uses a second .jnlp file. Webstart says all jars in
a single .jnlp file must be signed with the same certificate, but allows
you to reference other .jnlp files. This allows you to create separate
.jnlp files for different certificates. To do this, open your cy1.jnlp
remove the line "<jar href="lib/jhall.jar"/>". Now add the line
"<extension name="Sun Jars" href="sunJars.jnlp"/>". This basically just
says it find more data in a file named 'sunJars.jnlp'. Now we have to
create the second .jnlp file. This is the one I use.
<?xml version="1.0" encoding="utf-8"?>
<jnlp spec="1.0+" codebase="http://phu614.um.us.sbphrd.com:4010/webstart/"
href="sunJars.jnlp">
<information>
<title>Cytoscape WebStart, Figure #1</title>
<vendor>ISB, David J. Reiss, Galitskilab</vendor>
</information>
<resources>
<jar href="lib/jhall.jar"/>
</resources>
<component-desc/>
</jnlp>
Change the codebase URL and you should be set to go.

---- examples from dreiss (jan 2006)
main jnlp:
<?xml version="1.0" encoding="utf-8"?>
<jnlp
codebase="http://halo.systemsbiology.net/cmonkey/private/halo"
href="cy.jnlp">
<information>
<title>Biclusters with Association Network</title>
<vendor>D. Reiss, R. Bonneau</vendor>
<description>Bicluster Run Halo-LATEST3</description>
<homepage href="http://halo.systemsbiology.net/cmonkey/private/halo"/>
<offline-allowed/>
</information>
<security>
<all-permissions/>
</security>
<resources>
<j2se version="1.5+" max-heap-size="1024M"/>
<jar href="http://gaggle.systemsbiology.net/2005-11/jars/cytoscape.jar"/>
<jar href="http://gaggle.systemsbiology.net/2005-11/jars/inferelator.jar"/>
<jar href="http://gaggle.systemsbiology.net/2005-11/jars/ouai.jar"/>
<jar href="http://gaggle.systemsbiology.net/2005-11/jars/cytoAux.jar"/>
<jar href="http://gaggle.systemsbiology.net/2005-11/jars/jdom.jar"/>
<extension name="data" href="cy-data.jnlp"/>
</resources>
<application-desc>
<argument>-p</argument>
<argument>jar://project</argument>
<argument>--gooseName</argument>
<argument>Bicluster Run Version halo LATEST3</argument>
</application-desc>
</jnlp>


contained jnlp ----


*--------------------------------------------------------------------------------
* chilibot tricks & tips
enter a list of (for example) ecoli orthologs of the halo genes of interest
hit next >
modify
> DCTA (input: dctA)
to read
> gltP (input: dcta)
or
> VNG6308G (input: dcta)
where the substituted name is for the actual halo protein

*--------------------------------------------------------------------------------
* httpunit tricks & tips (programmatic web access from java & jython)

from http://httpunit.sourceforge.net/

put these in your classpath:
~/jars/httpunit/httpunit.jar
~/jars/httpunit/js.jar
~/jars/httpunit/junit.jar
~/jars/httpunit/nekohtml.jar
~/jars/httpunit/rhino-patch.txt
~/jars/httpunit/servlet.jar
~/jars/httpunit/Tidy.jar
~/jars/httpunit/xercesImpl.jar
~/jars/httpunit/xmlParserAPIs.jar

import sys
from com.meterware.httpunit import *
wc = WebConversation ()
HttpUnitOptions.setScriptingEnabled (0)
uri = 'http://string.embl.de'
request = GetMethodWebRequest (uri)
response = wc.getResponse (request)
forms = response.getForms ()
len (forms) -> 3
f = forms [0]
f.getParameterNames ()
array(['limit', 'UserId', 'required_score', 'identifier', 'sessionId', 'empty', 'sequence'], java.lang.String)
r2 = response.getLinks ()[5].click ()
f2 = r2.getForms () [0]
f2.getOptions ('multiple_input_query_species')  # get this from form source, find <select name='xxxxx'
f2.setParameter ('multiple_input_query_species', '64091')   # 64091 corresponds to halo
f2.setParameter ('multiple_input_items', 'VNG2384G')
r3 = f2.submit ()
r3.getText ()


--- search google for 'gaggle semantics' (9 aug 2007)

from com.meterware.httpunit import *
wc = WebConversation ()
HttpUnitOptions.setScriptingEnabled (0)
url = 'http://google.com'
request = GetMethodWebRequest (url)
response = wc.getResponse (request)
form = response.getForms ()[0]
print form.getParameterNames ()
assert ('q' in form.getParameterNames ())
form.setParameter ('q', 'gaggle semantics')
form.submit (form.getSubmitButton ('btnG'))
print wc.getCurrentPage().getText()


*--------------------------------------------------------------------------------
* sbeams tips
halo group's protein annotation url, used (april 2005) in gaggle plugin called 'Halo Sbeams'
https://db.systemsbiology.net/sbeams/cgi/ProteinStructure/GetAnnotations?search_scope=All&search_key=iron&action=GO&biosequence_set_id=2&action=QUERY

----- sbeamsToMatrices.py:  create two matrices from sbeams microarray result sets
https://db.systemsbiology.net/sbeams/cgi/Microarray/GetExpression
choose experiments, measurements, cutoffs, ....
create results set
python sbeamsToMatrices.py  query_pshannon_20051007-122837
sys.path.append ('/users/mpshannon/work/wrangle/sbeams')
from MicroarrayResultSet import *


rs = MicroarrayResultSet (sbeamsResultSetName)
(conditions, measurements) = rs.getConditionsAndMeasurementNames ()
for measurement in measurements:
matrix = rs.createMatrix (measurement)
filename = 'matrix.%s' % measurement
sys.stderr.write ('--- writing file %s, %d rows x %d cols\n' % \
(filename, len (matrix), len (matrix [0])))
writeMatrix (filename, matrix),




----- sbeams-to-cytoscape, servlet and python script (06 oct 2005)
the trailing 'sbeams' at the end of the ...../cytoscape/sbeams?....  url
invokes the servlet mapping defined in
/local/tomcat/webapps/cytoscape/WEB-INF/web.xml
pointing to the  servlet
/local/tomcat/webapps/cytoscape/WEB-INF/classes/sbeamsInJar.java
this servlet

1) defines static private final File projectBase =
new File ("/local/tomcat/webapps/cytoscape/projects/dynamic");

2) has method processDynamicProject, which
a) ascertains the project directory, and creates a new user directory if necessary
File projectDirectory = new File (projectBase, p.getProjectName ());
// project name here is, i believe, generic.  this must come from the sbeams generated url
File userDirectory =  new File (projectDirectory, p.getUser ());
b) writes an sbeams-produced tab-delimited file to the user directory
c) runs '/local/tomcat/webapps/cytoscape/projects/dynamic/generic/prep.py' on that file
creating a cytoscape project, after which jnlp text is sent back to the browser.

*--------------------------------------------------------------------------------
* windows tips
--- to mount my nfs directory to a windows box
from Start button, choose run
in the text box, type '\\isb-1\pshannon
a directory browser starts up
from tools, choose map drive
*--------------------------------------------------------------------------------
* jprofiler tips & tricks
on hazel
*--------------------------------------------------------------------------------
*--------------------------------------------------------------------------------
*--------------------------------------------------------------------------------
*--------------------------------------------------------------------------------
*--------------------------------------------------------------------------------
* x11 tips

   --- (14 mar 2017)
     install XQuartz, then start it up
     in laptop's ~/.bashrc:   export DISPLAY=":0.0"
     ssh -X pshannon@whovian

   ----- support remote x11 use on macos trickster's x server
    ~/bin/hazel is run by the 'emacs@hazel' menu entry of the x11 server app
     #!/bin/sh
     DISPLAY=:0.0; export DISPLAY
     ssh -2 -Y hazel emacs

*--------------------------------------------------------------------------------
* gtar tips

gtar -czf junk.tgz /users/pshannon/notes/roundpeak/t*
gtar tzf junk.tgz
users/pshannon/notes/roundpeak/taxes2001
users/pshannon/notes/roundpeak/traffic-ticket

gunzip < file.tar.gz | tar xvf -
gunzip < file.tgz    | tar xvf -

If you have GNU tar you can use the z option directly:
gtar xvzf file.tar.gz
gtar xvzf file.tgz

*--------------------------------------------------------------------------------
* curl tips

---- user & password
curl --user haloprivate:notforyou http://halo.systemsbiology.net/cmonkey/private/halo/data.jar > data.jar

* curl tips
*--------------------------------------------------------------------------------
* papers
knowledge-bases, reasoning, hypotheses, etc:
nam tran at arizona state   http://www.public.asu.edu/~nhtran/
*--------------------------------------------------------------------------------
* cyjs tips:  add edge between two selected nodes (3 apr 2014)

defined and used in ~/s/templates/cyjs/addEdgesProgrammatically/

addEdgesBetweenSelectedNodes = function(){
var selectedNodes = cy.$('node:selected');
var selectedNodeNames = new Array()
for(var n=0; n < selectedNodes.length; n++){
node = selectedNodes[n];
nodeName = node.data().id;
console.log("selected: " + nodeName)
selectedNodeNames.push(nodeName);
} // for n
if(selectedNodeNames.length == 2){
sourceNode = selectedNodeNames[0]
targetNode = selectedNodeNames[1]
console.log(sourceNode + " & " + targetNode);
edgeId = "e" + cy.$('edge').length
elements = [{data: { id: edgeId, source: sourceNode, target: targetNode },
group: 'edges'}]
cy.add(elements)
} // 2 nodes
} // addEdgesBetweenSelectedNodes


*------------------------------------------------------------------------------------------------------------------------
* javascraipt tips: Get max and min of object values from JavaScript array

  var minX = Math.min.apply(Math, a.map(function(val) { return val.x; }));
  var maxX = Math.max.apply(Math, a.map(function(val) { return val.x; }));

*------------------------------------------------------------------------------------------------------------------------
* javascript tips, cyjs tips

  --- get all values in a pulldown selector widget:

  $("#sampleSelector").children().map(function() {return $(this).val();}).get();
    ["average (of 3)", "1159.T.1", "1160.T.1", "1184.T.1"]

 --- filter the results

  var x = $("#datasetMenu").children().map(function() {return $(this).val();}).get();
    // ["", "DEMOdz", "TCGAbrain", "TCGAgbm"]

  x.filter(function(e) {return (e.length > 0)})
    // ["DEMOdz", "TCGAbrain", "TCGAgbm"]

--- specify viz style in cytoscape initializer
by example:  file://localhost/Users/pshannon/s/templates/cyjs/jsonNetworkAndVizmap/indexGit.html

$(document).ready(function() {
console.log("document ready");

var $cy = $("#cy");

$cy.cytoscape({
elements: network.elements,
// style: vizmap[0].style,  // the first style is the one we want
showOverlay: false,
minZoom: 0.1,
maxZoom: 4.0,
layout: {
name: 'preset',
fit: true
},
ready: function() {
console.log("cy ready");
}, // cy ready

style: cytoscape.stylesheet()
.selector('node')
.css({'background-color': 'blue'})
.selector('edge')
.css({'line-color': 'green',
'source-arrow-shape': 'circle',
'source-arrow-color': 'red',
'curve-style': 'bezier'         // haystack for faster drawing, but no arrows
})
}); // cy initializer: cytoscape
})  // document ready



--- select first neighbors of selected nodes
var selectedNodes = cy.$('node:selected');
s = "selected: " + selectedNodes.length
$("#msg").text("selected: " + selectedNodes.length)
console.log("line 3204 of angio.html");
for(var n=0;n < selectedNodes.length;n++){
node = selectedNodes[n]
nodeName = node.data().name
neighbors = node.neighborhood()
console.log(nodeName + ": " + neighbors.length + " neighbors")
for(var ns=0; ns < neighbors.length; ns++){
nayb = neighbors[ns]
nayb.select()
console.log("   nayb(" + ns +"): " + nayb.data().name)
} // for ns
s += ", " + nodeName
} // for n

*----------------------------------------------------------------------------------------------------
* javascript tips, cyjs tips

node.neighborhood() also includes edges, so you can use node.neighborhood('node') or any other
selector if you want to filter the neighbourhood.

Edit: You can also use degree to do what you want.

var otherNodesToDelete = node.neighborhood('node{degree = 1}');

Or you can do node.remove() and then do cy.$('node{degree = 0}') to look for disconnected nodes.


*----------------------------------------------------------------------------------------------------
* javascript tips

--- debugging, from dan
firebug:  https://addons.mozilla.org/firefox/addon/1843   It has a full fledged debugger but
console.log() is usually sufficient. It's equivalent to System.out.println().

--- debugging, from cbare.  requires starting firefox from command line
/Applications/Firefox.app/Contents/MacOS/firefox &
Enter about:config in the address area.
Right-click to make a new option.
Like this:

browser.dom.window.dump.enabled = true

Restart Firefox
Now your javaScript can do:

dump ("Hello World\n");

--- cbare's suggestions for using XMLHttpRequest

Here's how to set up an http request in Firefox. This won't work in IE, if I understand correctly.
var request = new XMLHttpRequest ();
request.onreadystatechange = function () {
dump ("getNetworkXml readyState = " + request.readyState + "\n");
if  (request.readyState == 4) {
if (request.status == 200) {
var text = request.responseText;
// ... do something with response text
}
}
request.open ("GET", url);
request.setRequestHeader ("User-Agent", "XMLHttpRequest");
request.setRequestHeader ("Accept-Language", "en");
request.send (null);

The function assigned to request.onreadystatechange is called back
periodically until the request completes (state 4). If it was
successful (HTTP response code 200), then we can get responseText or
responseXML.
There's decent documentation for this stuff here: http://www.javascriptkit.com/jsref/ajax.shtml


--- use ajax with callback function to obtain text from a servlet, enter it into the document
fully working example (though it depends upon a tomcat + servlet running at 8080 on localhost):
~/s/examples/javascript/ajaxDemo/go.html

cd ~/s/examples/javascript/ajaxDemo/
make
cp go.html  /usr/local/tc6/webapps/data/ajaxJavascriptDemo.html
open http://localhost:8080/data/ajaxJavascriptDemo.html
same-origin policy: the ajax destination url must be relative, and implicitly the same as the html


---- dynamically change text in any element from <script> function
see  ~/s/examples/javascript/document.write/go4.html

<html>
<head>
<script type="text/javascript">
function changeText () {
document.getElementById('boldStuff').innerHTML = 'new text';
document.getElementById('d1').innerHTML = 'new text for div d1';
}
</script>
</head>

<body>
<center>
<br> <br><br>
Change  <b id='boldStuff'>some text</b>
<br><br><br>
<input type='button' onclick='changeText()' value='Change Text'/>
<br> <br><br>
<div id='d1'>
original text in div d1
</div>
</center>
</html>


---- String.replace with regex
var rawHtml = request.responseText
var target = new RegExp ('SRC="/', "gi")     // do global replace, ignore case
var replacement = 'SRC="http://string.embl.de/'
html = rawHtml.replace (target, replacement)


---- introspection
for (in in someObject) dump (i + "\n")

---- javascript/html replace innerHTML
see  ~/examples/mozilla/js-html/innerHTML/go.html, with these methods:
function changeText (newText) { document.getElementById("test").innerHTML=newText}
which works on <div id="test">xxxx code xxxx</div>
function show () {dump (document.documentElement.innerHTML + "\n")}
which displays all html in the document

---- onload function
for xul:
<window xmlns="http://www.mozilla.org/keymaster/gatekeeper/there.is.only.xul"
onload="onLoadHandler ()">

---- trim leading and trailing spaces
str.replace (/^\s+/g, '').replace(/\s+$/g, '');

---- dom tips: elements, nodes & text
(from http://www.oreillynet.com/pub/a/javascript/synd/2001/08/17/DOM-2.html)

Nodes and Elements

The DOM-2 specification identifies all items that compose a document
as nodes. The node interface provides a set of common methods and
properties that allow items within a document to be accessed and
manipulated.

IE5 recognizes everything in your HTML document to be either an
element or a text node, as does NS6 (and Mozilla). It's important to
understand the fundamental differences between elements and text
nodes. Elements are universally associated with angle-bracketed
tags. In HTML, all tags are elements, such as <P>, <IMG> and
<DIV>. Elements are also likely to have attributes and contain child
nodes.

The DOM-2 has evolved from an exciting concept to a legitimate tool
that is now supported in the major browsers. Do you think more
developers will begin to take advantage of these tools, or will they
continue to rely on old tricks?  Post your comments

Text nodes, on the other hand, represent a chunk of text. Unlike
elements, text nodes have neither attributes nor children (although
they inherit both the childNodes and attributes collections from the
node interface.)

Consider the following example code:

<span id="weather">Partly cloudy, scattered showers, high 67</span>

The code above is comprised of two separate nodes. The <SPAN> tag is
an element node, with a single ID attribute. The text inside the SPAN
is in fact a separate text node. Being only text, it has no attributes
or children.

Elements and text nodes share some common properties:

nodeType: This property holds a numeric value that corresponds to the
type of node. Elements have a nodeType value of 1, while text nodes
have a nodeType value of 3. This is useful for identifying the type of
a particular node in an operation where several nodes of unknown type
need to be examined.

nodeName: This property holds a string that, like nodeType,
corresponds to the type of node. All text nodes have the string
"#text" as the value of nodeName. For elements, nodeName contains the
name of the element tag. Thus, an HTML image tag would have a nodeName
of "IMG."

nodeValue: This property holds the value of the node, if any. Elements
have a nodeValue of null. Text nodes have a nodeValue that is the
actual string of text within that node.

For a complete list of node properties and methods, you can refer to
the W3C DOM-2 specification.



---- flyover, mouseover, overlib
<!-- Code necessary for overlib -->
<DIV ID="overDiv" STYLE="position:absolute; visibility:hide; z-index:1;"></DIV>
<SCRIPT LANGUAGE="JavaScript"
SRC="http://loki.stockton.edu/~kinsellt/litresources/mswritinghelp/overlib2.js">
</script>
<!-- end of code necessary for overlib -->

<A HREF="javascript:void(0);" onMouseOver="return overlib('A piece
of enclosed ground, used for tillage or pasture: in most localities a
small piece of arable land adjacent to a house.  An alternate
definition is: a crypt, vault, cavern.(OED).The alternate defintion
can be seen as an underlying reference to death which would follow the
theme of the poem, even though Browning may have been engaging himself
in some word play here it seems that he meant for the more common
definition to be used in this instance.')"
onMouseOut="nd();">crofts,</A>


*--------------------------------------------------------------------------------
* rcs tips
ci -{fklqru}[rev] -mmsg -{nN}name -sstate -t[textfile] -Vn file ...
co -{fIlMpqru}[rev] -ddate -jjoins -ksubst -sstate -T -w[who] -Vn -xsuff -zzone file ...
co an old version to stdout, for study (10 jan 99)
co -p1.6 dzProfile.dtd > dz16.dtd

-- specify a version number explicitly (19 mar 98)
ci -l1.88 test.html
(-l means to follow the checkin with an automatic co -l)
the  explicit revision number requires some switch or other
to immediately preceed it, otherwise the number is interpreted
as a filename

---  ci, and co -l:    ci -l       (19 mar 98)

---  rcsdiff -r1.8 -r1.24 dzProfile.dtd | more
*----------------------------------------------------------------------------
* xml tips

-- xml schema to html
example: http://psidev.sourceforge.net/mi/xml/doc/MIF.html
"XML Schema documentation generated with XML Spy Schema
Editor http://www.altova.com/xmlspy"

*----------------------------------------------------------------------------
* psipred tips, bioinfobank tips, secondary structure tips

- secondary structure states

The reference secondary structure states (helix, strand and coil states) for each
structure in the training and test sets were derived from the definitions produced by
DSSP (Kabsch & Sander, 1983). The eight states (H, I, G, E, B, S, T, ?) were reduced to
three states according to the scheme outlined by Rost & Sander (1993), i.e. H and G are
taken to be helix states, E and B are taken to be strand states, and all others considered
to be coil.  To estimate a higher bound on the expected accuracy, a simpler mapping
scheme was also tried where only H states in DSSP are mapped to helix, and E states mapped
to strand.

--- kbsach & sander
Kabsch, W. & Sander, C. (1983). A dictionary of protein secondary structure. Biopolymers, 22, 2577-2637.

--- sample secondary structure sequence (gpd1: http://meta.bioinfo.pl/3djury.pl?meta=v2&id=13275)


MSAAADRLNLTSGHLNAGRKRSSSSVSLKAAEKPFKVTVIGSGNWGTTIAKVVAENCKGYPEVFAPIVQMWVFEEEINGEKL
--HHHHHHHHHHHH---------------------EEEEE---HHHHHHHHHHHHH----------EEEEEE--HHHHHHHH
--HHGHGTT--HHHHHTT---HHHH-H---T----EEEEE---HHHHHHHHHHHHHHHH-HGTT--EEEEEE--HHHHHHHH
-HHHHHHHHHHHHHHHHHH-HHHTHH---TTT---EEEEE---HHHHHHHHHHHHH-TTTTTTT--EEEEEE--HHHHHHHH

--- DSSP code: Dictionary of Protein Secondary Structure

* G = 3-turn helix (310 helix). Min length 3 residues.
* H = 4-turn helix (alpha helix). Min length 4 residues.
* I = 5-turn helix (pi helix). Min length 5 residues.
* T = hydrogen bonded turn (3, 4 or 5 turn)
* E = beta sheet in parallel and/or anti-parallel sheet conformation (extended strand). Min length 2 residues.
* B = residue in isolated beta-bridge (single pair beta-sheet hydrogen bond formation)
* S = bend (the only non-hydrogen-bond based assignment)

* C, L, or space : none of the above


[from http://en.wikipedia.org/wiki/Secondary_structure#The_DSSP_code]

The DSSP code is frequently used to describe the protein secondary structures with a
single letter code. DSSP is an acronym for "Dictionary of Protein Secondary
Structure", which was the title of the original article actually listing the secondary
structure of the proteins with known 3D structure (Kabsch and Sander 1983). The
secondary structure is assigned based on hydrogen bonding patterns as those initially
proposed by Pauling et al. in 1951 (before any protein structure had ever been
experimentally determined).

In DSSP, residues which are not in any of the above conformations is designated as ' '
(space), which sometimes gets designated with C (coil) or L (loop). The helices (G,H
and I) and sheet conformations are all required to have a reasonable length. This
means that 2 adjacent residues in the primary structure must form the same hydrogen
bonding pattern. If the helix or sheet hydrogen bonding pattern is too short they are
designated as T or B, respectively. Other protein secondary structure assignment
categories exist (sharp turns, Omega loops etc.), but they are less frequently used.

*----------------------------------------------------------------------------
* blast tips

---  align two sequences, fission yeast cki1 & mouse pka subunit c, alpha (23 sep 2008)
http://www.ebi.ac.uk/Tools/emboss/align/index.html
more info under this heading in ~/s/notes/kinases


--- Position-Specific Iterative BLAST (PSI-BLAST)

This program is used to find distant relatives of a protein. First, a list of all
closely related proteins is created. These proteins are combined into a general
"profile" sequence, which summarises significant features present in these
sequences. A query against the protein database is then run using this profile, and a
larger group of proteins is found. This larger group is used to construct another
profile, and the process is repeated.  By including related proteins in the search,
PSI-BLAST is much more sensitive in picking up distant evolutionary relationships than
a standard protein-protein BLAST.

--- blastx

Nucleotide 6-frame translation-protein (blastx) This program compares the six-frame
conceptual translation products of a nucleotide query sequence (both strands) against
a protein sequence database.


--- homologous genes, discovered in homologene, blast 2 sequence comparison
for example:
search ncbi homologenfor foxo3a
choose an entry, eg, "HomoloGene:31039. Gene conserved in Coelomata"
with human, mouse, rat, fly
show table of pairwise scores, then blast
leading to:
http://www.ncbi.nlm.nih.gov/blast/bl2seq/wblast2.cgi?1&program=blastp&one=4503739&two=45553353

---  environment variables

set the following environment variables:
export BLASTDB=/data/seqdb/blastformat

make yourself an .ncbirc file with this in it...
[NCBI]
Data=/package/genome/bin/data/


---- tblastn output formats

blastall -p tblastn -d nt -i fasta -m 8 -o out.tab

gi|1911733|gb|AAB50823.1|	gi|1911732|gb|S83559.1|	100.00	134	0	0	1	134	1	402	7e-71	 270
gi|1911733|gb|AAB50823.1|	gi|1813657|gb|U79590.1|HSU79590	82.84	134	23	0	1	134	1	402	2e-59	 232
gi|1911733|gb|AAB50823.1|	gi|49258109|gb|BC073792.1|	83.58	134	22	0	1	134	14	415	1e-58	 229

blastall -p tblastn -d nt -i fasta -m 9 -o out.withComments.tab

# TBLASTN 2.2.15 [Oct-15-2006]
# Query: gi|1911733|gb|AAB50823.1| REV25-2 [Homo sapiens]
# Database: nt
# Fields: Query id, Subject id, % identity, alignment length, mismatches, gap openings, q. start, q. end, s. start, s. end, e-value, bit score
gi|1911733|gb|AAB50823.1|	gi|1911732|gb|S83559.1|	100.00	134	0	0	1	134	1	402	7e-71	 270
gi|1911733|gb|AAB50823.1|	gi|1813657|gb|U79590.1|HSU79590	82.84	134	23	0	1	134	1	402	2e-59	 232
gi|1911733|gb|AAB50823.1|	gi|49258109|gb|BC073792.1|	83.58	134	22	0	1	134	14	415	1e-58	 229


blastall -p tblastn -d nt -i fasta -m 7 -o out.xml
<Hit>
<Hit_num>1</Hit_num>
<Hit_id>gi|1911732|gb|S83559.1|</Hit_id>
<Hit_def>V kappa III subgroup V-J kappa 2=REV25-2 [human, bone marrow cells, myeloma-associated light chain deposition disease patient, mRNA Partial, 402 nt]</Hit_def>
<Hit_accession>S83559</Hit_accession>
<Hit_len>402</Hit_len>
<Hit_hsps>
<Hsp>
<Hsp_num>1</Hsp_num>
<Hsp_bit-score>270.396</Hsp_bit-score>
<Hsp_score>690</Hsp_score>
<Hsp_evalue>6.88617e-71</Hsp_evalue>
<Hsp_query-from>1</Hsp_query-from>


---- blast output identifier tips

gi|1911732|gb|S83559.1|
gi = 1911732
gb = S83559.1   (accession version)
emb =

gi|33222|emb|X58082.1|HSIGKAPAB

*----------------------------------------------------------------------------
* mysql tips (28 sep 2006)

[create a mysql database called 'mysite':
mysqladmin -u root -h localhost password <old animal>
mysql -u root --password
create database mysite;
show databases;  --> information_schema, mysite, mysql, test
use mysql;
insert into user (host, user, password, select_priv, insert_priv, create_priv,
drop_priv, update_priv, alter_priv)
values ('localhost', 'django', PASSWORD('yojo'), 'Y', 'Y', 'Y', 'Y','Y', 'Y');
# remove user:
delete from user where user='django'; flush privileges;
select host, user, password from user where user = 'django';
| localhost | django | *A6732F65696BBB709708EA84FBA55972D9B962C0 |


-- get your bearings
show databases; # information_schema, test
use test;
show tables;    # membership, user, userGroup
select * from user;


-- update (modify, change)
use mysql;
select Delete_priv from user where user = 'django';   -->> 'N'
update user set Delete_priv = "Y" where user = 'django';
flush privileges;
*-------------------------------------------------------------------------------
* eda tips

-- tests for normality
R nortest package: http://cran.fhcrc.org/bin/macosx/universal/contrib/r-release/nortest_1.0.tgz
ls ('package:nortest')  # "ad.test"      "cvm.test"     "lillie.test"  "pearson.test" "sf.test"
odd: like jb, not consistent with large vectors from rnorm
ad.test (rnorm (10000))   # A = 0.25,   p-value = 0.7446
ad.test (rnorm (10000))   # A = 0.4259, p-value = 0.315
small p-value indicates non-normality

-- visual test for normality
qqnorm (vec)

-- pca
data (iris)
plot (princomp (iris [,1:4]))  # shows histogram of variance consumed by each eigenvector
names (iris.pca)  #  "sdev"     "loadings" "center"   "scale"    "n.obs"    "scores"   "call"

-- next up: fielding 23


* end eda tips
*-------------------------------------------------------------------------------
* heatmap tips, heatmap.2 tips

   library(gplots)
     # good for expression data, many samples
   heatmap.2(mtx.probes[probeRows,], trace='none', col=rev(heat.colors(10)), margins=c(15,15), cexCol=0.1, cexRow=1)


   library (gplots)
--- exploratory script
~/s/examples/R/heatmap/heatmap.2/fromManPage/go.R

--- for patrick paddison, 47 row names, all legible
heatmap.2(mtx.de, trace='none', col=colors, margins=c(10,10), cexRow=0.5)


--- from jim mcdonald, use pdf to avoid pixelation, create tall & skinny heatmap

I have rarely found the need to set the cexCol argument, and have found that the better idea is to make the resulting
image of the right dimensions. I assume here that you are creating a heatmap with lots of rows, and comparatively
speaking, much fewer columns. If you don't specify the dimensions of the output, then you will get a square-ish
heatmap with really thin rows that are hard to label.

If instead, you specify that the heatmap will be a really tall thin object, then you get something closer to what you
are likely interested in. Try something like this:

pdf("tmp.pdf", width = 8, height = 200) ## you may need to play with the height arg
heatmap.2(as.matrix(bb), scale="row", key=TRUE, symkey=FALSE, density.info="none", trace="none", cexCol=0.2,
dendrogram="both", Rowv=rowv, col=brewer.pal(9,"BuPu"))
dev.off()


--- colorpanel
heatmap (mf, col=colorpanel (16, '#00FF00', '#FFFFFF', '#FF0000'))
redgreen, greenred
all require gplots

--- martin morgan's broad & specific advice (bioc 29 aug 2010)
I'd guess the 'all read' (? red) is due to a few extreme values driving
the color palette -- perhaps you intend to log-transform or otherwise
pre-process the data before clustering / display, which might also help
convergence? Likewise applying a filter like varFilter in the genefilter
package to reduce the number of genes being clustered -- most will not
be contributing anything meaningful to the clustering algorithm.

I think what you want to do is to separate the steps of clustering,
reordering rows / columns, and displaying the image. See ?dendrogram,
?reorder, ?heatmap. Heatmpap should be doing little more than plotting
an image (no sense in printing the dendrograms, as they'll be too dense
to make sense of).


--- heatmap.2 simple use
heatmap.2 (some.matrix, trace='none', labRow = rep ('leo', 83),  labCol=rep ('leo', 51))

--- heatmap.2, explicit control of row & column labels.  there must be enough margin for the (column) labels.
heatmap.2 (some.matrix, trace='none', labRow = rep ('leo', 83),  labCol=rep ('leo', 51), )

--- heatmap.2 margins
margins= c(5, 5)   # this provides room for column & row names, respectively
control the other margins like this, before the call
par (mar=c (10, 10, 3, 10))  # bottom, left, top, right.  the '3' gives enough space for a heatmap title


--- remove the color key
key = FALSE

heatmap.2 (m2,
dendrogram='row',
margins= c(5, 5),
trace='none',
labRow=rownames,
labCol=day.status,
cexCol=1.0,
cexRow=1.5,
Colv=clusterColumns,
key=FALSE,     # toggles color key & histogram
keysize=0.3,   # vertical space, don't know what units. 1 is good size if key=T; 0.3 if F
col=rev(heat.colors (12))
#ColSideColors=rev(heat.colors (ncol (m2)))


--- extract clusters from heatmap
zz = heatmap (as.matrix (x), margins = c (20, 10))
names (zz)   #  "rowInd" "colInd" "Rowv"   "Colv"
zz$rowInd   #   9 18 19  4  5  2 16  3 12  6 13 10 11  7 15 20 17 14  8  1



library (gplots)
heatmap.2 (m [,x], col=rev (heat.colors (10)), Rowv=F, margins=c(8,8), dendrogram="column", trace='none')

Rowv: determines if and how the row dendrogram should be reordered.
T: default, order is recalculated based on row means
F: no dendrogram displayed, no re-ordering done
dendrogram: as-is, without re-ordering
Rowv=F seems to get rid of this error:
Error: evaluation nested too deeply: infinite recursion / options(expressions=)

trace: solid trace line draw across rows and/or down columns.
none:  my preference, gets rid of horrible turquoise confusion.

--- don't reorder rows or columns
heatmap.2 (p, col=rev (heat.colors (10)), Rowv=F, Colv=F, margins=c(8,8), dendrogram="none", trace='none')

* end heatmap tips, heatmap.2 tips
*----------------------------------------------------------------------------------------------------------------------
* biostring tips

--- write fasta file from sequence data
dna.string <<- toString (subseq (seq.chr1, loc-flank.size, loc+flank.size))
dna.string <<- gsub ('#', 'N', dna.string)
dna.set <<- DNAStringSet (dna.string)
seq.name = sprintf ('loc %d', loc)
printf ('%5d): %s', i, seq.name)
names (dna.set) <<- seq.name
dna.set.all <<- append (dna.set.all, dna.set)
} # for loc
write.XStringSet (dna.set.all, file='test-15000.fa', format="fasta") # writes to the console


--- dan/rna transcription and translation

transcribe(x)
cDNA(x)
codons(x)
translate(x)

## Related utilities
dna2rna(x)
rna2dna(x)


--- covered very nicely here:
http://www.bioconductor.org/workshops/2008/BioC2008/labs/biostrings/

--- abstract
Title: Efficient string manipulation and genome-wide motif searching with Biostrings and the BSgenome data packages
Author: Herve Pages <hpages@fhcrc.org>

The Biostrings package provides the infrastructure for representing and manipulating large nucleotide sequences (up
to hundreds of millions of letters) in Bioconductor as well as fast pattern matching functions for finding all the
occurrences of millions of short motifs in these large sequences. The Bioconductor project also provides a
collection of "BSgenome data packages". These packages contain the full genomic sequence for a number of commonly
studied organisms. The Biostrings package together with the BSgenome data packages provide an efficient and
convenient framework for genome-wide sequence analysis. This lab session is a general introduction to this framework
with some emphasis on the latest developments: the built-in masks in the BSgenome data packages; the ability to
inject SNPs from a SNPlocs package into the chromosome sequences of a given species (only Human supported for now);
and the matchPDict() function for efficiently finding all the occurrences in a genome of a big dictionary of short
motifs (like one typically gets from an ultra-high throughput sequencing experiment).


* end biostring tips
*----------------------------------------------------------------------------------------------------
* plot tips: Two different y axes on the same plot

from http://rwiki.sciviews.org/doku.php?id=tips:graphics-base:2yaxes

set par(new=TRUE) to prevent R from clearing the graphics device,
creating the second plot with axes=FALSE (and setting xlab and ylab to
be blank – ann=FALSE should also work) and then using axis(side=4) to
add a new axis on the right-hand side, and mtext(...,side=4) to add an
axis label on the right-hand side

x <- 1:10
y <- rnorm(10)
z <- runif(10, min=1000, max=10000) # second data set on a very different scale
par(mar = c(5, 4, 4, 4) + 0.3)  # Leave space for z axis
plot(x, y) # first plot
par(new = TRUE)
plot(x, z, type = "l", axes = FALSE, bty = "n", xlab = "", ylab = "")
axis(side=4, at = pretty(range(z)))
mtext("z", side=4, line=3)


*----------------------------------------------------------------------------------------------------------------------
* r tips

--- paste, collapse
symbols [[6]] # [1] "KRAS"  "RXRG"  "NTRK1" "TPM3"
(paste (symbols [[6]], collapse=','))  #  "KRAS,RXRG,NTRK1,TPM3"

--- find package:  where is an installed package installed?

.find.package ('gaggle')  --> /Library/Frameworks/R.framework/Resources/library/gaggle

--- ls () to global scope, from nested scope
run = function () {
tbl.names = grep ('tbl.spia', ls (sys.frame ()), v=T) [1:3]
}

--- write text file
~/s/examples/R/writeTextFile/go.R
out = c ()
out [[1]] = 'line aaaa'
out [[2]] = 'line bbbb'
write (out, sep='\n', file='lines.txt')


--- a service to build windows package, R package website url
http://win-builder.r-project.org/

--- get devel, pre-release  version of R for windows
http://cran.fhcrc.org/bin/windows/base/rdevel.html

--- create random string
paste (LETTERS [sample (0:9)], collapse='')  --> "BEIAHFDGC", "EGICDBAFH", ...

--- table tips
library (learnbayes)
data (studentdata)
barplot (table (studentdata$Drink), xlab='Drink', ylab='Count')

--- unload a library
detach ("package:spiaDemo")

--- install.packages, specifying repos
install.packages (repos="http://cran.fhcrc.org/",  c ("RCurl", "multicore", "igraph", "RSVGTipsDevice", "fUtilities", "hwriter"))

--- installation location on wombat
eg, /Library/Frameworks/R.framework/Resources/library/Biostrings/data/HNF4alpha.rda

--- has a variable been defined?  does it exist?
stopifnot (exists ('requiredVariable') & length (requiredVariable) > 0)

--- install R package from fhcrc
install.packages ('RSQLite', repos='http://cran.fhcrc.org')

--- multi-dimensional analysis
http://www.math.usu.edu/~minnotte/S5600S07/

--- match tips
match.vector <<- match (tbl.all.chr22$begin, tbl.genes.added.chr22$begin)
mapped.indices <<- which (!is.na (match.vector))
tbl.all.chr22$geneID [mapped.indices] <<- tbl.genes.added.chr22$geneID [match.vector [mapped.indices]]
tbl.all.chr22$symbol [mapped.indices] <<- tbl.genes.added.chr22$symbol [match.vector [mapped.indices]]

--- merge tips
tbl.srf4way <<- merge (tbl.sr4way, tbl.all [, c ('chrom', 'begin', 'freq')], by.x = c ('begin', 'chrom.x'), by.y = c ('begin', 'chrom'), all.x=TRUE)

--- warnings ()
turn warnings into true errors:  options(warn=2)
default value: options (warn)[[1]] --> 0

--- vignettes, sweave, tex on macos
see https://www.nescent.org/wg_phyloinformatics/R_Hackathon_1/R_Vignette_HowTo
recommends MacTex, says it recognizes .Rnw files
--- create tex file
R> Sweave ("gaggle.Rnw")
Writing to file gaggle.tex
Processing code chunks ...
1 : echo (label=Broadcast0)
2 : echo (label=Broadcast1a)
3 : echo (label=Broadcast1b)
You can now run LaTeX on 'gaggle.tex'
-- create pdf from tex

--- update bioc
source("http://bioconductor.org/biocLite.R")
update.packages(repos=biocinstallRepos(), ask=FALSE)
better yet (24 oct 2010):   update.packages (repos='http://cran.fhcrc.org')

--- cran & install
repos = c ()
repos ["CRAN"] = "http://cran.fhcrc.org"
options ('repos'=repos)


--- install.packages

--- turn string into variable name
mystr = "reallyfunnyvariable"
eval(parse(text=paste(mystr,"=list()",sep="")))
ls()  # [1] "mystr"               "reallyfunnyvariable"
reallyfunnyvariable   # list()

--- exceptions, try, catch, tryCatch
?tryCatch

--- working example: ~/work/cy13/R/pkg/crytoscape/R/cRytoscape.R/test.check.discrete.rule.for.plausibility.colon.format ()

in the called function, 'check.discrete...' this is found:

if (length (pair) != 2)
warning (sprintf ('format error in %s rule using "%s" attribute:  key:value pairs need a separating colon, not found in "%s"',
rule.name, attribute.name, keyValuePairs [k]), immediate.=TRUE, call.=TRUE)
this warning is caught; the warning message is retrieved via the passed in msg [1].  msg [2] is the text of the call

validation.1 = function (msg) {
expected = 'grainydashed_5'
expected = 'key:value pairs need a separating colon, not found in "grainydashed_5"'
match = length (grep (expected, msg [[1]]))
if (match != 1)
print (msg [2])
stopifnot (match == 1)
}
} # validation
tryCatch (
check.discrete.rule.for.plausibility ('edgeType',  c ('pocked:line_5', 'grainy;dashed_5', 'rough:dotted_3'),
known.data.values, line.types, 'edgeStyle'), warning=validation.1)




--- bimap tips
herve says (email 7 apr 2009)
First note that for any Bimap object 'x':
length(mget(mappedRkeys(x), x))
is the same as:
count.mappedRkeys(x)
but the latter is much more efficient.
Furthermore, if 'x' is a right-to-left map like in your case (see 'summary(x)'), then then 'count.mappedRkeys(x)' is equivalent
to 'count.mappedkeys(x)'  But generally speaking, there is no reason to expect:

nrow(toTable(x)) == count.mappedkeys(x)  # generally not true

unless the mapping contained in 'x' is one-to-one. Explanation:
'toTable(x)' returns a flat representation of Bimap object 'x' e.g.

Lkey   Rkey
1     a      A
2     a      B
3     b      A
4     d      C

All the edges (or links) of the bipartite graph are listed. Note that right key "A" is mapped to left keys "a" and "b", so this mapping is
not one-to-one. The left (or right) keys that don't map to anything don't appear in this table.
'count.mappedRkeys(x)' counts the number of (unique) right keys that map at least one left key i.e. 3 in the small example above.

So in fact, the following is true for any Bimap object 'x':

length(unique(toTable(x)[[2]])) == count.mappedkeys(x)  # always TRUE


--- create summary go enrichment table
# source is in ~/s/data/public/human|yeast|mouse/xref.R
tbl.bp <<- tabular.go.enrichment (genes.up.up, 'BP', 0.1, union (genes.down.down, genes.up.up))
# source is ~/s/data/utils/go.R
tbl.bp.compact = condense.go.table (tbl.bp)

--- open web page
Use browseURL:
browseURL('about:blank')
or  shell.exec("http://www.yahoo.com")



--- save an env without potection stack overflow
env <- new.env();
...
x <- list(env=env);
save("x", file="x.RData");

better yet:
So I think the moral is to hash large environments, and increasing
--max-ppsize should enable this one to be read in.



--- history
Sys.setenv(R_HISTSIZE=200000)

--- histStack in library geneplotter
can allegedly overlay histograms

--- boxpplot tips:  use 'as function of' notation
library (learnbayes)
data (studentdata); attach (studentdata)
hours.of.sleep = WakeUp - ToSleep
length (Gender); length (hours.of.sleep)  # 657, 657
boxplot (hours.of.sleep ~ Gender, ylab='Hours of Sleep')

--- boxplot tips  (http://en.wikipedia.org/wiki/Boxplot)
example: boxplot (-log (tbl.motifs.yck1d [,'phospval']), -log (tbl.motifs.yck1u [,'phospval']), main='-log (motif enrichment pvalue)', names=c('yck1d', 'yck1u'))
also: cex.axis=1.8, cex.main=1.6)  # for axis label size, and main label size.  cex means magnifier
-- a full-blown, 2 dataset example:
boxplot (subset (tbl.mot.1, experiment=='yck1d', select=score) [,1], subset (tbl.mot.1, experiment=='yck1u', select=score) [,1],
main='Primary Motif Enrichment Scores',
names=c('yck1d', 'yck1u'),
cex.axis=1.8, cex.main=1.6,
ylab='-log10 (pvalue)',
cex.lab=2)   #ylab crowds left edge of plot window.  how to fix that?  --> par (mai=c (1,1,1,1))


summarized: IQR is within the box
whiskers are at Q1 - 1.5 IQR, and Q3 + 1.5 IQR
Q1 cuts off the bottom 25% of the data
Q3 the top
Q2 is the median
mild outlier: more than median +/- IQR * 1.5, less than median +/- IQR * 3
extreme outlier: beyond IQR * 3

+-----+-+
o           *     |-------|     | |---|
+-----+-+

+---+---+---+---+---+---+---+---+---+---+---+---+   number line
0   1   2   3   4   5   6   7   8   9  10  11  12

For this data set:

* smallest non-outlier observation = 5 (left "whisker") (left "whisker" would have been 4 had there been an observation with a value of 4 (Q1  \scriptstyle 1.5\cdot\mathrm{IQR}))
* lower (first) quartile (Q1, x.25) = 7
* median (second quartile) (Med, x.5) = 8.5
* upper (third) quartile (Q3, x.75) = 9
* largest non-outlier observation = 10 (right "whisker")
* interquartile range, IQR = Q3  Q1 = 2
* the value 3.5 is a "mild" outlier, between  1.5 * IQR} and 3 * IQR below Q1
* the value 0.5 is an "extreme" outlier, more than  3 * IQR below Q1
* the data is skewed to the left (negatively skewed)

The horizontal lines (the "whiskers") extend to at most 1.5 times the
box width (the interquartile range) from either or both ends of the
box. They must end at an observed value, thus connecting all the
values outside the box that are not more than 1.5 times the box width
away from the box. Three times the box width marks the boundary
between "mild" and "extreme" outliers. In this boxplot, "mild" and
"extreme" outliers are differentiated by closed and open dots,
respectively.

There are alternative implementations of this detail of the box plot
in various software packages, such as the whiskers extending to at
most the 5th and 95th (or some more extreme) percentiles. Such
approaches do not conform to Tukey's definition, with its emphasis on
the median in particular and counting methods in general, and they
tend to produce "outliers" for all data sets larger than ten, no
matter what the shape of the distribution.[1]


--- quick gene tables, revmap et al
library("org.Hs.eg.db")
genes <- c("TP53", "SOX4", "PTEN")
entrez = toTable( revmap(org.Hs.egSYMBOL)[genes] )
go = toTable( org.Hs.egGO[entrez$gene_id] )
combined = merge(entrez, go)
gene_id symbol      go_id Evidence Ontology
1     5728   PTEN GO:0000079      TAS       BP
2     5728   PTEN GO:0001525      IEA       BP
3     5728   PTEN GO:0006470      IDA       BP

. . . .

91    7157   TP53 GO:0019899      IPI       MF
92    7157   TP53 GO:0046982      IPI       MF
93    7157   TP53 GO:0047485      IPI       MF

--- venn diagrams, from xinxia  (originally written for limma)
http://bioinfo-mite.crb.wsu.edu/Rcode/Venn.R
sample use (i think): http://research.stowers-institute.org/efg/R/Math/VennDiagram.htm



--- warnings
old.options = options ('warn')[[1]]
options ('warn'=-1)   # turn off warnings
intensity = as.integer ('aaa')
options ('warn' = old.options)


if (length (entry) > 1)  ## for normal use, so the user knows when things are odd...
warning (sprintf ('multiple matches to aa sequence: %d', length (entry)))

suppressWarnings (test.aa.to.protein.name ())   # during unit tests, so as not to attract unneeded attention

--- get pubmed abstract
library (RCurl)
pmid = '1644835'
p2 = "http://eutils.ncbi.nlm.nih.gov/entrez/eutils/efetch.fcgi?db=pubmed&id="
p3 = pmid
p4 = "&retmode=text&rettype=abstract"
p5 = "&email=pshannon@systemsbiology.org"
url = paste (p2, p3, p4,p5, sep='')
s =  getURL (url)
writeLines (strwrap (s, 80))

--- time
system.time (run ())
user  system elapsed
74.631  17.559  93.265

--- RCurl
* getURL ()
* getForm ()
* postForm ()

--- read.table tips
column.classes = c ('character', 'factor', 'factor', 'numeric', 'factor', 'integer', 'factor', 'integer', 'factor')
tbl.pheno <<- read.table ('/Users/pshannon/s/data/isb/copd/incoming/phenoData.tsv', sep='\t', header=T, colClasses=column.classes)
embedded single-quotes wreak havoc.  avoid this by, e.g.,
dim (read.table ('~/s/data/public/yeast/yeast.anno', sep='\t', quote="", as.is=TRUE))
skip=0, nrows=-1:  how many lines to read, and where to start

--- hyperg tips, category tips, hyperGTest tips, KEGGHyperGParams tips, GOHyperGParams tips
see demo/test in ~/s/examples/R/bioc/category/go.R

GO:
library (GOstats)
library (YEAST)
genes = c ("YLR113W", "YBL047C", "YBR001C")
params = new ("GOHyperGParams", geneIds = unique (genes),
universeGeneIds = character (0), annotation = "YEAST",
ontology = 'BP', pvalueCutoff = 0.1, conditional = FALSE,
testDirection = "over")

hgr.yeast.go <<- hyperGTest (params)
subset (summary (hgr.yeast.go), Count >1)
GOBPID     Pvalue OddsRatio  ExpCount Count Size                 Term
GO:0006950 GO:0006950 0.01592363  24.83402 0.2244204     2  484   response to stress
GO:0050896 GO:0050896 0.03763668  15.17663 0.3500773     2  755 response to stimulus

geneIdsByCategory (hgr.yeast.go, c ('GO:0006950', 'GO:0050896'))
$`GO:0006950`
[1] "YLR113W" "YBR001C"
$`GO:0050896`
[1] "YLR113W" "YBR001C"

--- hgr tips, go enrichment tips
KEGG:
genes = c ("YLR113W", "YFL026W")
params = new ("KEGGHyperGParams", geneIds = unique(genes),
universeGeneIds = character(0), annotation = "YEAST",
pvalueCutoff = 0.1, testDirection = "over")
hgr.yeast.kegg <<- hyperGTest (params)
checkEquals (geneCounts (hgr.yeast.kegg),  c ('04010'=2))
checkEqualsNumeric (pvalues (hgr.yeast.kegg), c ('04010'=0.002047118), tol=1e-5)
checkEquals (universeCounts (hgr.yeast.kegg), c ('04010'=55))
checkEquals (universeMappedCount (hgr.yeast.kegg),  55)
checkEqualsNumeric (expectedCounts (hgr.yeast.kegg), c ('04010'=0.0912863), tol=1e-5)
checkEquals (oddsRatios (hgr.yeast.kegg), c('04010'=Inf))
checkEquals (annotation (hgr.yeast.kegg), "YEAST")
checkEquals (geneIds (hgr.yeast.kegg), c ("YLR113W","YFL026W"))
checkEquals (length (geneIdUniverse (hgr.yeast.kegg)[['04010']]), 55)
checkEquals (geneIdsByCategory (hgr.yeast.kegg) [['04010']], c ("YLR113W", "YFL026W"))
checkEquals (sigCategories (hgr.yeast.kegg), "04010")
checkEquals (geneMappedCount (hgr.yeast.kegg), 2)
checkEquals (pvalueCutoff (hgr.yeast.kegg), 0.1)
checkEquals (testDirection (hgr.yeast.kegg), "over")
checkEquals (description (hgr.yeast.kegg), "Gene to KEGG  test for over-representation")
checkEquals (testName (hgr.yeast.kegg), "KEGG")
checkEquals (conditional (hgr.yeast.kegg), FALSE)
summary = summary (hgr.yeast.kegg)
checkEquals (dim (summary), c (1, 7))
checkEquals (colnames (summary), c ("KEGGID", "Pvalue", "OddsRatio", "ExpCount", "Count", "Size", "Term"))
checkEquals (summary (hgr.yeast.kegg) [1,'KEGGID'], "04010")
checkEqualsNumeric (summary (hgr.yeast.kegg) [1,'Pvalue'],  0.002047118, tol=1e-5)
checkEquals (summary (hgr.yeast.kegg) [1,'OddsRatio'],  Inf)
checkEqualsNumeric (summary (hgr.yeast.kegg) [1,'ExpCount'],  0.0912863, tol=1e-5)
checkEquals (summary (hgr.yeast.kegg) [1,'Count'],  2)
checkEquals (summary (hgr.yeast.kegg) [1,'Size'],  55)
checkEquals (summary (hgr.yeast.kegg) [1,'Term'],  "MAPK signaling pathway")
#     htmlReport

PFAM:
genes = c ("YLR113W", "YNR031C")
genes = targets
params = new ("PFAMHyperGParams", geneIds = unique(genes),
universeGeneIds = character(0), annotation = "YEAST",
pvalueCutoff = 0.1, testDirection = "over")

hgr.yeast.pfam <<- hyperGTest (params)
subset (summary (hgr.yeast.pfam), Count >= 2)
PFAMID       Pvalue OddsRatio   ExpCount Count Size    Term
PF00069 PF00069 0.0006923468       Inf 0.05285118     2  114 PF00069
>
checkEquals (geneIdsByCategory (hgr.yeast.pfam)[['PF00069']], c ("YLR113W", "YNR031C"))
checkEquals (length (geneCounts (hgr.yeast.pfam)), 32)


--- help tips
help (mget, package=base)
help (package="GOstats")             # full description
help (hyperGTest, package=GOstats)   # prints to stdout, not to a new buffer

--  when lost, by example:
help.search ("KEGGHyperGParams")

response:
KEGGHyperGParams-class(Category)                Class "KEGGHyperGParams" and "PFAMHyperGParams"
categoryToEntrezBuilder(Category)               Return a list mapping category ids to Entrez Gene ids
hyperGTest(Category)                            Hypergeometric Test for association of categories and genes
universeBuilder(Category)                       Return a vector of gene identifiers with category annotations

solution:
class?KEGGHyperGParams
also
accessors?HyperGResult


--- heatmap
the function heaplot in the made4 package will do this for you.  We also
added additional functionality to the function in the new release of
made4. If you provide heatplot with a character vector representing
grouping in your samples, it will add a colour bar beneath the
dendrogram so you can easily see if your samples cluster.  The function
pretty.dend is an extension to this and will add multiple colour bars
for each of your sample covariates.

-----  heatmap tips, heatmap.2 tips

library (gplots)
heatmap.2 (m [,x], col=rev (heat.colors (10)), Rowv=F, margins=c(8,8), dendrogram="column", trace='none')

Rowv: determines if and how the row dendrogram should be reordered.
T: default, order is recalculated based on row means
F: no dendrogram displayed, no re-ordering done
dendrogram: as-is, without re-ordering
Rowv=F seems to get rid of this error:
Error: evaluation nested too deeply: infinite recursion / options(expressions=)

trace: solid trace line draw across rows and/or down columns.
none:  my preference, gets rid of horrible turquoise confusion.

--- don't reorder rows or columns
heatmap.2 (p, col=rev (heat.colors (10)), Rowv=F, Colv=F, margins=c(8,8), dendrogram="none", trace='none')

--- hclust
plot (rhc, pch=20, cex=0.4, xlab="", sub="", main = "Hierarchical Clustering")

--- na.omit
as.numeric (na.omit (c (0, 1, NA, 4, 10)))  # [1]  0  1  4 10

--- env tips, eapply tips
env <- new.env(); env$a <- 1:10; env$beta <- log2(1:5); env$logic <- c(TRUE,FALSE,FALSE,TRUE)
eapply (env, function (x) length (x))

seth suggests:

Read the help page for details, but generally if you are using an
environment as a hashtable you don't what it to inherit bindings and
parent=emptyenv() is what you want.

affylmGUIenvironment <- new.env (hash=TRUE, parent=emptyenv())

---- pre-release mac binaries, dev versions
http://r.research.att.com/#nightly

---- order tops
order (x$mean)  # 13  4 11  6 14  2  9  7 15  3 10  8  1  5 12
x [order (x$mean,decreasing=T),]
probe        gene             mean                sd
12 var2CSA 3422             4.11813230326446  1.14735317700616
5  var2CSA 3422             4.03239522620239  1.11964978049995
...

---- data.frame tips, data.frame frustrations, data.frame inanities, data.frame annoyances
construct one on the fly
tbl <<- data.frame (cbind (a=LETTERS[1:5], b=LETTERS[3:7], weight=rnorm (5, 2)))


--- data.frame success rbind
[good example in  ~/s/data/sbri/gonzalo/rifins/go.R:find.up.down.reg.genes ()]

construct a data.frame by row.  KEY!  --> supply the first row to the constructor   <-- KEY!
KEY!  --> don't use c () to build up rows: this forces all types to be the same,
typically downgrading numbers to strings. <-- KEY!

template.row = list (gene='dummy',   row=-1, log2ratio=-99,99, sd=-99.99, rifinType='dummy', slideCount=-99)
x = list (gene='PFF1570w',   row=14657, log2ratio=-1.98, sd=2.20, rifinType='B', slideCount=5)
y = list (gene='MAL8P1.208', row=3219,  log2ratio=-1.11, sd=0.56, rifinType='A', slideCount=12)
z = list ('MAL8P1.301', 3211,  -1.32, 0.69, 'AB', 11)

df = data.frame ((x|template.row), stringsAsFactors=FALSE)   # or dummy.first.line
df [1,] = x   # replace the template.row, if you used that approach
df = rbind (df, y)
df = rbind (df, z)
is.factor (df [,'gene'])  # must be TRUE


when constructing a data.frame, don't do the
df = rbind (df, newRow)
this produces useless junk, and warnings galore, like this:
There were 47 warnings (use warnings() to see them)
X.var2CSA.4495.  X.. X.4.00493662383496. X.1.40644004531356.
1     var2CSA 4495         4.00493662383496    1.40644004531356
2             <NA> <NA>                <NA>                <NA>
3             <NA>                     <NA>                <NA>

--- data.frame success cbind
probes = vector (); genes = vector (); means = vector (); sds = vector ();
max = length (good.rows)
for (r in 1:max) {
...
probes [r] = probe.name
genes [r] = gene.name
means [r] = mean.value
sds [r] = stdev
} # for r
result = data.frame (cbind (probes, genes, means, sds))
colnames (result) = c ('probe', 'gene', 'mean', 'sd')
invisible (result)


---- keggsoap

library(KEGGSOAP)
get.genes.by.pathway function (pathway.id)

---- plot.normality = function () {
par (mfrow = c (3, 4))
lapply (1:ncol (ratios), function (col) {
stat = jarque.test (ratios [,col])$statistic;
title = sprintf ('%s: %f', col,stat);
plot (density (ratios [,col]), main=title)
})} # plot.normality

uw r course online:  http://www.stat.washington.edu/fritz/files421.html
var.names = ls (sys.frame ())  # gets global-scope vars when w/in a function

--- sort/order a data frame
RSiteSearch("sort.data.frame")   # drives your browser to a list of results
http://wiki.r-project.org/rwiki/doku.php?id=tips:data-frames:sort
examples:
airquality2 <- airquality [order(airquality$Temp), ]
airquality3 <- airquality [order(airquality$Temp, decreasing = TRUE, na.last = TRUE), ]
dd <- data.frame(b = factor(c("Hi", "Med", "Hi", "Low"),  levels = c("Low", "Med", "Hi"), ordered = TRUE), x = c("A", "D", "A", "C"), y = c(8, 3, 9, 9), z = c(1, 1, 1, 2))
with (dd, dd [order(z, x), ])  #     b x y z
1  Hi A 8 1
3  Hi A 9 1
2 Med D 3 1
4 Low C 9 2
with(dd, dd[order(-z, rev(x)), ]) #     b x y z
4 Low C 9 2
2 Med D 3 1
1  Hi A 8 1
3  Hi A 9 1
--- the generic function sort may now have a specialization for data frames:
sort(dd, by = ~ -z + b)  #   b x y z
4 Low C 9 2
2 Med D 3 1
1  Hi A 8 1
3  Hi A 9 1

.Rprofile
.libPaths ("/users/home/me/rlib')  gets/sets the library trees within which packages are found
source("http://www.bioconductor.org/biocLite.R")
sessionInfo ()  Print version information about R and attached packages.
biocLite (destdir='/users/pshannon/r/packages', lib='/users/pshannon/r/lib')
traceback ()    prints the call stack of the last uncaught error
openVignette () bioconductor only; bioc must be loaded (eg, library (GOstats))
openPDF ("/Library/Frameworks/R.framework/Resources/library/gaggle/doc/gaggle.pdf")
class (x)       class name
slotNames (x)   names of fields (slots) in a variable
typeof (x)      what kind of an object is x?
help (package = "packagename")
help.start ()                  what functions are available in a package?
library (packagename)
ls ("package:packagename")
ls (pat='targets.*topTable')   # find files via regex
validObject (g)
attach (obj); detach (obj);
loop control structures:  next   (like 'continue' in python & java), break
class?ExpressionSet            # get help on the class ExpressionSet
options(error=recover)         # will put you into the debugger

capabilities ()
jpeg      png    tcltk      X11 http/ftp  sockets   libxml     fifo
FALSE    FALSE     TRUE     TRUE     TRUE     TRUE     TRUE     TRUE
cledit    iconv      NLS
FALSE     TRUE     TRUE
myGlobalVar <<- "some value"
options ('width' = 150)    # set the screen width, so that R doesn't wrap wide tables needlessly
v = vector ()              # an extensible list of one base type

-- and, or && || & |
The general rule is that inside an if() you want to use && and ||
because these return a logical value of length one.

When you want a vectorized logical operation, use | and &.  A warning
will be raised if you use & or | inside an if and the returned vector
has length greater than one.  So misuse will be noisy.

-- rep
rep (c (1,2,3), c (3,3,3))         # 1 1 1 2 2 2 3 3 3
values     distribution
rep ('aaa', 5)                     # "aaa" "aaa" "aaa" "aaa" "aaa"

--- precision: digits to print for numeric variables
1...22 with default 7.  See the warning in 'print.default'
about values greater than 15.
as.numeric (options ('digits')) --->   7
options ('digits'=2)

--- with
with (x, statements)  # where x is a data.frame, list, environment, or R data file
with (nba.draft, as.vector (sample (Team,1,prob=Balls))) #  Chicago
with (nba.draft, {as.vector (sample (Team,1,prob=Balls))})

--- list () vs. c ()
error message:   more elements supplied than there are to replace
indicates you are using a vector, not a list. switch from x=c() to x=list()

--- spineplot: a histogram of sorts, with bar widths instead of height;
bars are then divided horizontally by a further attribute
full example: ~/s/study/r/ggobi/tips/go.R: tips.by.day.and.gender ()

spineplot (contingency.table, col=c (DefaultGray, 'orange'),
off=0.5,   # horizontal spacing between bars, in percent
main=''    # no title, since we can't control it
)
title (main='Spineplot', cex.main=2.0)



cd ~/s/study/r/ggobi/crabs/; reload ();
spineplot (tbl$sex ~ tbl$CL, main='Test')
# spineplot is

--- spineplot tips: email from the author

I did not implement the cex.* arguments because there would have
to be a fair number of them making the code somewhat
clumsy. There are two alternatives if you want to increase the
size of the annotation on screen that I could think of, both
have been posted in the thread on R-help (1. suppress annotation
and add afterwards, 2. use par() before calling spineplot()). If
you want to have larger labels for inclusion in a paper or
slides or so, I would recommend to simply print on a smaller
device (keeping the size of the included graphic constant),
e.g.,

pdf("foo.pdf", height = 4.5, width = 4.5)
spineplot(...)
dev.off()
and then (assuming you are using LaTeX):
\includegraphics[width=0.8\textwidth]{foo}

--- plot linetype, lty
0=blank, 1=solid, 2=dashed, 3=dotted, 4=dotdash, 5=longdash, 6=twodash

--- plot linewidth, lwd
lwd=5

--- Point type: pch

pch=19 - solid circle
pch=20 - bullet (smaller circle)
pch=21 - circle
pch=22 - square
pch=23 - diamond
pch=24 - triangle point-up
pch=25 - triangle point down.

---- plot point  (draw just a single point, of specified type, size and color
points (12, 4, pch=16, cex=5, col='blue')

-- matplot tips
plot the columns of one matrix against the other
1) the scale of the first matrix is the x axis
2) the scale of the second matrix is the y axis
3) one column at a time is treated
4) the number of the column is the character printed at the x,y coordinates,
matplot(1:10, (-4:5)^2, main = "Quadratic") # two vectors
m.random = matrix (sample (1:100,100), 10, 5)   #       [,1] [,2] [,3] [,4] [,5]
#  [1,]   14   13   75   35   82
#  [2,]   58   80    5   98   30
#  [3,]   70   59   37   29   52
#  [4,]   64   51   18   27   68
#  [5,]   62   49   78   23   87
#  [6,]   99   28   72   33   94
#  [7,]    9   96   84   74  100
#  [8,]   71   57   47   77   92
#  [9,]   32    4   31   21    6
# [10,]   11   85   42   43    7

--- plot tips
broad example: ~/s/data/isb/richGelinas/ada/fibronectin/lung-vs-liver-plot/go.R
arrows, text, titles, colors
slide show

--- plot tips, shows use of legend, line width, color
(from ~/s/data/galas/jihoon/acetaminophen/pathways/go.R)
library (RColorBrewer)
hours = as.integer (sapply (tbls, function (t) return (strsplit (t, ".h")[[1]][2])))
columns.trimmed <<- which (colMeans (m) > 1.0)
column.names <<- as.character (sapply (colnames (m [, columns.trimmed]), function (id) subset (tbl.kegg, path_id==id)$path_name))
dz.columns <<- grep ('cancer|diabetes', column.names)
columns.trimmed <<- columns.trimmed [- dz.columns]
m.trimmed = m [, as.numeric (columns.trimmed)]
color.palette = 'Paired'
color.palette = 'Accent'
color.palette = 'Set2'
colors =  brewer.pal (ncol (m.trimmed), color.palette)
line.types = rep (1:6, 5)
plot (xlim=c(0,72), ylim=c(0,8), main='Pathway Enrichments by Time', xlab='Hour', ylab='-log10 (pG)',
xaxt='n',
x=NA, y=NA,
type='l')
#for (r in 1:ncol (m)) {
for (r in 1:ncol (m.trimmed)) {
lines (x = hours, y=m.trimmed[, r], type='b', col=colors[r], lty=1, lwd=3)
}
axis (1, at=hours, labels=as.character (hours), col.axis="black", las=0)
legend.titles = as.character (sapply (colnames (m.trimmed), function (id) subset (tbl.kegg, path_id==id)$path_name))
legend (50, 8, legend.titles, colors)


---- plot type tips
p for *p*oints,
l for *l*ines,
b for *b*oth,
c for the lines part alone of '"b"',
o for both '*o*verplotted',
h for '*h*istogram' like (or 'high-density') vertical lines,
s for stair *s*teps,
S for other *s*teps, see 'Details' below,
n for no plotting.

---- plot tips: pairs tips,  color tips
pairs (tbl.train [, 2:5], col=ifelse (tbl.train$Speciesname=='setosa', 'blue',
ifelse (tbl.train$Speciesname=='versicolor', 'red', 'green')))

---- plot tips: sd and error bars
try having a look at the plotCI function from gplots, for plotting error bars and confidence intervals.

--- plot tips, take control of the axis, plot axis
x.axis.labels = c ('one', 'two', 'three', 'four')
plot (y=log10(line.all.snps), x=1:4,
main='Simple Recessive Disease Model SNPs as a\nFunction of Family Configuration',
xlab='Family Members Included in Search',
ylab='SNP Count',
xaxt='n',
yaxt='n',
cex.main=1.3, cex.lab=1.2, type='l',
xlim=c(0.5,4.5),
ylim=c (0,7),
col='purple', lwd=2)
lines (y=log10 (line.exonic.snps), 1:4, type='l', col='blue', lwd=2)
lines (y=log10 (line.novel.snps), 1:4, type='l', col='dark green', lwd=2)
lines (y=log10 (line.exonic.novel.snps), 1:4, type='l', col='black', lwd=2)
lines (y=log10 (line.disruptive.snps), 1:4, type='l', col='red', lwd=2)
axis (1, at=1:4,labels=x.axis.labels, col.axis="black", las=0)
axis (2,
at=0:7,
labels=c('1','10',
expression (10^"2"),
expression (10^"3"),
expression (10^"4"),
expression (10^"5"),
expression (10^"6"),
expression (10^"7")),
las=2)


---- plot axis tips: horizontal exponential labels
horizontal: las=2
exponents:  expression (10^"6")
font size: cex.axis=1.1

---- plot tips: date axis
tbl.date.paul$Date <<- as.Date (tbl.date.paul$Date, "%m/%d/%Y")  # convert, eg, 05/19/2009 to standard form
plot (tbl.date.paul$Date, tbl.date.paul$Balance, type='l', col='green', ylim=c(-500, 5000))  # plot detects date type, labels x axis appropriately

---- plot tips: multiple plots on one device
x11 (width=17, height=10)   # fill macbook screen
par ('mfrow' = c (1,2))     # plot in 1 row, 2 columns
yBounds = c (-0.2, maxY); plot (densityRaw, col=rawColor, ylim=yBounds)  # specify bounds of y axis

---- plot tips: font size, hist tips
hist (s, xlab='score', main='yck1d primary motif scores', cex.main=2, cex.lab=1.5, cex.axis=1.5)
good examples, from the ggobi tips dataset:  ~/s/study/R/ggobi/tips/go.R, for example:
hist (tbl [,'tip'], breaks=seq (0,10,0.1), ylim=c(0,40), labels=T, xlab='Tip Amount', main='10 cent bins',
cex.main=2, cex.lab=1.5)

--- plot tips, barplot tips, cex maninpulations
barplot labels controlled by cex.names:
lfc = c (-3, 0, 1)
names (lfc) =  c ('A', 'B', 'C')
barplot (lfc, main='log fold-change', cex.main=2, cex.axis=1.5, cex.names=1.5, col=c ('green', 'white', 'red'))


--- plot tips, text tips, locate tips, locator tips
# use locator () to find points on surface in the appropriate coordinate system.  left button chooses point, right button ends function
text (6.5, 34, 'Note concentration at dollar', cex=1.2)    # center this line of text at x=6.5
text (6.5, 32.5, 'and half-dollar amounts.', cex=1.2)

# seems to
text (6.5, 34, 'Note concentration at dollar', cex=1.2)
text (6.5, 32.5, 'and half-dollar amounts.', cex=1.2)


- plot tips, legend for cory
tbl <- data.frame(geneA=1:10, geneB=21:30, apoe=sample(c(31,32,32,44), size=10, replace=TRUE), stringsAsFactors=FALSE)
map <- list("31"="red", "44"="yellow", "32"= "blue")
tbl$color <- unlist(lapply(tbl$apoe, function(value) map[[as.character(value)]]))
tbl$color <- unlist(lapply(tbl$apoe, function(value) map[[as.character(value)]]))
with(tbl, plot(geneA, geneB, col=color))
legend.titles <- names(map)
colors <- as.character(map)
legend (6.5, 25, legend.titles, pch=16, col=colors)  # makes box with 2 rows


--- plot tips, more hist tips



par (mfrow = c (1,2))   # two plots in one window
par (mai=c (1,1,1,1))   # one inch margin all around
#-- traditional style
hist (tbl [,'tip'], breaks=seq (0.5,10.5,1), ylim=c(0,100), labels=T, xlab='Tip Amount',ylab='Count', main='$1 bins', cex.main=2, cex.lab=1.5)
axis (1, at = seq (1,10,1))
hist (tbl [,'tip'], breaks=seq (0,10,0.1), ylim=c(0,40), labels=T, xlab='Tip Amount', ylab='Count', main='10 cent bins', cex.main=2, cex.lab=1.5) #, cex.axis=1.5)
axis (1, at = seq (1,10,1))
text (7, 34, 'Note concentration at dollar', cex=1.2)
text (7, 32.5, 'and half-dollar amounts.', cex=1.2)

---- plot tips: jitter
introduce some noise into a vector of numbers, to reduce overlap in
plotting:
plot (jitter (as.numeric (subset (iris, Species=='setosa', select=Petal.Width) [,1])))

---- plot tips: legend and main title
plot.title = orf.name
plot (anemic, col='red', pch=16, cex=1, ylim=c(-5,5), main=plot.title)
legend (6.5, 5, c('anemic', 'normal'), pch=16, col= c('red', 'green'))  # makes box with 2 rows

---- plot tips: parameters, par, pch

xpd=T|F: clip to plot or to figure region
plot (vector, col='red', cex=5)   # red, largish circles
pch: data symbol type  (see R Graphics, p 69)
1) circle
2) triangle
3) cross
4) x
5) diamond
6) down-pointing triangle
7) rectangle with x
8) asterik
9) diamond with cross
10) circle with cross
11)
12)
13)
14)
15)
16) filled circle, sort of

--- plot tips: set margins of graphics device
par (mai=c (1,1,1,1))   # one 'inch' all the way around

--- plot tips, splom tips, lattice, scatter plot matrix
library (lattice)
data (iris)
super.sym <- trellis.par.get("superpose.symbol")
splom (~iris[1:4], groups = Species, data = iris, panel = panel.superpose,
key = list (title = "Three Varieties of Iris",
columns = 3,
points = list(pch = super.sym$pch[1:3],
col = super.sym$col[1:3]),
text = list(c("Setosa", "Versicolor", "Virginica"))))


---- generate sequence of numbers
pretty (c (-3.25, 3.25), 10)
-3.5 -3.0 -2.5 -2.0 -1.5 -1.0 -0.5  0.0  0.5  1.0  1.5  2.0  2.5  3.0  3.5
seq (-3.25, 3.25, 0.5)
-3.25 -2.75 -2.25 -1.75 -1.25 -0.75 -0.25  0.25  0.75  1.25  1.75  2.25  2.75  3.25

---- exec a command
result = system ('ls', intern=T)

--- grid.text, grid graphics:  put two strings right next to each other, in two colors
library (grid)
grid.newpage ()
s = 'hallo!'
gp.1 <<- gpar(fontsize=40, fontfamily='Courier', col='red')
grid.text (s, y=unit (6, 'lines'), x=unit(5, 'char'),  gp=gp.1)
gp.2 <<- gpar(fontsize=40, fontfamily='Courier', col='blue')
grid.text (s, y=unit (6, 'lines'), x=unit(5, 'char') + stringWidth(s),  gp=gp.2)

------  expand.grid(1, 5:7, 2:3)
Var1 Var2 Var3
1    1    5    2
2    1    6    2
3    1    7    2
4    1    5    3
5    1    6    3
6    1    7    3
>
---- plotting
x11 (width=17, height=10)   # fill macbook screen
par ('mfrow' = c (1,2))     # plot in 1 row, 2 columns
yBounds = c (-0.2, maxY); plot (densityRaw, col=rawColor, ylim=yBounds)  # specify bounds of y axis

--- create submatrix, subtable, picking out columns at intervals
dat <- read.table(....)
signalMatrix <- as.matrix(dat[,seq(2,ncol(dat),3)]) # extract every third  olumn starting with the second column
detectionMatrix <- as.matrix(dat[,seq(3,ncol(dat),3]) # And start with the third column, etc.

---- machine learning in R, web pages, 2006
http://www.economia.unimi.it/projects/marray/2006/material/Lab3/MachineLearning/

--- install package in a local lib directory
R CMD INSTALL -l ~/lib/r
--- 'number of items to replace is not a multiple of replacement length'
x = list ()
x ["GO:0016020"] = c ('2200', '710')
Warning message:  number of items to replace is not a multiple of replacement length
x [["GO:0016020"]] = c ('2200', '710')   # okay!

--- data packages
has MASS, used in UsingR, Venable & Ripley
curl http://cran.r-project.org/bin/macosx/universal/contrib/r-release/VR_7.2-30.tgz > VR_7.2-30.tgz

--- RUnit
checkEquals(target, current, msg, tolerance = .Machine$double.eps^0.5, checkNames = TRUE, ...)
checkEqualsNumeric(target, current, msg, tolerance = .Machine$double.eps^0.5, ...)
checkIdentical(target, current, msg)
checkTrue(expr, msg)
checkException(expr, msg, silent=FALSE)
DEACTIVATED(msg)

   checkException(
      tbl.2vars <- TReNA:::.parseVariantString(mm, "rs3763040:C"),
      "caught!", silent=TRUE)



---- file tips, delete files and directories
unlink ('unitTestDirectory', recursive=TRUE)

--- file i/o
f = file ('test.noa', 'w')
cat ('ho yo\n', file=f)
close (f)

--- file exists, i/o, more details  (from aphelion, cd ~/examples/r/writeNoa/)

writeNodeAttributeFile = function (dataList, attributeName, filename, directory='./') {
if (!file.exists (directory))
dir.create (directory, recursive=TRUE)
if (length (grep ('/$', directory)) == 0) # add trailing / if needed
directory = paste (directory, '/', sep='')
fullFilename = paste (directory, filename, sep='')
f = file (fullFilename, 'w')
cat (paste (attributeName, '\n', sep=''), file=f)
names = names (dataList)
for (n in 1:length (names)) {
name = names [n]
value = dataList [[name]]
s = paste (name, ' = ', value, '\n', sep='')
cat (s, file=f)
}
close (f)
}

---  dhyper: understanding GOstats use of hypergeometic probability (21 apr 2007)

--  Kng1 and Hrg are annotated to cysteine protease inhibitor activity
2 genes, 25 in the organism, 72 in the cancer set, maybe 16000 in the gene universe
dhyper (2, 25, 16000, 72) = 0.00539982

--  receptor activity
16880   0.982489165732104       2       1354
17836


--- table basics
table (someVector) finds the unique values, tablulates their frequencies
table (c (1, 1, 1, 999, 15)) -->   1  15 999
3   1   1

--- create a mis-leading barplot, with non-zero ylim, labels and main title
beer = scan ()   [typ in numbers: 1: 3 4 1 1 3 4 3 3 1 3 2 1 2 1 2 3 2 3 1 1 1 1 4 3 1]
table(beer)  -->   beer
1  2  3  4
10  4  8  3
barplot (table (beer)/length(beer), xlab="type", ylab="proportion", main="Beer",ylim=c(0.1, 0.5),xpd=F)

--- labeled piechart (deprecated, since barplots do a better job of displaying differences)
tbeer = (table (beer))
names (tbeer) = c ('domestic can', 'domestic bottle', 'microbrew', 'import')
pie (tbeer, main='BEER')

--- dotchart is a barplot turned 90 degrees (looks like a horserace, going left to right)
dotchart (tbeer, main='BEER')

--- dotchart of malpractice awards, sorted, by state
data (npdb)  (from UsingR)
dotchart (sort (table (npdb [,'state'])))

--- table (table (npdb$ID))
table (ID):  6797 doctor id's, with number of malpractice suits for each
table (table (ID)):  how many doctors had 1, 2, 3, ... 73 suits against them

1    2    3    4    5    6    8   11   15   22   73
6105  235   12    4    7    1    1    1    1    1    1

which physican had 73 suits?
tid = table (ID)
tid [tid == 73]   --> 171491
73
rownames (tid) [which (tid == 73)] -->  "171491"

--- a data.frame is not a table nor a matrix

data.frames: tightly coupled collections of variables which share
many of the properties of matrices and of lists, used as the
fundamental data structure by most of R's modeling software.
typeof (some data.frame) == 'list'

A data frame may for many purposes be regarded as a matrix with
columns possibly of differing modes and attributes. It may be
displayed in matrix form, and its rows and columns extracted using
matrix indexing conventions.

data frames are matrix-like structures, in which the columns can
be of different types. Think of data frames as `data matrices'
with one row per observational unit but with (possibly)
both numerical and categorical variables. Many experiments are
best described by data frames: the treatments are categorical but
the response is numeric.'

A data frame is a list with class "data.frame". There are
restrictions on lists that may be made into data frames, namely

* The components must be vectors (numeric, character, or logical),
factors, numeric matrices, lists, or other data frames.
* Matrices, lists, and data frames provide as many variables to the
new data frame as they have columns, elements, or variables, respectively.
* Numeric vectors, logicals and factors are included as is, and
character vectors are coerced to be factors, whose levels are
the unique values appearing in the vector.
* Vector structures appearing as variables of the data frame
must all have the same length, and matrix structures must all
have the same row size.


this works:
rownames (df), colnames

this doesn't:
dim (df)


--- rJava  lib.so problem, solved with LD_LIBRARY_PATH
the error:
library (rJava)
Error in dyn.load(x, as.logical(local), as.logical(now)) :unable to load shared library '/depot/R-2.4.0/lib/R/library/rJava/libs/rJava.so':
libjvm.so: cannot open shared object file: No such file or directory Error in library(rJava) : .First.lib failed for 'rJava'

the solution:
for example, on linux at sbri:
export LD_LIBRARY_PATH=/depot/jdk-1.5.0_08/jre/lib/i386/client:/depot/R-2.4.0/lib/R/library/rJava/libs

--- modulo and integer division
5 %% 2   -> 1
4 %% 2   -> 0
4.55 %% 2  ->  0.55
4.55 %/% 2 ->  2
>

--- negative indices [see  verzani, p 29]
primes [-1]     # 304 element array of doubles, without the first element
primes [-304]   # without the last
primes [-1] - primes [-304] # pairwise subtraction, a-b, with a being
# elements 2,3,...,n, and b being 1,2,...,n-1
# yielding the difference between successive elements

--- set operations
union(x, y)
intersect(x, y)
setdiff(x, y)
setdiff(y, x)
setequal(x, y)
is.element(x, y) is identical to 'x %in% y'.
duplicated (x)

---- subset a matrix
x = matrix (seq (9), 3, 3)
colnames (x) = c ('a', 'b' , 'c')
a b c
[1,] 1 4 7
[2,] 2 5 8
[3,] 3 6 9

subset (x, x [,'b'] > 5)           a b c
[1,] 3 6 9

subset (x, x [,'b'] > 4 & x [,'c'] < 9)    a b c
[1,] 2 5 8

---- subset cm, a large 5 column matrix, with rownames for proteins
colnames (cm) ->  "tz145" "tz638" "tz199" "tz046" "ratio"
t0 = is.na (cm [,'tz145']) & is.na (cm [,'tz199'])
subset (cm, t0)[1:5,]
tz145 tz638 tz199 tz046       ratio
3503          NA  35.3    NA  52.5    1.487252
11026         NA   6.0    NA   7.4    1.233333
AAQ05741.1    NA    NA    NA  27.3 1000.000000
AAN37262.1    NA    NA    NA   1.3 1000.000000
ABE97274.1    NA    NA    NA  28.2 1000.000000


---- subset  a table
subset (t, M < 2, select = ID)
subset (tt1, ID %in% c ("N170_4"))
ID        M      P.Value
5752  N170_4 5.932804 1.047175e-07
15352 N170_4 5.995971 1.182754e-07


---- setdiff
setdiff (c ('a', 'b', 'c', 'd'), c ('a', 'd', 'f')) -->  "b" "c"
setdiff (c ('a', 'd', 'f'), c ('a', 'b', 'c', 'd')) --> "f"

---- .Rdata operations, save tips

save (g, file='example.Rd')
save (list=c ('g', 'nodes'), file='example.Rd')
load ('example.Rd')

cat (probeNames, file="probeNames.txt", sep="\n")

---- environments (aka hash maps, associative arrays)
tsvFile = '/Users/mpshannon/data/sbri/susan/probe-to-genes/probeToGene.tsv'
t = read.table (tsvFile, sep='\t')
map = new.env ()
x = apply (t, 1, function (r) assign (r[[1]], r[[2]], envir=map})
oldRowNames [1:10]
[1] "oPFK12891" "N170_4"    "Ks157_2"   "Ks157_1"   "A10325_32" "Kn2020_1"
[7] "M58736_5"  "IL2"       "F65043_4"  "F65043_3"
newRowNames =  as.character (mget (oldRowNames, env=map, ifnotfound=oldRowNames))
newRowNames [1:10]
[1] "oPFK12891"   "N170_4"      "Ks157_2"     "Ks157_1"     "PFA0110w"
[6] "PF07_0004"   "MAL13P1.356" "IL2"         "MAL7P1.7"    "MAL7P1.7"


---- directory manipulations
getwd ()
setwd ('new/directory')
list.files ()
file.create (...)
file.exists (...)
file.remove (...)
file.rename (from, to)
file.append (file1, file2)
file.copy (from, to, overwrite = FALSE)
file.symlink (from, to)
dir.create (path, showWarnings = TRUE, recursive = FALSE)


Sys.sleep (2)     sleep for 2 seconds
DYLD_PRINT_LIBRARIES=1 R    if you want to know which dylibs get loaded, start R like this:

quartz (width=8, height=8) or x11 ()  # create new active plotting window
par (mfrow=c(2,3))  # create a 6 plot window, 2 rows & 3 columns
dev.off ()  # deletes active plotting window
plot (p12,p13, type='b')

---- add column
copy original to wider matrix, then explicitly assign that column

---- delete rows & columns from table or matrix

tbl2 = (tbl [,-c(7,8,9,10,11,12,13)])   # funny off-by-one errors...
tbl2 = tbl [, seq (1,6)]                # postive extraction, not deletion
m = matrix ( nrow =17, ncol=34)
m  [,'columnName'] = NULL        # delete a column, shrinking the dimension
newMatrix = m [-12,]             # delete a row

which (x == "EMPTY")             # delete undesirable element "EMPTY" from x
newX = x [-34]]
or
newX = x [-(which (x=="EMPTY"))]

---- run R in batch, with a script  (and remotely!)
ssh db 'R --no-save < /net/dblocal/wwwspecial/gaggle/R/packages/gaggle/1.0/rebuild.R'


---- vectors vs. lists
vectors are homogenous: x = c (8, 9, 'a')  -->  "8" "9" "a"
lists are heterogeneous: list (8, 9, 'a')  --> [[1]] [1] 8  [[2]] [1] 9  [[3]] [1] "a"

list elements are obtained with the [[i]] operator

--- string tips
functions:
toupper, tolower
strsplit
paste
grep:
s = "0929a01(Amp1)"; grep ('\\(.*\\)', s) # 1
grep ('\\(.*\\)', s, value=T)             # "0929a01(Amp1)"

sub, gsub  (replace once, replace global)
gsub ('\\(.*\\)', '', s)  #  "0929a01"

count matches:  length (gregexpr ('\\.', '[MFIVL]......A.[st]')[[1]])  # 7

--- regex tips, replace, use grouping:  \\n recalls parenthetical match

gsub  ('S\\[166.9984\\](..)S\\[166.9984\\]', 's\\1s', x) #  "K.RPVASsAGsENNDHLDDMNHLR"

--- regex tips, extraction
gsub ('a(.*?)ef', '\\1', 'abcdef')   # "bcd"

--- ungreedy vs greedy gsub:   perl=T required
gsub ('a.*?b', 'XX', 'aaaabbbbcccccbbb', perl=T)  #  "XXbbbcccccbbb"
gsub ('a.*b', 'XX', 'aaaabbbbcccccbbb', perl=T)   #  "XX"

nchar
substr
letter ('paul', 3) # u     # by me: letter = function (s, n) return (substr (s, n, n))
# letter is also in Biostrings

unlist (strsplit ('FBgn0020638|FBgn0020637|FBgn0042120', '\\|'))
[1] "FBgn0020638" "FBgn0020637" "FBgn0042120"

-- agrep tips, fuzzy matching
grep ("abc", c("abbc", "jdfja", "cba"))  # numeric(0)
agrep ("abc", c("abbc", "jdfja", "cba")) # [1] 1

-- regex character classes
s =  'HEIE!KSTYHAKIKKsDSGTVLGAIPLNSRS'
grep ('[0-9A-Za-z]', s)  #  1
grep ('[[:alnum:]]', s)  #  1

? any punctation characters?
grep ('[[:punct:]]', s)  #  1  (note the exclamation mark)

'[:alnum:]' Alphanumeric characters: '[:alpha:]' and '[:digit:]'.
'[:alpha:]' Alphabetic characters: '[:lower:]' and '[:upper:]'.
'[:blank:]' Blank characters: space and tab.
'[:cntrl:]' Control characters.  In ASCII, these characters have octal codes 000 through 037, and 177 ('DEL').
'[:digit:]' Digits: '0 1 2 3 4 5 6 7 8 9'.
'[:graph:]' Graphical characters: '[:alnum:]' and '[:punct:]'.
'[:lower:]' Lower-case letters in the current locale.
'[:print:]' Printable characters: '[:alnum:]', '[:punct:]' and space.
'[:punct:]' Punctuation characters: '! " # $ % & ' ( ) * + , - . / : ; < = > ? @ [ \ ] ^ _ ` { | } ~'.
'[:space:]' Space characters: tab, newline, vertical tab, form feed, carriage return, and space.
'[:upper:]' Upper-case letters in the current locale.
'[:xdigit:]' Hexadecimal digits: '0 1 2 3 4 5 6 7 8 9 A B C D E F a b c d e f'.

-- moral equivalent of 'find'
s = "R.SQS[166.9984]LTS[166.9984]SVANNAPQSVRDDVELPETLEER"
gregexpr ('\\[', s)[[1]][1] >= 0   # TRUE
gregexpr ('\\[', 'XXXX')[[1]][1] >= 0    # FALSE
gregexpr ('[sty]', 'STY')[[1]][1] >= 0   # FALSE
gregexpr ('[sty]', 'StY')[[1]][1] >= 0   # TRUE


-- regex tips, gregexpr tips, matching tips
seq =  "MKYLAAYLLLVQGGNAAPSAADIKAVVESVGAEVDEARINELLSSLEGKGSLEEIIAEGQKKFATVPTGGASSAAAGAAGAAAGGDAAEEEKEEEAKEESDDDMGFGLFD*"
# find all the 3-letter subsequences which start with A, followed by any character, followed by one or more of K,M,E,L,Y
match =  gregexpr ('A.[KMELY]+', seq)[[1]]
[1]  5 87 96
attr(,"match.length")
[1] 6 9 4
for (m in 1:length (match)) {
start = match [m];
size = attr (match, 'match.length')[m];
s = substr (seq, start, start+size);
print (s)
}
[1] "AAYLLLV"
[1] "AAEEEKEEEA"
[1] "AKEES"


-- grep tips
grep ("EMPTY", x) ->  34
grep ("empty", x, ignore.case=T) -> [1] 34
newX = x [-grep ("EMPTY", x, ignore.case=T)]

nm = rownames (state.x77)
grep ("^M", nm)
#  19 20 21 22 23 24 25 26
grep ("^M", nm, value=TRUE)
[1] "Maine"         "Maryland"      "Massachusetts" "Michigan"
[5] "Minnesota"     "Mississippi"   "Missouri"      "Montana"


--- use grep in table subsetting
nm = rownames (state.x77)
grep ("^M", nm)  # [1] 19 20 21 22 23 24 25 26
grep ("^M", nm, value=T)
[1] "Maine"         "Maryland"      "Massachusetts" "Michigan"
[5] "Minnesota"     "Mississippi"   "Missouri"      "Montana"
nm %in% grep ("^M", nm, value=T)
[1] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE
[13] FALSE FALSE FALSE FALSE FALSE FALSE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE
[25]  TRUE  TRUE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE
[37] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE
[49] FALSE FALSE
start.with.M = nm %in% grep ("^M", nm, value=T)
subset (state.x77, start.with.M)
Population Income Illiteracy Life Exp Murder HS Grad Frost   Area
Maine               1058   3694        0.7    70.39    2.7    54.7   161  30920
Maryland            4122   5299        0.9    70.22    8.5    52.3   101   9891
Massachusetts       5814   4755        1.1    71.83    3.3    58.5   103   7826
Michigan            9111   4751        0.9    70.63   11.1    52.8   125  56817
Minnesota           3921   4675        0.6    72.96    2.3    57.6   160  79289
Mississippi         2341   3098        2.4    68.09   12.5    41.0    50  47296
Missouri            4767   4254        0.8    70.69    9.3    48.8   108  68995
Montana              746   4347        0.6    70.56    5.0    59.2   155 145587

-- grep to get indices
colnames (coverageMatrix)
"m0046gel" "m0046scx" "m0046wax" "m0199gel" "m0199scx" "m0199wax" "p0029scx" "p0145gel"
"p0145scx" "p0145wax" "p0241scx" "p0331scx" "p0403scx" "p0638gel" "p0638scx" "p0638wax"
grep ('^p', colnames (coverageMatrix))  #   7  8  9 10 11 12 13 14 15 16
grep ('^m', colnames (coverageMatrix))  #   1 2 3 4 5 6

-- substring
substring ('leo duva shannon', 1,3) -->  "leo"



---- emacs rss mode tips
ctr-c ctr-j  runs the line
ctr-c ctr-r  runs the region - mark the beginning of the region with ctr-spc
ctr-c ctr-b  runs the buffer

---- get old version
http://cran.cnr.berkeley.edu/bin/windows/base/old/

---- startup
?Startup
on mac os 10.4, with R 2.1.1:
/Library/Frameworks/R.framework/Versions/2.1.1/Resources/etc/Renviron
Kickstarting R:  http://cran.r-project.org/doc/contrib/Lemon-kickstart/

to expand the library search path, add this line to ~/.Renviron
R_LIBS=/path1:/path2

----- set operations, set ops
help (union, PKG=base)

(x <- c(sort(sample(1:20, 9)),NA))
(y <- c(sort(sample(3:23, 7)),NA))
union(x, y)
intersect(x, y)
setdiff(x, y)
setdiff(y, x)
setequal(x, y)

## True for all possible x & y :
setequal( union(x,y),
c(setdiff(x,y), intersect(x,y), setdiff(y,x)))

is.element(x, y)# length 10
is.element(y, x)# length  8

intersect (c (1,2,3), c (3,4,5)) --> [1] 3


----- bayesian package
install.packages("deal",depend=TRUE)
R> library(deal)
R> demo(ksl)

----- examine shell environment
Sys.getenv ('CLASSPATH')

----- read names from a file
genes = readLines ('networkGenes.txt')

----- plot using x11 on macos
x11 (display=":0")   --> an empty plot window appears
plot (1:5)           --> basic plot

----- have R read (and install) packages from a local library
burak says:
I created a .Renviron and added
R_LIBS=/users/bkutlu/lib/R/:/usr/lib/R/library/

----- read tsv file into a data frame; file has many missing values we want to be filled with NA's
# fill: pad out missing values
# stringsAsFactors=FALSE  # don't construe them as experimental factors. here they are IPI ids
# na.strings=''           # could be list.  these are produced by fill=T, and then converted to NA
f = '~/data/human/huiZhang/brca/eifPepxml/EIF_Cancer_20patients_target2pepxml.tsv'
cancer.alignedPeptides = read.table (f, sep='\t', fill=TRUE, header=TRUE, stringsAsFactors=FALSE, na.strings='')  # 485 x 10

----- read tab-delimited matrix file into a matrix

df = read.table ("matrix.ratio", row.names=1, header=T, sep="\t")
summary (df)    # gives info like this:
bat.vs.bat.sig      cmyc1.vs.cmyc1        X
Min.   :-0.309000   Min.   :-0.62300   Mode:logical
1st Qu.:-0.042000   1st Qu.:-0.08800
Median :-0.002000   Median : 0.05800
Mean   :-0.003423   Mean   : 0.02704
3rd Qu.: 0.035000   3rd Qu.: 0.16800
Max.   : 0.430000   Max.   : 0.50300
boxplot (df$bat.vs.bat.sig, df$cmyc1.vs.cmyc1)

--- read tab-delimted matrix into table, forcing numerical column to be a character
(useful for entrez geneID's)
read.table ('tmp.tsv', header=T, sep='\t', colClasses = "character")

----- read tab-delimited matrix file into a matrix, skipping some columns
colClasses = c ("character", "NULL", "NULL", "NULL", "character", "character", ...)
# "NULL" columns are skipped
colnames (read.table ('first5.tsv', header=T, as.is=T, row.names=1, sep='\t', colClasses=colClasses))

----- info on installed packages, by example
> packageDescription ("rJava")
Package: rJava
Version: 0.1-10
Title: Low-level R to Java interface
Author: Simon Urbanek <urbanek@research.att.com>
Maintainer: Simon Urbanek <urbanek@research.att.com>
Depends: R (>= 1.5.0)
Description: Low-level interface to Java VM very much like .C/.Call
and friends. Allows creation of objects, calling methods and
accessing fields.
License: GPL version 2 or newer
URL: http://www.rosuda.org/software/rJava/
Built: R 2.1.1; powerpc-apple-darwin7.9.0; 2005-08-03 10:36:19; unix
-- File: /Library/Frameworks/R.framework/Resources/library/rJava/DESCRIPTION


----- build from source on linux (hazel) (v 2.1.1, 22 jul 2005)
download R-2.1.tar-gz to ~/ftp
tar xf ~/ftp/R-2.1.1.tar
cd R-2.1.1
./configure --prefix=/local --enable-R-shlib
make; make check; make install
dynamic R library needed by JGR, is it there?
find /local/lib -name libR.so -> /local/lib/R/lib/libR.so
5263927 Jul 22 12:43 /local/lib/R/lib/libR.so

this version (2.1.1) did not work with JGR 1.2
>  broadcast (rownames (m0))
Error in lazyLoadDBfetch(key, datafile, compressed, envhook) :
open failed on /usr/lib/R/library/datasets/data/Rdata.rdb
Error in get(objects[i]) : recursive default argument reference
Error in get(objects[i]) : recursive default argument reference
Error in get(objects[i]) : recursive default argument reference

so now, try building R 2.1.0, and installing it for JGR to use:
cd ~/src/R-2.1.0
hazel.R-2.1.0>  ./configure --prefix=/local/R210 --enable-R-shlib
make; make check; make install

----- get info on function or package
find ("functionname")
packageDescription ("packagename")


Here are 3 examples of creating histograms in R

---------------- example 1

R
> x <- c (1, 2, 3, 1, 1, 1, 5)
> hist (x)       produces expected histogram

----------------- example 2
R
> h0 <- scan ("junk11.data")    # Read 11 items
> h0                            #  [1] 1 1 1 1 5 5 5 9 9 9 8
> hist (inp)

> x <- scan ("junk36.data")     # Read 36 items
> x
[1] 1 2 2 3 3 3 4 4 4 4 5 5 5 5 5 6 6 6 6 6 6 7 7 7 7 7 7 7 8 8 8 8 8 8 8 8
> hist (x,breaks=-1:10, axes=FALSE)  # specify custom binning
> axis (1,-1:10)
> axis (2,0:10)


----------------- example 3: custom labeling on x axis, print to a postscript file

R
> x <- scan ("geneFusionVsInteractome.allDistances")   # Read 5928 items
> postscript ("geneFusionVsInteractome.hist.ps")
> hist (x, axes=FALSE, main='Gene Fusion Predictions vs. Interactome')
> axis (2)
> for (x in 0:10) { text (-0.5 + x, -70, (x-1));}
> dev.off ();


------------ determine the type of an R object
typeof (c (1, 2, 3))  # a vector of double, result is 'double'

------------ operations in the r goose, on a data matrix
colnames (m), rownames (m), dim (m)
> m
cu__0700um_vs_NRC-1 cu__0850um_vs_NRC-1 cu__1000um_vs_NRC-1
VNG0006G                1.74               0.050               0.415
VNG0008G                0.54               0.925               1.015

get value at [1,1] as a labeled submatrix:  m [1]
get value at [1,1]:  m [[1]]
get 1st row (with column titles):  m [1,]
get 1st column (with row titles):  m [,1]
transpose matrix: t (m)

------------ loop over rows of a matrix
dim (m2) -> [1]  5 32
for (i in 1:5) { print (max (as.numeric (m2 [i,])))}

------------ for correlation of two vectors (having same length
dim (m0)
cor (m0 [1,], m0 [2,])     # returns a double

------------ apply a function to each row
[find the correlation of row 1 with all rows, one at a time]
standard form:  apply (X, (1|2|c(1,2)), function, optional arguments to that function)
apply (m2, 1, cor, m2 [1,])
VNG0001H    VNG0002G    VNG0003C    VNG0005H    VNG0006G
1.00000000  0.42891348  0.58519318 -0.01383992  0.28358115


------------ for correlation between a one row matrix, and each row of a big matrix
for (i in 1:2400) {print (cor (as.numeric (ibp [1,]), as.numeric (all [i,])))}

-----------  calculate the mean of a matrix, taken row by row, then correlations
of each row to that mean
dim (m0)   -> 9 166
avg = as.numeric (apply (m0, 2, mean))
length (avg) -> 166
cor (avg, m0 [1,])  -> 0.8931806
apply (m0, 1, cor, avg)
VNG0451G  VNG0452G  VNG0453G  VNG0455G  VNG0458G  VNG0535C  VNG2302G  VNG2483G  VNG2531G
0.8931806 0.9452814 0.9095135 0.8900737 0.7567349 0.8894644 0.8941343 0.8133812 0.8779917
correlations = apply (m0, 1, cor, avg)
correlations [1] ->  VNG0451G
0.8931806
x = correlations    # for convenience
x [ x > 0.9]
VNG0452G  VNG0453G
0.9452814 0.9095135
names (x [ x > 0.9]) -> [1] "VNG0452G" "VNG0453G"    # a vector
sel = as.list (names (x [ x > 0.9]))
[[1]]
[1] "VNG0452G"
[[2]]
[1] "VNG0453G"
(this is suitable for broadcast)

----- normalize a vector
transform vector so that mean is zero, and stddev  [sqrt (var (vec))] is 1
norm = function (vec) {m=mean (vec); s = sqrt (var (vec)); return ((vec-m)/s);}

-----------  normalize a matrix, normalize microarray data
accomplish this: broadcast (normalize (m0))
dave reiss suggests, for each row:
find the mean and the variance
subtract the mean, divide by the variance
use sapply to build the new matrix from the old

also see http://www.maths.lth.se/help/R/.R/library/limma/html/4normalization.html


--------- find all rows in a (gaggle/dmv) matrix which contain only positive numbers
dim (m3) -> 5, 3
m3
cu__0700um_vs_NRC-1 cu__0850um_vs_NRC-1 cu__1000um_vs_NRC-1
VNG0001H               0.092               0.092               0.093
VNG0002G               0.070               0.111               0.168
VNG0003C               0.058               0.037               0.019
VNG0005H              -0.062               0.027               0.086
VNG0006G              -0.051               0.007               0.023

rownames (m3) [apply (m3, 1, function (i) all (i > 0))] ->  "VNG0001H" "VNG0002G" "VNG0003C"
rownames (m3) [apply (m3, 1, function (i) any (i < 0))] ->  "VNG0005H" "VNG0006G"

--------- find all rows in a (gaggle/dmv) matrix which, column by column, show a pattern
rownames (m3) [apply (m3, 1, function (i)  (i [1] > 0))] ->  "VNG0001H" "VNG0002G" "VNG0003C"
rownames (m3) [apply (m3, 1, function (i)  (i [1] > 0 && i [2] < 0.1))] "VNG0001H" "VNG0003C"

----- How do I test if a data.frame has a column named X?
is.na (match ("X", names (df)))
Mere syntactic sugar, but self-documenting:
"X" %in% names(mydf)

---- sorting a matrix on values found in a particular column
> aaa
[,1] [,2]
[1,]    1 -0.2
[2,]    3  0.8
[3,]    4  0.3
[4,]    5  0.2
[5,]    7  0.9

sort this to produce:

1  -0.2
5   0.2
4   0.3
3   0.8
7   0.9

You can use "order" as follows:
> p <- order(aaa[,2])
> aa[p,]

p is the permutation putting aaa[,2] in ascending order, then aaa[p,]
reorders the rows according to p.

or, restated by another contributor:

> A=matrix(c(1,3,4,5,7, -0.2, 0.8, 0.3, 0.2, 0.9 ),5,2)
> A
[,1] [,2]
[1,]    1 -0.2
[2,]    3  0.8
[3,]    4  0.3
[4,]    5  0.2
[5,]    7  0.9
> A[order(A[,2]), ]
[,1] [,2]
[1,]    1 -0.2
[2,]    5  0.2
[3,]    4  0.3
[4,]    3  0.8
[5,]    7  0.9

---- get unique values from a vector, and a count of them
x <- c (2,1,2,1,4,2,1,4,1,1)
table (x) -> 1 2 4
5 3 2
?table -> 'table' uses the cross-classifying factors to build a contingency
table of the counts at each combination of factor levels.

---- extract rows & columns from a matrix
m <-  matrix (c (1,2,3,11,12,13,21,22,23), nrow=3, ncol=3, byrow=T)
[,1] [,2] [,3]
[1,]    1    2    3
[2,]   11   12   13
[3,]   21   22   23
m [1,] -> 1 2 3
is.matrix (m) ->  TRUE
is.matrix (m [1,]) -> FALSE
is.matrix (m [1,,drop=F]) ->  TRUE


---------- text mining in R
http://wwwpeople.unil.ch/jean-pierre.mueller/
I am sorry, but for the moment there is not an english manual...
It is in my "todo" list for a while. R 2.1 as introduced many new
functions for text, and i need correct my package first. May be in the nexts weeks?
The package try to code what is shown in:
Lebart, L., Salem, A. and Berry, L. (1998) "Exploring textual data".
Dordrecht: Kluwer.

---- apply (a function to all rows or columns of a matrix)
apply (matrix, [1=rows|2=columns], myFunction)
examples:
apply (matrix, 1, mean)
apply (matrix, 1, function (i) all (i > 0))  # find all positive rows

--- pairwise pearson correlation
d is a data frame, 48 rows, 10 columns
cor (d) works properly providing all pairwise Pearson correlation coefficients among columns


---- computing the exponential function over a matrix
exp (m)
claimed annoyance:
transformed.mtx <- t (apply (mtx, 1, exp))

---- discover the order of a matrix
order (c (3, 8, 1, 0)) -> [1] 4 3 1 2
'sort.list' is the same, using only one argument.

----- package vs library

A *library* is a directory in which you can find R *packages* (just
as in real life you can find books in a library) and with
library("foo", lib.loc = "/path/to/bar") you want to get the package
(book) "foo" from the library "bar" located at "/path/to/bar".

So the two are really distinct...in real life, you also wouldn't say
that you have been in the book where they had a lot of libraries on
the shelves, would you? ;-)

But as Kurt explained: this distinction between "library" and
"package" is specific to R and does not correspond to common practice
for other software systems.


-----  Version 1.0-1 of bayesm is now available on CRAN. (20 may 2005)

This is our first "production" version which include s much
improved documentation as well as five data sets used in our book,
Bayesian Statistics and Marketing.

----- don't let NA's distort median calculation
v = c (1, 2, 3, 4, NA, 5, 6, 7, 8)
median (v) ->   NA
median (v, na.rm=TRUE) -> 4.5


----- list files, search for pattern (from bioconductor affy 'list.celfiles')
files <- list.files(...)
return(files[grep(".[cC][eE][lL].gz$|.[cC][eE][lL]$", files)])

----- read affy cel files
library (affy)
list.celfiles ()
Data <- ReadAffy ()
class (Data) -> [1] "AffyBatch"
This is a class representation for Affymetrix GeneChip probe level
data. The main component are the intensities from multiple arrays
of the same 'CDF' type. In extends 'exprSet-class'.

slotNames (Data) -> [1] "cdfName"     "nrow"        "ncol"        "exprs"       "se.exprs"
[6] "phenoData"   "description" "annotation"  "notes"

slot (Data, 'cdfName')
slot (Data, 'notes')

---------- basic directory navigation
getwd ()
setwd ('new/directory')
list.files ()


---------- finding matrix rows whose elements meet certain criteria
which, any, all
m <- matrix (1:12, 3, 4)
m -> > m [,1] [,2] [,3] [,4]
[1,]    1    4    7   10
[2,]    2    5    8   11
[3,]    3    6    9   12
which (m > 11) -> 12
which (m > 6)  -> [1]  7  8  9 10 11 12
length (which (m > 6)) -> 6

------- 'classify' random numbers into well-ordered rounded set
Multiply by 4, round and divide by 4.
a <- c( 1.15,5.82)
round (a*4, digits=0)/4

or:
m <- matrix (runif(6), 2, 3)
[,1]      [,2]      [,3]
[1,] 0.6885473 0.4598892 0.2738169
[2,] 0.2393461 0.8863284 0.7891100
round (m * 4) / 4
[,1] [,2] [,3]
[1,] 0.75  0.5 0.25
[2,] 0.25  1.0 0.75

----- plot salamander lengths as vertical segments (though these data include negative values)
x <- 1:10
low <- rnorm(10)
high <- rnorm(10)
plot (x, low, ylim = range(c (low, high)), type="n")
# x, y, ylimits of the plot  (in this case, -1.20999 -> 1.592911)
# n: no plotting
segments(x, low, x, high)


------ make plotting window 2 x 2 with 'par'  -- set or query graphical parameters
par (mfrow = c (2, 2))

------ reading affy cel files
library (affY)
setwd (<directory with .cell files>)
batch <- ReadAffy ()
expressionSet <- rma (batch)    # has lot exprs, and se.exprs
m <- exprs (expressionSet)      # log 2 ratios
hist (as.matrix (m))
see also:  MAplot
map affy proble ID's:  see functions anaffy & annotate

---- histogram, several datasets, legends
I have a histogram with histograms for several datasets superimposed.
How can I add a legend that indicates which dataset uses which linetype?
?legend
6?locator

---- debugging
browser (), trackback (), options (error=recover)

----- ls
find variables whose names start with "c.":   vars <- ls (pat='^c\\.')

---- rm: remove all variables that look like   c.0, c.28, c.232
rm (list = ls (pat='^c\\.[0-9]+$'))

---- get value of variable whose name was returned by ls
eval (parse (text=vars[1]))

----- get variables by matching a pattern in their names (from ls), and assemble into a big list
clusterNames <- ls (pat='^c\\.[0-9]+')
clusters = list ()
for (name in clusterNames [c (1,2,3)]) {
clusterVar <- eval (parse (text=name))
clusters [[length (clusters) + 1]] <- clusterVar
}

------ append to a list
x = list ()
vars = c (8, 9, 10)
for (v in vars) {
x <- c (x, v)

---------- simple indexed for loop
for (i in seq (10)) { cat (paste (i, "\n"))}


------ good example of looping over list of arrays, and checking for the size
of the union: see /net/dblocal/wwwspecial/gaggle/rdev/clusterOverlaps.r

vars <- ls (pat='^c\\.[0-9]+$')

allClusters = list ()
for (v in vars) {
allClusters <- c (allClusters, eval (parse (text=v)))
}

cat (paste ("length of allClusters: ", length (allClusters), "\n"))

for (i in seq (2:length (allClusters))) {
targetGenes <- allClusters [1]$rows
comparisonGenes <- allClusters [i]$rows
overlapCount <- length (union (targetGenes, comparisonGenes))
cat (paste ("overlap between ", 1, "and", i, ": ", overlapCount, "\n"))
}

---------- fit a linear model
*** dumb example: is weight a function of height?
> weight <- (c (100, 120, 140, 160, 180))
> height <- (c (48, 52, 56, 60, 64))
> model <- lm (weight ~ height)
> coef (model)
(Intercept)      height
-140           5
---->      from which I conclude that weight = -140 + (height * 5)
> summary (model)
Call:
lm(formula = weight ~ height)

Residuals:
1          2          3          4          5
2.046e-14 -2.401e-14 -5.209e-15  6.031e-16  8.154e-15

Coefficients:
Estimate Std. Error    t value Pr(>|t|)
(Intercept) -1.400e+02  8.477e-14 -1.652e+15   <2e-16 ***
height       5.000e+00  1.506e-15  3.320e+15   <2e-16 ***
---
Signif. codes:  0 `***' 0.001 `**' 0.01 `*' 0.05 `.' 0.1 ` ' 1

Residual standard error: 1.905e-14 on 3 degrees of freedom
Multiple R-Squared:     1,	Adjusted R-squared:     1
F-statistic: 1.102e+31 on 1 and 3 DF,  p-value: < 2.2e-16

---- lm, p-value, extract from summary ()




if 'b' is a fitted model -- the result of calling lm (model, data),
then the coefficents may be found:

dim(summary (b)$coefficients) # 3,4
summary (b)$coefficients[,4]
m836         m918         m920
1.725225e-08 5.656475e-10 6.500279e-08

# from ~/s/data/sbri/susan/peripheral-microarrays/2007-aug-03/go.R, test.do.fit ()
fit.mal13p1.470.a = do.fit (5681)
#  the information we want is in the coefficients slot, a matrix with as many rows as terms in the
#  model, and 4 columns:
checkEquals (colnames (summary (fit.mal13p1.470.a)$coef), c ("Estimate", "Std. Error", "t value",  "Pr(>|t|)"))
checkEqualsNumeric (summary (fit.mal13p1.470.a)$coef ['m836',], c (4.867611e+00, 2.782708e-01, 1.749235e+01, 2.237840e-09), tol=1e-5)


----------- create a coef object -- slope & intercept, plot with abline
[from verzani, problem 3.28, p 103]
# background: folklore is that it is acceptable for a man to marry a woman
# no younger than half his age, + 7:   female = male/2 + 7.  do survey
# results support this?
# library (UsingR)
# attach (too.young)
# model = lm (Female ~ Male)
# coef (model)  --> (Intercept)        Male
#                     5.4720370   0.5753518
# abline (coef (model))
# x, below, mimics the coef object returned
x = vector (mode='double', length=2)
x [1] = 7
x [2] = 0.5
names (x) = c ("(Intercept)", "Male")
abline (x, col='red')


----------- fit linear models to inferelator predictions: chemotaxis cluster 699
1) load all expression data in the DMV; choose cluster 699 and its regulators in the inferelator
2) two AND-gated regulators: VNG0101G & VNG0458G
3) nine cluster genes: VNG0970G VNG0971G VNG0973G VNG1557G VNG1558H VNG1567G
VNG1568G VNG2219G
4) broadcast cluster to the dmv, then add two regulators
5) broadcast this 11 x 163 matrix to R
6) create a data.frame, which presumes that experimental variables are columns,
and conditions are rows:  df699 <- data.frame (t (m0))
7) model one of the cluster genes as a combination of the two regulators:
c699.fit <- lm (VNG0966G ~ VNG0101G + VNG0458G, df699)
8) coef (c699.fit)

(redid this with only one target variable: the average of all 9 cluster genes)
got this result
> summary (fitOfAverage)

Call:
lm(formula = c699.avg ~ prp1 + cspd1)

Residuals:
Min        1Q    Median        3Q       Max
-0.191196 -0.039551 -0.001806  0.033800  0.253574

Coefficients:
Estimate Std. Error t value Pr(>|t|)
(Intercept) -0.013018   0.005323  -2.446   0.0155 *
prp1         0.641967   0.045393  14.143   <2e-16 ***
cspd1        0.225058   0.016210  13.884   <2e-16 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

Residual standard error: 0.05605 on 160 degrees of freedom
Multiple R-Squared: 0.7034,	Adjusted R-squared: 0.6997
F-statistic: 189.7 on 2 and 160 DF,  p-value: < 2.2e-16


F-statistic: provides an indication of the lack of fit of the data to the
estimated values of the regression
F = Mean Squre Regersssion / Means Square Error (residual)

------------ create numeric vectors of length 10
v1 <- vector ('numeric', 10) # zero-filled
v2 <- runif (10)             # rand
mean (runif (100000))        # approaches 0.5
var  (runif (100000))        # approaches 0.83333  (1/12)
see also:  rnorm, rpois

----------- find the average of rows in a matrix
create the matrix first
m <- matrix (rnorm (20), nrow=4,ncol=5, byrow=T)
apply (m, 2, mean)    # '2' means apply to columns

------------ match predictions (from lm) to data (see http://gaggle/rdev/c699.r for context & code)
avg <- apply (m699 [rownames (m699)[3:length (rownames (m699))],], 2, mean)
cspd1 <- m699 ['VNG0101G',]
prp1  <- m699 ['VNG0458G',]
plot (avg, pch=23, bg='red', cex=2)
combinedModel <- lm (formula = avg ~ prp1 + cspd1)
lines (predict (combinedModel), lwd=2, col='green')
prp1Model <- lm (formula = avg ~ prp1)
lines (predict (prp1Model), lwd=2, col='blue')
cspd1Model <- lm (formula = avg ~ cspd1)
lines (predict (cspd1Model), lwd=2, col='magenta')



------  query the environment for the names of all variables matching the pattern 'c.[0-9]+$'
e.g., c.12, c.333, c.01, get the variables those names refer to, and return them in a list

clusters <- function () {
result = list ()
clusterNames =  ls (pat='^c\\.[0-9]+$', env=parent.frame())
for (name in clusterNames) {
clusterVar <- eval (parse (text=name))
result [[length (result) + 1]] <- clusterVar
}
result
}

----- plot to jpeg
jpeg(file="my.jpg")
plot(rnorm(100))
dev.off()

postscript("myplot.ps");
plot(1:10, sqrt(1:10));
dev.off();

---- plotting with legends (from susan's peripheral microarrays)
plotTitle = paste ('row: ', row, '   (dye-swaps inverted for easier comparison)', sep='')
plot (actual, ylim = c (-10,15), col='red', xlab='', ylab='log2 (ratio)', axes=FALSE, main=plotTitle)
labels = colnames (MA$M)
axis (1, 1:length (labels),  labels, las=2)
axis (2, at = seq (-10, 10, 5))
points (fitted, ylim= c (-10,10), col='blue')
box ()
legend (24, 15, c('actual', 'fitted'), pch=1, col= c('red', 'blue'))


----  nice EPS files, suitable for inclusion in LaTeX:
postscript ("myplot.eps", width=8, height=6, onefile=FALSE, horizontal=FALSE);

I think you forgot 'paper="special"' (see ?postscript).  Since I always
forget myself, I use the following wrapper

eps <- function (file="Rplot%03d.eps", onefile=FALSE, horizontal=FALSE,
paper="special", ...) {
postscript (file=file, onefile=onefile, horizontal=horizontal,
paper=paper, ...)
}

now use it:
eps ("myplot.eps")
plot (1:10, sqrt(1:10))
dev.off()

* end r tips
*--------------------------------------------------------------------------------
* rggobi tips

--- the tips dataset
got tips.csv from http://www.ggobi.org/book/ (scroll down to Data)

* end rggobi tips
*--------------------------------------------------------------------------------
* globaltest tips (r tip)
aphelion, cd ~/study/r/bioc/globaltest/
--- using the golub data set
paper: http://www.broad.mit.edu/cgi-bin/cancer/publications/pub_paper.cgi?mode=view&paper_id=43
library (golubEsets)
library (vsn)   # calibrates for sample-to-sample variations through shifting
# and scaling, and transforms the intensities to a scale where
# the variance is approximately independent of the mean intensity.
# The variance stabilizing transformation is equivalent to the
# natural logarithm in the high-intensity range, and to a linear
# transformation in the low-intensity range. In an intermediate
# range, the _arsinh_ function interpolates smoothly between the two.
data (golubMerge)
?golubMerge
# instance of exprSet which  directly extends annotatedDataset, a class representation
# for microarray data, and methods for processing them.
) annotations
go = lapply (go, function (x) x [!is.na (names (x)) & (names (x) != "IEA")])

# call with an exprSet, and the name of a response variable, asking:
# how does the expression data predict AML vs ALL in the phenoData?
# dim (exprs (golub)) --> 7129 x 72
# colnames (exprs (golub)) --> NULL  (so look elsewhere to see which column corresponds
#                                     to ALL.AML):
# dim (pData (phenoData (golub))) --> [1] 72 11
# colnames (pData (phenoData (golub)))
#    [1] "Samples"   "ALL.AML"   "BM.PB"     "T.B.cell"  "FAB"       "Date"
#    [7] "Gender"    "pctBlasts" "Treatment" "PS"        "Source"
# pData (phenoData (golub))[,"ALL.AML"]
#    [1] ALL ALL ALL ALL ALL ALL ALL ALL ALL ALL ALL ALL ALL ALL ALL ALL ALL ALL ALL
#   [20] ALL AML AML AML AML AML AML AML AML AML AML AML AML AML AML ALL ALL ALL ALL
#   [39] ALL ALL ALL ALL ALL ALL ALL ALL ALL ALL ALL ALL ALL ALL ALL ALL ALL ALL ALL
#   [58] ALL ALL ALL ALL AML AML AML AML AML AML AML AML AML AML AML
#   Levels: ALL AML
gt.all = globaltest (golub, "ALL.AML")
# function (X, Y, genesets, model, levels, d, event = 1, adjust,
#    method = c("auto", "asymptotic", "permutations", "gamma"),
#    nperm = 10^4, scaleX = TRUE, accuracy = 50, ...)
# X: an exprSet
# Y: the name of the response variable
#   or
# X: matrix of gene expression measurements (possibly still an exprSet object)
# Y: entire vector of measured response
#
# Global Test result:
# Data: 72 samples with 7129 genes; 1 pathway tested
# Model: logistic
# Method: Asymptotic distribution
#
#     Genes Tested Statistic Q Expected Q sd of Q    P-value
# all  7129   7129      53.992         10  2.5554 1.5133e-10
# 'logistic' because the ALL.AML response is two-values
# p-value calculated using asymptotic distribution
# test statistic Q, its expectation and sd under the null hypothesis; p-value
# implies: AML/ALL status correlated with similar expression profiles
#          non-negligible proportion of 7129 gnees are differentially expressed between
#          AML and ALL patientes
#          there exists a potential to predict ALL/AML status from the expression
#          profile over all 7129 genes.

---- explicitly supply the vector of the response variable  (5 jan 2006)
responseVector = pData (phenoData (golub))[,"ALL.AML"]
length (responseVector)   # [1] 72
gt.all = globaltest (golub, responseVector)  # same as above

---- globaltest on genes from a specific pathway  (5 jan 2006)
library (hu6800)
kegg <- as.list (hu6800PATH2PROBE)
go <- as.list (hu6800GO2ALLPROBES)
go <- lapply (go, function(x) x[!is.na(names(x)) & (names(x) != "IEA")])
GO.cellcycle <- go[["GO:0007049"]]    # 379 probes
KEGG.cellcycle <- kegg[["04110"]]     # 104 probes
length (intersect (KEGG.cellcycle, GO.cellcycle)) #  54
cellcycle <- list (go = GO.cellcycle, kegg = KEGG.cellcycle)
globaltest (Golub, "ALL.AML", cellcycle)
Data: 72 samples with 7129 genes; 2 pathways tested
Model: logistic
Method: Asymptotic distribution

Genes Tested Statistic Q Expected Q sd of Q    P-value
go     379    273      75.936    12.0320  3.7174 2.1032e-09
kegg   104    104      67.022     9.7383  3.4898 1.9955e-08

# test all the kegg pathways at once
# first, what's in the kegg variable?
names (kegg)[1:3]    # "03050" "04510" "04320"
kegg [["03050"]][1:3]  # "U86782_at"   "M64992_at"   "D00760_at"
gt.kegg <- globaltest (golub, "ALL.AML", kegg)
Data: 72 samples with 7129 genes; 3 pathways tested
Model: logistic
Method: Asymptotic distribution
Genes Tested Statistic Q Expected Q sd of Q    P-value
00980    51     51      53.794     6.9564  2.4677 6.1469e-12
04610    81     81     113.350     8.8611  3.7845 7.0806e-12
04640   119    119     159.390    17.0210  6.6980 1.1952e-11

kegg.top3 = sort (gt.kegg)[1:3]
names (kegg.top3) = as.list(KEGGPATHID2NAME)[names(kegg.top3)]
options ('width' = 110)
kegg.top3
Global Test result:
Data: 72 samples with 7129 genes; 3 pathways tested
Model: logistic
Method: Asymptotic distribution
Genes Tested Statistic Q Expected Q sd of Q    P-value
Metabolism of xenobiotics by cytochrome P450    51     51      53.794     6.9564  2.4677 6.1469e-12
Complement and coagulation cascades             81     81     113.350     8.8611  3.7845 7.0806e-12
Hematopoietic cell lineage                     119    119     159.390    17.0210  6.6980 1.1952e-11




*--------------------------------------------------------------------------------
* exprSet tips (r tip)
- class for microarray data
- derived from annotatedDataset, providing the phenoData data and methods

library (Biobase)

---- example [golub, famous leukemia data set from golub et al, 1999, with 7192
genes for 79 samples.
AML: acute myeloid leukemia, is a cancer of the myeloid line of white
blood cells, characterized by the rapid proliferation of abnormal
cells which accumulate in the bone marrow and interfere with the
production of normal blood cells. AML is the most common acute
leukemia affecting adults, and its incidence increases with age
'myeloid': originating in the bone marrow; not to be confused with 'myelin'

ALL: acute lymphoblastic leukemia, a cancer of the white blood cells,
characterised by the overproduction and continuous multiplication
of malignant and immature white blood cells (referred to as lymphoblasts)
in the bone marrow.
'lymphoblast': immature lymphocyte, a type of white blood cell involved
in the immune system, of which there are two types:
large granular: NK, or natural killer cells
small: T and B cells
distinguishing ALL from AML is critical for successful treatment; chemotherapy
regimens differ....

library (golubEsets)
golub = golubMerge
exprs (golub) = exprs (vsn (exprs (golubMerge)))
# exprs is getter and setter, accessing the expression and error measuruments of
# assay data stored in an eSet or exprSet object
slotNames (golub)
[1] "exprs"             "se.exprs"          "description"
[4] "annotation"        "notes"             "reporterInfo"
[7] "phenoData"         ".__classVersion__"
class/dim/typeof (exprs (golub)) # matrix, 7192x72, double
class/dim/typeof (se.exprs (golub)) # matrix, 0x0, double
length (rownames (exprs (golub))    # 7129, all the affy probe names
length (colnames (exprs (golub)))   # 0  (usually present, just missing here?)
# description and pData give detail on the samples, in this case, 11 kinds of
# clinical info on each subject
description (golub)                 # 11 strings
[1] "Samples"   "ALL.AML"   "BM.PB"     "T.B.cell"  "FAB"       "Date"
[7] "Gender"    "pctBlasts" "Treatment" "PS"        "Source"
class/dim/typeof (pData (golub))  # data.frame, 72 x 11, list
colnames (pData (golub))
[1] "Samples"   "ALL.AML"   "BM.PB"     "T.B.cell"  "FAB"       "Date"
[7] "Gender"    "pctBlasts" "Treatment" "PS"        "Source"



*--------------------------------------------------------------------------------
* lm tips (r tip)

--- simple use
library (UsingR)
data (batting)   # data.frame of 438 players, 22 columns
model = lm (RBI ~ HR, data=batting)
names (summary (model))
call terms residuals coefficients aliased sigma df r.squared adj.r.squared fstatistic cov.unscaled

--- scatter plot tips, jitter tips, lm tip
see bayesian computation with R p 7
library (LearnBayes)
data (studentdata); attach (studentdata)
hours.of.sleep = WakeUp - ToSleep
plot (jitter (ToSleep), jitter (hours.of.sleep))
fit = lm (hours.of.sleep ~ ToSleep)   # (Intercept) 7.9628   ToSleep   -0.5753
# with 0 ToSleep (going to bed at midnight), you get 7.96 hours sleep.  for every hour you go to sleep later, you lose 0.57 hours of sleep

abline (fit)

--- interactive demo of lm with height of people at age 2, and as adults
cd ~/s/study/R/lm/basic/
run (0) -- good data -- run this repeatedly to see how residual stderr, r-squared and F vary with goodness of fit
want big F (50 or better), small residual stderr, r-squared near 1
run (2) -- bad data --
see tiny F, tiny r-squared, big residual stderr

---- how to fit a row of microarray data, ratios from peripheral blood
[fabricate one row of a matrix.  normally the matrix would be real,
and you would just slice out one row at a time.]

r.487 = c (-0.446552089, 0.132209275, 0.274379648, 0.472373482, 0.008863704,
3.372025554, 2.141352113, 0.560153798, 1.712525229, 0.484556188,
1.399650299, 0.188901299, 5.239135074, 4.951903562)


column.names = c ("m918c073", "m836c073", "m836c135", "m918c135", "m918c140",
"m920c140", "m836c372", "m836c451", "m918c372", "m918c413",
"m918c425", "m918c451", "m920c372", "m920c425")

m = as.matrix (rbind (r.487))
mothers = c ('918', '836', '836', '918', '918',
'920', '836', '836', '918', '918',
'918', '918', '920', '920')

colnames (m) = column.names
row.df <<- as.data.frame (list (ratio=m [1,], m=mothers))
row.lm = lm (ratio ~ 0+m, data=row.df)

# now add children:
children = c ("073", "073", "135", "135", "140",
"140", "372", "451", "372", "413",
"425", "451", "372", "425")

row.df <<- as.data.frame (list (ratio=m [1,], m=mothers,c=children))
row.lm = lm (ratio ~ 0+m+c, data=row.df)

---- good example, Using R, p102, exercise 3.24
library (UsingR)
data (fat)
attach (fat)
plot (abdomen ~ wrist)   # see relation of circumferences

-- find model:
formula = abdomen ! wrist
plot (formula)
model = lm (formula)
abline (model)
# predict is generic.  lm's model's version requires data.frame for args)
predict (model, data.frame (wrist=17))         #  83.75187
predict (model, data.frame(wrist=c(17,22)))    #         1         2
#  83.75187 119.54776
-- plot residuals
# library (MASS) # from cran, package VR
attach (wtloss)
plot (Weight ~ Days)
model = lm (Weight ~ Days)
abline (model)
sum (residuals (model))            # should be very close to 0
plot (residuals (model) ~ Days)    # a volcano plot

-- identify a plotted point interactively, learning its index
identify (wrist, abdomen, n=1)   # x, y, numbe of clicks before returning to prompt
# clicked on the outlier point at top right of plot, response:   39
wrist [39]; abdomen [39]  # [1] 21.4, [1] 148.1
predict (model, data.frame (wrist=21.4))  # 115.2523
residuals (model)[39]  #      32.84775
find biggest: max (residuals (model))  #  32.84775

--------- lm tips
library (UsingR)
data (batting)
x11 ()
plot (RBI ~ HR)
model = lm (RBI ~ HR)
abline (model)
# mike piazza: 33 HR and 98 RBI
predict (model, data.frame(HR=33))  --> 104.1099
# find out piazza's residual
# first find out which row is his in the model; same in residuals?
grep ('piaz', batting [,'playerID']) # 198
resid (model) [grep ('piaz', batting [,'playerID'])]      198: -6.1099


---- programmatic access to all (?) aspects of the calculated model

names (summary (row.lm))

call
terms
residuals
coefficients
aliased
sigma
df
r.squared
adj.r.squared
fstatistic
cov.unscaled

* ending lm tips
*--------------------------------------------------------------------------------
* sbri tips

---  L drive
mapped to /labs/duffy

--- J drive
mapped to ????

--- microarray data
shell01.sbri.org:/labs/duffy/susan

--- linux view of windows filesystems
\\Netapp01\Duffy  is  /labs/duffy/DCS

--- password is 99 appended to the usual old animal

--- vmware directories
java 1.5.08 in /depot/jdk-1.5.0_08/bin
R in two places:
/apps/bin/R -> /depot/R-2.3.1/bin/R
*----------------------------------------------------------------------------
* servlet tips

--- compile a simple servlet
javac -cp /local/tomcat/apache-tomcat-5.5.20/common/lib/servlet-api.jar HibernateTest.java

--- redirect

url = 'http://www.ncbi.nlm.nih.gov/BLAST/Blast.cgi?QUERY=%s' % sequence
response.sendRedirect (url)

--- minimal example, hello world  (29 dec 2006)
mink, cd /usr/local/apache-tomcat-5.5.20/webapps
mkdir helloWorld/WEB-INF/classes
create and compile Hello.java in classes/

import java.io.*;
import javax.servlet.*;
import javax.servlet.http.*;
public class Hello extends HttpServlet {
public void doGet(HttpServletRequest request, HttpServletResponse response)
throws IOException, ServletException {
response.setContentType("text/html");
PrintWriter out = response.getWriter();
out.println ("<h4>Hello from the minimal servlet!</h4>");
}
} // class Hello

http://localhost:8080/helloWorld/test
/usr/local/apache-tomcat-5.5.20/webapps/helloWorld/WEB-INF/web.xml:

<?xml version="1.0" encoding="UTF-8"?>
<web-app>
<servlet>
<servlet-name>HelloWorld</servlet-name>
<servlet-class>Hello</servlet-class>
</servlet>
<servlet-mapping>
<servlet-name>HelloWorld</servlet-name>
<url-pattern>/test</url-pattern>
</servlet-mapping>
</web-app>

*----------------------------------------------------------------------------
* name tips

---- refseq NM to geneID, all organisms
aphelion, cd ~/data/ncbi/gene2refseq
get ftp://ftp.ncbi.nlm.nih.gov/gene/DATA/gene2refseq.gz
grep NM_ gene2refseq | awk -F'\t' '{print $2 "\t" $4}' | \
awk -F'.' '{print $1}' | sort | uniq > refseqNM2geneID.tsv   # 198661 lines

---- human IPI to geneID, using ebi's  using ipi.genes.HUMAN.xrefs
ftp://ftp.ebi.ac.uk/pub/databases/IPI/current/ipi.genes.HUMAN.xrefs.gz
3263 KB  	12/1/06  	4:51:00 PM
aphelion, cd ~/data/ipi/3.24
python parse.py > humanIPItoGeneId.tsv
quick QC: maps 95/107 of matthias's proteins


---- human IPI to geneID, using goa human.xrefs
working in /Users/mpshannon/data/xlate/human/ipi-to-geneID
rename previous versions:
mv human.xrefs human.xrefs-2006-05-03
mv humanIPItoGeneId.tsv humanIPItoGeneId.tsv-2006-05-03
curl ftp://ftp.ebi.ac.uk/pub/databases/GO/goa/HUMAN/human.xrefs.gz > human.xrefs.gz
gunzip human.xrefs.gz
python parse.py  > humanIPItoGeneId.tsv
wc -l humanIPItoGeneId.tsv  --> 48822


--- ncbi protein id to geneID
aphelion, cd ~/data/ncbi/gene2accession
ftp://ftp.ncbi.nlm.nih.gov/gene/DATA/gene2accession.gz  (use firefox) (90MB)
grep ^9606 gene2accession > gene2accession.human
cat gene2accession.human | awk '{print $6 "\t"  $2}' > gene2accession.human.entrezProtein.geneID.tsv
cat gene2accession.human | awk '{print $6 "\t"  $2}' | egrep -v "^-" | sort | uniq > human.entrezProtein.geneID.tsv
python parse.py > map.tsv   # eliminates duplicates
wc -l map.tsv gene2accession.human.entrezProtein.geneID.tsv
243939 map.tsv
327906 gene2accession.human.entrezProtein.geneID.tsv


--- prolog name maps
/Users/mpshannon/data/identifiers/prolog:
-rw-r--r--   1 pshannon  pshannon  7316753 Jan  8 10:05 entrezProtein2geneID.pl
-rw-r--r--   1 pshannon  pshannon  1647771 Jan  8 09:49 humanIPI_324_2GeneID_augmented.pl
-rw-r--r--   1 pshannon  pshannon  6359457 Jan  8 09:54 nm2geneID.pl
cat *.pl > geneID.pl
swipl: consult('geneID.pl').

---- gene_info
aphelion, cd /Users/mpshannon/data/ncbi/gene_info
ftp ftp.ncbi.nlm.nih.gov
cd gene/DATA
get gene_info.gz, gunzip, rename to, e.g., gene_info-2006-dec-14

---- meld human gene_info (was 'LL_out') and gene2accession.hman to produce 4 column fwb table

aphelion, cd /data/ncbi/protein2gene
[depends on prior creation of ../gene2accession/map.tsv, see above]
[depends on up-to-date version of gene_info, see above]

grep ^9606 ../gene_info/gene_info-2006-dec-14 > gene_info.human
cat gene_info.human | awk -F'\t' '{print $2 "\t" $3 "\t" $9}' > gene_info.human.tsv
python go.py > ncbiProtein2gene.tsv
wc -l ncbiProtein2gene.tsv   #   243935

----- meld ipi and gene_info for fwb MultiMapper
aphelion, cd ~/data/ipi/2.28
cp ~/data/ncbi/protein2gene/go.py meld.py
python meld.py ipi228-geneID.tsv > ipi228.tsv   # 24757 lines
uses  geneInfoFile = '/Users/mpshannon/data/ncbi/protein2gene/gene_info.human.tsv'
mv ipi228.tsv ipi228-geneInfo.tsv
cp ipi228-geneInfo.tsv ~/src/gwt/samples/fwb/nameMaps/
*----------------------------------------------------------------------------
* GOHyperG tips, hyperGTest tips

--- geneIds
geneIdsByCategory (hgr) [['GO:0051240']]

--- htmlReport
htmlReport (hgr, file='hgr.MF.01.html'))
geneIdsByCategory not (currently) included in this table

--- where do gene-to-GOterm mappings come from?
environment GOENTREZID2GO is in the GO package
hyperGTest for GO must use this by default

--- hyperGTest  (GOstats & Category versions 2.0.3, human example)
library (GOstats)
library (hgu95av2)
genes = c ('5444',  '3492',  '8857')
slotNames ("GOHyperGParams")
[1] "ontology"          "conditional"       "geneIds"
[4] "universeGeneIds"   "annotation"        "cateogrySubsetIds"
[7] "categoryName"      "pvalueCutoff"      "testDirection"

params = new ("GOHyperGParams", geneIds = genes, universeGeneIds=character(0),
annotation='hgu95av2',ontology='BP')
hgr = hyperGTest (params)
slotNames (hgr)
[1] "goDag"         "pvalue.order"  "conditional"   "annotation"
[5] "geneIds"       "testName"      "pvalueCutoff"  "testDirection"

---- HyperGResult
assume:  hg = hyperGTest (params)
summary (hg) # a data frame.
rows: one per go term
columns: GOBPID, Pvalue, OddsRatio, ExpCount, Count, Size, Term url
pvalues (hg) [1:3]    GO:0006826  GO:0006879  GO:0046916
0.001480086 0.001883746 0.002556512
geneMappedCount (hg)     # 1
universeMappedCount (hg) # 7432
isConditional (hg)       # FALSE
testDirection (hg)       # "over"
testName (hg)            # "GO" "BP"


--- non-chip annotation packages
humanLLMappings: http://bioconductor.org/packages/1.9/data/annotation/html/humanLLMappings.html (does not work with hyperGTest)
mouseLLMappings:  mouseLLMappings  (does not work with hyperGTest)
ratLLMappings
YEAST: does work

--- simple human example
library (hgu95av2)
library (GOstats)
genes = c ('84059', '338', '727')
x = GOHyperG (genes, lib='hgu95av2')
names (x) -->  "pvalues"   "goCounts"  "intCounts" "numLL"     "numInt"    "chip"
"intLLs"    "go2Affy"

--- simple yeast example, just stats, no induced graph

db, cd ~/work/bioc/go/yeast/
start R, ensure that .libPaths () reports ~/r/lib, to my updated packages
library (GOstats)
library (YEAST)
orfs = c ("YBR114W", "YDR419W", "YJR035W")
x = GOHyperG (orfs, lib='YEAST')    # does not return induced graph

--- hyperGTest  (GOstats & Category versions 2.0.3, mouse example)
library (GOstats)
library (mouse4302)
genes = c ('71909', '23821', '22370')
slotNames ("GOHyperGParams")
[1] "ontology"          "conditional"       "geneIds"
[4] "universeGeneIds"   "annotation"        "cateogrySubsetIds"
[7] "categoryName"      "pvalueCutoff"      "testDirection"
# note all-inclusive p-value
params = new ("GOHyperGParams", geneIds = genes, pvalueCutoff=1.0,
universeGeneIds=character(0),
annotation='mouse4302',ontology='BP')
hgr = hyperGTest (params)
slotNames (hgr); summary (hgr)

--- createCyGraph, yeast  (also makes the induced GO graph, before calculating enrichment)
db,  cd ~/work/bioc/go/yeast/
library (GOstats); library (YEAST);
source ('/users/pshannon/work/bioc/go/cygo.R')
y = createCyGraph (orfs, ontology='BP', annotation.lib='YEAST', geneName2GO.map=YEASTGO)
writeCytoscapeProject (y, 'test')
test/ now has these files:

dataSetCounts.noa  328
genes.noa  294
network.sif  708
organismCount.noa  374
pvalues.noa  671

cp /local/wwwspecial/gaggle/2005-11/cy/enrichment/template/* .
python localizeJnlp.py cy.jnlp-raw > cy.jnlp
make
javaws /users/pshannon/work/bioc/go/yeast/test4/cy.jnlp

--- createCyGraph, human  (also makes the induced GO graph, before calculating enrichment)

x = createCyGraph (genes, ontology='MF', geneToGoEnvironment=GOENTREZID2GO)
x = createCyGraph (genes, lib='hgu95av2', ontology='MF', geneToGoEnvironment=GOENTREZID2GO)


--- some background, and what varies from organism to organism

need to supply an annotation environment
hgu95av2 for human  (supplied by affy, for a chip that has most geneID's)
YEAST: a whole-genome annotation package

need to specify which environment in the package has gene-to-GO-term annotation
YEASTGO: for YEAST
GOENTREZID2GO: for hgu95av2

had to modify GOstats method makeGOGraph because of this line (which is
now parameterized, in db:~/work/bioc/go/cygo.R-myMakeGoGraph ()

newNodes <- mget(x, env = GOENTREZID2GO, ifnotfound = NA)

names (get ("Q0045", env=YEASTGO)) # "GO:0005751" "GO:0004129" "GO:0006123" "GO:0009060"
names (get ("1", env=GOENTREZID2GO)) #  "GO:0000004" "GO:0005576" "GO:0005554"

--- how to use hyperGTest () with KEGG or Pfam
https://stat.ethz.ch/pipermail/bioconductor/2006-November/014835.html


*------------------------------------------------------------------------------------------
* hyperg htmlReport tips
Thanks for that!
I can now almost get what I want.....
Here is the code I use:

hgOver = hyperGTest(params)
report = summary(hgOver, htmlLinks=TRUE)
cats = sigCategories(hgOver)
reportGenes = vector()

for(i in 1:length(cats)){
reportGenes = append(reportGenes, geneIdsByCategory(hgOver, cats[i]))
}

This gives me reportGenes as a list something like this:

$`04650`
[1] 10451  4277  5296  5880  6464  8743  8795  8797

$`04670`
[1] 10451  1365  5296  5829  5880  6387  6494    87  9564

$`00150`
[1]  3291 51451  6715

$`04080`
[1]  154 2150 4886 4923 7433

$`04360`
[1] 10512  1969  2043 56920 57522 57556  5880  6387

I would then like to run the following code:

report <- data.frame(report, reportGenes)
xtab <- xtable(report, caption="A Caption")
print(xtab, type="html", file="Afile.html", caption.placement="top",
sanitize.text.function=function(x) x, include.rownames=FALSE)

But I get the following error:
Error in data.frame("04650" = c(10451L, 4277L, 5296L, 5880L, 6464L,
8743L,  :
arguments imply differing number of rows: 8, 9, 3, 5, 7

----- jim replies
But I get the following error:
Error in data.frame("04650" = c(10451L, 4277L, 5296L, 5880L, 6464L,
8743L,  :
arguments imply differing number of rows: 8, 9, 3, 5, 7

This is the part where I said you have to wrap the Entrez Gene IDs in
<P>EGID</P> so you can a.)have a vector of the correct length, and b.)
create a table that will be readable.

Something like this should suffice:

rg.out <- sapply(reportGenes, function(x)
paste("<P>", paste(x, collapse="</P><P>"), "</P>", sep=""))

then use rg.out in lieu of reportGenes when making the data.frame.
-------------------------------------------------


How should I deal with this list so that I can add it to the data.frame?
And are there any faster ways to do what I have done in this code?
I am still getting used to R.
thanks heaps,
Sebastien

James W. MacDonald wrote:
Hi Sebastien,

Maybe not directly, but note that htmlReport() is simply using xtable
to create the HTML page using the output from summary(). So you could
just create the table and then add a column of Entrez Gene IDs and
then output the result.

Say your GOHyperGResult object is called 'hypt':

out <- summary(hyp, summary.args=list(htmlLinks=TRUE, categorySize=10))

Note that the categorySize argument isn't necessary, but does protect
you from choosing arguably spurious results (like a GO term with 3
genes in the universe and 1 that was significant).

Now you are going to have to create a vector containing all the Entrez
Gene IDs for each GO term. For this to work in HTML, you will also
need to separate each ID with a <P>EntreGeneID</P>, so you will need
to either cat() or paste() things together. Once you have that, just
add to the data.frame created above:

out <- data.frame(out, entregeneidvector)
xtab <- xtable(out, caption="A Caption", digits=rep(c(3,0), c(4,8)))
print(xtab, type="html", file="A file name.html",
caption.placement="top", sanitize.text.function=function(x) x,
include.rownames=FALSE)

HOWEVER, that might not really be what you want, as it will obviously
be a bit of work, and could get really messy if there are dozens of
Entrez Gene IDs for a particular GO term. An alternative is to output
individual HTML tables for each GO term of interest that list out the
probesets that contributed to the significance of that term. For that
you might want to look at hyperGoutput() in the affycoretools package.

Best,

Jim


Sebastien Gerega wrote:
Hi,
is there any way to get additional information into the hyperGTest
html report?
Specifically, I would like to include the Entrez IDs for the genes
contr
*------------------------------------------------------------------------------------------
* sequence tips

---- ipi (old version, 2.28)

ftp://ftp.ebi.ac.uk/pub/databases/IPI/old/HUMAN   get ipi 2.28 here
put two files in db:~/data/ipi/
-rw-r--r--    1 pshannon isb      53448533 Nov 23 07:34 ipi.dat.v2.28
-rw-r--r--    1 pshannon isb      24005729 Nov 23 07:35 ipi.fasta.v2.28

--- ipi, get current version (human)
aphelion, cd ~/data/ipi/3.24/
ftp ftp.ebi.ac.uk
cd pub/databases/IPI/current

4232157 Dec  1 08:51 ipi.HUMAN.IPC.gz
34725138 Dec  1 08:50 ipi.HUMAN.dat.gz
19292664 Dec  1 08:50 ipi.HUMAN.fasta.gz
1618853 Dec  1 08:51 ipi.HUMAN.history.gz
2658387 Dec  1 08:51 ipi.HUMAN.xrefs.gz
get ipi.genes.HUMAN.xrefs.gz  [explained at http://www.ebi.ac.uk/IPI/geneXrefs.html]


--- ipi, get specific mouse fasta file


---- swissprot rat to geneID
aphelion, cd ~/data/ncbi/gene2accession
taxonomy id: 10116
grep ^10116 gene2accession > gene2accession.rat


---- ncbi protein ids to geneID and gene name
aphelion, cd ~/data/sbri/davidSimpson/biomarkers/reduce/current/
source ('readAndWrite.R')
allGeneNames = sapply (rownames(hm), getGeneName)
*------------------------------------------------------------------------------------------
* bioinformatic resource tips
--- H-Inv DB
Annotated Human Gene Database
http://jbirc.jbic.or.jp/hinv/ahg-db/index.jsp
linked to, prominently, from EBI IPI gene cross-references page:
http://www.ebi.ac.uk/IPI/geneXrefs.html

*------------------------------------------------------------------------------------------
* mac os x tips, osx tips, mac tips

---- firefox tab navigation

Control-tab will cycle to the next tab to the right (and wrap at the end).
Page-up and Page-down keys can be used to move to adjacent tabs in either direction
(again, wrapping is in effect). Control-page-up (control-fn-page-up on laptop keyboards)
moves left. Control-page-down (control-fn-page-down) moves right.

---- redo the file-type/application mapping
/System/Library/Frameworks/ApplicationServices.framework/Frameworks/LaunchServices.framework/Support/lsregister  \
-kill -r -domain local -domain system -domain user
this precise command fixed the  'open <excel spreadsheet>' capapbility that had been plaguing me on the new mac book,
due apparently to replacing the ms office demo with the real thing.
error code was -10660

--- make & modify application shortcuts
http://www.hawkwings.net/2005/10/27/make-your-own-apple-mail-shortcuts/

---  keycue license key
KC-MCY-072007-1-118128-994489-1

* end os x tips, osx tips, mac tips
*------------------------------------------------------------------------------------------
* firefox tips

alert:  'warning: unresponsive script'
about:config
filter on 'script', find dom.max_script_run_time from default 10 to (say) 120

*------------------------------------------------------------------------------------------
* go tips, gene ontology tips

  --- convenience function: goReport
     goReport <- function(genes, ontologies="BP") {
       tbl.genes <- select(org.Hs.eg.db, keys=genes, keytype="SYMBOL", columns=c("SYMBOL", "GO"))
       tbl.goTerms <- select(GO.db, keys=tbl.genes$GO, keytype="GOID", columns=c("GOID", "TERM", "ONTOLOGY"))
       tbl.merged <- merge(subset(tbl.genes, ONTOLOGY=="BP"), tbl.goTerms, by.x="GO", by.y="GOID")
       browser(); xyz <- 99
       dups <- which(duplicated(tbl.merged[, c(1,2)]))
       if(length(dups) > 0)
          tbl.merged <- tbl.merged[-dups,]
           tbl.merged
       } # goReport


  --- look up one gene
    tbl.runx1 <- select(org.Hs.eg.db, keys="RUNX1", keytype="SYMBOL", columns=c("SYMBOL", "GO"))
    tbl.goTerms <- select(GO.db, keys=tbl.go.runx1$GO, keytype="GOID", columns=c("GOID", "TERM", "ONTOLOGY"))
    merge(tbl.runx1, tbl.goTerms, by.x="GO", by.y="GOID")
    merge(subset(tbl.runx1, EVIDENCE=="TAS"), tbl.goTerms, by.x="GO", by.y="GOID")
    merge(subset(tbl.runx1, ONTOLOGY=="BP"), tbl.goTerms, by.x="GO", by.y="GOID")

--- Evidence Codes [http://www.geneontology.org/GO.evidence.shtml]
made into prolog rules, see ~/svn/data/public/GO/evidenceCodes.pl

IC: Inferred by Curator
IDA: Inferred from Direct Assay
IEA: Inferred from Electronic Annotation
IEP: Inferred from Expression Pattern
IGC: Inferred from Genomic Context
IGI: Inferred from Genetic Interaction
IMP: Inferred from Mutant Phenotype
IPI: Inferred from Physical Interaction
ISS: Inferred from Sequence or Structural Similarity
NAS: Non-traceable Author Statement
ND: No biological Data available
RCA: inferred from Reviewed Computational Analysis
TAS: Traceable Author Statement
NR: Not Recorded


* end go tips, gene ontology tips
*------------------------------------------------------------------------------------------
* printer tips

elm: 2nd floor, next to nitin, double-sided printing
oak: copier on left, 1st floor, double-sided printing
fir: copier/fax machine in hallway, 1st floor, double-sided printing

* end printer tips
*------------------------------------------------------------------------------------------
* biomart tips:  ensembl_gene_id and hgnc_symbol

mart.human = useMart(biomart = 'ensembl', dataset = 'hsapiens_gene_ensembl')
targets = c ('ENSG00000004142', 'ENSG00000002079')
columns = c ("ensembl_gene_id", "hgnc_symbol", "entrezgene")
getBM (filters="ensembl_gene_id", values=targets, attributes=columns, mart=mart.human)
ensembl_gene_id hgnc_symbol entrezgene
1 ENSG00000002079       MYH16         NA
2 ENSG00000004142     POLDIP2         NA

*------------------------------------------------------------------------------------------
* biomaRt tips

library (biomaRt)
human.mart = useMart ("ensembl", dataset="hsapiens_gene_ensembl")
listAttributesp (human.mart)   # show what values can be retrieved
listFilters (human.mart)      # show values to search (filter) on


--- map ensembl gene ids to entrez & symbol
bm <<- useMart("ensembl")
listDatasets(bm)
bm <<- useDataset("hsapiens_gene_ensembl", mart=bm)
select.by <- "ensembl_gene_id"
attributes.to.retrieve <- c("ensembl_gene_id", "entrezgene", "hgnc_symbol")
query <- head( unique(tbl.mrna$Ensembl.gene.ID), n=3)
getBM(attributes=attributes.to.retrieve, filters=select.by, values=query, mart=bm)


--- miRNA gene locs
Re: [BioC] microRNA: which genes code for a specific mirna?

Use Biomart

library(biomaRt)

mart.obj <- useMart(biomart = 'ensembl', dataset = 'hsapiens_gene_ensembl')

atb <- c('ensembl_gene_id', 'external_gene_id', 'external_gene_db',
'chromosome_name', 'start_position', 'end_position', 'strand')

mir.locs <- getBM(attributes=atb, filters="biotype", values="miRNA", mart=mart.obj)


mir.locs[1:10,]
ensembl_gene_id external_gene_id      external_gene_db chromosome_name start_position end_position strand
1  ENSG00000222732       AC008671.1 Clone-based (Ensembl)               5      171706206    171706319      1
2  ENSG00000207864      hsa-mir-27b               miRBase               9       97847727     97847823      1
3  ENSG00000221173       AL161908.1 Clone-based (Ensembl)               9      129338809    129338909     -1
...

--- vectorized queries   (wolfgang huber)

Please have a look at the documentation of the biomaRt package (its vignette, and the man page of the getBM function)
where you can learn that getBM supports vectorized queries, i.e. queries in which the "values" argument of getBM has
multiple elements per attribute. This will be much faster and resource-efficient than the way you propose. Note that
the BioMart webservice that you are connecting to is a public service that wants to be used by many people.

--- features, homologs, sructures, sequences & variations

this fails:
getBM(attributes=c("affy_hg_u133_plus_2","entrezgene","validated"),filters="affy_hg_u133_plus_2",mart=ensembl,values=p);

The Ensembl mart attributes are set up as 4 separate categories or "pages". If you take a look at the martview
interface you will see that these categories are: Features, Homologs, Structures, Sequences and Variations. At
present, it is not possible to mix attributes from multiple sections as you will get the error message you received
(i.e. in your query the "validated" attribute came from the "Variations" section and the rest of the attributes came
from the "Features" section).  The way around this is to perform two separate queries; one to select the features
attributes and one to retrieve the variations attribute. You may also be able to link to two separate datasets, one
for the validated part of the query and the other for the features part of the query and pull out all the information
you need. I'm not sure how this is done using biomaRt, but perhaps someone else from the mailing list can help you to
do this.


--- get coding sequence
human.mart = useMart ("ensembl", dataset="hsapiens_gene_ensembl")

getSequence (id='58524', mart=human.mart, type='entrezgene', seqType='coding')$coding)
translate to aa:
translate (DNAString (getSequence (id='58524', mart=human.mart, type='entrezgene', seqType='coding')$coding))

--- get sequence:  seqTypes
gene_exon
transcript_exon
transcript_exon_intron
gene_exon_intron
cdna
coding
coding_transcript_flank
coding_gene_flank
transcript_flank
gene_flank
peptide
3utr
5utr

--- find start of gene
human.mart = useMart ("ensembl", dataset="hsapiens_gene_ensembl")

getBM ('sequence_gene_chrom_start', 'entrezgene', '5004', mart=human.mart)   #   start_position: 116125119

--- find all starts
colnames = c ('start_position', 'transcript_start', 'sequence_gene_chrom_start', 'structure_gene_chrom_start',
'sequence_transcript_chrom_start',  'structure_transcript_chrom_start',  'exon_chrom_start')
queryFields = 'entrezgene'
queryValues = '5004'
getBM (colnames, queryFields, queryValues, mart=human.mart)

--- find exons on human zfp37
library (biomaRt)
human.mart = useMart ("ensembl", dataset="hsapiens_gene_ensembl")
zfp37 = "7539"
getBM(attributes = c("ensembl_exon_id", "rank", "exon_chrom_start", "exon_chrom_end"), filters = "entrezgene", values = zfp37, mart = human.mart)
ensembl_exon_id rank exon_chrom_start exon_chrom_end
1 ENSE00001462839    4        114843995      114846369
2 ENSE00000806242    3        114851463      114851597
3 ENSE00001317422    2        114851892      114851973
4 ENSE00001462841    1        114858658      114858817

--- how to find mysteriously named attributes -- geneSymbol especially
for example, what mouse mart attribute corresponds to geneSymbol?  --> external_gene_id
for (a in 1:100) {att = attributes [a,1]; print (getBM (att, filters='entrezgene', values="12401", mart=mouse.mart))}

--- find data attributes in a mart
colnames (listAttributes (mouse.mart))  "name"        "description"

--- human
library (biomaRt)
human.mart = useMart ("ensembl", dataset="hsapiens_gene_ensembl")
getBM (c ('entrezgene', 'external_gene_id', 'description'), filters='entrezgene', values=zfp37, mart=human.mart)
entrezgene external_gene_id                                                                      description
1       7539            ZFP37 Zinc finger protein 37 homolog (Zfp-37) [Source:UniProtKB/Swiss-Prot;Acc:Q9Y6Q3]

--- yeast  ('description' includes gene symbol)
yeast.mart = useMart ('ensembl', dataset='scerevisiae_gene_ensembl')
attributes = listAttributes (yeast.mart)
getBM (c ('ensembl_gene_id', 'peptide'), filters='ensembl_gene_id', values='YFL026W', mart=yeast.mart)  # aa sequence
getBM (c ('ensembl_gene_id', 'description'), filters='ensembl_gene_id', values='YFL026W', mart=yeast.mart) # description
getBM (c ('ensembl_gene_id', 'go_description'), filters='ensembl_gene_id', values='YFL026W', mart=yeast.mart) # description

--- mouse
mouse.mart=useMart("ensembl", dataset="mmusculus_gene_ensembl")
attributes = listAttributes (mouse.mart)
getBM (c ('entrezgene', external_gene_id', 'description'), filters='entrezgene', values="12401", mart=mouse.mart)
# can't do the reverse, so 'external_gene_id' is not a valid filters

--- get yeast aa sequence

--- yeast mart attributes
name
1                                  affy_yeast_2
2                                   affy_yg_s98
3                                       biotype
4                               chromosome_name
5                                   description
6                                          embl
7                                  end_position
8                            ensembl_CDS_length
9                           ensembl_cDNA_length
10                              ensembl_gene_id
11                           ensembl_peptide_id
12                       ensembl_peptide_length
13                        ensembl_transcript_id
14                                   entrezgene
15                                evidence_code
16                             external_gene_db
17                             external_gene_id
18                                       family
19                           family_description
20                                 feat_chr_end
21                                feat_chr_name
22                               feat_chr_start
23                                  feature_set
24                                 feature_type
25                                feature_value
26                                           go
27                               go_description
28                                     interpro
29                         interpro_description
30                   interpro_short_description
31                                          pdb
32                        percentage_gc_content
33                                         pfam
34                                       prints
35                                      prosite
36                                      protein
37                               refseq_peptide
38                                          sgd
39                                signal_domain
40                                       source
41                               start_position
42                                       status
43                                       strand
44                             transcript_count
45                           transcript_db_name
46                        transcript_display_id
47                               transcript_end
48                             transcript_start
49                            transcript_status
50                         transmembrane_domain
51                              unified_uniprot
52                    unified_uniprot_accession
53                             uniprot_sptrembl
54                            uniprot_swissprot
55                  uniprot_swissprot_accession
56                          uniprot_varsplic_id


* end biomaRt tips
*------------------------------------------------------------------------------------------
* subset tips

--- multiple constraints, multiple outputs:  & and c ()
subset (anno, PrintRun=='PrintJC4(23Apr2007)' & Patient=='0960a01', select=Patient:FileName)

* end subset tips
*------------------------------------------------------------------------------------------
* limma tips

--- F-test, fdr, etc

logFC is the difference between two groups, so it is not defined when you do an F-test which in essence compares any
number of groups. If you do have some specific comparisons of interest, then specify the coef argument when you run
toptable eg toptable(my.fit, coef=1, ...)

When you choose method="BH", toptable just calculates the FDR, using the BH method, and puts the FDR values in the
adj.p.val column. toptable itself does no thresholding on those values. You choose the threshold yourself. So if you
choose only those genes where adj.p.val < 0.05, then you have controlled the FDR to a level of 5%

--- map from printer layout to slide image to actual measurements
scenario:  slide image has long columns of white.  what's going on there?
cd ~/s/data/sbri/cate/liverStage/R/; source ('go.R')
read.and.process.data ()
# read just one target for a quick look
f = 'simple-targets.txt'
targets <<- readTargets (f)[1,]
filterFunction <<- function (x) as.numeric (x$Flags >= 100 & x$ID != 'Empty')
RG <<- read.maimages (targets, source="genepix", wt.fun=filterFunction)
RG <<- backgroundCorrect (RG, method="normexp", offset=50)
RG$printer <<- getLayout (RG$genes)
MA <<- normalizeWithinArrays (RG)

plotSlide (1)

block (aka, print-tip group) 8 has two white columns
blocks are numbered from lower left corner, up.  so block 8 is at the top
of the second column from the left.  within each block, rows run from top
to bottom, columns from left to right.  turn the slide image 90-degrees clockwise.
blocks
4    8
3    7
2    6
1    5  9 ...

find those all-white columns.  rows 5 & 17.
subset (RG$genes,Block==8 & Row==17)
Block Row Column    ID  Name
4585     8  17      1 Empty Empty
4586     8  17      2 Empty Empty
4587     8  17      3 Empty Empty
4588     8  17      4 Empty Empty
4589     8  17      5 Empty Empty
....

lapply (1:24, function (r) fivenum (RG$R [as.numeric (rownames (subset (RG$genes,Block==8 & Row==r)))]))
1)   67.20231  76.70231  107.20231  238.20231  2648.20231
2)   62.20231  78.20231  102.70231  427.20231  2983.20231
3)   65.20231  87.20231  168.20231  599.20231  1964.20231
4)   67.20231  76.70231  112.70231  164.70231 10174.20231
5)   51.20244  52.20231   53.20231   54.20231    58.20231
6)   65.20231  75.20231   85.70231  181.70231   482.20231
7)   63.20231  82.70231  172.70231  323.20231  1663.20231
8)   53.20231  71.20231  114.70231  447.20231  8276.20231
9)   64.20231  69.70231  102.20231  164.20231  1462.20231
10)  64.20231  85.70231  111.70231  233.20231  1024.20231
11)  65.20231  86.20231  139.70231  403.20231  1564.20231
12)  54.20231 102.20231  141.70231  218.70231  6249.20231
13)  63.20231  78.20231   87.20231  174.20231  1024.20231
14)  63.20231  76.20231  118.70231  380.20231  2871.20231
15)  65.20231  93.70231  164.70231  551.20231  1138.20231
16)  53.20231 119.20231  176.70231  353.70231  1161.20231
17)  50.10548  51.20244   52.20231   52.70231    55.20231
18)  58.20231  65.70231   88.20231  227.20231  2130.20231
19)  75.20231 101.20231  209.20231  375.20231   964.20231
20)  66.20231  81.20231  250.20231  397.70231   919.20231
21)  71.20231  93.20231  168.70231  421.20231 47755.20231
22)  74.20231 176.70231  360.70231  840.20231  4224.20231
23)  61.20231  74.70231   91.20231  176.70231  1826.20231
24)  69.20231  73.70231  138.20231  254.20231   808.20231


sapply (1:24, function (r) mean (RG$R [as.numeric (rownames (subset (RG$genes,Block==8 & Row==r)))]))
[1]  339.45231  477.49397  434.95231  572.61897   53.49398  142.95231  275.91064  979.78564  187.86897  222.36897  380.95231  551.32731  229.53564  394.61897
[15]  351.61897  342.07731   52.07935  267.36897  299.03564  288.95231 2807.07731  757.41064  194.24397  205.57731
>






--- quick start
targets <<- readTargets ("targets.txt")
filterFunction = function (x) as.numeric (x$Flags >= 100)
RG <<- read.maimages (targets, source="genepix", wt.fun=filterFunction)
# recommended for genepix data
RG <<- backgroundCorrect (RG, method="normexp", offset=50)

RG$printer <- getLayout (RG$genes)
MA <- normalizeWithinArrays (RG)
#   normalizeWithinArrays (object, layout, method="printtiploess", weights=object$weights,
#                          span=0.3, iterations=4, controlspots=NULL, df=5, robust="M",
#                          bc.method="subtract", offset=0)

# equivalent to
#  RGb <- backgroundCorrect(RG, method="subtract")
#  MA <- normalizeWithinArrays(RGb)
method: "none"      "median"  "loess" "printtiploess"
"composite" "control"  "robustspline"
plotPrintTipLoess (MA)


*---------------------------------------
# QC plotting: look at the red channel
*---------------------------------------

summary (RG$R [,1])    Min. 1st Qu.  Median    Mean 3rd Qu.    Max.
26.0    31.0    40.0   248.7   105.0 59900.0
for (i in 1:39) imageplot (RG$R[,i], RG$printer,low='white', high='red', zlim=c(26, 105))

*---------------------------------------
# QC plotting: look at the ratios
*---------------------------------------
for (i in 1:39) imageplot (MA$M[,i], RG$printer,zlim=c(-3,3))

plotDensities (RG)
plotDensities (MA)
plotPrintTipLoess (MA)

*-----------------------------------------
# QC plotting: one MA plot for every slide
*-----------------------------------------
par (mfrow = c (5,8))
for (i in 1:39) plotMA (MA, i)

*-------------------------------------------------------------------------------
# QC plotting: 5 image plots per slide
# from a function in ~/s/data/sbri/jing/anemia-two-color/R/go4.R
# plot red background & red signal; green background & green signal. use min &
# 3rd quartile to scale the intensity.   finally, plot the ratios
*-------------------------------------------------------------------------------
plotSlide = function (slideNumber) {
par (mfrow = c (3,2))
imageplot (RG$Rb [,slideNumber],
RG$printer,low='white', high='red',
zlim=as.numeric (summary (RG$R[,slideNumber])[c (1,5)]))

imageplot (RG$R [,slideNumber],
RG$printer,low='white', high='red',
zlim=as.numeric (summary (RG$R[,slideNumber])[c (1,5)]))

imageplot (RG$Gb [,slideNumber],
RG$printer,low='white', high='green',
zlim=as.numeric (summary (RG$G[,slideNumber])[c (1,5)]))

imageplot (RG$G [,slideNumber],
RG$printer,low='white', high='green',
zlim=as.numeric (summary (RG$G[,slideNumber])[c (1,5)]))

imageplot (MA$M[,slideNumber], RG$printer,zlim=c(-3,3))
}# plotSlide

--- background correction

Background correction (background subtraction) is also performed
by the 'normalizeWithinArrays' method for 'RGList' objects, so it
is not necessary to call 'backgroundCorrect' directly unless one
wants to use a method other than simple subtraction. Calling
'backgroundCorrect' before 'normalizeWithinArrays' will over-ride
the default background correction.

recommended for genepix data, in the limma user's guide, section 3.2, p9

The following command implements a type of adaptive background correction.
This is optional but recommended for GenePix data.
RG <- backgroundCorrect (RG, method="normexp", offset=50)


--- construct a targets dataframe by hand
data.frame (cbind (SlideNumber=1:2, Patient=c('0037a01-01','0037a01-02'),
FileName=c('../gpr/jchen_13583876_2007-03-23.gpr', '../gpr/jchen_13583876_2007-03-22.gpr')))
SlideNumber    Patient                             FileName
1           1 0037a01-01 ../gpr/jchen_13583876_2007-03-23.gpr
2           2 0037a01-02 ../gpr/jchen_13583876_2007-03-22.gpr
>

* end limma tips
*------------------------------------------------------------------------------------------
* scansite tips

--- batch input, text output file import
suggestions
- add this title:
orf	motif	motifFamily	site	score	percentile	sequence	surfaceAccessibility
convert spaces to tabs
read:  (there will probably always be duplicate row names,
scansite.56.out.tbl = read.table ('/Users/pshannon/s/data/eth/proteomics/bodenmiller/tpk2/scansite-56.out', sep='\t', header=T)

--- batch input, text output file explained:
http://stjuderesearch.org/scansite/tutorials.php

Here is a description of the information in the eight columns, in order:

1. The protein ID, as submitted in your input file.

2. The motif found, and thus a predicted interaction. For example,
the motif "Fyn_SH2" indicates that a tyrosine residue on the input
protein, once phosphorylated, is recognized by the SH2 domain of the
kinase Fyn.

3. The motif family. Scansite organizes motifs of similar types
into families. For example, the proline-directed serine/threonine
kinases group (Pro_ST_Kin) is currently composed of Cdc2, Cdk5, Erk1,
and p38 MAPK. These have similar motifs, and a predicted interaction
with one of them may involve one of the others instead.

4. The site found, such as "Y69".

5. The calculated score. Lower numbers indicate better matches. A
score of 0.000 means the site matches the motif description perfectly,
whereas the score increases for sequences with some substituted
low-scoring residues.

6. The percentile rank of this site compared to others in a
reference set. Lower numbers mean better specificity; a percentile of
0.130% indicates that this site is a better match to the motif
description than 99.870% of potential sites in the reference data. The
reference used is the vertebrate category of Swiss-Prot, chosen for
its low redundancy. Specifically, for a motif with a central serine or
threonine, all serine and threonine residues in all vertebrate
Swiss-Prot proteins are scored as potential sites. A low percentile
indicates the site is very rare in the vertebrate proteome.

7. The 15-mer sequence surrounding the site. If the residues are
numbered 1 to 15, the "site" is the central residue, at position
8. For sites very near the N or C termini of the protein, the N or C
termini are indicated with the characters "$" (for N terminus) or "*"
(for C terminus). If there are still fewer than 15 residues to
display, spaces fill in the rest of the positions.

8. The calculated surface accessibility. This is calculated from
the relative hydrophobicity of nearby residues, and is intended to
help judge whether the site found is near the protein surface and thus
available for an interaction. Values lower than 1.0 are typically
buried, and higher values are increasingly hydrophilic regions and
thus likely to be near the surface. This calculation is not foolproof,
but is useful when no protein structure is available.

* end scansite tips
*------------------------------------------------------------------------------------------
* rbgl tips, graph tips, graphNEL tips

--- all possible paths between two nodes and their associated lengths
rober gentleman says  google suggests this method,  http://www.perlmonks.org/?node_id=522270
should be relatively straightforward in R, or you can just use their perl code.
One word of caution is that if the graph is at all large or dense the size ofthe output can be enormous.

--- from adjacency matrix graph to node & edge list graph
g.nel = as (g.am, 'graphNEL')

--- queries
isDirected (g)

--- all values for a particular node attribute   --> ~/.Rprofile:noa (g, 'type')
sapply (nodes (g), function (x) as.character (nodeData (g, x, 'type')))
A         B         C
"kinase"      "TF" "protein"


--- all values for a particular edge attribute    --> ~/.Rprofile:eda (g, 'type')
sapply (names (edgeData (g)), function (n) edgeData (g)[[n]]$type)
A|B              A|C              B|A              B|C              C|A              C|B
"pp" "phosphorylates"             "pp"        "complex" "phosphorylates"        "complex"

--- neighbors
ns = edges (g.biogrid.yeast)[[cdc28]]

--- quick creation
g = new ("graphNEL", nodes=letters[1:4],
edgeL=list(a=list(edges=4), b=list(edges=3), c=list(edges=c(2,1)),
d=list(edges=1)), edgemode="directed")

--- standard simple creation
g = new ('graphNEL', edgemode='directed')
nodeDataDefaults (g, 'type') = 'none'
edgeDataDefaults (g, 'type') = 'none'
a = 'A'; b = 'B'
g = addNode (a, g)
g = addNode (b, g)
g = addEdge (a, b, g)
nodeData (g, a, 'type') = 'kinase'
nodeData (g, b, 'type') = 'substrate'
edgeData (g, a, b, 'type') = 'phosphorylates'


---- create from adjacency matrix (aka, from-to-matrix, or ftm) (from burak)
library(graph)
> ftm = matrix(1:20,ncol=2)
> ftm
[,1] [,2]
[1,]    1   11
[2,]    2   12
[3,]    3   13
[4,]    4   14
[5,]    5   15
[6,]    6   16
[7,]    7   17
[8,]    8   18
[9,]    9   19
[10,]   10   20
> graphHold = ftM2graphNEL(ftm)
> graphHold
A graphNEL graph with directed edges
Number of Nodes = 20
Number of Edges = 10


----- new packages that havebeen accepted into the 2.2 branch of bioconductor.
GraphAlignment: Graph alignment is an extension package for the R
programming environment which provides functions for finding an
alignment between two networks based on link and node similarity scores.
(J. Berg and M. Laessig, "Cross-species analysis of biological networks
by Bayesian alignment", PNAS 103 (29), 10967-10972 (2006))


--- graph methods
edgeL (g)
nodes (g)
edges (g)
edgeDataDefaults (g)

g = new ('graphNEL', edgemode='undirected')
nodeDataDefaults (g, attr='type') = 'KEGG Pathway'
edgeDataDefaults (g, attr='edgeType') = 'edge'
g = addNode ('YBR103W', g)
nodeData (g, 'YBR103W', 'commonName') = 'HOG1'
g = addEdge ('YBR103W', 'YBR103W', g)
edgeData (g, a, b, 'edgeType') = 'fancy edge'

edgeData (g)
edgeData (g, '12266', '12628')  # all attibutes
edgeData (g, '12266', '12628', 'evidence')
$`12266|12628`
[1] "http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=PureSearch&db=PubMed&details_term=11367533,9988761"

--- remove nodes and edges
g = removeNode ('A', g)
g = removeEdge (from, to, graph)

--- make simple graph
g = new ('graphNEL', edgemode='undirected')
nodes = c ('A', 'B', 'C', 'D', 'E', 'F')
g = addNode ('A', g)
g = addNode ('B', g)
g = addNode ('C', g)
g = addNode ('D', g)
g = addNode ('E', g)
g = addNode ('F', g)
edgeDataDefaults (g, attr='edgeType') = 'edge'
g = addEdge ('YBR103W', 'YBR103W', g)

-- has edge (see ~/s/data/public/referenceNetworks/yeast/go.R::hasEdge (g, a, b))
if (a %in% names (edges (g)))
if (b %in% as.character (unlist (edges (g)[a])))
return (TRUE)

return (FALSE)

-- explore orphan-to-network stitching (24 jul 2007)

cd ~/svn/examples/R/RBGL/bridgeNetworks/
test ();  includes call to make.dip.graph (dip.tbl) creating:
gdip:  A graphNEL graph with undirected edges
Number of Nodes = 2127
Number of Edges = 5109
save (list=c('dip.tbl', 'gdip'), file='~/svn/data/public/dip/yeastDip.Rd')
load ('~/svnPublic/data/public/dip/yeastDip.Rd')

--- stitch an orphan into a cy network
x = getNameList ()
broadcast (subGraph (sp.between (gdip, x [1], x[2])[[1]]$path, gdip))

--- more complete functions, from work on Tor1 kinase deletions, with  bernd bodemiller
cd ~/s/data/eth/proteomics/bodenmiller/2007-jul-23/WTvsTor1D/

go.R, attach.orphans = function (orphans, hub, gdip) {
orphans = intersect (orphans, nodes (gdip))
tweeners = list ()
for (n in 1:length (orphans)) {
node = orphans [n]
cat (paste ('about to find sp between', node, 'and', hub, '\n'))
path = sp.between (gdip, node, hub)[[1]]$path
if (length (path) == 1 && is.na (path))
next
tweeners = unique (c (tweeners, path))
}
return (unlist (tweeners))
}

expand.graph = function (nodes, reference.graph) {
expansion = new ('graphNEL', edgemode='undirected')
candidates = intersect (nodes, nodes (reference.graph))
cat (paste ('candidates:', candidates, '\n'))
if (length (candidates) > 0) {
in.edges = inEdges (candidates, reference.graph)
cat (paste ('neighbors: ', in.edges, '\n'))
count = length (names (in.edges))
cat (paste ('count:', count, '\n'))
for (n in 1:count) {
root.node = names (in.edges) [n]
neighbors = in.edges [[n]]
neighbors = neighbors [-(which (root.node == neighbors))]
expansion = join (expansion, subGraph (c (root.node, neighbors), gdip))
} # for
}# if > 0
return (expansion)
}

* end rbgl tips, graph tips
*----------------------------------------------------------------------------------------------------
* nl tips
head -85 registry.genenames.tab | tail -1 | tr '\t' '\n' | nl -ba
*----------------------------------------------------------------------------------------------------
* salish unicode

--  barred lambda:
Unicode Character 'LATIN SMALL LETTER LAMBDA WITH STROKE' (U+019B)  411 &#411;
no html entity defined  &#x019b;

--  find a new character, example, barred-lambda
.emacs has function lm, which places &#x019b; at point
good website    http://www.fileformat.info/info/unicode/char/search.htm

&#x294;  &#x30c; &#x2b7;

*----------------------------------------------------------------------------------------------------
* statistics tips, stats tips, stat tips, probability tips, prob tips

--- CV, coefficient of variation, coefficient of variance, variance-to-mean ratio
standard deviation / mean
variance / mean

--- combine independent probabilities
burak's formula: pchisq(-2*sum(log(z)), df = 2*length(z), lower.tail=FALSE)
Fisher's Combined Probability test:
R. A. Fisher (the man who invented ANOVA and several other statistical techniques) devised a test which can
combine the p-values across independent tests of the same question.

Fisher noted that the distribution of p-values from independent
tests of a true null hypothesis would be such that -2S ln[p]
would be c2 distributed with degrees of freedom equal to 2 times
the number of tests.

For example we would like to know whether there is any effect of
logging on the number of nesting birds in an area. A search of
the literature would turn up many studies on this topic; for
simplicity a random sample of only five studies are presented
here. (In reality, doing meta-analysis it is important to use as
many studies as possible, to attempt to minimize publication
biases, etc.)

--- phyper:  hypergeometric probability to calculate surprise

draw 100 balls from an urn with 14000 white and 86000 black balls
if 28 are white, pvalue = 0.0000761
7                     0.977

phyper (28, 14000, 86000, 100, lower.tail=F)  # 7.608553e-05
phyper ( 7, 14000, 86000, 100, lower.tail=F)  # 0.9766969


* end statistics tips, stats tips, stat tips, probability tips, prob tips
*------------------------------------------------------------------------------------------
* gsea tips

--- broad molecular signatures database: http://www.broadinstitute.org/gsea/msigdb/index.jsp

c1: positional gene sets, for each human chromosome and each cytogenetic band
c2: curated gene sets, from online pathway databases, publications in PubMed, and knowledge of domain experts
c3: motif gene sets, based on conserved cis-regulatory motifs from a comparative analaysis of the human, mouse, rat and dog genomes
c4: computational gene sets, defined by expression neighborhood centered on 380 cancer-associated genes
c5: GO gene sets, consists of genes annotated by the same GO terms

--- get latest data (10 dec 2009)
download xml file from http://www.broadinstitute.org/gsea/downloads.jsp
put file in ~/s/data/public/gsea/msigdb_v2.5.xml')  # a list with 5452 names
gsea = getBroadSets ('~/s/data/public/gsea/msigdb_v2.5.xml')    # takes forever on wombat, 160 seconds on bobama
save (gsea, file='~/s/data/public/gsea/msigdb_v2.5.Rdata')

grep ('apoptosis_', names (gsea), ignore.case=T, v=T)
APOPTOSIS_KEGG, APOPTOSIS_GENMAPP,  MENSE_HYPOXIA_APOPTOSIS_GENES,
INDUCTION_OF_APOPTOSIS_BY_EXTRACELLULAR_SIGNALS, APOPTOSIS_GO, INDUCTION_OF_APOPTOSIS_BY_INTRACELLULAR_SIGNALS

--- tiny R example
cd ~/s/examples/R/gsea
run (-1); xref.init ()
run (0:3)

--- use in R, with GSEABase version 1.8.0
slotNames (gsea [['APOPTOSIS_KEGG']])
geneIdType geneIds setName setIdentifier shortDescription longDescription organism pubMedIds urls
contributor version creationDate collectionType

* end gsea tips
*------------------------------------------------------------------------------------------
* gff tips
[from http://www.sanger.ac.uk/Software/formats/GFF/GFF_Spec.shtml]

Fields are: <seqname> <source> <feature> <start> <end> <score> <strand> <frame> [attributes] [comments]

<seqname>

The name of the sequence. Having an explicit sequence name allows a feature file to be prepared for a data set of
multiple sequences. Normally the seqname will be the identifier of the sequence in an accompanying fasta format file. An
alternative is that <seqname> is the identifier for a sequence in a public database, such as an EMBL/Genbank/DDBJ
accession number. Which is the case, and which file or database to use, should be explained in accompanying information.

<source>

The source of this feature. This field will normally be used to indicate the program making the prediction, or if it
comes from public database annotation, or is experimentally verified, etc.

<feature>

The feature type name. We hope to suggest a standard set of features, to facilitate import/export, comparison
etc.. Of course, people are free to define new ones as needed. For example, Genie splice detectors account for a region
of DNA, and multiple detectors may be available for the same site, as shown above.

We would like to enforce a standard nomenclature for common GFF features. This does not forbid the use of other
features, rather, just that if the feature is obviously described in the standard list, that the standard label should
be used. For this standard table we propose to fall back on the international public standards for genomic database
feature annotation, specifically, the DDBJ/EMBL/GenBank feature table documentation).

<start>, <end>

Integers. <start> must be less than or equal to <end>. Sequence numbering starts at 1, so these numbers should be
between 1 and the length of the relevant sequence, inclusive. (Version 2 change: version 2 condones values of <start>
and <end> that extend outside the reference sequence. This is often more natural when dumping from acedb, rather than
clipping. It means that some software using the files may need to clip for itself.)

<score>

A floating point value. When there is no score (i.e. for a sensor that just records the possible presence of a
signal, as for the EMBL features above) you should use '.'. (Version 2 change: in version 1 of GFF you had to write 0 in
such circumstances.)

<strand>

One of '+', '-' or '.'. '.' should be used when strand is not relevant, e.g. for dinucleotide repeats. Version 2
change: This field is left empty '.' for RNA and protein features.

<frame>

One of '0', '1', '2' or '.'. '0' indicates that the specified region is in frame, i.e. that its first base
corresponds to the first base of a codon. '1' indicates that there is one extra base, i.e. that the second base of the
region corresponds to the first base of a codon, and '2' means that the third base of the region is the first base of a
codon. If the strand is '-', then the first base of the region is value of <end>, because the corresponding coding
region will run from <end> to <start> on the reverse strand. As with <strand>, if the frame is not relevant then set
<frame> to '.'. It has been pointed out that "phase" might be a better descriptor than "frame" for this field. Version 2
change: This field is left empty '.' for RNA and protein features.

[attribute]

From version 2 onwards, the attribute field must have an tag value structure following the syntax used within
objects in a .ace file, flattened onto one line by semicolon separators. Tags must be standard identifiers
([A-Za-z][A-Za-z0-9_]*). Free text values must be quoted with double quotes. Note: all non-printing characters in such
free text value strings (e.g. newlines, tabs, control characters, etc) must be explicitly represented by their C (UNIX)
style backslash-escaped representation (e.g. newlines as '\n', tabs as '\t'). As in ACEDB, multiple values can follow a
specific tag. The aim is to establish consistent use of particular tags, corresponding to an underlying implied ACEDB
model if you want to think that way (but acedb is not required). Examples of these would be:

seq1     BLASTX  similarity   101  235 87.1 + 0	Target "HBA_HUMAN" 11 55 ; E_value 0.0003
dJ102G20 GD_mRNA coding_exon 7105 7201   .  - 2 Sequence "dJ102G20.C1.1"

The semantics of tags in attribute field tag-values pairs has intentionally not been formalized. Two useful
guidelines are to use DDBJ/EMBL/GenBank feature 'qualifiers' (see DDBJ/EMBL/GenBank feature table documentation), or the
features that ACEDB generates when it dumps GFF.

Version 1 note In version 1 the attribute field was called the group field, with the following specification:

An optional string-valued field that can be used as a name to group together a set of records. Typical uses might be
to group the introns and exons in one gene prediction (or experimentally verified gene structure), or to group multiple
regions of match to another sequence, such as an EST or a protein.

All of the above described fields should be separated by TAB characters ('\t'). All values of the mandatory fields
should not include whitespace (i.e. the strings for <seqname>, <source> and <feature> fields).

Version 1 note In version 1 each string had to be under 256 characters long, and the whole line should under 32k
long. This was to make things easier for guaranteed conforming parsers, but seemed unnecessary given modern languages.



* end gff tips
*------------------------------------------------------------------------------------------
* iphone tips



Turn Data Roaming "OFF":
Be sure to download and install the latest version of iPhone software from iTunes. By default the setting for international data roaming will be in the "OFF" position.
To turn data roaming "ON/OFF" tap on
Settings>General>Network>Data Roaming

Utilize WiFi Instead of 3G/GPRS/EDGE:
WiFi is available in many international airports, hotels and restaurants to browse the Web or check email.

Turn Fetch New Data "Off":
Check email and sync contacts and calendars manually instead of having the data pushed to your iPhone automatically. This way you can control the flow of data coming to your iPhone.
To turn off the Auto-Check functionality tap on
Settings>Mail, Contacts, Calendars>Fetch New Data, Change Push to "OFF" and Select to Fetch Manually

Consider Purchasing an International Data Package:
If you are traveling outside the U.S., purchasing a Data Global Plan will significantly reduce the cost of using data abroad.

Reset the Usage Tracker to Zero:
When you arrive overseas access the usage tracker in the general settings menu and select reset statistics. This will enable you to track your estimated data usage.


To reset Usage Tracker to Zero tap on
Settings>General>Usage>Reset



* end iphone tips
*------------------------------------------------------------------------------------------
*------------------------------------------------------------------------------------------
1998@leo@LEO: isb, (25 sep 2007)
windows: syeh0b!
gateway: syehub.bibsceb

*------------------------------------------------------------------------------------------
* poem from ms eick
What to Remember When Waking
by David Whyte

In that first hardly noticed moment in which you wake,
coming back to this life from the other
more secret, moveable and frighteningly honest world
where everything began,
there is a small opening into the new day
which closes the moment you begin your plans.

What you can plan is too small for you to live.
What you can live wholeheartedly will make plans enough
for the vitality hidden in your sleep.

To be human is to become visible
while carrying what is hidden as a gift to others.
To remember the other world in this world
is to live in your true inheritance.

You are not a troubled guest on this earth,
you are not an accident amidst other accidents
you were invited from another and greater night
than the one from which you have just emerged.

Now, looking through the slanting light of the morning window
toward the mountain presence of everything that can be
what urgency calls you to your one love?
What shape waits in the seed of you
to grow and spread its branches
against a future sky?

Is it waiting in the fertile sea?
In the trees beyond the house?
In the life you can imagine for yourself?
In the open and lovely white page on the waiting desk?

*------------------------------------------------------------------------------------------------------------------------
http://andrewsullivan.thedailybeast.com/2013/01/the-god-of-understanding.html

An old boss of mine used to claim that the most seductive words are
not "I love you", but "I understand you."  Surely a deep need is
expressed by the line, "Thou knowest my downsitting and my uprising,
thou understandest my thought afar off."

*------------------------------------------------------------------------------------------------------------------------
* posture tips
Two of the easiest things people can do to improve their posture:

1. Before you sit, think of lifting up your tailbone (like a cat
trying to not sit on its tail) and sit down of the front of your sit
bones. By doing this, your spine will be aligned while seated, and not
slouching should be effortless.

2. When standing (or walking or sitting for that matter) think about
the position of your sternum (breast bone). Imagine a string attached
to it and the other end to a kite pulling your sternum up and
forward. By having your sternum up, it will provide a healthy curve in
the low back, it will allow your shoulders to rest down and back, and
it will naturally pull your head back and on top of the neck rather
than jutting forward.

*------------------------------------------------------------------------------------------------------------------------
Szentkirlyi, Gadamer and Deleuze, as standing in front of a Baroque church (The building interpreted
 with the approach of Szentkirlyi and Gadamer)
Antal Puhl
Period. Polytech. Arch., Vol. 44, No. 2 (2013), pp. 55-59.
DOI: 10.3311/PPar.7394
Online published: 13-03-2014

Reference to this paper
Abstract

Every era has its basic tasks that must be performed. The issues to be
solved are ‘in the air’; they are generated by the era; they are
components of the spirit of the age. The question generated by the
time (the middle of the 20th century) was: that whether the only way
to reveal the truth would be the method of natural sciences (also
applied by the history of architecture), or such experiences of the
truth existed that could reach the surface only by means of art,
philosophy or history. On these basic questions that change period by
period, the different areas of arts and sciences and philosophy work
almost always in parallel.  Zoltán Szentkirályi wrote his paper Some
issues of the evaluation of the Baroque in 1964. The opus magnum of
Hans-Georg Gadamer, Truth and method, was published in
1960. Szentkirályi starts from the philosophy and reaches the history
of art and architecture; Gadamer starts from the history of art and
arrives at philosophy. The virtual meeting of the two happens through
the role of tradition in the interpretation of works.

The works of art are ‘addressed’ by the knowledge of tradition, by
means of which the truth carried by the work can reach the
surface. The new ‘...while abrogating the validity of the former one,
always activates and maintains all the positive results of the
previous stage of development – just through the fact of
abolition. This preservation role of the development is not always
obvious’ says Szentkirályi. In turn – as Gadamer would have continued
this text – ‘…we are always situated within traditions, and this is no
objectifying process – i.e. we do not conceive of what tradition says
as something other, something alien. It is always a part of us, a
model or exemplar’.

The lecture intends to show the inevitability of being familiar with
tradition in the understanding of both historical and contemporary
architecture alongside these two works.

Keywords
baroque; folding; hermeneutics; Szentkirályi; Gadamer; Deleuze
lindsey kevitch
*------------------------------------------------------------------------------------------------------------------------
* martha's tachycardia
SVT -- Supraventricular tachycardia
http://en.wikipedia.org/wiki/Supraventricular_tachycardia
